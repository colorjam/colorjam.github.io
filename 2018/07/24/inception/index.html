<!DOCTYPE html>
<html lang=en>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="GoogleNet《Going Deeper With Convolutions》是最早提出Inception结构的文章。文章指出，增加神经网络的大小通常能获得更好的表现，但随之而来的缺点是模型很容易过拟合，并且计算代价高昂。关于这两个问题，最直观的解决办法是用稀疏的层来代替全连接层。 然而目前的计算机对于非均匀的稀疏数据运算不太友好，所以大多数系统是基于卷积实现的。卷积是我们稀疏空间域的好帮手，">
<meta property="og:type" content="article">
<meta property="og:title" content="与Inception有关的那些事儿">
<meta property="og:url" content="http://yoursite.com/2018/07/24/inception/index.html">
<meta property="og:site_name" content="Colorjam">
<meta property="og:description" content="GoogleNet《Going Deeper With Convolutions》是最早提出Inception结构的文章。文章指出，增加神经网络的大小通常能获得更好的表现，但随之而来的缺点是模型很容易过拟合，并且计算代价高昂。关于这两个问题，最直观的解决办法是用稀疏的层来代替全连接层。 然而目前的计算机对于非均匀的稀疏数据运算不太友好，所以大多数系统是基于卷积实现的。卷积是我们稀疏空间域的好帮手，">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1ftlxlf8uiwj30ss0f0q46.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79ly1ftlxlr4cz3j30sg0fidhf.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1ftm3sth6elj31ga0w2aia.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1ftm6copd73j31020hudif.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1ftm6xrwibpj30vo0g40y3.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79ly1ftm716z34xj30vs0jkq69.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNc79ly1ftm7neonf9j314u0u20vh.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79ly1ftm7u6ebzvj31dk128tcb.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79ly1ftm7zo7emqj31540yk0xc.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tKfTcly1ftn0p7kdgkj30y40eagmw.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tKfTcly1ftn1hqzbx1j30vo0eutad.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tKfTcly1ftkwd3szd8j30um0l6tdx.jpg">
<meta property="og:updated_time" content="2018-07-26T07:26:03.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="与Inception有关的那些事儿">
<meta name="twitter:description" content="GoogleNet《Going Deeper With Convolutions》是最早提出Inception结构的文章。文章指出，增加神经网络的大小通常能获得更好的表现，但随之而来的缺点是模型很容易过拟合，并且计算代价高昂。关于这两个问题，最直观的解决办法是用稀疏的层来代替全连接层。 然而目前的计算机对于非均匀的稀疏数据运算不太友好，所以大多数系统是基于卷积实现的。卷积是我们稀疏空间域的好帮手，">
<meta name="twitter:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1ftlxlf8uiwj30ss0f0q46.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>与Inception有关的那些事儿</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
</head>

<div id="particles-js"></div>
<body class="max-width mx-auto px3 ltr">    
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/07/27/Network-compression-speedup/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2018/07/17/Interleaved-Group-Convolutions/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://yoursite.com/2018/07/24/inception/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://yoursite.com/2018/07/24/inception/&text=与Inception有关的那些事儿"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoursite.com/2018/07/24/inception/&is_video=false&description=与Inception有关的那些事儿"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=与Inception有关的那些事儿&body=Check out this article: http://yoursite.com/2018/07/24/inception/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://yoursite.com/2018/07/24/inception/&name=与Inception有关的那些事儿&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#GoogleNet"><span class="toc-number">1.</span> <span class="toc-text">GoogleNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Inceptoin-module"><span class="toc-number">1.1.</span> <span class="toc-text">Inceptoin module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GoogleNet-architecture"><span class="toc-number">1.2.</span> <span class="toc-text">GoogleNet architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Auxiliary-classifier"><span class="toc-number">1.3.</span> <span class="toc-text">Auxiliary classifier</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-v2"><span class="toc-number">2.</span> <span class="toc-text">Inception-v2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Design-Principles"><span class="toc-number">2.1.</span> <span class="toc-text">Design Principles</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Factorizing-Convolutions"><span class="toc-number">2.2.</span> <span class="toc-text">Factorizing Convolutions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception-module"><span class="toc-number">2.3.</span> <span class="toc-text">Inception module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Grid-Size-Reduction"><span class="toc-number">2.4.</span> <span class="toc-text">Grid Size Reduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception-v2-architecture"><span class="toc-number">2.5.</span> <span class="toc-text">Inception-v2 architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Label-Smoothing-Regularization"><span class="toc-number">2.6.</span> <span class="toc-text">Label Smoothing Regularization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-v3"><span class="toc-number">3.</span> <span class="toc-text">Inception-v3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-v4"><span class="toc-number">4.</span> <span class="toc-text">Inception-v4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Questions💫"><span class="toc-number">5.</span> <span class="toc-text">Questions💫</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        与Inception有关的那些事儿
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Colorjam</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2018-07-24T05:42:32.000Z" itemprop="datePublished">2018-07-24</time>
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html" target="_blank" rel="external">《Going Deeper With Convolutions》</a>是最早提出Inception结构的文章。文章指出，增加神经网络的大小通常能获得更好的表现，但随之而来的缺点是模型很容易过拟合，并且计算代价高昂。关于这两个问题，最直观的解决办法是用稀疏的层来代替全连接层。</p>
<p>然而目前的计算机对于非均匀的稀疏数据运算不太友好，所以大多数系统是基于卷积实现的。卷积是我们稀疏空间域的好帮手，它像一个收集器，将前一层中的图像块稠密连接起来。但是，目前的卷积网络大多是均匀的结构。因此作者就提出了这么一个问题：如何利用好卷积的稀疏性，同时使用对计算机友好的稠密矩阵乘法进行计算。</p>
<h3 id="Inceptoin-module"><a href="#Inceptoin-module" class="headerlink" title="Inceptoin module"></a>Inceptoin module</h3><p>以往的许多文献表明，稀疏矩阵乘法运算可以通过将稀疏矩阵聚类成相对稠密的子矩阵来实现。Inception结构就是本文提出的稠密组件，用来近似卷积视觉网络的最佳局部稀疏结构。作者首先给出了naive版本的Inception组件(a)，如下图所示：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ftlxlf8uiwj30ss0f0q46.jpg" alt="inception_module_naive"></p>
<p>作者假设来自前一层的每个单元与输入的某些区域对应。在网络的浅层（靠近输入）部分，单元集中在局部区域，因此可以通过1x1卷积将其传递到下一层网络。同时，在较大的图像块上进行卷积，可以获得更少数量但扩展空间更大的特征图。因此作者将1x1卷积，3x3卷积，5x5卷积，再加上由经验表明效果很好的池化层，对它们的输出进行拼接，一起构成了Inception组件。</p>
<p>由于要将Inception组件层层堆叠，会导致网络高层部分的特征图通道数增加，这也意味着较大卷积的计算负担加重，特别是还要拼接上池化层的输出。因此作者提出了第二种减少维度的Inception组件(b)，即在较大卷积之前，池化层之后，加入1x1卷积来减少特征图的通道数：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftlxlr4cz3j30sg0fidhf.jpg" alt="inception_module_dimensionality_reduction"></p>
<h3 id="GoogleNet-architecture"><a href="#GoogleNet-architecture" class="headerlink" title="GoogleNet architecture"></a>GoogleNet architecture</h3><p>由以上两个组件构成的GoogleNet网络结构如下图所示：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ftm3sth6elj31ga0w2aia.jpg" alt="GoogleNet"></p>
<p>在计算参数数量的时候发现了两个问题🤔</p>
<ol>
<li>7x7的卷积数量应该为$7^2 \times 3 \times 64 = 9408$，但表格中是2.7K，google了一下说有可能7x7卷积由7x1和1x7卷积构成，因此参数数量为$(7 \times 1+ 1\times7 ) \times 3 \times 64=2688$。</li>
<li>计算参数时都没有将depth计算在内，并且最后的结果需要除以1024。比如第二个3x3卷积，$(64 \times 64 + 9 \times 64 \times 192) =114,688$，除以1024后得到112K。</li>
</ol>
<h3 id="Auxiliary-classifier"><a href="#Auxiliary-classifier" class="headerlink" title="Auxiliary classifier"></a>Auxiliary classifier</h3><p>作者还在Inception (4a) 和 (4d) 之后添加了辅助分类器，将辅助分类器获得的损失以0.3的比例，添加到最后的损失函数中。然而辅助分类器的影响在之后的实验中证明发现是很小的。</p>
<p>完整的GoogleNet网络图太长啦，仅贴出含辅助分类器的Inception (4a)部分：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ftm6copd73j31020hudif.jpg" alt="googlenet_auxiliary_classifier"></p>
<h2 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception-v2"></a>Inception-v2</h2><p>在<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="external">《Rethinking the Inception Architecture for Computer Vision》</a>中，作者基于GoogleNet的Inception组件，提出了一些新的思考。</p>
<h3 id="Design-Principles"><a href="#Design-Principles" class="headerlink" title="Design Principles"></a>Design Principles</h3><p>作者首先提出了四个设计原则：</p>
<p>➊ 避免极端压缩的瓶颈。在信息传递的过程中，应缓慢减小特征图的大小。</p>
<p>➋ 更高维度的特征图更容易在网络中进行本地处理。在卷积网络中增加每个区块的激活能够解开更多特征。</p>
<p>❸ 空间聚合可以通过嵌入较低维度的特征图来完成，并且其表示能力没有太多损失。</p>
<p>❹ 平衡网络的宽度和深度。</p>
<h3 id="Factorizing-Convolutions"><a href="#Factorizing-Convolutions" class="headerlink" title="Factorizing Convolutions"></a>Factorizing Convolutions</h3><p>➊ 更小的卷积核</p>
<p>较大的卷积核可以用堆叠的较小的卷积核替代。比如一个5x5卷积就可以用两个连续的3x3替代：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ftm6xrwibpj30vo0g40y3.jpg" alt="smaller_convolutions"></p>
<p>这样就减小了计算代价：$(3+3) \times 2 / (5+5)=18/25$</p>
<p>➋ 非对称卷积</p>
<p>一个3x3卷积又可以在空间上分解为3x1卷积和1x3卷积：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftm716z34xj30vs0jkq69.jpg" alt="asymmetric_convolution"></p>
<p>再一次减少了计算代价：$(1 \times 3) + (3\times1) / (3 \times 3) = 2/3$</p>
<h3 id="Inception-module"><a href="#Inception-module" class="headerlink" title="Inception module"></a>Inception module</h3><p>因此基于设计原则➂和卷积核的分解方法➀，本文更新了传统的Inception组件结构：</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1ftm7neonf9j314u0u20vh.jpg" alt="inceptionv2_module1"></p>
<p>在实践中，作者发现将$n\times n$卷积替换成$1 \times n$和$n\times1$的组合卷积，对于早期的网络层效果不是很好，但是在中期的网络层有很好的表现。基于卷积核的分解方法➁的Inception组件结构：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1ftm7u6ebzvj31dk128tcb.jpg" alt="inceptionv2_module2"></p>
<p>基于设计原则➁，作者还提出了第三种Inception组件结构：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftm7zo7emqj31540yk0xc.jpg" alt="Inception_module3"></p>
<p>作者解释道，仅在最粗糙的网格上使用第三种结构，因为与空间聚集相比，通过1x1卷积进行本地处理的比率增强时，产生高维稀疏表示的位置是最关键的，</p>
<h3 id="Grid-Size-Reduction"><a href="#Grid-Size-Reduction" class="headerlink" title="Grid Size Reduction"></a>Grid Size Reduction</h3><p>假设输入特征图大小为$d \times d \times k$，我们希望获得$\frac{d}{2} \times \frac{d}{2} \times 2k$大小的特征图，通常会使用池化层来减小其网格大小，常见的方式有以下两种：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1ftn0p7kdgkj30y40eagmw.jpg" alt="two_ways_reduce_grid_size"></p>
<p>❶ 先进行池化，再进行卷积（左）</p>
<p>这种方法的计算代价是$2(\frac{d}{2})^2 k^2$，但是特征图一下子就减小到$(\frac{d}{2})^2 k$，产生了瓶颈，违反了设计原则➀</p>
<p>❷ 先进行卷积，再进行池化（右）</p>
<p>这种方法会造成较高的计算代价：$2d^2k^2$</p>
<p>于是本文就提出了一种既不产生瓶颈，又能减少计算代价的方法，如下图右边所示。该方法使用两个stride为2的模块：池化层$P$和卷积层$C$，并将它们的输出拼接起来。计算代价减小为$2(\frac{d}{2})^2k^2$，然而不是很懂这个方法为什么不产生瓶颈。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftn1hqzbx1j30vo0eutad.jpg" alt="reduce_gride_size"></p>
<h3 id="Inception-v2-architecture"><a href="#Inception-v2-architecture" class="headerlink" title="Inception-v2 architecture"></a>Inception-v2 architecture</h3><p>将上述方法结合在一起，构成了Incpetion-v2网络：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftkwd3szd8j30um0l6tdx.jpg" alt="Inception-v2"></p>
<h3 id="Label-Smoothing-Regularization"><a href="#Label-Smoothing-Regularization" class="headerlink" title="Label Smoothing Regularization"></a>Label Smoothing Regularization</h3><p>假设一个训练样本产生$k$个分类的可能性分别为为$p(k)$，实值的分布为$q(k)$，那么交叉熵定义的损失函数为：<br>$$<br>L = - \sum_{k=1}^{K}\log ({p(k)})q(k)<br>$$<br>对输出值$z_k$求偏导：$\frac { \partial \ell } { \partial z _ { k } } = p ( k ) - q ( k )$</p>
<p>顺便复习了一下Softmax函数及其求导过程👉🏻<a href="https://blog.csdn.net/behamcheung/article/details/71911133#softmax%E5%87%BD%E6%95%B0" target="_blank" rel="external">Softmax函数与交叉熵</a></p>
<p>假设第$y$个为正确的标签，当$k=y$时，$q(k)=1$，当$k \ne q$时，$q(k)=0$。在这种情况下，最小化交叉熵的过程相当于最大化正确标签的对数似然函数。假设分类正确，那么$z_y \gg  z_k$。文章指出，这样会带来两个问题：</p>
<p>❶ 可能造成过拟合，如果模型学会为每个训练样本分配到正确标签的完整概率，则不能保证泛化。</p>
<p>❷ 使得最大的输出值和其他输出值之间的差异变大，降低模型的适应性。</p>
<p>也就是说，模型对它的预测太过自信。为了让模型不要太骄傲，作者提出了将实值分布$q ( k | x ) = \delta _ { k , y }$替换为标签平滑正则化(label-smoothing regularizatoin, LSR)：<br>$$<br>q ^ { \prime } ( k | x ) = ( 1 - \epsilon ) \delta _ { k , y } + \epsilon u ( k )<br>$$<br>其中$\epsilon$表示权重，$ u(k)$表示一个基于标签的先验分布，本文将其设置为均匀分布，则上式可以写为：<br>$$<br>q ^ { \prime } ( k ) = ( 1 - \epsilon ) \delta _ { k , y } + \frac { \epsilon } { K }<br>$$<br>$q(k)$意味着取值不是1就是0，而$q ^ { \prime } ( k )$意味着所有不正确的分类都有一个正下界。</p>
<p>我们还可以用交叉熵来理解LSR：<br>$$<br>H \left( q ^ { \prime } , p \right) = - \sum _ { k = 1 } ^ { K } \log p ( k ) q ^ { \prime } ( k ) = ( 1 - \epsilon ) H ( q , p ) + \epsilon H ( u , p )<br>$$<br>其中，$H(u,p)$可以用KL散度来表示：<br>$$<br>H ( u , p ) = D _ { K L } ( u | p ) + H ( u )<br>$$<br>由于KL散度用于衡量两个分布之间的距离，当$u$代表均匀分布时，$H(u)$是固定的，则$H(u,p)$代表预测分布$p$与均匀分布的差异程度。</p>
<h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception-v3"></a>Inception-v3</h2><p>Inception-v3其实也是👆🏻那篇论文提出的。文章表明移除GoogleNet中的辅助分类器，并没有对实验结果产生不利的影响。实验结果表示，将辅助分类器作为正则项，当支路采用BN的时候，能够使主分类器有更好的结果。因此，本文将Inception-v2加上使用BN的支路称为Inception-v3。</p>
<h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception-v4"></a>Inception-v4</h2><p><a href="https://arxiv.org/abs/1602.07261" target="_blank" rel="external">《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》</a>探索了ResNet给Inception组件带来的变化，提出了Inception-ResNet-v1和Inception-ResNet-v2，同时加深了网络结构。文章中有很多Inception组件，感觉不是很有意思，就大概滴看一下🤐</p>
<h2 id="Questions💫"><a href="#Questions💫" class="headerlink" title="Questions💫"></a>Questions💫</h2><ol>
<li>在Inception组件中，concat操作是直接将特征拼在一起的，若维度采用交叉拼接是否会使特征分布更均匀？</li>
</ol>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#GoogleNet"><span class="toc-number">1.</span> <span class="toc-text">GoogleNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Inceptoin-module"><span class="toc-number">1.1.</span> <span class="toc-text">Inceptoin module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GoogleNet-architecture"><span class="toc-number">1.2.</span> <span class="toc-text">GoogleNet architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Auxiliary-classifier"><span class="toc-number">1.3.</span> <span class="toc-text">Auxiliary classifier</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-v2"><span class="toc-number">2.</span> <span class="toc-text">Inception-v2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Design-Principles"><span class="toc-number">2.1.</span> <span class="toc-text">Design Principles</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Factorizing-Convolutions"><span class="toc-number">2.2.</span> <span class="toc-text">Factorizing Convolutions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception-module"><span class="toc-number">2.3.</span> <span class="toc-text">Inception module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Grid-Size-Reduction"><span class="toc-number">2.4.</span> <span class="toc-text">Grid Size Reduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception-v2-architecture"><span class="toc-number">2.5.</span> <span class="toc-text">Inception-v2 architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Label-Smoothing-Regularization"><span class="toc-number">2.6.</span> <span class="toc-text">Label Smoothing Regularization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-v3"><span class="toc-number">3.</span> <span class="toc-text">Inception-v3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-v4"><span class="toc-number">4.</span> <span class="toc-text">Inception-v4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Questions💫"><span class="toc-number">5.</span> <span class="toc-text">Questions💫</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://yoursite.com/2018/07/24/inception/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://yoursite.com/2018/07/24/inception/&text=与Inception有关的那些事儿"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoursite.com/2018/07/24/inception/&is_video=false&description=与Inception有关的那些事儿"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=与Inception有关的那些事儿&body=Check out this article: http://yoursite.com/2018/07/24/inception/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://yoursite.com/2018/07/24/inception/&title=与Inception有关的那些事儿"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://yoursite.com/2018/07/24/inception/&name=与Inception有关的那些事儿&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 Colorjam
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- particles -->
<script src="/lib/particles/particles.min.js"></script>
<script type="text/javascript">
    particlesJS('particles-js', {
        "particles": {
            "number": {
            "value": 60,
            "density": {
                "enable": true,
                "value_area": 1200
            }
            },
            "color": {
            "value": "#d25e5e"
            },
            "shape": {
            "type": "circle",
            "stroke": {
                "width": 0,
                "color": "#000000"
            },
            "polygon": {
                "nb_sides": 3
            },
            "image": {
                "src": "img/github.svg",
                "width": 100,
                "height": 100
            }
            },
            "opacity": {
            "value": 0.35,
            "random": false,
            "anim": {
                "enable": false,
                "speed": 1,
                "opacity_min": 0.1,
                "sync": false
            }
            },
            "size": {
            "value": 2,
            "random": true,
            "anim": {
                "enable": false,
                "speed": 40,
                "size_min": 0.1,
                "sync": false
            }
            },
            "line_linked": {
            "enable": true,
            "distance": 150,
            "color": "#e88181",
            "opacity": 0.352750653390415,
            "width": 0.9620472365193136
            },
            "move": {
            "enable": true,
            "speed": 6,
            "direction": "none",
            "random": false,
            "straight": false,
            "out_mode": "out",
            "bounce": false,
            "attract": {
                "enable": false,
                "rotateX": 600,
                "rotateY": 1200
            }
            }
        },
        "interactivity": {
            "detect_on": "canvas",
            "events": {
            "onhover": {
                "enable": true,
                "mode": "repulse"
            },
            "onclick": {
                "enable": true,
                "mode": "push"
            },
            "resize": true
            },
            "modes": {
            "grab": {
                "distance": 400,
                "line_linked": {
                "opacity": 1
                }
            },
            "bubble": {
                "distance": 400,
                "size": 40,
                "duration": 2,
                "opacity": 8,
                "speed": 3
            },
            "repulse": {
                "distance": 200,
                "duration": 0.4
            },
            "push": {
                "particles_nb": 4
            },
            "remove": {
                "particles_nb": 2
            }
            }
        },
        "retina_detect": true
        });
</script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
<div style="width:300px;margin:0 auto; padding:20px 0;">
  <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020302033436" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><img src="" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;">闽公网安备 35020302033436号</p></a>
</div>

</html>
