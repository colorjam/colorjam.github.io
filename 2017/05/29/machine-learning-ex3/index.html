<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Machine Learning ex3 · Colorjam's Blog</title><meta name="description" content="Machine Learning ex3 - Colorjam"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Colorjam's Blog"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/pinkladies" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Machine Learning ex3</h1><div class="post-info">May 29, 2017</div><div class="post-content"><p>这一章练习也有两大部分，第一部分是正则化逻辑回归方程的多类分类，识别图像中的数字。觉得逻辑回归应该也是神经网络的一部分吧，只是没有hidden layer，直接就final了。第二部分需要解决的问题是一样的，识别图像中的文字，只通过是神经网络来达到这个目的。</p>
<a id="more"></a>
<h1 id="1-Multi-Class-Classification"><a href="#1-Multi-Class-Classification" class="headerlink" title="1/ Multi-Class Classification"></a>1/ Multi-Class Classification</h1><h3 id="Vectorizing-Logistic-Regression"><a href="#Vectorizing-Logistic-Regression" class="headerlink" title="Vectorizing Logistic Regression"></a>Vectorizing Logistic Regression</h3><p>按照pdf的步骤，先写出不正则化的逻辑回归方程，打印了一下这时函数参数的X </p>
<img src="/2017/05/29/machine-learning-ex3/2017/05/29/machine-learning-ex3/Xt.png" alt="Xt.png" title="">
<p>发现这一节要求不使用循环，全部向量化，那我上一章就基本实现了耶，我真棒~ 稍微修改了一下方程，用一下hint的.*和sum，终于懂星号前面有一点是什么鬼了，是不使用矩阵乘法，而是对应的元素相乘。方程如下：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算unregulized cost function</span></div><div class="line">J = sum(-y .* <span class="built_in">log</span>(sigmoid(X*theta)) - (<span class="number">1</span>-y) .* <span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta))) / m;</div></pre></td></tr></table></figure>
<p>此时输出J的值为0.734819，但是参考值是2.534819，等正则化了看看结果。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算gradient</span></div><div class="line">grad = X' * (sigmoid(X * theta) - y);</div></pre></td></tr></table></figure>
<p> 接下来就要开始正则化cost function和gradient了。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 正则化cost function</span></div><div class="line">J += lambda * sum(theta(<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>) / (<span class="number">2</span> * m);</div></pre></td></tr></table></figure>
<p>上一章傻傻的用循环来避开对theta~0~的处理，现在get了用冒号来限制处理范围。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 正则化gradient</span></div><div class="line">temp = theta;</div><div class="line">temp(<span class="number">1</span>) = <span class="number">0</span>;</div><div class="line">grad += lambda * temp / m;</div></pre></td></tr></table></figure>
<p>提交发现咋不对啊。对照了一下ex2发现gradient忘记 / m了，我这粗心的小脑袋啊。。。</p>
<h3 id="oneVsAll"><a href="#oneVsAll" class="headerlink" title="oneVsAll"></a>oneVsAll</h3><p>看完毫无头绪要怎么训练啊。。我回顾一下one-vs-all是什么鬼。嗯。。再回来理解一下题目，把每个训练集分成K个类，返回一个Kx(N+1)的矩阵theta，矩阵的每一行是通过逻辑回归方程学习到的theta值。继续仔细看，没让你直接用一个函数就完成预测，这个函数只是用来生训练分类器tehta矩阵的，并且还提示使用一个给定函数fmincg来生成theta，只是循环K次，每次生成一个向量。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: num_labels</div><div class="line">  <span class="keyword">if</span> <span class="built_in">i</span> == <span class="built_in">i</span> </div><div class="line">  	c = <span class="number">10</span>;</div><div class="line">  <span class="keyword">else</span> </div><div class="line">  	c = <span class="built_in">i</span>;</div><div class="line">  initial_theta = <span class="built_in">zeros</span>(n + <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">  options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</div><div class="line">  [theta] = ...</div><div class="line">    fmincg(@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</div><div class="line">                initial_theta, options);</div><div class="line">   all_theta(c, :) = theta';</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>一开始对于c的概念有一些模糊，在经过测试以后发现 一个向量==一个数值 时，返回一个向量，其中与这个值相等的位置为1，其他位置均为0。再回顾一下上课的笔记，那么根据这个函数的意思，在num_labels个循环中y == c 就生成了num_labels个1位置不同的向量，这个向量作为判断结果，对于每一个结果通过fmincg函数来生成一个theta向量，但是这个向量是(n+1)x1的，因此要把theta转置成all_theta对应的那一行。</p>
<img src="/2017/05/29/machine-learning-ex3/2017/05/29/machine-learning-ex3/multiy.png" alt="multiy.png" title="">
<p>修改代码：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> c = <span class="number">1</span>: num_labels</div><div class="line">  initial_theta = <span class="built_in">zeros</span>(n + <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">  options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</div><div class="line">  [theta] = ...</div><div class="line">    fmincg(@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</div><div class="line">                initial_theta, options);</div><div class="line">   all_theta(c, :) = theta';</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>理解了c的值以后，就知道0为什么要用10来表示啦。</p>
<p>接下来完成进行预测的函数。要对所有训练集进行训练，也就是h = X * theta’，然后与y进行比较，判断所属类型。不过我们已经知道了y就是一个向量，1在不同的位置为不同的类别。那么就是每一个训练集得到的 h 向量中数值最大的那一个就是我们的类别。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算hypothesis</span></div><div class="line">h = X * all_theta';</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  [maxn, maxi] = max(h(<span class="built_in">i</span>));</div><div class="line">  p(<span class="built_in">i</span>) = maxi;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>但是结果又不对，思路应该是没错的，检查了一下size(theta)，是一个10x401的矩阵没错，h计算出来的结果肯定也没错。那么问题肯定就出现在查找最大值上。输出了一下h(1)发现只是一个数值，我们要查找的应该是一行中的最大值，把max(h(i))改成max(h(i, :))就对啦。</p>
<h1 id="2-Neural-Networks"><a href="#2-Neural-Networks" class="headerlink" title="2/ Neural Networks"></a>2/ Neural Networks</h1><p>上一部分我们通过多类分类的逻辑回归方程来识别手写的数字。但是由于逻辑回归仅仅是一个线性分类器，对于更复杂的行为很难处理，因此在这个部分我们实践一下神经网络。这个神经网络有3层，输入层，隐藏层，输出层。我们使用已经训练完成的权重来进行预测。</p>
<h3 id="Feedforward-Propagation-and-Prediction"><a href="#Feedforward-Propagation-and-Prediction" class="headerlink" title="Feedforward Propagation and Prediction"></a>Feedforward Propagation and Prediction</h3><p>这个预测函数通过给定的Theta1、Theta2来对输入层进行训练，判断结果和one-vs-all通过最大值来分类是一样的。</p>
<p>我们先来看下训练集X、Theta1、Theta2的大小</p>
<img src="/2017/05/29/machine-learning-ex3/2017/05/29/machine-learning-ex3/size.png" alt="size.png" title="">
<p>如上图所示，也就是说训练集有5000个，400个项（不包含x~0~ = 1），因此加上x~0~以后，Theta1把401个项训练成25个，再加上x~0~ = 1，最后训练出10个分类结果。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% add x0 = 1</span></div><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line"></div><div class="line"><span class="comment">% compute hidden layer</span></div><div class="line">layer2 = [ones(m, <span class="number">1</span>), X * Theta1<span class="string">'];</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">% compute output layer</span></div><div class="line"><span class="string">layer3 = layer2 * Theta2'</span>;</div><div class="line"></div><div class="line">% predict</div><div class="line">for i = <span class="number">1</span> : m</div><div class="line">  [maxn, maxi] = max(layer3(<span class="built_in">i</span>, :));</div><div class="line">  p(<span class="built_in">i</span>) = maxi;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>自信满满写完submit发现还是错的 orz…准确率不对，回去看一下训练模型，好像每一层训练的时候都要用到sigmodi函数？</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% add x0 = 1</span></div><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line"></div><div class="line"><span class="comment">% compute hidden layer</span></div><div class="line">z2 = [ones(m, <span class="number">1</span>) X * Theta1<span class="string">'];</span></div><div class="line"><span class="string">a2 = sigmoid(z2);</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">% compute output layer</span></div><div class="line"><span class="string">z3 = a2 * Theta2'</span>;</div><div class="line">a3 = sigmoid(z3);</div><div class="line"></div><div class="line">% predict</div><div class="line">for i = <span class="number">1</span> : m</div><div class="line">  [maxn, maxi] = max(z3(<span class="built_in">i</span>, :));</div><div class="line">  p(<span class="built_in">i</span>) = maxi;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>啊。。。明明准确率对，结果也对为什么submit以后还是没有分数呢。。。再回去认真看模型。。</p>
<img src="/2017/05/29/machine-learning-ex3/2017/05/29/machine-learning-ex3/model.png" alt="model.png" title="">
<p>好像隐藏层是先逻辑回归，再添加a~0~嗯。。。got it。。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% compute output layer</span></div><div class="line">z3 = a2 * Theta2';</div><div class="line">a3 = sigmoid(z3);</div></pre></td></tr></table></figure>
<img src="/2017/05/29/machine-learning-ex3/2017/05/29/machine-learning-ex3/nice.png" alt="nice.png" title=""></div></article></div></main><footer><div class="paginator"><a href="/2017/05/31/machine-learning-ex4/" class="prev">PREV</a><a href="/2017/05/28/machine-learning-ex2/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2018 <a href="http://yoursite.com">Colorjam</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>