<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> image-classification-note · Colorjam's Blog</title><meta name="description" content="image-classification-note - Colorjam"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Colorjam's Blog"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/pinkladies" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">image-classification-note</h1><div class="post-info">Oct 19, 2017</div><div class="post-content"><h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems:"></a>Problems:</h3><ol>
<li>Semantic Gap: There’s a huge gap between the semantic idea of a cat, and these pixel values that the computer is actually seeing.</li>
<li>Viewpoint variation: All pixels change when the camera moves</li>
<li>Illumination: There can be lighting conditions going on in the scene</li>
<li>Deformation: Cats can assume a lot of different, varied poses and positions.</li>
<li>Occlusion: You might only see a part of a cat.</li>
<li>Background Clutter: The foreground of the cat look similar in appearance</li>
<li>Intraclass variation: Cats can come in different shapes and sizes and colors and ages</li>
</ol>
<a id="more"></a>
<h3 id="An-image-classifier"><a href="#An-image-classifier" class="headerlink" title="An image classifier"></a>An image classifier</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify_image</span><span class="params">(image)</span>:</span></div><div class="line">	<span class="comment"># Some magic here?</span></div><div class="line">    <span class="keyword">return</span> class_label</div></pre></td></tr></table></figure>
<p> <strong>no obvious way</strong> to hard-code the algorithm for recognizing a cat, or other classes.</p>
<h3 id="Data-Driven-Approach"><a href="#Data-Driven-Approach" class="headerlink" title="Data-Driven Approach"></a>Data-Driven Approach</h3><ol>
<li>Collect a dataset of images and labels</li>
<li>Use Machine Learning to train a classifier</li>
<li>Evaluate the classifier on new images</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(images, labels)</span>:</span></div><div class="line">	<span class="comment"># Machine learning</span></div><div class="line">	<span class="keyword">return</span> model</div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(model, test_images)</span>:</span></div><div class="line">	<span class="comment"># Use model to predict labels</span></div><div class="line">    <span class="keyword">return</span> test_labels</div></pre></td></tr></table></figure>
<p>Rather than a single function that just inputs an image and recognizes a cat, we have these two functions. One called <strong>train</strong>, that’s going to input images and labels and then output a model, another function called <strong>predict</strong>, which will input the model and make predictions for images.</p>
<p>#Nearest Neighbor classifier</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NearestNeighbor</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">		<span class="keyword">pass</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></div><div class="line">	<span class="string">""" X is N x D where each row is an example. Y is 1-dimension of size N """</span></div><div class="line">    <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></div><div class="line">    self.Xtr = X</div><div class="line">    self.ytr = y</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></div><div class="line">     <span class="string">""" X is N x D where each row is an example we wish to predict label for """</span></div><div class="line">    num_test = X.shape[<span class="number">0</span>]</div><div class="line">    <span class="comment"># lets make sure that the output type matches the input type</span></div><div class="line">    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)</div><div class="line">    </div><div class="line">    <span class="comment"># loop over all test rows</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line">		<span class="comment"># find the nearest training image to the i'th test image</span></div><div class="line">     	<span class="comment"># using the L1 distance (sum of absolute alue differences)</span></div><div class="line">        distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = <span class="number">1</span>)</div><div class="line">        min_index = np.argmin(distances) <span class="comment"># get the index with smallest distance</span></div><div class="line">		Ypred[i] = self.ytr[min_index] <span class="comment">#predict the label of the nearest example</span></div><div class="line">     <span class="keyword">return</span> Ypred</div></pre></td></tr></table></figure>
<p>Q: With N examples. how fast are training and prediction?</p>
<p>A: Train O(1), predict O(N)</p>
<p>This is bad: we want classifiers that are <strong>fast</strong> at prediciton; <strong>slow</strong> for training is ok.</p>
<h3 id="k-Nearest-Neighbors"><a href="#k-Nearest-Neighbors" class="headerlink" title="k-Nearest Neighbors"></a>k-Nearest Neighbors</h3><p>Instead of copying label from nearest neighbor, thake <strong>majority vote</strong> form K closest points.</p>
<p>###Hyperparameters</p>
<ul>
<li>What is the best value of <strong>k</strong> to use?</li>
<li>What is the best <strong>distance</strong> to use?</li>
</ul>
<p>These are <strong>hyperparameters</strong>: choices about the algorithm that we set rather than learn</p>
<p><em>Very problem-dependent.</em></p>
<p><em>Must try them all out and see what works best.</em></p>
<h3 id="Setting-Hyperparameters"><a href="#Setting-Hyperparameters" class="headerlink" title="Setting Hyperparameters"></a>Setting Hyperparameters</h3><ul>
<li>Split data into <strong>train</strong>, <strong>val</strong>, and <strong>test</strong>; choose hyperparameters on val and evaluate on test</li>
<li><strong>Cross-Validation</strong>: Split data into **folds, try each fold as validation and average the results. Useful for small datasets but not used too frequently in deep learning.</li>
</ul>
<h3 id="k-Nearest-Neighbor-on-images-never-used"><a href="#k-Nearest-Neighbor-on-images-never-used" class="headerlink" title="k-Nearest Neighbor on images never used"></a>k-Nearest Neighbor on images never used</h3><ul>
<li>Very slow at test time</li>
<li>Distance metrics on pixels are not informative</li>
<li>Curse of dimensionality</li>
</ul>
<h3 id="k-Nearest-Neighbors-Summary"><a href="#k-Nearest-Neighbors-Summary" class="headerlink" title="k-Nearest Neighbors: Summary"></a>k-Nearest Neighbors: Summary</h3><ul>
<li>In <strong>Image classification</strong> we start with a <strong>training set</strong> of images and labels, and must predict labels on the <strong>test set</strong></li>
<li>The *K-Nearest Neighbors classifier predicts labels based on nearest training examples</li>
<li>Distance metric and K are <strong>hyperparameters</strong></li>
<li>Choose hyperparameters using the <strong>validation set</strong>; only run on the test set once at the very end!</li>
</ul>
<p>#Linear Classification</p>
<p>These deep neural networks are kind of like Legos and this linear classifier is kind of like the most basic building blocks of these giant networks.</p>
<p>f(x, W) = Wx + b</p>
</div></article></div></main><footer><div class="paginator"><a href="/2017/10/20/machine-learning-in-action-note3/" class="prev">PREV</a><a href="/2017/10/18/machine-learning-in-action-note2/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2017 <a href="http://yoursite.com">Colorjam</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>