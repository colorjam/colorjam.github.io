<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 《Machine Learning in Action》学习笔记一 · Colorjam's Blog</title><meta name="description" content="《Machine Learning in Action》学习笔记一 - Colorjam"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Colorjam's Blog"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/pinkladies" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">《Machine Learning in Action》学习笔记一</h1><div class="post-info">Oct 15, 2017</div><div class="post-content"><p>正在学习《Machine Learning in Action》，随笔记录一下，代码基本上都是跟着书本敲的，就不大量复制了，仅写一些自己的理解并对出现的问题进行整理和归纳。</p>
<a id="more"></a>
<h1 id="1-kNN分类算法"><a href="#1-kNN分类算法" class="headerlink" title="1/ kNN分类算法"></a>1/ kNN分类算法</h1><p>kNN分类算法（k-Nearest Neighbors classification algorithm）是比较简单的一种分类算法。原理是通过训练集训练出与待预测数据最接近的k个类别，这k个类别中出现最多的类即为预测结果。</p>
<p>🙂：准确度高／对异常值不敏感／不假设数据</p>
<p>🙁：计算复杂度高／占用大量内存</p>
<p>🛠：数值型／标称型</p>
<h3 id="kNN的一般流程"><a href="#kNN的一般流程" class="headerlink" title="kNN的一般流程"></a>kNN的一般流程</h3><ol>
<li>收集数据</li>
<li>准备数据：最好使用结构化数据格式，因为计算距离需要数值。</li>
<li>分析数据</li>
<li>训练算法：此步骤不适用于kNN算法</li>
<li>测试算法：计算错误率</li>
<li>使用算法：这首先需要获取一些输入数据和结构化的输出数据，然后在输入数据上运行kNN算法并判断它属于哪一类，最后对计算出的分类执行后续处理。</li>
</ol>
<h1 id="2-决策树算法"><a href="#2-决策树算法" class="headerlink" title="2/决策树算法"></a>2/决策树算法</h1><p>🙂：计算复杂度不高／便于人们理解学习结果／对中间的缺失值不敏感／可以处理无关的特征值</p>
<p>🙁：可能会过拟合</p>
<p>🛠：数值型／标称型</p>
<h3 id="决策树的一般流程"><a href="#决策树的一般流程" class="headerlink" title="决策树的一般流程"></a>决策树的一般流程</h3><ol>
<li>数据收集</li>
<li>准备数据：这个构造树的过程只适用于标称型数据，因此需要离散化连续的数值</li>
<li>分析数据</li>
<li>训练算法：构造一个树的数据结构</li>
<li>测试算法：使用经验树计算错误率</li>
<li>使用算法：这可以应用于任何监督学习任务。通常，决策树树可以更好的理解数据的内在含义。</li>
</ol>
<p>在treePlotter.py中发现一个神奇的地方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotNode</span><span class="params">(nodeTxt, centerPt, parentPt, nodeType)</span>:</span></div><div class="line">    <span class="comment"># 2 Draws annotations with arrows</span></div><div class="line">    createPlot.ax.annotate(nodeTxt, xy=parentPt, xycoords=<span class="string">'axes fraction'</span>,</div><div class="line">                           xytext = centerPt, textcoords=<span class="string">'axes fraction'</span>,</div><div class="line">                           va=<span class="string">'center'</span>, ha=<span class="string">'center'</span>, bbox=nodeType, arrowprops=arrow_args)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createPlot</span><span class="params">()</span>:</span></div><div class="line">    fig = plt.figure(<span class="number">1</span>, facecolor=<span class="string">'white'</span>)</div><div class="line">    fig.clf()</div><div class="line">    createPlot.ax = plt.subplot(<span class="number">111</span>, frameon=<span class="keyword">False</span>)</div><div class="line">    plotNode(<span class="string">'a decision node'</span>, (<span class="number">.5</span>, <span class="number">.1</span>), (<span class="number">.1</span>, <span class="number">.5</span>), decisionNode)</div><div class="line">    plotNode(<span class="string">'a leaf node'</span>, (<span class="number">.8</span>, <span class="number">.1</span>), (<span class="number">.3</span>, <span class="number">.8</span>), leafNode)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure>
<p>Python中一切皆为对象，在createPlot函数中，为这个函数对象绑定了一个属性ax，变成了一个全局的变量，可以在plotNode函数中调用。</p>
<p>书中作者利用treePlotter中写好的树结构来进行预测，但tree.py里头不有一个createDataSet函数和createTree函数吗？尝试一下利用这两个函数来生成并预测：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">myDat, labels = createDataSet()</div><div class="line">myTree = createTree(myDat, labels)</div></pre></td></tr></table></figure>
<p>Buuuuuuuut……….<img src="/2017/10/15/machine-learning-in-action-note1/no_surfacing_error.png" alt="no_surfacing_error.png" title=""></p>
<p>检查了一下调用createTree函数前后labels的值，发现调用前后labels的值发生了变化，因此对原函数createTree稍作修改：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></div><div class="line"></div><div class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line"></div><div class="line">    <span class="comment"># 1 Stop when all classes are equal</span></div><div class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</div><div class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 2 When just one feature, return majority</span></div><div class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> majorityCnt(classList)</div><div class="line"></div><div class="line">    subLabels = labels[:] <span class="comment"># 将labels全部复制到subLabels，进行接下来的处理</span></div><div class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</div><div class="line">    bestFeatLabel = subLabels[bestFeat] <span class="comment"># 利用subLabels来获取最佳分类特征</span></div><div class="line">    myTree = &#123;bestFeatLabel: &#123;&#125;&#125;</div><div class="line">    <span class="keyword">del</span>(subLabels[bestFeat])</div><div class="line"></div><div class="line">    <span class="comment"># 3 Get list of unique values</span></div><div class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">    uniqueVals = set(featValues)</div><div class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">        <span class="comment">#subLabels = labels[:] 作者在这里才进行参数赋值，会改变labels的值</span></div><div class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)</div><div class="line">    <span class="keyword">return</span> myTree</div></pre></td></tr></table></figure>
<p>接下来就可以愉快利用该函数进行分类了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> treePlotter</div><div class="line"></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="string">省略一堆作者源代码</span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line"></div><div class="line">myDat, labels = createDataSet()</div><div class="line">myTree = createTree(myDat, labels) <span class="comment"># 训练数据</span></div><div class="line">treePlotter.createPlot(myTree) <span class="comment"># 显示模型</span></div><div class="line">print(classify(myTree, labels, [<span class="number">1</span>, <span class="number">1</span>])) <span class="comment"># 预测数据</span></div></pre></td></tr></table></figure>
<p>看一看生成的决策树模型：</p>
<img src="/2017/10/15/machine-learning-in-action-note1/tree1.png" alt="tree1.png" title="">
<p>我们可以引入pickle模块来将训练出的模型序列化，保存在磁盘中，以便后续的调用。因为书本作者是使用Python2的，我打算用Python3来完成，在下面的代码中就遇到了问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    <span class="comment">#Python2用法：fw = open(filename,'w')</span></div><div class="line">    <span class="comment">#改为python3:</span></div><div class="line">    <span class="keyword">with</span> open(filename,<span class="string">'wb'</span>) <span class="keyword">as</span> fw:</div><div class="line">        pickle.dump(inputTree, fw)</div><div class="line">    fw.close()</div></pre></td></tr></table></figure>
<p>接下来就要引入稍微大一点的数据集来进行训练了，然鹅….</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">fr = open(<span class="string">'lenses.txt'</span>)</div><div class="line">lenses = [inst.strip().split(<span class="string">'\t'</span>) <span class="keyword">for</span> inst <span class="keyword">in</span> fr.readline()]</div><div class="line">lensesLables = [<span class="string">'age'</span>, <span class="string">'prescript'</span>, <span class="string">'astigmatic'</span>, <span class="string">'tearRate'</span>]</div><div class="line">print(lenses)</div></pre></td></tr></table></figure>
<img src="/2017/10/15/machine-learning-in-action-note1/readlines_error.png" alt="readlines_error.png" title="">
<p>这输出的啥玩意儿？仔细一看，<strong>fr.readlines()</strong>函数写错了，少了一个<strong>sssssssss</strong>。修改好以后我们就来看看训练完的决策树吧：</p>
<img src="/2017/10/15/machine-learning-in-action-note1/lenses_tree1.png" alt="lenses_tree1.png" title="">
<p>？？？这又啥玩意儿？？这看得下去？？？？那就只能修改一下plotMidText函数了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotMidText</span><span class="params">(cntrPt, parentPt, txtString)</span>:</span></div><div class="line">    xMid = (parentPt[<span class="number">0</span>] - cntrPt[<span class="number">0</span>])/<span class="number">2</span> + cntrPt[<span class="number">0</span>]</div><div class="line">    yMid = (parentPt[<span class="number">1</span>] - cntrPt[<span class="number">1</span>])/<span class="number">2</span> + cntrPt[<span class="number">1</span>]</div><div class="line">    createPlot.ax.text(xMid, yMid, txtString, fontsize=<span class="number">8</span>, horizontalalignment=<span class="string">'center'</span>,verticalalignment=<span class="string">'center'</span>, rotation=<span class="number">30</span>)</div></pre></td></tr></table></figure>
<img src="/2017/10/15/machine-learning-in-action-note1/lenses_tree2.png" alt="lenses_tree2.png" title="">
<p>完美！</p>
</div></article></div></main><footer><div class="paginator"><a href="/2017/07/25/china-map/" class="next">下一篇</a></div><div class="copyright"><p>© 2015 - 2017 <a href="http://yoursite.com">Colorjam</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>