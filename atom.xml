<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Colorjam</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-08-01T05:53:21.563Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Colorjam</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/08/01/Quantization/"/>
    <id>http://yoursite.com/2019/08/01/Quantization/</id>
    <published>2019-08-01T05:50:24.083Z</published>
    <updated>2019-08-01T05:53:21.563Z</updated>
    
    <content type="html"><![CDATA[<h2 id="量化方法"><a href="#量化方法" class="headerlink" title="量化方法"></a>量化方法</h2><h3 id="Accurate-and-Efficient-2-Bit-Quantized-Neural-Netowrks"><a href="#Accurate-and-Efficient-2-Bit-Quantized-Neural-Netowrks" class="headerlink" title="Accurate and Efficient 2-Bit Quantized Neural Netowrks"></a>Accurate and Efficient 2-Bit Quantized Neural Netowrks</h3><p><strong>PACT</strong></p><p>PAramaterized Clipping acTivation（参数化截略式激活），对ReLU的输出进行截略(clipping)，限制输出范围再$[0, \alpha]$。一个暗恋过只有一个$\alpha$值，通过SGD对$\alpha$值进行更新。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;量化方法&quot;&gt;&lt;a href=&quot;#量化方法&quot; class=&quot;headerlink&quot; title=&quot;量化方法&quot;&gt;&lt;/a&gt;量化方法&lt;/h2&gt;&lt;h3 id=&quot;Accurate-and-Efficient-2-Bit-Quantized-Neural-Netowrks&quot;&gt;&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/08/01/Multi-task%20Learning/"/>
    <id>http://yoursite.com/2019/08/01/Multi-task Learning/</id>
    <published>2019-08-01T03:16:59.168Z</published>
    <updated>2019-08-07T02:46:08.550Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Multi-task-Learning"><a href="#Multi-task-Learning" class="headerlink" title="Multi-task Learning"></a>Multi-task Learning</h1><p>多任务同时进行不分主次，多个相关的任务放在一起学习，任务之间的知识共享和共同学习。</p><ul><li><p>Cross-stitch Networks for Multi-task Learning </p><ul><li>提出一个”cross-stitch”单元，学习的<strong>activation</strong>之间的线性映射，期望找到最优的share / task-specific特征组合。</li><li>方法：基于一个AlexNet（one-task network），然后在两个任务上分别进行finetune获得网络A和B，引入corss-stitching。</li><li>数据集和任务：<ul><li>Semantic segmentation（SemSeg）and Surface Normal Prediction（SN）on NYU-v2 </li><li>object detection and attribute prediction on PASCAL VOC 2008</li></ul></li><li>实验：<ul><li>初始值$\alpha$的影响，one-task / ensemble两个网络 / split architecture / MTL-shared</li></ul></li></ul><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190803113347827.png" alt="image-20190803113347827"></p><blockquote><p>只考虑权重，没有考虑网络结构的影响。而且增加了模型大小。</p></blockquote></li><li><p><strong>DAN</strong>: Incremental Learning Through Deep Adaptation (ICLR2018)</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190803113821256.png" alt="image-20190803113821256"></p></li><li><ul><li><p>假设基于的是保持网络结构不变，在T1任务上训练好的网络N，通过改变网络权重能够迁移到T2任务。</p></li><li><p>方法：基于VGG-B，引入controller modules，封装了原先的卷积层，对原始权重做了一下线性变换，每个任务有一个二值变量$\alpha$，控制选择原始权重or新的权重。</p></li><li><p>数据集和任务：Caltech-256, CIFAR-10, Daimler, GTSR, Omniglot, Plankton imagery data, Human Sketch dataset, SVHN</p></li><li><p>实验：</p><ul><li>control-module中W的初始化方式</li><li>base network的选择</li><li>Visual Decathlon Challenge：</li></ul><blockquote><p>不同于cross-stitch的jointly learning，而是one-by-one，在一个网络的基础上训练出另外一个。</p></blockquote></li></ul></li></ul><ul><li><p>Learning multiple visual domains with residual adapters（NIPS2017）</p></li><li><p>Efficient parametrization of multi-domain deep neural networks（CVPR2018）</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190805213652297.png" alt="image-20190805213652297"></p></li></ul><ul><li><ul><li>和👆一篇是同一个作者，不同的是一个上一篇用串行的adapaters，这篇用并行的。</li><li>方法：基于ResNet结构引入residual adapters，引入较少的参数对feature进行了变换。</li><li>实验：<ul><li>adapters的位置（early / mid / late）</li><li>和在各自任务上获得finetune网络进行比较</li></ul></li></ul></li></ul><ul><li>LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING （ICLR2018）</li></ul><ul><li><p><strong>Piggyback</strong>: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights</p><p><a href="https://github.com/arunmallya/piggyback" target="_blank" rel="external">https://github.com/arunmallya/piggyback</a></p><ul><li>one-by-one learning</li><li>每个卷积核学习一个mask（剪枝），mask的值为0和1（量化）</li><li>数据集：CUBS / Stanford Cars / WikiArt / Sketch</li><li>方法：不改变pretrained模型的backbone，学习binary mask，让卷积核稀疏以达到适应新数据集的目的。</li></ul><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190807104608124.png" alt="image-20190807104608124"></p></li><li><p><strong>MTAN</strong>: End-to-End Multi-Task Learning with Attention  (cvpr2019)</p><p><a href="https://github.com/lorenmt/mtan" target="_blank" rel="external">https://github.com/lorenmt/mtan</a></p></li></ul><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190803164905002.png" alt="image-20190803164905002"></p><ul><li><ul><li>jointly learning，几个任务是同时训的。</li><li>有一个backbone网络作为task-shared网络（本文采用SegNet），每个任务有对应的attention module。</li><li>提出了DWA，动态平衡loss系数。</li></ul></li></ul><ul><li><p>Nerttailor (cvpr2019)</p><p><a href="https://github.com/pedro-morgado/nettailor" target="_blank" rel="external">https://github.com/pedro-morgado/nettailor</a></p><p><img src="https://github.com/pedro-morgado/nettailor/raw/master/docs/figs/teaser_row.png" alt="img"></p><ul><li><p>one-by-one learning，先在一个任务上训练完迁移到另一个任务上。</p></li><li><p>universarial network是在目标任务上fine-tune一个pre-trained网络，区别在于不仅改变权重，还改变了网络的结构。soft Attention+NAS。</p></li><li><p>动态改变网络结构，backbone是在一个域上训好的ResNet，通过搜索辅助单元。</p></li></ul></li></ul><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190804144750941.png" alt="image-20190804144750941"></p><ul><li><p>Efficient parametrization of multi-domain deep neural networks</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190805171712077.png" alt="image-20190805171712077"></p><ul><li>网络结构相同的网络，第一个卷积层不同（输入不同）</li><li>通过权值共享的方式进行两个域模型的压缩。首先怼了GrOWL(Group weighted order lasso)的方法。</li><li><strong>三个数据集：</strong>SUN-RGBD Dataset（RGB图像和深度图），UCF-101 Dataset（Youtube videos），HMDB-51 Dataset（video）</li><li><strong>两个任务：</strong>RGB-D Scene Classification：Alex-Net，Action Recognition Tasks：VGG-16</li></ul></li></ul><p>weight sharing?</p><p>基于特征</p><ul><li>不同任务特征转换，学习特征之间的线性组合（Cross-stitch、Deep Adaptation</li><li><p>特征选择，稀疏（Group sparsity）</p></li><li><p>分解，低秩分解</p></li></ul><p>基于任务聚类</p><ul><li>加权最近邻分类器。针对每个任务，通过调整权重实现最小化类内距离，最大化类间距离。每个任务之间构建转化矩阵A，其中$a_{ij}$表示使用任务$T_j$的分类器对任务$T_i$样本进行分类的繁花精度。基于矩阵A，将$m$个任务聚成$r$个簇。一个簇里各个任务的样本共享，每个簇训练出一个共同的加权最近邻分类器。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Multi-task-Learning&quot;&gt;&lt;a href=&quot;#Multi-task-Learning&quot; class=&quot;headerlink&quot; title=&quot;Multi-task Learning&quot;&gt;&lt;/a&gt;Multi-task Learning&lt;/h1&gt;&lt;p&gt;多任
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.10</title>
    <link href="http://yoursite.com/2019/07/26/weekly-paper-10/"/>
    <id>http://yoursite.com/2019/07/26/weekly-paper-10/</id>
    <published>2019-07-26T15:48:10.000Z</published>
    <updated>2019-07-31T13:30:32.838Z</updated>
    
    <content type="html"><![CDATA[<p>### </p><h3 id="1️⃣-Interpretable-and-Fine-Grained-Visual-Explanations-for-Convolutional-Neural-Networks"><a href="#1️⃣-Interpretable-and-Fine-Grained-Visual-Explanations-for-Convolutional-Neural-Networks" class="headerlink" title="1️⃣ Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks"></a>1️⃣ Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks</h3><p><strong>本文是基于干扰项方法的可解释</strong>。可解释的区域$\mathbf{e}^__{C_T}$可以分为<strong>最小保留的区域</strong>和_*最小移除区域__，前者意味着这些区域是保证模型分类正确的部分，后者意味着这些区域必须移除以改变模型输出。</p><p>添加干扰项的图像可以表示为：$\mathbf{e}=\mathbf{m} \cdot \mathbf{x}+(1-\mathbf{m}) \cdot \mathbf{r}$，通过训练使mask稀疏。</p><ul><li><p>保留解释：<br>$$<br>\begin{aligned} \mathbf{e}_{c_{T}}^{_} &amp;=\mathbf{m}_{c_{T}}^{_} \cdot \mathbf{x} \\ \mathbf{m}_{c_{T}}^{*} &amp;=\underset{\mathbf{m}_{c_{T}}}{\arg \min }\left\{\varphi\left(y_{x}^{c_{T}}, y_{e}^{c_{T}}\right)+\lambda \cdot\left|\mathbf{m}_{c_{T}}\right|_{1}\right\} \end{aligned}<br>$$<br>图像中的e区域，保证模型的分类正确。</p></li><li><p>移除解释：<br>$$<br>\begin{aligned} \mathbf{e}_{c_{T}}^{_} &amp;=\mathbf{m}_{c_{T}}^{_} \cdot \mathbf{x} \\ \mathbf{m}_{c_{T}}^{*} &amp;=\underset{\mathbf{m}_{e_{T}}}{\arg \max }\left\{\varphi\left(y_{x}^{c_{T}}, y_{e}^{c_{T}}\right)+\lambda \cdot\left|\mathbf{m}_{c_{T}}\right|_{1}\right\} \end{aligned}<br>$$<br>图像中的e区域，使得模型分类错误。</p></li></ul><h3 id="2️⃣-THE-DEEP-WEIGHT-PRIOR"><a href="#2️⃣-THE-DEEP-WEIGHT-PRIOR" class="headerlink" title="2️⃣ THE DEEP WEIGHT PRIOR"></a>2️⃣ THE DEEP WEIGHT PRIOR</h3><p>【ICLR2019】</p><p>本文的目标是能够通过某个概率分布生成网络的权重。可以看作是增强网络初始化的一种方法。以前贝叶斯神经网络都是需要对参数的先验分布$p(W)$进行假设，通常是log-uniform。<br>$$<br>\mathcal{L}(\theta)=\sum_{i=1}^{N} \mathbb{E}_{q_{\theta}(W)} \log p\left(y_{i} | x_{i}, W\right)-D_{\mathrm{KL}}\left(q_{\theta}(W) | p(W)\right) \rightarrow \max _{\theta}<br>$$<br>VAE是通过隐变量$z_i$估计后验概率分布$q(z_i|x_i)$的方法。其中$x_i$是生成图像。<br>$$<br>\mathcal{L}(\theta, \phi)=\sum_{i=1}^{N} \mathbb{E}_{q_{\theta}\left(z_{i} | x_{i}\right)} \log p_{\phi}\left(x_{i} | z_{i}\right)-D_{\mathrm{KL}}\left(q_{\theta}\left(z_{i} | x_{i}\right) | p\left(z_{i}\right)\right) \rightarrow \max _{\theta, \phi}<br>$$<br>本文的假设是基于预训练的网络参数$\hat{p}_{l}(w)$，参数的先验概率分布为：<br>$$<br>\hat{p}_{l}(w)=\int p\left(w | z ; \phi_{l}\right) p_{l}(z) d z<br>$$<br>引入auxiliary lower bound KL:<br>$$<br>\begin{array}{l}{D_{\mathrm{KL}}(q(W) | \hat{p}(W))=\sum_{l, i, j} D_{\mathrm{KL}}\left(q\left(w_{i j}^{l} | \theta_{i j}^{l}\right) | \hat{p}_{l}\left(w_{i j}^{l}\right)\right) \leq \sum_{l, i, j}\left(-H\left(q\left(w_{i j}^{l} | \theta_{i j}^{l}\right)\right)+\right.} \\ {+\mathbb{E}_{q\left(w_{i j}^{l} | \theta_{i j}^{l}\right)}\left[D_{\mathrm{KL}}\left(r\left(z | w_{i j}^{l} ; \psi_{l}\right) | p_{l}(z)\right)-\mathbb{E}_{r\left(z | w_{i j}^{l} ; \psi_{l}\right)} \log p\left(w_{i j}^{l} | z ; \phi_{l}\right)\right] )=D_{\mathrm{KL}}^{b o u n d}}\end{array}<br>$$<br>这样就和VAE对上，用VAE的encoder估计参数的先验概率（文章假设隐变量$z_i$服从N(0,1)），然后用VAE估计网络参数的先验概率分布，然后从该分布中生成网络的参数。</p><p><img src="https://i.loli.net/2019/07/27/5d3c4f29da39269692.png" alt=""></p><h3 id="3️⃣-DSC-Dense-Sparse-Convolution-for-Vectorized-Inference-of-Convolutional-Neural-Networks"><a href="#3️⃣-DSC-Dense-Sparse-Convolution-for-Vectorized-Inference-of-Convolutional-Neural-Networks" class="headerlink" title="3️⃣ DSC: Dense-Sparse Convolution for Vectorized Inference of Convolutional Neural Networks"></a>3️⃣ DSC: Dense-Sparse Convolution for Vectorized Inference of Convolutional Neural Networks</h3><p>【CVPR2019】</p><p>本文是从很现实的角度做压缩，基于具体的Winograd convolution的压缩方式。</p><p><strong>计算单元向量化</strong>：从现实角度来看，从内存中读取8-bit整形和32-bit浮点型的能耗相同，从i7 CPU读取数据64-bits数据和Altera Arria 10度去32-bit数据的能耗相同。只读取同bit数据(align data)填充寄存器只需要一次操作，同时读取不同bit数据(unaligned data)则需要两次操作。通常CPU数据流缓存块的大小是64bytes (64*8bits)，意味着64x8-bit整形和 16x32-bit的数据可以平行填充寄存器。</p><p><strong>WInograd convolution</strong>：基于Winograd卷积是用更多的加法来减少惩罚操作，2D Winograd Convolution F(2x2, 3x3)的计算公式如下：</p><p><img src="https://i.loli.net/2019/07/28/5d3cfdb637a8236799.png" alt=""></p><p><strong>Dense-Sparse Convolution</strong></p><p><img src="https://i.loli.net/2019/07/28/5d3cfe28d812326769.png" alt=""></p><p>针对Sparse Convolution，把卷积核用CSR格式存放，进行direct sparse convolution。</p><p>针对Sparse-Dense Convolution，作者先通过一个threshold判断的卷积核的稀疏程度，然后用下面的公式进行计算：</p><p><img src="https://i.loli.net/2019/07/28/5d3cff84895ca39428.png" alt=""></p><h3 id="4️⃣-Efficient-Neural-Network-Compression"><a href="#4️⃣-Efficient-Neural-Network-Compression" class="headerlink" title="4️⃣ Efficient Neural Network Compression"></a>4️⃣ Efficient Neural Network Compression</h3><p>【CVPR2019】</p><p>本文的压缩方法是针对卷积核进行低秩分解，目标是找到针对整个网络的最优rank以进行压缩（相当于通道ratio）</p><p><img src="https://github.com/Hyeji-Kim/ENC/raw/master/fig/overall2.png" alt="i"></p><p>两种Layer-wise Accuracy Metrics</p><ul><li><p>PCA energy-based：$y_{p, l}\left(r_{l}\right)$<br>$$<br>y_{p, l}\left(r_{l}\right)=\frac{\sigma_{l}^{\prime}\left(r_{l}\right)-\sigma_{l}^{\prime}(1)}{\sigma_{l}^{\prime}\left(r_{l}^{\max }\right)-\sigma_{l}^{\prime}(1)}<br>$$<br>其中第$l$层的秩是$r_l$，$\sigma_l(d)$是经过分解的第$d$个对角值，$\sigma_{l}^{\prime}\left(r_{l}\right)=\sum^{r_l}_{d=1}\sigma_l(d)$表示卷积核分解后对应秩的元素之和，进行归一化。</p></li><li><p>Measurement-based Metric：$y_{m, l}\left(r_{l}\right)$</p><p>只改变网络层$l$的秩，所获得的整体精度。用VBMF进行秩的采样。</p></li></ul><p>假设每层的metric是独立的，联合概率分布表示网络整体的accuracy metric：<br>$$<br>\mathrm{P}(A ; R)=\prod_{l=1}^{L} \mathrm{P}\left(a_{l} ; r_{l}\right)<br>$$<br>三种Overall accuracy metric：</p><ul><li>Measurement-based：$A_{m}(R)=\prod_{l=1}^{L} y_{m, l}\left(r_{l}\right)$</li><li><p>PCA-based：$A_{p}(R)=\prod_{l=1}^{L} y_{p, l}\left(r_{l}\right)$</p></li><li><p>combied metric：$A_{c}(R)=\left\{A_{p}(R) \times \frac{C(R)}{C_{\text {orig}}}\right\}+A_{m}(R)$</p></li></ul><p><strong>ENC-Map</strong>：利用Accuracy-Complexity的映射来选择每层的rank配置。文章认为让网络每层的具有相同的精度损失与具有相同压缩率相比，是更合理的压缩策略。因此假设在VBMF生成的rank下，每层的metric都相同：<br>$$<br>R_{e}=R | y_{i, l}\left(r_{l}\right)=y_{i, k}\left(r_{k}\right)<br>$$<br>然后我们可以计算出$R_e$的复杂度$C(R)=\sum_{l=1}^{L} C_{l}\left(r_{l}\right)=\sum_{l=1}^{L} c_{l} r_{l}$</p><p>于是有了complexity和accuracy的映射：$f_{C-A}： \mathbb{R} \rightarrow \mathbb{R}$，进一步得到complexity和accuracy到rank的映射：$f_{C-R}：\mathbb{R} \rightarrow \mathbb{R}^L$。</p><p><strong>ENC-Model/Inf</strong>：将扩展ENC-Map至rank的组合问题，需要搜索合适的rank，通过1. 利用已知复杂度来限制 2. 把长得差不多的的卷积核的rank分到一组。</p><h3 id="5️⃣-ECC-Platform-Independent-Energy-Constrained-Deep-Neural-Network-Compression-via-a-Bilinear-Regression-Model"><a href="#5️⃣-ECC-Platform-Independent-Energy-Constrained-Deep-Neural-Network-Compression-via-a-Bilinear-Regression-Model" class="headerlink" title="5️⃣ ECC: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model"></a>5️⃣ ECC: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model</h3><p>本文用限制能耗来进行模型压缩，提出了用一个双线性回归模型来估计target硬件平台的能耗。</p><p>目标用下面的公式表示：<br>$$<br>\begin{array}{cl}{\min _{\mathcal{W}, \mathbf{s}}} &amp; {\ell(\mathcal{W})} \ \\{\text { s.t. }} &amp; {\phi\left(\mathbf{w}^{(u)}\right) \leq s^{(u)}, \quad u \in \mathcal{U}}\\ \ {} &amp; {\mathcal{E}(\mathbf{s}) \leq E_{\text { budget }}}\end{array}<br>$$<br>解决上面问题需要解决稀疏率到能量的映射模型$\mathcal{E}(\mathbf{s})$。用data-driven的方法来训练这个近似模型$\hat{\mathcal{E}}$：<br>$$<br>\hat{\mathcal{E}}=\underset{f \in \mathcal{F}}{\arg \min } \mathbb{E}_{\mathbf{s}}\left[(f(\mathbf{s})-\mathcal{E}(\mathbf{s}))^{2}\right]<br>$$<br>用双线性模型来估计网络整体能耗：<br>$$<br>\mathcal{F} :=\{f(\mathbf{s})=a_{0}+\sum_{j=1}^{|\mathcal{U}|} a_{j} s_{j} s_{j+1} : a_{0}, a_{1}, \ldots, a_{|\mathcal{U}|} \in \mathbb{R}_{+} \}<br>$$<br>ECC整体框架分为两个部分，Online和Offline部分。在Offline部分建立近似能量估计模型$\hat{\mathcal{E}}$</p><p><img src="https://i.loli.net/2019/07/28/5d3d42fd271e241820.png" alt=""></p><p>Online部分基于能量模型进行压缩和ADMM进行压缩。将目标转为minmax优化问题：<br>$$<br>\min _{\mathcal{W}, \mathbf{s}} \max _{z \geq 0, \mathbf{y} \geq \mathbf{0}} \mathcal{L}(\mathcal{W}, \mathbf{s}, \mathbf{y}, z)<br>$$<br>引入对偶变量$y$和$z$用于限制稀疏率，引入z用于限制能量：<br>$$<br>\mathcal{L}(\mathcal{W}, \mathbf{s}, \mathbf{y}, z) \quad :=\ell(\mathcal{W})+\mathcal{L}_{1}(\mathcal{W}, \mathbf{s}, \mathbf{y})+\mathcal{L}_{2}(\mathbf{s}, z)<br>$$<br>其中$\mathcal{L}_{1}(\mathcal{W}, \mathbf{s}, \mathbf{y}) \quad :=\quad \frac{\rho_{1}}{2} \sum_{u}\left[\phi\left(\mathbf{w}^{(u)}\right)-s^{(u)}\right]_{+}^{2}+\sum_{u} y^{(u)}\left(\phi\left(\mathbf{w}^{(u)}\right)-s^{(u)}\right), \mathcal{L}_{2}(\mathbf{s}, z)$</p><p>$\mathcal{L}_{2}(\mathbf{s}, z) :=\frac{\rho_{2}}{2}\left[\hat{\mathcal{E}}(\mathbf{s})-E_{\mathrm{budget}}\right]_{+}^{2}+z\left(\hat{\mathcal{E}}(\mathbf{s})-E_{\text { budget }}\right)$</p><p>算法通过迭代更新参数来达到最终目标</p><ul><li>Update $W$：用Proximal Adam</li><li><p>Update $s$：$\mathbf{s}^{t+1}=\mathbf{s}^{t}-\beta\left(\nabla_{\mathbf{s}} \mathcal{L}_{1}\left(\mathcal{W}, \mathbf{s}^{t}, \mathbf{y}\right)+\nabla_{\mathbf{s}} \mathcal{L}_{2}\left(\mathbf{s}^{t}, z\right)\right)$</p></li><li><p>Update 对偶变量：$\begin{aligned} y^{(u)^{t+1}} &amp;=\left[y^{(u)^{t}}+\rho_{1}\left(\phi\left(\mathbf{w}^{(u)}\right)-s^{(u)}\right)\right]_{+} \\ z^{t+1} &amp;=\left[z^{t}+\rho_{2}\left(\hat{\mathcal{E}}(\mathbf{s})-E_{\mathrm{budget}}\right)\right]_{+} \end{aligned}$</p></li></ul><h3 id="NETTAILOR-Tuning-the-architecture-not-just-the-weights"><a href="#NETTAILOR-Tuning-the-architecture-not-just-the-weights" class="headerlink" title="NETTAILOR: Tuning the architecture, not just the weights"></a>NETTAILOR: Tuning the architecture, not just the weights</h3><p>这篇文章很有意思，不止fintune网络权重，还FT网络结构。目前大部分网络使用的是相同的backbone，没有考虑到网络结构本身的影响。可能小一些的网络在目标数据集上就足够了。本文将pre-trained的backbone网络结构为universal blocks，加上一些task-specific网络来生成新的网络。通过soft-attention机制和网络的复杂度限制来学习新的网络结构和权重。</p><p>一些相关工作包括迁移学习、多任务学习（增强任务之间的泛化性），迁移学习假设图像来自不同的域，MTL假设所有任务是处于同域的。Domain adaptation解决两个不同域数据集的任务。Cascaded classifiers &amp; Adaptive inference graphs能够自动调整网络的拓扑结构。但是针对不同的任务要训练不同的网络，NETTAILOR通过重用universal blocks，只训练task相关的block来解决multi-domain transfer learning problems。</p><p>算法主要分成以下四步：1. 在目标任务上用pre-trained网络训练一个teacher network。2. 定义包括proxy layers的学生网络。3. 在目标任务上只训练task-specific参数，同时加上复杂度限制。4. 精简网络结构后进行finetune。</p><p><img src="https://github.com/pedro-morgado/nettailor/raw/master/docs/figs/teaser_row.png" alt="img"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;### &lt;/p&gt;
&lt;h3 id=&quot;1️⃣-Interpretable-and-Fine-Grained-Visual-Explanations-for-Convolutional-Neural-Networks&quot;&gt;&lt;a href=&quot;#1️⃣-Interpretable-an
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>进化策略</title>
    <link href="http://yoursite.com/2019/07/20/evolution-strategies/"/>
    <id>http://yoursite.com/2019/07/20/evolution-strategies/</id>
    <published>2019-07-19T23:44:06.000Z</published>
    <updated>2019-07-20T00:25:32.893Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.otoro.net/2017/10/29/visual-evolution-strategies/" target="_blank" rel="external">这篇博客</a></p><p>进化策略是一种黑箱优化算法，防止参数陷入局部最优解。进化策略可以看作一种提供一系列候选解决方案来评估一个问题的算法。评估结果基于一个目标函数(objective function)，一个解决方案返回一个适应度(fitness value)，基于当前解决方案的适应度，再生成下一集合的候选者。最简单的伪代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">solver = EvolutionStrategy()</div><div class="line"></div><div class="line">while True:</div><div class="line"></div><div class="line">  # 请求ES生成候选者</div><div class="line">  solutions = solver.ask()</div><div class="line"></div><div class="line">  # 初始化适应度</div><div class="line">  fitness_list = np.zeros(solver.popsize)</div><div class="line"></div><div class="line">  # 评估候选者，生成与其对应的适应度</div><div class="line">  for i in range(solver.popsize):</div><div class="line">    fitness_list[i] = evaluate(solutions[i])</div><div class="line"></div><div class="line">  # 返回适应度结果给ES</div><div class="line">  solver.tell(fitness_list)</div><div class="line"></div><div class="line">  # 从ES中获取最优参数和最优适应度</div><div class="line">  best_solution, best_fitness = solver.result()</div><div class="line"></div><div class="line">  if best_fitness &gt; MY_REQUIRED_FITNESS:</div><div class="line">    break</div></pre></td></tr></table></figure><p>以简单的2D问题为例，参数由$\mu=\left(\mu_{x}, \mu_{y}\right)$和$\sigma=\left(\sigma_{x}, \sigma_{y}\right)$组成Simple ES和Simple GA都是固定$\sigma$不变，通过进化算法学习$\mu$，由此CMA-ES算法诞生。它是一种不基于梯度的算法，通过计算所有参数空间的协方差矩阵，在每次迭代时从多元正态分布中采样解决方案。</p><p>上面提到的一些算法只保留了最优解，忽略了其他解决方案，因此也可能忽略大部分对生成下一代有用的信息。结合RL算法，有人提出了REINFORCE-ES以及NES，遵循的原则是不论好坏综合所有候选者以估计梯度，往梯度方向更新参数。核心思想是<strong>最大化采样候选者的适应度期望值</strong>：<br>$$<br>J(\theta)=E_{\theta}[F(z)]=\int F(z) \pi(z, \theta) d z<br>$$<br><a href="http://www.jmlr.org/papers/volume15/wierstra14a/wierstra14a.pdf" target="_blank" rel="external">NES</a>提供了梯度的推导，利用log-likelihood trick和蒙特卡洛采样可以得到：<br>$$<br>\nabla_{\theta} J(\theta) \approx \frac{1}{N} \sum_{i=1}^{N} F\left(z^{i}\right) \nabla_{\theta} \log \pi\left(z^{i}, \theta\right)<br>$$<br><a href="http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf" target="_blank" rel="external">REINFORCE</a>为特殊的案例，当$\pi(z, \theta)$是一个factored multi-variate normal distribution，即每个参数服从一个一元正态分布$z_{j} \sim N\left(\mu_{j}, \sigma_{j}\right)$，给出了一个梯度的封闭解：<br>$$<br>\begin{array}{l}{\nabla_{\mu_{j}} \log N\left(z^{i}, \mu, \sigma\right)=\frac{z_{j}^{i}-\mu_{j}}{\sigma_{j}^{2}}} \\ {\nabla_{\sigma_{j}} \log N\left(z^{i}, \mu, \sigma\right)=\frac{\left(z_{j}^{i}-\mu_{j}\right)^{2}-\sigma_{j}^{2}}{\sigma_{j}^{3}}}\end{array}<br>$$<br>这些论文提出了一些tricks，比如PEPG中的antithetic sampling，NES中利用Fisher Information更新梯度等等。</p><p>在OenAI的<a href="https://blog.openai.com/evolution-strategies/" target="_blank" rel="external">论文</a>里，它们固定$\sigma$，只更新$\mu$，主要是解决执行层面的并行运算问题。</p><p>通常进化策略都会采样一个称为Fitness Shaping的trick，把种群适应度转化为种群内部的相对值，即rank一下fitness，保证评估指标的不变性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://blog.otoro.net/2017/10/29/visual-evolution-strategies/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;进化策略是一种黑箱优化算法，防止参数
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.09</title>
    <link href="http://yoursite.com/2019/07/08/weekly-paper-09/"/>
    <id>http://yoursite.com/2019/07/08/weekly-paper-09/</id>
    <published>2019-07-08T01:07:11.000Z</published>
    <updated>2019-07-17T13:39:48.882Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-Natural-Evolution-Strategies"><a href="#1️⃣-Natural-Evolution-Strategies" class="headerlink" title="1️⃣ Natural Evolution Strategies"></a>1️⃣ Natural Evolution Strategies</h3><p>NES是一种利用搜索梯度(search gradients)更新搜索分布参数(parameters of the search distribution)的黑箱优化算法，与经典方法（EDAs）利用最大似然拟合采样分布的方法不同，本文提出的更新策略是沿着更高期望适应度的方向。</p><p>最大化所采样样本的适应度的期望值。核心思想就是在每次新的种群里更新mean和std，从新的结果中继续更新</p><h4 id="0-Search-Gradients"><a href="#0-Search-Gradients" class="headerlink" title="0/ Search Gradients"></a>0/ Search Gradients</h4><p>假设我们从分布$\pi(\mathbf z | \theta)$中采样$\mathbf z$，用$f(\mathbf z)$表示该采样的适应度。在该搜索分布下的期望适应度为：<br>$$<br>J(\theta)=\mathbb{E}_{\theta}[f(\mathbf{z})]=\int f(\mathbf{z}) \pi(\mathbf{z} | \theta) d \mathbf{z}<br>$$<br>利用 <a href="http://blog.shakirm.com/2015/11/machine-learning-trick-of-the-day-5-log-derivative-trick/" target="_blank" rel="external">log-likelihood trick</a>：<br>$$<br>\begin{aligned} \nabla_{\theta} J(\theta) &amp;=\nabla_{\theta} \int f(\mathbf{z}) \pi(\mathbf{z} | \theta) d \mathbf{z} \\ &amp;=\int f(\mathbf{z}) \nabla_{\theta} \pi(\mathbf{z} | \theta) d \mathbf{z} \\ &amp;=\int f(\mathbf{z}) \nabla_{\theta} \pi(\mathbf{z} | \theta) \frac{\pi(\mathbf{z} | \theta)}{\pi(\mathbf{z} | \theta)} d \mathbf{z} \\ &amp;=\int\left[f(\mathbf{z}) \nabla_{\theta} \log \pi(\mathbf{z} | \theta)\right] \pi(\mathbf{z} | \theta) d \mathbf{z} \\ &amp;=\mathbb{E}_{\theta}\left[f(\mathbf{z}) \nabla_{\theta} \log \pi(\mathbf{z} | \theta)\right] \end{aligned}<br>$$<br>利用种群大小$\lambda$对搜索梯度进行近似估计：<br>$$<br>\nabla_{\theta} J(\theta) \approx \frac{1}{\lambda} \sum_{k=1}^{\lambda} f\left(\mathbf{z}_{k}\right) \nabla_{\theta} \log \pi\left(\mathbf{z}_{k} | \theta\right)<br>$$<br>$\nabla_{\theta} J(\theta)$提供了梯度上升的方向，最直接的方法参数更新方法：$\theta \leftarrow \theta+\eta \nabla_{\theta} J(\theta)$</p><blockquote><p>我们希望最大化期望值，因此是梯度上升。</p></blockquote><p>这样，我们可以写出标准搜索梯度算法：</p><p><img src="https://i.loli.net/2019/07/08/5d229d3f6943c17863.png" alt=""></p><p>以多元正态分布为例，$\theta=\langle\boldsymbol{\mu}, \boldsymbol{\Sigma}\rangle$为需要学习的分布参数。我们还需要满足$\mathbf{A}^{\top} \mathbf{A}=\mathbf{\Sigma}$的协方差矩阵的平方根矩阵$\mathbf{A} \in \mathbb{R}^{d \times d}$，使得$\mathbf{z}=\boldsymbol{\mu}+\mathbf{A}^{\top} \mathbf{s}$将标准正态分布$\mathbf{s} \sim \mathcal{N}(0, \mathbb{I})$转化为种群个体$\mathbf{z} \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{\Sigma})$，需要对$\boldsymbol{\mu}, \mathbf{\Sigma}$求导，更新算法为：</p><p><img src="https://i.loli.net/2019/07/08/5d229f6ae0f3061548.png" alt=""></p><h4 id="1-Limitations"><a href="#1-Limitations" class="headerlink" title="1/ Limitations"></a>1/ Limitations</h4><p>针对普通搜索梯度算法的局限，本文提出的解决办法可以用下表总结：</p><p><img src="https://i.loli.net/2019/07/08/5d2299a8b796f92761.png" alt=""></p><p>这些问题和方法让我们来一个个攻破。</p><p><strong>a. Natural gradient</strong></p><p>令$\lambda=1, d=1$，$\mu \leftarrow \mu+\eta \frac{z-\mu}{\sigma^{2}},\quad \sigma \leftarrow \sigma+\eta \frac{(z-\mu)^{2}-\sigma^{2}}{\sigma^{3}}$</p><p>由于$\Delta \mu \propto \frac{1}{\sigma}, \Delta \sigma \propto \frac{1}{\sigma}$，$\sigma$同时控制了$\mu$和$\sigma$的更新，造成参数的更新不是尺度不变(scale-invariant)的：我们减小$\sigma$让$\mu$接近最优解的同时也增大了$\sigma$，使其在参数更新的时候再次远离最优解。</p><p>自然梯度的提出便是为了解决尺度不变的问题。原始梯度测量的是参数分布的欧拉距离。自然梯度利用的是参数分布的KL散度。<br>$$<br>\begin{aligned} \max _{\delta \theta} J(\theta+\delta \theta) &amp; \approx J(\theta)+\delta \theta^{\top} \nabla_{\theta} J \\ \text {s.t. } D(\theta+\delta \theta | \theta) &amp;=\varepsilon, \end{aligned}<br>$$<br>$J(\theta)$仍然是期望适应度，$\varepsilon$是一个很小的增量，通过二阶泰勒展开$\lim \delta \theta \rightarrow 0$，$D(\theta+\delta \theta | \theta)=\frac{1}{2} \delta \theta^{\top} \mathbf{F}(\theta) \delta \theta$。其中<br>$$<br>\begin{aligned} \mathbf{F} &amp;=\int \pi(\mathbf{z} | \theta) \nabla_{\theta} \log \pi(\mathbf{z} | \theta) \nabla_{\theta} \log \pi(\mathbf{z} | \theta)^{\top} d \mathbf{z} \\ &amp;=\mathbb{E}\left[\nabla_{\theta} \log \pi(\mathbf{z} | \theta) \nabla_{\theta} \log \pi(\mathbf{z} | \theta)^{\top}\right] \end{aligned}<br>$$<br>表示为费雪信息矩阵(Fisher information matrix)。若$ \mathbf{F}$可逆，则自然梯度表示为：<br>$$<br>\widetilde{\nabla}_{\theta} J=\mathbf{F}^{-1} \nabla_{\theta} J(\theta)<br>$$</p><blockquote><p>推导可以参考<a href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/" target="_blank" rel="external">blog</a></p></blockquote><p>然后我们就可以写出标准自然演化策略算法：</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190708145437180.png" alt="image-20190708145437180"></p><p>与算法1的区别就在于，更新的时候梯度乘以了一个费雪信息矩阵的逆。</p><p><strong>b. Fitness shaping</strong></p><p>用效用函数(utility)替an代适应度：<br>$$<br>\nabla_{\theta} J(\theta)=\sum_{k=1}^{\lambda} u_{k} \nabla_{\theta} \log \pi\left(\mathbf{z}_{k} | \theta\right)<br>$$<br>本文定义的效用函数为：<br>$$<br>u_{k}=\frac{\max \left(0, \log \left(\frac{\lambda}{2}+1\right)-\log (k)\right)}{\sum_{j=1}^{\lambda} \max \left(0, \log \left(\frac{\lambda}{2}+1\right)-\log (j)\right)}-\frac{1}{\lambda}<br>$$<br><strong>c. Adapation Sampling</strong></p><p>用质量函数判断，当前采样$\mathbf {z’}$很大程度上优于之前的采样$\mathbf {z}$，才进行参数更新。与单纯的最大化适应度函数本身不同，适应采样最大化的是进步的步伐(pace of progress)。以最重要的参数学习率$\eta_{\sigma}$为例：</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190708163252563.png" alt="image-20190708163252563"></p><p>首先利用$1.5\eta_{\sigma, t}$和$\theta_{t-1}$计算出假想参数$\theta ‘$，计算每个个体的权重$w_k ‘$，用Mann-Whitney test检验两个质量函数，当大于阈值$\rho=\frac{1}{2}-\frac{1}{3(d+1)}$时，增加学习率，否则让它靠近初始的学习率。</p><p><strong>d. Exponential parameterization &amp; Natural coordinate system</strong></p><p>NES不直接更新协方差$\mathbf \Sigma$，考虑以它的平方根$\mathbf A$为参数的正态分布，利用自然梯度进行更新。为了避免估计Fisher矩阵，xNES使用了局部坐标系和指数映射。局部坐标系下的自然梯度为：<br>$$<br>\begin{aligned} \nabla_{\boldsymbol{\delta}} J &amp;=\sum_{k=1}^{\lambda} f\left(\mathbf{z}_{k}\right) \cdot \mathbf{s}_{k} \\ \nabla_{\mathbf{M}} J &amp;=\sum_{k=1}^{\lambda} f\left(\mathbf{z}_{k}\right) \cdot\left(\mathbf{s}_{k} \mathbf{s}_{k}^{\top}-\mathbb{I}\right) \end{aligned}<br>$$<br>其中$\mathbf {s}_k$是局部坐标系下第$k$个最优样本，$\mathbf {z}_k$是目标2坐标系下的相同样本。把协方差因子$\mathbf{A}$分解为步长$\sigma &gt;0$和满足$\operatorname{det}(\mathbf{B})=1$的归一化协方差因子$\mathbf{B}$。这种分解使得两个正交成分可以有各自的学习率（$\eta_{\sigma}$, $\eta_{\mathbf {B}}$），对步长$\sigma$和$B$的更新做了指数映射。</p><p><img src="https://i.loli.net/2019/07/08/5d230b687c16942920.png" alt=""></p><p>本文还提了separable NES(SNES)，使用分离的搜索分布减少计算复杂度。本文的实现方式是限制$\mathbf {A}$为可逆的对角变换矩阵。</p><p><img src="https://i.loli.net/2019/07/08/5d230b390673572266.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-Natural-Evolution-Strategies&quot;&gt;&lt;a href=&quot;#1️⃣-Natural-Evolution-Strategies&quot; class=&quot;headerlink&quot; title=&quot;1️⃣ Natural Evolution Strate
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>手撕PyTorch的Batch Normalization</title>
    <link href="http://yoursite.com/2019/07/02/batch-normalization/"/>
    <id>http://yoursite.com/2019/07/02/batch-normalization/</id>
    <published>2019-07-02T00:35:20.000Z</published>
    <updated>2019-07-05T09:03:38.738Z</updated>
    
    <content type="html"><![CDATA[<p>BN是防网络过拟合的一个很重要的模块，细微的差别可能对输出效果有很大影响。因此需要理解一下PyTorch中BN的具体实现。PyTorch的源码用C实现的torch.batchnorm。可以<a href="https://github.com/marvis/pytorch-yolo2/blob/master/layers/batchnorm/src/batchnorm.c" target="_blank" rel="external">yolo2</a>里找到具体实现。</p><h3 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h3><p>$Input : \mathcal{B}=\left\{x_{1}, \cdots, x_{m}\right\}$ 表示batch_size为$m$的输入数据。</p><p>$Output:  \gamma ,  \beta$   PyTorch中为weights和bias。</p><p><strong>更新过程：</strong></p><p>$\mu_{\mathcal{B}} \leftarrow \frac{1}{m} \sum_{i=1}^{m} x_{i}$</p><p>$\sigma_{\mathcal{B}}^{2} \leftarrow \frac{1}{m} \sum_{i=1}^{m}\left(x_{i}-\mu_{\mathcal{B}}\right)^{2}$</p><p>$\hat{x}_{i} \leftarrow \frac{x_{i}-\mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^{2}+\epsilon}}$</p><p>$y_{i} \leftarrow \gamma \hat{x}_{i}+\beta \equiv \mathrm{B} \mathrm{N}_{\gamma, \beta}\left(x_{i}\right)$</p><p>首先通过代码测试一下具体更新过程的实现。</p><p><strong>测试输出：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">x = torch.range(<span class="number">0</span>, <span class="number">35</span>).reshape(<span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment"># initilization</span></div><div class="line">bn = nn.BatchNorm2d(<span class="number">3</span>)</div><div class="line">bn.weight.data.fill_(<span class="number">1</span>)</div><div class="line">bn.bias.data.zero_()</div><div class="line">mean, new_mean = torch.zeros([<span class="number">3</span>]), torch.zeros([<span class="number">3</span>])</div><div class="line">var, new_var = torch.ones([<span class="number">3</span>]), torch.zeros([<span class="number">3</span>])</div><div class="line"></div><div class="line"><span class="comment"># compute mean</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">  new_mean[i] = x[:, i, :, :].mean()</div><div class="line"></div><div class="line"><span class="comment"># compute variance</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">  new_var[i] = torch.pow((x[:, i, :, :] - new_mean[i]), <span class="number">2</span>).mean()</div><div class="line">  <span class="comment"># 等同于 new_var[i] = x[:, i, :, :].var(False) </span></div><div class="line">  <span class="comment"># 计算方差时不使用贝塞尔校正</span></div><div class="line">  </div><div class="line">normalized_x = torch.zeros_like(x)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">  normalized_x[:, i, :, :] = (x[:, i, :, :] - new_mean[i]) / torch.sqrt(new_var[i] + bn.eps)</div><div class="line">  </div><div class="line">print(bn_x)</div><div class="line">print(normalized_x)</div></pre></td></tr></table></figure><p><strong>测试runing_mean和running_var：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># moving average</span></div><div class="line">running_mean = bn.momentum * new_mean + (<span class="number">1</span> - bn.momentum) * mean</div><div class="line">running_var = bn.momentum * new_var + (<span class="number">1</span> - bn.momentum) * var</div><div class="line"></div><div class="line">print(bn.running_mean, bn.running_var)</div><div class="line">print(running_mean, running_var)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="number">1.3500</span>, <span class="number">1.7500</span>, <span class="number">2.1500</span>] [<span class="number">11.5091</span>, <span class="number">11.5091</span>, <span class="number">11.5091</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="number">1.3500</span>, <span class="number">1.7500</span>, <span class="number">2.1500</span>] [<span class="number">10.6250</span>, <span class="number">10.6250</span>, <span class="number">10.6250</span>]</div></pre></td></tr></table></figure><p>running_mean对上了，可是running_var却不对。仔细看了一下源代码在函数<code>variance_cpu</code>中注释掉了一句<code>float scale = 1./(batch * spatial - 1)</code>，这句就很关键了。修改一下上面var的计算方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">scale = x.size(<span class="number">0</span>) * x.size(<span class="number">2</span>) * x.size(<span class="number">3</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">  new_var[i] = x[:, i, :, :].var(<span class="keyword">False</span>) </div><div class="line">  </div><div class="line">new_var = new_var * scale / (scale - <span class="number">1</span>)</div><div class="line">running_var = bn.momentum * new_var + (<span class="number">1</span> - bn.momentum)*var</div><div class="line">print(running_var)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="number">11.5091</span>, <span class="number">11.5091</span>, <span class="number">11.5091</span>]</div></pre></td></tr></table></figure><p>这回方差也🉑️了。说明归一化中的方差使用的是正常计算出的方差，而running_var的方差在scale上做了-1的处理。</p><blockquote><p>需要注意的是，running_mean和running_var的变化，与optimizer无关，不是执行step以后才更新值，而是每次做前向值都会改变。</p></blockquote><p><strong>完整代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mean</span><span class="params">(x, running_mean, mom=<span class="number">0.1</span>)</span>:</span></div><div class="line">    nc = x.size(<span class="number">1</span>)</div><div class="line">    new_mean = torch.zeros([nc])</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nc):</div><div class="line">        new_mean[i] = x[:, i, :, :].mean()</div><div class="line">    running_mean = mom * new_mean + (<span class="number">1</span> - mom) * running_mean</div><div class="line">    <span class="keyword">return</span> new_mean, running_mean</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_var</span><span class="params">(x, running_var, mom=<span class="number">0.1</span>)</span>:</span></div><div class="line">    nc = x.size(<span class="number">1</span>)</div><div class="line">    scale = x.size(<span class="number">0</span>) * x.size(<span class="number">2</span>) * x.size(<span class="number">3</span>)</div><div class="line">    new_var = torch.zeros([nc])</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nc):</div><div class="line">        new_var[i] = x[:, i, :, :].var(<span class="keyword">False</span>)</div><div class="line">    temp_var = new_var * scale / (scale - <span class="number">1</span>)</div><div class="line">    running_var = mom * temp_var + (<span class="number">1</span> - mom) * running_var</div><div class="line">    <span class="keyword">return</span> new_var, running_var</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">norm_x</span><span class="params">(x, mean, var, eps=<span class="number">1e-5</span>)</span>:</span></div><div class="line">    normalized_x = torch.zeros_like(x)</div><div class="line">    nc = x.size(<span class="number">1</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nc):</div><div class="line">        normalized_x[:, i, :, :] = (x[:, i, :, :] - mean[i]) / torch.sqrt(var[i] + eps)</div><div class="line">    <span class="keyword">return</span> normalized_x</div><div class="line">  </div><div class="line">mean, running_mean = get_mean(x, running_mean)</div><div class="line">var, running_var = get_var(x, running_var)</div><div class="line">x = norm_x(x, mean, var)</div></pre></td></tr></table></figure><p>小结一下，BN在训练和测试采取的是两种模式，训练阶段每个batch用的是当前batch算出的均值和方差进行归一化，而测试阶段每个用的是moving averages的统计值。在训练阶段学习一个线性映射，即$\gamma, \beta$使得每层的数据分布尽可能平稳。</p><h3 id="相关参数"><a href="#相关参数" class="headerlink" title="相关参数"></a>相关参数</h3><p>知道了具体更新过程的实现后，来看一下PyTorch中BatchNorm的API</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">torch.nn.BatchNorm1d(num_features, </div><div class="line">                     eps=<span class="number">1e-05</span>, </div><div class="line">                     momentum=<span class="number">0.1</span>, </div><div class="line">                     affine=<span class="keyword">True</span>, </div><div class="line">                     track_running_stats=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><p>其中<code>affine</code>表明是否用$\gamma$和$\beta$进行仿射，当<code>affine=False</code>时，<code>weigthts=None, bias=None</code>，<code>track_running_stats</code>表明是否更新统计特性，当<code>track_running_stats=False</code>时，<code>running_mean=None, running_var=None</code>，即每次归一化的时候只用当前batch的均值和方差进行归一化，而不会对之前算出的均值和方差进行平滑。</p><p><strong>参考链接：</strong></p><ul><li><a href="https://blog.csdn.net/LoseInVain/article/details/86476010" target="_blank" rel="external">Pytorch的BatchNorm层使用中容易出现的问题</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;BN是防网络过拟合的一个很重要的模块，细微的差别可能对输出效果有很大影响。因此需要理解一下PyTorch中BN的具体实现。PyTorch的源码用C实现的torch.batchnorm。可以&lt;a href=&quot;https://github.com/marvis/pytorch-
      
    
    </summary>
    
    
      <category term="维修指南" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>卷积核的低秩分解</title>
    <link href="http://yoursite.com/2019/07/01/tensor-decompositions/"/>
    <id>http://yoursite.com/2019/07/01/tensor-decompositions/</id>
    <published>2019-07-01T11:25:02.000Z</published>
    <updated>2019-07-28T01:57:23.769Z</updated>
    
    <content type="html"><![CDATA[<p>通过<a href="https://jacobgil.github.io/deeplearning/tensor-decompositions-deep-learning" target="_blank" rel="external">这篇blog</a>了解一下低秩分解。</p><p>低秩分解仅作用于线性网络层的权重，可能忽略不同网络层的联系。</p><blockquote><p>There are works that try to address these issues, and its still an active research area.</p></blockquote><h3 id="全连接层的张量分解"><a href="#全连接层的张量分解" class="headerlink" title="全连接层的张量分解"></a>全连接层的张量分解</h3><p>首先简单介绍一下SVD。奇异值分解(SVD)是对矩阵进行分解：<br>$$<br>A_{n \times m}=U_{n \times n} S_{n \times m} V_{m \times m}^{T}<br>$$<br>其中$S$是非负实数对角矩阵，对角线上元素即为$A$的<strong>奇异值</strong>。通常会将奇异值由大到小排序。$U$和$V$是酉矩阵，满足$U^{T} U=V^{T} V=I$。当我们取其最大的$t$个奇异值，将剩下的值置0，则能得到近似矩阵$\hat{A}=U_{n x t} S_{t x t} V_{m x t}^{T}$。</p><p>我们对全连接层的公式$A x+b$进行分解有：$\left(U_{n \times t} S_{t \times t} V_{m \times t}^{T}\right) x+b=U_{n \times t}\left(S_{t \times t} V_{m \times t}^{T} x\right)+b$</p><p>这样将一个大矩阵转化为两个小矩阵，参数量从 $n \times m$ 降为 $t  (n+m)$</p><h3 id="卷积层的张量分解"><a href="#卷积层的张量分解" class="headerlink" title="卷积层的张量分解"></a>卷积层的张量分解</h3><p>下面介绍对卷积层进行张量分解最经典的两种方法：CP分解和Tucker分解</p><p><strong>CP分解</strong></p><p>论文地址：<a href="https://arxiv.org/abs/1412.6553" target="_blank" rel="external">Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition</a></p><p>对$A$进行低秩分解有：<br>$$<br>A(i, j)=\sum_{n=1}^{R} A_{1}(i, r) A_{2}(j, r), \quad i=\overline{1, n}, \quad j=\overline{1, m}<br>$$<br>对d维的$A$进行CP分解有：<br>$$<br>A\left(i_{1}, \ldots, i_{d}\right)=\sum_{r=1}^{R} A_{1}\left(i_{1}, r\right) \ldots A_{d}\left(i_{d}, r\right)<br>$$<br>对$d \times d \times S \times T$的4D的卷积核进行CP分解<br>$$<br>K(i, j, s, t)=\sum_{r=1}^{R} K^{x}(i-x+\delta, r) K^{y}(j-y+\delta, r) K^{s}(s, r) K^{t}(t, r)<br>$$<br>则输出可以$V$ 表示为：<br>$$<br>V(x, y, t)=\sum_{r=1}^{R} K^{t}(t, r)\left(\sum_{i=x-\delta}^{x+\delta} K^{x}(i-x+\delta, r)\left(\sum_{j=y-\delta}^{y+\delta} K^{y}(j-y+\delta, r)\left(\sum_{s=1}^{S} K^{s}(s, r) U(i, j, s)\right)\right)\right)<br>$$<br>则1个卷积操作可以分解为4个卷积操作：<br>$$<br>\begin{aligned} U^{s}(i, j, r) &amp;=\sum_{s=1}^{S} K^{s}(s, r) U(i, j, s) \\ U^{s y}(i, y, r) &amp;=\sum_{j=1}^{y+\delta} K^{y}(j-y+\delta, r) U^{s}(i, j, r) \\ U^{s y z}(x, y, r) &amp;=\sum_{i=x-\delta}^{x+\delta} K^{x}(i-x+\delta, r) U^{s y}(i, y, r) \\ V(x, y, t) &amp;=\sum_{r=1}^{R} K^{t}(t, r) U^{s y x}(x, y, r) \end{aligned}<br>$$</p><ol><li>用$1\times1$的pointwise卷积将输入降至R纬度</li><li>在垂直维度做$d\times1$的depthwise卷积</li><li><p>在水平纬度做$d\times1$的depthwise卷积</p></li><li><p>用$1\times 1$的pointwise卷积获得$T$维的输出</p></li></ol><p>复杂度分析：</p><ul><li>原始卷积 $STd^2$</li><li>CP分解 $R(S+2d+T)$</li></ul><p><strong>Tucker分解</strong></p><p>论文地址：<a href="https://arxiv.org/abs/1511.06530" target="_blank" rel="external">Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications</a></p><p>Tucker分解也称为高阶SVD，4D卷积核表示为：<br>$$<br>K(i, j, s, t)=\sum_{r_{1}=1}^{R_{1}} \sum_{r_{2}=1}^{R_{2}} \sum_{r_{3}=1}^{R_{3}} \sum_{r_{4}=1}^{R_{4}} C’_{r_1, r_2, r_3, r_4} K_{r 1}^{x}(i) K_{r_2}^{y}(j) K_{r_3}^{s}(s) K_{r _4}^{t}(t)<br>$$<br>卷积核通常比较小($3 \times 3$)，就不再在空间维度进行分解<br>$$<br>K(i, j, s, t)=\sum_{r_{3}=1}^{R_{3}} \sum_{r_{4}=1}^{R_{4}} C’_{i,j, r_3, r_4} K_{r_3}^{s}(s) K_{r _4}^{t}(t)<br>$$<br>其中$C$代表$d \times d \times R_3 \times R_4$ 的核心张量。</p><p>于是将1个卷积操作分解为3个卷积操作：<br>$$<br>\begin{aligned} \mathcal{Z}_{h, w, r_{3}} &amp;=\sum_{s=1}^{S} U_{s, r_{3}}^{(3)} \mathcal{X}_{h, w, s} \\ \mathcal{Z}_{h^{\prime}, w^{\prime}, r_{4}}^{D} &amp;=\sum_{i=1}^{D} \sum_{j=1}^{D} \sum_{r_{3}=1}^{R_{3}} \mathcal{C}_{i, j, r_{3}, r_{4}} z_{h_{i} w_{j}, r_{3}} \\ y_{h^{\prime}, w^{\prime}, t} &amp;=\sum_{r_{4}=1}^{R_{4}} U_{t, r_{4}}^{(4)} \mathcal{Z}_{h^{\prime}, w^{\prime}, r_{4}}^{\prime} \end{aligned}<br>$$</p><ol><li>用$1\times1$的pointwise卷积将输入降至R纬度</li><li>进行$d \times d$的卷积</li><li>用$1\times 1$的pointwise卷积获得$T$维的输出</li></ol><h3 id="挑选分解的秩"><a href="#挑选分解的秩" class="headerlink" title="挑选分解的秩"></a>挑选分解的秩</h3><p>在分解的时候秩$R$的选择很重要，Tucker分解中用了VBMF的方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;通过&lt;a href=&quot;https://jacobgil.github.io/deeplearning/tensor-decompositions-deep-learning&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇blog&lt;/a&gt;了解一下低秩分解
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.08</title>
    <link href="http://yoursite.com/2019/06/29/weekly-paper-08/"/>
    <id>http://yoursite.com/2019/06/29/weekly-paper-08/</id>
    <published>2019-06-29T02:42:16.000Z</published>
    <updated>2019-07-08T01:08:09.009Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-Centripetal-SGD-for-Pruning-Very-Deep-Convolutional-Networks-with-Complicated-Structure"><a href="#1️⃣-Centripetal-SGD-for-Pruning-Very-Deep-Convolutional-Networks-with-Complicated-Structure" class="headerlink" title="1️⃣  Centripetal SGD for Pruning Very Deep Convolutional Networks with Complicated Structure"></a>1️⃣  Centripetal SGD for Pruning Very Deep Convolutional Networks with Complicated Structure</h3><p>The main idea of this work is to make some filters close to each other in the same cluster during training, and propose Centripetal SGD (C-SGD). </p><p>the update rule of C-SGD is<br>$$<br>\boldsymbol{F}^{(j)} \leftarrow \boldsymbol{F}^{(j)}+\tau \Delta \boldsymbol{F}^{(j)}<br>$$</p><p>$$<br>\begin{aligned} \Delta \boldsymbol{F}^{(j)}=&amp;-\frac{\sum_{k \in H(j)} \frac{\partial L}{\partial \boldsymbol{F}^{(k)}}}{|H(j)|}-\eta \boldsymbol{F}^{(j)} \\ &amp;+\epsilon\left(\frac{\sum_{k \in H(j)} \boldsymbol{F}^{(k)}}{|H(j)|}-\boldsymbol{F}^{(j)}\right) \end{aligned}<br>$$</p><p>For the filters in the same cluster 1）objective function are averaged 2）weight decay 3）gradually eliminate the difference in the initial values.</p><h3 id="2️⃣-Variational-Convolutional-Neural-Network-Pruning"><a href="#2️⃣-Variational-Convolutional-Neural-Network-Pruning" class="headerlink" title="2️⃣ Variational Convolutional Neural Network Pruning"></a>2️⃣ Variational Convolutional Neural Network Pruning</h3><p>本文用变分推理来进行剪枝感觉还蛮有意思的。首先文章基于Network Slimming做了一些改进。对于BN的$\gamma$，如果只稀疏这个值，不考虑$\beta$的影响，那实际上归一化后的输出不会为0，而是加上$\beta$后的值，所以文章考虑的改进方式是令$\tilde{\beta} = \gamma \cdot \beta$，<br>$$<br>x_{o u t}=\gamma \cdot B N(x)+\tilde{\beta}<br>$$<br>文中将这个$\gamma$称为<em>channel saliency</em>，我们的目标是学习稀疏的$\gamma$同时最大化条件概率$p(y | x, \gamma)$。</p><p>首先利用贝叶斯公式我们可以得到：$ p(\gamma | \mathcal{D})= \frac{p(\gamma) p(\mathcal{D} | \gamma)} { p(\mathcal{D})}$</p><p>由于$p(\mathcal{D})=\int p(\mathcal{D}, \gamma) d \gamma$难以计算，这个后验概率分布我们很难直接求的。在变分推理中，我们可以用一个参数分布$q_{\phi}(\gamma)$来近似这个后验概率分布。利用KL散度拉近两个分布的距离：$\min _{\phi} D_{K L}\left(q_{\phi}(\gamma) | p(\gamma | \mathcal{D})\right)$。等价于最大化ELBO：<br>$$<br>\mathcal{L}(\phi)=L_{\mathcal{D}}(\phi)-D_{K L}\left(q_{\phi}(\gamma) | p(\gamma)\right)<br>$$<br>其中，$\mathcal{L}_{\mathcal{D}}(\phi)=\sum_{(x, y) \in \mathcal{D}} \mathbb{E}_{q_{\phi}(\gamma)}[\log p(y | x, \gamma)]$</p><p>可以看到目标函数由两部分构成，第一部分是重建项，是极大似然估计，第二部分为正则项，后面会引入一个先验分布对参数进行惩罚，即稀疏$\gamma$。</p><p>对于$\mathcal{L}(\phi)$需要解决两个问题：</p><ol><li>第一项中由于期望的存在，$\mathcal{L}_{\mathcal{D}}(\phi)$的梯度无法直接求得。</li><li>第二项参数分布$q_\phi(\gamma)$和先验分布$p(\gamma)$的选择。</li></ol><p>🔺 问题1的解决：</p><p>​    引入再参化技巧，则$q_{\phi}(\gamma)$可以表示为一个可导函数$\gamma=f(\phi, \epsilon)$，其中$\epsilon \sim \mathcal{N}(0,1)$<br>$$<br>\mathcal{L}_{\mathcal{D}}(\phi) \simeq \mathcal{L}_{\mathcal{D}}^{\mathcal{A}}(\phi)=\frac{N}{M} \sum_{m=1}^{M} \log p\left(y_{i m} | x_{i m}, \gamma_{i m}=f(\phi, \epsilon)\right)<br>$$<br>​    其中$M$为batch size，$N$为data数量。</p><p>​    将模型参数$\mathbf{w}$加入优化目标中：<br>$$<br>\mathcal{L}(\phi, \mathbf{w}) \simeq \mathcal{L}_{\mathcal{D}}^{\mathcal{A}}(\phi, \mathbf{w})-D_{K L}\left(q_{\phi}(\gamma) | p(\gamma)\right)<br>$$</p><p>🔺 问题2的解决：</p><p>​    本文选取高斯分布作为参数的分布：<br>$$<br>q_{\phi}(\gamma)=\prod_{i=1}^{C} q\left(\gamma_{i}\right), \quad \gamma_{i} \sim \mathcal{N}\left(\mu_{i}, \sigma_{i}\right)<br>$$<br>​    为了让学习出的参数$\phi=(\mu, \sigma)$使分布$q_\phi(\gamma)$尽可能稀疏，本文引入的先验分布为：<br>$$<br>p(\gamma)=\prod_{i=1}^{C} p\left(\gamma_{i}\right), \quad \gamma_{i} \sim \mathcal{N}\left(0, \sigma_{i}^{_}\right)<br>$$<br>​    这样就能让$\gamma$尽可能向0值靠近。<br>$$<br>\begin{aligned} D_{K L}\left(q_{\phi}(\gamma) | p(\gamma)\right) &amp;=\sum_{i} D_{K L}\left(q_{\phi}\left(\gamma_{i}\right) | p\left(\gamma_{i}\right)\right) \\ &amp;=\sum_{i} \log \frac{\sigma_{i}^{_}}{\sigma_{i}}+\frac{\sigma_{i}^{2}+\mu_{i}^{2}}{2\left(\sigma_{i}^{*}\right)^{2}}-\frac{1}{2} \end{aligned}<br>$$<br>​    让两个分布的方差相同，则上式可以表示为：<br>$$<br>D_{K L}\left(q_{\phi}(\gamma) | p(\gamma)\right)=\sum_{i} k \mu_{i}^{2}<br>$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-Centripetal-SGD-for-Pruning-Very-Deep-Convolutional-Networks-with-Complicated-Structure&quot;&gt;&lt;a href=&quot;#1️⃣-Centripetal-SGD-for-Pruni
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.07</title>
    <link href="http://yoursite.com/2019/06/25/weekly-paper-07/"/>
    <id>http://yoursite.com/2019/06/25/weekly-paper-07/</id>
    <published>2019-06-25T00:55:36.000Z</published>
    <updated>2019-07-08T01:08:06.520Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-Universally-Slimmable-Networks-and-Improved-Training-Techniques"><a href="#1️⃣-Universally-Slimmable-Networks-and-Improved-Training-Techniques" class="headerlink" title="1️⃣  Universally Slimmable Networks and Improved Training Techniques"></a>1️⃣  Universally Slimmable Networks and Improved Training Techniques</h3><p>Slimmable network的拓展工作，将固定宽度的网络扩展到任意宽度。提出了3个挑战：</p><ol><li>如何解决包含batch-normalization的网络？</li><li>如何更有效地训练US-Nets</li><li>与单独训练某个宽度的网络相比，US-Nets是如何提升整体精度的？</li></ol><p>🔺 问题1的解决：</p><ol><li><p>训练阶段每次前向时，计算出该batch的均值和方差，然后对输出进行归一化：<br>$$<br>\hat{x}_{B}=\gamma \frac{x_{B}-E_{B}\left[x_{B}\right]}{\sqrt{\operatorname{Var}_{B}\left[x_{B}\right]+\epsilon}}+\beta<br>$$<br>训练过程会对均值和方差做<strong>moving averages</strong>：<br>$$<br>\begin{aligned} \mu_{t} &amp;=m \mu_{t-1}+(1-m) E_{B}\left[x_{B}\right] \\ \sigma_{t}^{2} &amp;=m \sigma_{t-1}^{2}+(1-m) \operatorname{Var}_{B}\left[x_{B}\right] \end{aligned}<br>$$</p><blockquote><p> 需要注意的是，在PyTorch的实现中，每次进行统计时$Var_B = \frac{n}{n-1}Var_B$，其中 $n=c \times h \times w$</p></blockquote><p>测试阶段，用统计值$\mu=\mu_{T}， \sigma^2=\sigma^2_T$进行归一化：<br>$$<br>\hat{x}_{t e s t}=\gamma^{_} \frac{x_{t e s t}-\mu}{\sqrt{\sigma^{2}+\epsilon}}+\beta^{_}<br>$$<br>其中$\gamma^_, \beta^_$是bn学出的weight和bias。进一步可以表示为：<br>$$<br>\hat{x}_{t e s t}=\gamma^{\prime} x_{t e s t}+\beta^{\prime}, \gamma^{\prime}=\frac{\gamma^{_}}{\sqrt{\sigma^{2}+\epsilon}}, \beta^{\prime}=\beta^{_}-\gamma^{\prime} \mu<br>$$</p></li></ol><p>   如果对不同宽度的网络采用Shared BN，由于特征是相加的，前一层是用不同的通道数，输出值就会有所不同，均值和方差也不同，导致了统计值不准确的问题。Slimmable Network的解决办法是对每个宽度都训练了一个单独的BN层，但如果对所有宽度都这样做代价太大了。本文的解决办法是做exact averages：<br>   $$<br>   \begin{aligned} m &amp;=(t-1) / t \\ \mu_{t} &amp;=m \mu_{t-1}+(1-m) E_{B}\left[x_{B}\right] \\ \sigma_{t}^{2} &amp;=m \sigma_{t-1}^{2}+(1-m) \operatorname{Var}_{B}\left[x_{B}\right] \end{aligned}<br>   $$<br>   统计值的计算不在训练过程中进行，而是训练结束后，用随机采样的训练数据进行估计。</p><p>🔺 问题2的解决：</p><ol><li>本文假设模型的表现限制于宽度$[0.25 \times, 1.0 \times]$，优化lower bound和upper bound就能优化整个网络。于是提出了<strong>Sandwich Rule</strong>，在每次训练时随机采样$n-2$个宽度，加上最小宽度和最大宽度一起训练。同时跟踪这两个模型的验证精度，能大概知道US-Net的lower bound和upper bound。并且，训练最大宽度的模型可以用于<strong>Inplace Distillation</strong>。最大宽度的模型用groud truth做loss，而其它宽度的模型可以用最大宽度模型预测出的soft-probabilities做loss。</li></ol><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190703111249984.png" alt="image-20190703111249984"></p><p>文章最后坐着讨论了几个话题：</p><ol><li>我们能不能训练一个非均匀的US-Net这样每层能够调整它自己的宽度比？</li><li></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-Universally-Slimmable-Networks-and-Improved-Training-Techniques&quot;&gt;&lt;a href=&quot;#1️⃣-Universally-Slimmable-Networks-and-Improved-Train
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow中的PixelShuffle(depth_to_space)</title>
    <link href="http://yoursite.com/2019/06/23/tf-pixshuffle/"/>
    <id>http://yoursite.com/2019/06/23/tf-pixshuffle/</id>
    <published>2019-06-23T08:31:38.000Z</published>
    <updated>2019-06-28T02:10:01.249Z</updated>
    
    <content type="html"><![CDATA[<p>在尝试对PixelShuffle前的卷积层做剪枝时遇到了一些问题，对PixelShuffle的具体操作有了进一步的了解。</p><p>PixelShuffle通过将通道重排对图像进行上采样，tf中的函数是<code>tf.depth_to_sapce</code>，第一个参数是<code>Tensor</code>，第二个参数是需要放大倍数。当输入<code>X</code>的大小为<code>[1 2 2 16]</code>，放大倍数为2，H和W各乘2，C除以4，PixelShuffle后的结果就为<code>[1 4 4 4]</code>。</p><p>🔺坑点1：想当然的以为参与重排的通道是<code>[:, :, :, i:i+4]</code></p><p>测试代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">x = tf.range(<span class="number">64</span>)</div><div class="line">x = tf.reshape(x, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">16</span>])</div><div class="line">y = tf.depth_to_space(x, <span class="number">2</span>) <span class="comment"># [1, 4, 4, 4]</span></div></pre></td></tr></table></figure><p>下面看一下具体x和y每个通道的值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x[:, :, :, <span class="number">0</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">0</span>, <span class="number">16</span>],</div><div class="line">[<span class="number">32</span>, <span class="number">48</span>]]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x[:, :, :, <span class="number">1</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">1</span>, <span class="number">17</span>],</div><div class="line">[<span class="number">33</span>, <span class="number">49</span>]]]</div><div class="line"> </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>y[:, :, :, <span class="number">0</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">0</span>,  <span class="number">4</span>, <span class="number">16</span>, <span class="number">20</span>],</div><div class="line">[ <span class="number">8</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">28</span>],</div><div class="line">[<span class="number">32</span>, <span class="number">36</span>, <span class="number">48</span>, <span class="number">52</span>],</div><div class="line">[<span class="number">40</span>, <span class="number">44</span>, <span class="number">56</span>, <span class="number">60</span>]]]</div></pre></td></tr></table></figure><p>可以看出<code>y</code>的第0维通道包含的是<code>x</code>通道数为0、4、8、12的特征图。可视化一下就是这样的效果：</p><p><img src="https://i.loli.net/2019/06/27/5d14b6a1d9bbf35069.png" alt=""></p><p>将Y的一个通道单独取出，看一下每个点属于原来X的哪个坐标：</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190628095308642.png" alt="image-20190628095308642"></p><p>可以看到Y的一个通道实际上分成4个象限，在空间上由<code>(0,0)(0,1)(1,0)(1,1)</code>构成。在通道上每4个间隔提取对应通道。这里的间隔对应的是Pixshuffle后的通道数。</p><p>假设原始通道数为<code>c_out</code>，PS后的通道数为<code>ps_out</code>，实际上<code>y</code>的第<code>i</code>通道对应的是<code>x</code>的<code>[i, i+ps_out, i+2*ps_out, i+3*ps_out]</code></p><p>而我原先理解的通道排列方式是❌</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>y[:, :, :, <span class="number">0</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">5</span>],</div><div class="line">[ <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">6</span>,  <span class="number">7</span>],</div><div class="line">[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">12</span>, <span class="number">13</span>],</div><div class="line">[<span class="number">10</span>, <span class="number">11</span>, <span class="number">14</span>, <span class="number">15</span>]]]</div></pre></td></tr></table></figure><p>🔺坑点2：提取k个保留的通道时，只需取索引的前k个值</p><p>假设放大倍率是4，用L1的剪枝方式，需要保留的通道数为<code>c_keep</code>。当对应到具体的剪枝通道的时候，需要找到PixShuffle后剪掉通道所对应的原始卷积输出的4个通道。从上面的坐标我们就可以看出，剪掉Y的0通道时，需要对应剪掉X的0、4、8、12通道。来看看具体的实现。主要分为几步：</p><ol><li>计算Y对应X的通道</li><li>计算Y需要保留的通道</li><li>将Y的通道映射回X</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1. 计算Y对应X的通道</span></div><div class="line">norm_list, shuffled_idx_list = [], []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(ps_out):</div><div class="line">shuffled_idx = [i+k*ps_out <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">4</span>)]  <span class="comment"># Y通道对应的4个X通道</span></div><div class="line">shuffled_idx_list.append(shuffled_idx)</div><div class="line">  norm_sum = tf.reduce_sum(tf.gather(norm_value, shuffled_idx)) <span class="comment"># 提取对应索引的通道</span></div><div class="line">  norm_list.append(sess.run(norm_sum))</div><div class="line">  </div><div class="line"><span class="comment"># 2. 计算需要保留的通道</span></div><div class="line">remain_idx = np.sort(np.argsort(norm_list)[::<span class="number">-1</span>][:int(c_keep/<span class="number">4</span>)])</div><div class="line"></div><div class="line">remain_list = []</div><div class="line"><span class="comment"># 3. 将Y的通道映射回X</span></div><div class="line"><span class="keyword">for</span> remain <span class="keyword">in</span> remain_idx:</div><div class="line">  remain_list.extend(shuffled_idx_list[remain])</div><div class="line">remain_list = np.sort(remain_list)</div></pre></td></tr></table></figure><p>这样<code>remain_list</code>即原始卷积输出需要剪掉的通道索引。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在尝试对PixelShuffle前的卷积层做剪枝时遇到了一些问题，对PixelShuffle的具体操作有了进一步的了解。&lt;/p&gt;
&lt;p&gt;PixelShuffle通过将通道重排对图像进行上采样，tf中的函数是&lt;code&gt;tf.depth_to_sapce&lt;/code&gt;，第一个
      
    
    </summary>
    
    
      <category term="维修指南" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.06</title>
    <link href="http://yoursite.com/2019/06/18/weekly-paper-06/"/>
    <id>http://yoursite.com/2019/06/18/weekly-paper-06/</id>
    <published>2019-06-18T01:49:16.000Z</published>
    <updated>2019-06-21T09:12:49.701Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-AutoSlim-Towards-One-Shot-Architecture-Search-for-Channel-Numbers"><a href="#1️⃣-AutoSlim-Towards-One-Shot-Architecture-Search-for-Channel-Numbers" class="headerlink" title="1️⃣ AutoSlim: Towards One-Shot Architecture Search for Channel Numbers"></a>1️⃣ AutoSlim: Towards One-Shot Architecture Search for Channel Numbers</h3><p>这篇和<a href="https://arxiv.org/abs/1812.08928" target="_blank" rel="external">ICLR2019</a>、<a href="https://arxiv.org/abs/1903.05134" target="_blank" rel="external">Universally Slimmable Networks</a>是同一个作者，解决的问题都是通道剪枝。下面先了解一下本文。</p><p><strong>Why?</strong></p><p>Most channel pruning methods are grouneded on <strong>the importance of trained weights</strong>, so the slimmed layer usually consists channels of discrete index. Most NAS methods have high computational cost and time cost.</p><p><strong>How?</strong></p><p>Extending the work of slimmable networks and propose AutoSlim. The training process is as following:</p><ol><li><p>Train a slimmable model for a few epochs to get a benchmark performance estimator.</p><ul><li><p>Searching space is defined between the upper bound and lower bound of channel numbers. In each training iteration, randomly sample the number of channels in each layer. In each layer remove a group of channels. </p><blockquote><p>in resents, first sample the channel number of residual dentity pathway and then randomly and independenly sample channel number inside each residual block.</p></blockquote></li></ul></li><li><p>Evaluate the trained slimmable model and greedily slim the layer with minimal accuracy drop on validation set.</p></li><li><p>Obtain the optimized channel configurations under different resource constraints.</p></li><li><p>Train optimized architectures individually or slimmable network for full training epochs.</p></li></ol><p>The paper is based on the assumption that <strong>the importance of weight is implicitly ranked by its index</strong>, which means that the smaller index of one filter the more important of this filter.</p><h3 id="2️⃣-AutoGrow-Automatic-Layer-Growing-in-Deep-Convolutional-Networks"><a href="#2️⃣-AutoGrow-Automatic-Layer-Growing-in-Deep-Convolutional-Networks" class="headerlink" title="2️⃣ AutoGrow: Automatic Layer Growing in Deep Convolutional Networks"></a>2️⃣ AutoGrow: Automatic Layer Growing in Deep Convolutional Networks</h3><p>The method can be easily found in the title, to gradually grow the depth of DNN.</p><p>The  <em>network</em> is  composed of <em>sub-netwok</em>, and <em>sub-network</em> is composed of <em>sub-modules</em>.<br>$$<br>g\left(\mathcal{X}_{0}\right)=l\left(\boldsymbol{f}_{M-1}\left(\boldsymbol{f}_{M-2}\left(\cdots \boldsymbol{f}_{1}\left(\boldsymbol{f}_{0}\left(\mathcal{X}_{0}\right)\right) \cdots\right)\right)\right)<br>$$<br>AutoGrow is based on Network Morphism, but propose to initilize the last Batch Normalization layer in a residual block of <em>AdamInit</em> insted of <em>ZeroInit</em></p><p><strong>AdamInit</strong></p><p>given the new layers $\mathcal{W}$, we have:<br>$$<br>g\left(\mathcal{X}_{0} ; \mathbb{W}\right)=g\left(\mathcal{X}_{0} ; \mathbb{W} \cup \mathcal{W}\right) \forall \mathcal{X}_{0}<br>$$<br>freeze all parameters except the last Batch Normalization layer in $\mathcal{W}$, use Adam optimizer to optimize the last Batch Normalization layer.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-AutoSlim-Towards-One-Shot-Architecture-Search-for-Channel-Numbers&quot;&gt;&lt;a href=&quot;#1️⃣-AutoSlim-Towards-One-Shot-Architecture-Search-f
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.05</title>
    <link href="http://yoursite.com/2019/06/10/weekly-paper-05/"/>
    <id>http://yoursite.com/2019/06/10/weekly-paper-05/</id>
    <published>2019-06-10T02:29:31.000Z</published>
    <updated>2019-06-18T01:49:25.901Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-Dynamic-Capacity-Networks"><a href="#1️⃣-Dynamic-Capacity-Networks" class="headerlink" title="1️⃣ Dynamic Capacity Networks"></a>1️⃣ Dynamic Capacity Networks</h3><p>use two alternative sub-networks: </p><ol><li>coarse layers $f_c$ on the whole input $\mathbf {x}$  </li><li>fine layers $f_f$ at salient regions </li></ol><p><strong>coarse representation vectors</strong><br>$$<br>f_{c}(\mathbf{x})=\left\{\mathbf{c}_{i, j} |(i, j) \in\left[1, s_{1}\right] \times\left[1, s_{2}\right]\right\}<br>$$</p><p>$$<br>h_{c}(\mathbf{x})= \mathbf{o}_c = g\left(f_{c}(\mathbf{x})\right)<br>$$</p><p>$\mathbf{c}_{i, j}=f_{c}\left(\mathbf{x}_{i, j}\right) \in \mathbb{R}^{D}$ </p><p><strong>salient input regions</strong><br>$$<br>H=-\sum_{l=1}^{C} \mathbf{o}_{c}^{(l)} \log \mathbf{o}_{c}^{(l)}<br>$$</p><p>$$<br>M_{i, j}=\left|\nabla_{\mathbf{c}_{i, j}} H\right|_{2}<br>$$</p><p>$C$ is the number of class labels, $\mathbf{M} \in \mathbb{R}^{s_{1} \times s_{2}}$</p><p>select top $k$ input regions $\mathbf{X}^{s}=\left\{\mathbf{x}_{i, j} |(i, j) \in \mathbf{I}^{s}\right\}$ based on $\mathbf{M}$</p><p><strong>fine representation vectors</strong><br>$$<br>f_{f}\left(\mathbf{X}^{s}\right)=\left\{\mathbf{f}_{i, j} |(i, j) \in \mathbf{I}^{s}\right\}<br>$$<br>refined representation $f_r(\mathbf {x})$ by combining $f_c(\mathbf{x})$ and $f_f(\mathbf{X}^s)$</p><p><strong>loss</strong></p><ol><li><p>Cross Entropy<br>$$<br>J=-\sum_{i=1}^{m} \log p\left(y^{(i)} | \mathbf{x}^{(i)} ; \theta\right)<br>$$</p></li><li><p>encourage similarity between the coarse and fine representations</p></li></ol><p>$$<br>\sum_{\mathbf{x}_{i, j} \in \mathbf{X}^{s}}\left|f_{c}\left(\mathbf{x}_{i, j}\right)-f_{f}\left(\mathbf{x}_{i, j}\right)\right|_{2}^{2}<br>$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-Dynamic-Capacity-Networks&quot;&gt;&lt;a href=&quot;#1️⃣-Dynamic-Capacity-Networks&quot; class=&quot;headerlink&quot; title=&quot;1️⃣ Dynamic Capacity Networks&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Gumbel Softmax</title>
    <link href="http://yoursite.com/2019/05/28/gumbel-softmax/"/>
    <id>http://yoursite.com/2019/05/28/gumbel-softmax/</id>
    <published>2019-05-28T07:29:09.000Z</published>
    <updated>2019-07-16T00:34:11.969Z</updated>
    
    <content type="html"><![CDATA[<p>在PAG里发现了Gumbel Sampling Trick，把离散的采样过程用公式表达出来，于是可以放进神经网络中进行求导和反向，觉得是很有意思的工作，想要多加深一些了解。</p><h3 id="问题引入"><a href="#问题引入" class="headerlink" title="问题引入"></a>问题引入</h3><p>通过<a href="https://www.cnblogs.com/initial-h/p/9468974.html" target="_blank" rel="external">博客</a>入了一下小门，结合<a href="https://www.zhihu.com/question/62631725/answer/201338234" target="_blank" rel="external">知乎</a>，首先来理解一下Gumbel Sampling Trick用来做什么。</p><blockquote><p>已知一个离散随机变量X的分布，我们想得到一些服从这个分布的离散的x的值。</p></blockquote><p>比较简单的方法是用<code>np.random.choice</code>。比如我们现在有5个值，概率分布是<code>[0.1, 0, 0.3, 0.6, 0]</code>，即第4个元素最有可能被采样到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">5</span>, <span class="number">3</span>, p=[<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0</span>])</div><div class="line">array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>])</div></pre></td></tr></table></figure><p>这样我们是获取到了值，但是这个过程在神经网络中无法求导和方向。于是gumbel-max出现了：</p><blockquote><p>将采样的过程公式化，公式中的参数为离散随机变量的概率分布。</p></blockquote><p>$$<br>z_{i}=\left\{\begin{array}{l}{1, i=\operatorname{argmax}_{j}\left(\log \left(p_{j}\right)+g_{j}\right)} \\ {0, \text { otherwise }}\end{array}\right.<br>$$</p><p>其中$g_{i}$代表gumbel噪声，$g_{i}=-\log \left(-\log \left(u_{i}\right)\right), u_{i} \sim U n i f o r m(0,1)$。输出$z_i$是一个$j$维的one-hot向量。</p><p>由于argmax不可导，用可导的softmax替代argmax<br>$$<br>\boldsymbol{z}=\operatorname{softmax}((\log (\boldsymbol{p})+\boldsymbol{g}) / \tau)<br>$$<br>参数$ \tau$越小，$z$越接近one-hot向量。</p><blockquote><p>我们把不可导的采样过程，从x本身转嫁到了求取x的公式中的一项g上面，而g不依赖于概率分布p。这样一来，x对p仍然是可导的，而我们得到的x仍然是离散值的采样。这样的采样过程转嫁的技巧叫再参化技巧(reparameterization trick)</p></blockquote><p>那么网络有哪些地方需要采样呢？接下来了解一下VAE的相关应用。</p><h3 id="相关应用"><a href="#相关应用" class="headerlink" title="相关应用"></a>相关应用</h3><p><strong>变分自动编码器VAE</strong></p><p><a href="http://kvfrans.com/variational-autoencoders-explained/" target="_blank" rel="external">这篇博客</a> 解释得很好，自动编码器由编码器(encoder, E)和解码器(decoder, D)构成，E对输入图像进行编码，生成隐向量， D对隐向量进行解码，输出图像。</p><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165000500-1207992534.jpg" alt="img"></p><p>但是这样我们必须通过图像来生成隐向量，局限性较大，可不可以随便来一个隐向量，输入进D就能生成图片呢？于是VAE就出现了。</p><blockquote><p>限制编码器生成服从单元高斯分布的隐向量。</p></blockquote><p>因此学习目标就可以分为两部分：1）生成图像和真实图像尽可能接近； 2）隐变量服从单元高斯分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">generation_loss = mean(square(generated_image - real_image))  </div><div class="line">latent_loss = KL-Divergence(latent_variable, unit_gaussian)  </div><div class="line">loss = generation_loss + latent_loss</div></pre></td></tr></table></figure><p>为了优化KL散度，需要引入👆🏻提到过的再参化技巧。</p><blockquote><p>E不直接生成隐向量，而是生成一个均值向量和一个方差向量。再通过均值和方差采样出隐向量。</p></blockquote><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165407236-1369432498.png" alt="img"> </p><p>至此我们明白了<strong>采样</strong>是为了让数据尽可能服从某一分布，通过<strong>再参化技巧</strong>来学习这个分布的参数。高斯分布是连续的，直接可求导，那一些不连续的离散分布怎么办呀？这就回到了一开始的问题「Gumbel Sampling Trick」。</p><p><strong>分类再参化(Categorical reparameterization)</strong></p><p>ICLR 2017的<a href="https://arxiv.org/pdf/1611.01144.pdf" target="_blank" rel="external">这篇文章</a> 就利用Gumbel-Softmax分布，将离散的分类概率分布采样过程转化为了可求导的过程。</p><p><img src="https://i.loli.net/2019/05/30/5cef4476d308a17728.png" alt=""></p><p>上图反映了参数$ \tau$对连续概率分布(a)和离散的one-hot类别分布的影响。当$ \tau$太小时会导致梯度的方差过大，所以文章在实验中用了退火的策略来逐渐减小参数$ \tau$。还可以利用熵正则来学习$\tau$，自动调整Gumbel-Softmax分布采样的置信度。</p><p>本文的训练过程采用Straight-Through (ST) Gumbel Estimator，即前向用argmax，梯度回传时用softmax的梯度。</p><p><strong>参考链接：</strong></p><ul><li><p><a href="https://www.cnblogs.com/initial-h/p/9468974.html" target="_blank" rel="external">Gumbel-Softmax Trick和Gumbel分布</a></p></li><li><p><a href="https://lips.cs.princeton.edu/the-gumbel-max-trick-for-discrete-distributions/" target="_blank" rel="external">The Gumbel-Max Trick for Discrete Distributions</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在PAG里发现了Gumbel Sampling Trick，把离散的采样过程用公式表达出来，于是可以放进神经网络中进行求导和反向，觉得是很有意思的工作，想要多加深一些了解。&lt;/p&gt;
&lt;h3 id=&quot;问题引入&quot;&gt;&lt;a href=&quot;#问题引入&quot; class=&quot;headerlin
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>weekly-paper-04</title>
    <link href="http://yoursite.com/2019/05/25/weekly-paper-04/"/>
    <id>http://yoursite.com/2019/05/25/weekly-paper-04/</id>
    <published>2019-05-25T08:30:05.000Z</published>
    <updated>2019-05-27T12:12:52.191Z</updated>
    
    <content type="html"><![CDATA[<p>为了锻炼自己的英语写作能力，以后尽量用英文做进行归纳（⌘+C &amp; ⌘+V）～</p><h3 id="1️⃣-To-prune-or-not-to-prune-exploring-the-efficacy-of-pruning-for-model-compression"><a href="#1️⃣-To-prune-or-not-to-prune-exploring-the-efficacy-of-pruning-for-model-compression" class="headerlink" title="1️⃣ To prune, or not to prune: exploring the efficacy of pruning for model compression"></a>1️⃣ To prune, or not to prune: exploring the efficacy of pruning for model compression</h3><p>这篇是TensorFlow自己出的，直接在训练过程中融合L1剪枝。通过将操作融入TensoFlow的training graph，在训练过程中对权重进行排序，用一个mask将最小的weights置0。从inital sparsity values $s_i$开始，以$\Delta t$ 的剪枝频率，最终达到final sparsity value $s_f$<br>$$<br>s_{t}=s_{f}+\left(s_{i}-s_{f}\right)\left(1-\frac{t-t_{0}}{n \Delta t}\right)^{3} \text { for } t \in\left\{t_{0}, \quad t_{0}+\Delta t, \ldots, t_{0}+n \Delta t\right\}<br>$$<br>masks每隔$\Delta t$更新一次，直到达到$s_f$后不再更新。同时文章表明，$n$的选择与学习率的下降策略密切相关。</p><h3 id="2️⃣-OBJECT-DETECTORS-EMERGE-IN-DEEP-SCENE-CNNS"><a href="#2️⃣-OBJECT-DETECTORS-EMERGE-IN-DEEP-SCENE-CNNS" class="headerlink" title="2️⃣ OBJECT DETECTORS EMERGE IN DEEP SCENE CNNS"></a>2️⃣ OBJECT DETECTORS EMERGE IN DEEP SCENE CNNS</h3><p>📍<a href="https://github.com/metalbubble/cnnvisualizer" target="_blank" rel="external">Github Repo</a></p><p><strong>Contributions</strong></p><ul><li>object detection emerges inside a CNN trained to recognize scenes, even more than when trained with ImageNet</li><li>the same network can do both object localization and scene recognition in a single forward-pass.</li></ul><p><strong>Experiments</strong></p><ul><li><p>identify the differences in the type of images preferred at the different layers of each network</p></li><li><p>Places-CNN and ImageNet-CNN  prefer similar images in the earlier layers, while the later layers tend to be more specialized to the specific task of scene or object categorization.</p></li><li><p>understand the nature of the representation that the network is learning</p><ul><li><em>simplifying the input images:</em> 1) removing segments from the image to produce the smallest decrease of the correct classification score until the image is incorrectly classified 2) generate the minimal image representations using image set of SUN database. =&gt; use minimal image representations as inputs to show the contribute important information for the network to recognize the scene.</li><li><em>visualize the receptive fields (RFs) of units and their activatoin patterns:</em> use sliding-window to identify which regions of the image led to the high unit activations. =&gt; as the layers go deeper the RF size gradually increases and the activation regions become more semantically meaningful.</li><li><em>understan and quantify the precise semantic learnd by each unit: </em>ask AMT to indentify the common concepts that exists between the top scoring segmentations for each unit.</li></ul></li><li><p>emergence of objects as the internal representation</p><ul><li><p>what object classes emerge? =&gt; use pool5 to show the distribution of objects</p></li><li><p>why do those obejcts emerge? </p><ul><li><p>possibility 1:  the objects correspond to the most frequent ones in the database. (correlation is 0.54)</p></li><li><p>possibility 2:  the objects that allow discriminatin among scene categories. (correlation is 0.84)</p><p>=&gt; the network is automatically identifying the most discriminative object categories to a large extent</p></li></ul></li></ul></li></ul><h3 id="3️⃣-Network-Dissection-Quantifying-Interpretability-of-Deep-Visual-Representations"><a href="#3️⃣-Network-Dissection-Quantifying-Interpretability-of-Deep-Visual-Representations" class="headerlink" title="3️⃣ Network Dissection: Quantifying Interpretability of Deep Visual Representations"></a>3️⃣ Network Dissection: Quantifying Interpretability of Deep Visual Representations</h3><p>📍<a href="https://github.com/CSAILVision/NetDissect-Lite" target="_blank" rel="external">Github Repo</a></p><p><strong>Questions</strong></p><ul><li>What is a disentangled representation, and how can its factors be quantified and detected?</li><li><p>Do interpretable hidden units reflect a special alignment of feature space, or are interpretations a chimera?</p></li><li><p>What conditions in state-of-the-art training lead to representations with greater or lesser entanglement?</p></li></ul><p><strong>Measurement of interpretability: three-step process of Network Dissection</strong></p><ol><li><p>Identify a broad set of human-labeld visual concepts.</p></li><li><p>Gather hidden variables’ response to known concepts.</p><ul><li>draw concepts $c$ from the Broden dataset.</li></ul></li><li><p>Quantify alignment of hidden variable — concept pairs.</p><ul><li><p>Scoring Unit Interpretability</p><p>input image $x$, activation map $A_{k}(\mathbf{x}) \stackrel{scale up}{\longrightarrow}S_k(x) $，individual unit activations $a_k$</p><p>top quantile level $T_k$： $P\left(a_{k}&gt;T_{k}\right)=0.005$</p><p>binary segmentation：$M_{k}(\mathbf{x}) \equiv S_{k}(\mathbf{x}) \geq T_{k}$</p><p>input annotaion mask $L_c$ </p><p>score：the accuracy of unit $k$ in detecting concept $c$<br>$$<br>I o U_{k, c}=\frac{\sum\left|M_{k}(\mathbf{x}) \cap L_{c}(\mathbf{x})\right|}{\sum\left|M_{k}(\mathbf{x}) \cup L_{c}(\mathbf{x})\right|}<br>$$</p></li></ul></li></ol><h3 id="4️⃣-Pixel-wise-Attentional-Gating-for-Scene-Parsing"><a href="#4️⃣-Pixel-wise-Attentional-Gating-for-Scene-Parsing" class="headerlink" title="4️⃣ Pixel-wise Attentional Gating for Scene Parsing"></a>4️⃣ Pixel-wise Attentional Gating for Scene Parsing</h3><p><strong>Contributions:</strong></p><ul><li>Dynamic computation depth: insert PAG at multiple lyaers of ResNet to control computational parsimony.</li><li>Dynamic spatial pooling: adaptively chooses the proper pooling size for each pixel to aggregate information for inference.</li><li>Experimetns on various pixel labeling tasks, including semantic segmentation, boundary detection, monocular depth and surface normal estimation.</li></ul><p><img src="https://i.loli.net/2019/05/27/5ceb52642beaa24177.png" alt=""></p><p>binary spatial mask $\mathbf{G}$ on ResBottleneck:<br>$$<br>\begin{array}{ll}{\mathbf{X}=\mathcal{F}^{1}(\mathbf{I})} &amp; {\mathbf{X}=\mathcal{F}^{1}(\mathbf{I}), \mathbf{G}=\mathcal{G}(\mathbf{I})} \\ {\mathbf{Y}=\mathcal{F}^{2}(\mathbf{X})} &amp; {\mathbf{Y}=\mathcal{F}_{\mathbf{G}}^{2}(\mathbf{X})} \\ {\mathbf{Z}=\mathcal{F}^{3}(\mathbf{Y})} &amp; {\mathbf{Z}=\mathcal{F}_{\mathbf{G}}^{3}(\overline{\mathbf{G}} \odot \mathbf{X}+\mathbf{G} \odot \mathbf{Y})} \\ {\mathbf{O}=\mathbf{I}+\mathbf{Z}} &amp; {\mathbf{O}=\mathbf{I}+\mathbf{Z}}\end{array}<br>$$<br><strong>Methods:</strong></p><ul><li><p>Learning attention maps</p><blockquote><p>The key to the proposed PAG is the gating function G that produces a discrete (binary) mask which allows for reduced computation. However, producing the binary mask using hard thresholding is non-differentiable, and thus cannot be simply incorporated in CNN where gradient descent is used for training. To bridge the gap, we exploit the Gumbel-Max trick [19] and its recent continuous relaxation [39, 28].</p></blockquote><p>Gumbel distribution  $m \equiv-\log (-\log (u))$, where $u \sim \mathcal{U}[0,1]$</p><p>$g$ is a discrete random variable with probabilities  $P(g=k) \propto a_{k}$</p><p>$\left\{m_{k}\right\}_{k=1, \dots, K}$ is a sequence of i.i.d Gumbel random variables </p><p>sample from the discrete variable:<br>$$<br>g=\underset{k=1, \ldots, K}{\operatorname{argmax}}\left(\log \alpha_{k}+m_{k}\right)<br>$$<br>Gumbel Sampling Trick (replaces the argmax operation with a softmax): </p></li></ul><p>$$<br>\mathbf{g}=\operatorname{softmax}((\log (\boldsymbol{\alpha})+\mathbf{m}) / \tau)<br>$$</p><p>​        <strong>forwardd pass</strong>: discrete smaples of the argmax </p><p>​        <strong>backward pass</strong>: compute gradient of the softmax relaxation</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;为了锻炼自己的英语写作能力，以后尽量用英文做进行归纳（⌘+C &amp;amp; ⌘+V）～&lt;/p&gt;
&lt;h3 id=&quot;1️⃣-To-prune-or-not-to-prune-exploring-the-efficacy-of-pruning-for-model-compressi
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.03</title>
    <link href="http://yoursite.com/2019/05/19/weekly-paper-03/"/>
    <id>http://yoursite.com/2019/05/19/weekly-paper-03/</id>
    <published>2019-05-19T13:09:17.000Z</published>
    <updated>2019-05-23T10:42:12.181Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse-Decomposition"><a href="#1️⃣-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse-Decomposition" class="headerlink" title="1️⃣ On Compressing Deep Models by Low Rank and Sparse Decomposition"></a>1️⃣ On Compressing Deep Models by Low Rank and Sparse Decomposition</h3><p>本文将网络权重分解成低秩和稀疏的成分，利用贪心双边分解（GreBdec）算法进行模型压缩。</p><p>目标函数：<br>$$<br>\begin{array}{cl}{\min _{L, S}} &amp; {\frac{1}{2}|W-L-S|_{F}^{2}} \\ {\text {s.t.}} &amp; {\operatorname{rank}(L) \leq r} \\ &amp;card(S) \leq c \end{array}<br>$$<br>假设$L=UV$，其中$U \in R^{m \times r}, V \in R^{r \times k}$。本文用两个卷积层进行低秩近似，$V$将通道数映射到$r$，$U$代表$1\times1$卷积。然后把低秩近似的结果和稀疏的结果相加利用mask乘到原filters上，修改目标函数：<br>$$<br>\begin{array}{cl}{\min _{L, S}} &amp; {\frac{1}{2 n}|Y-(L+S) X|_{F}^{2}} \\ {\text {s.t.}} &amp; {\frac{1}{2}|W-L-S|_{F}^{2} \leq \gamma} \\ &amp; rank(L) \leq r, \\ &amp; card(S) \leq c.\end{array}<br>$$<br>等同于利用迭代优化策略优化目标函数：<br>$$<br>\frac{1}{2 n}|Y-(L+S) X|_{2}^{2}+\frac{\lambda}{2}|W-L-S|_{F}^{2}<br>$$<br>其中<br>$$<br>\left\{\begin{array}{l}{L_{i}=\text { TruncatedGSVD }\left(B_{i} A^{\dagger}, r\right)} \\ {S_{i}=P_{\Omega}(M), \text { and } M=S_{i-1}-\eta\left(A S_{i-1}-C_{i}\right)}\end{array}\right.<br>$$<br>本文用SVD-free的GreBdec算法进行优化，令$L=UV$<br>$$<br>\begin{array}{cl}{\min _{U, V, S}} &amp; {\frac{1}{2 n}|Y-(U V+S) X|_{F}^{2}+\frac{\lambda}{2}|W-U V-S|_{F}^{2}} \\ {\text {s.t.}} &amp; {\operatorname{card}(S) \leq c}\end{array}<br>$$<br>$U,V,S$通过以下公式更新：<br>$$<br>\left\{\begin{array}{l}{U_{i}=B_{i} V_{i-1}^{\top}\left(V_{i-1} A V_{i-1}^{\top}\right)^{\dagger}} \\ {V_{i}=\left(U_{i}^{\top} U_{i}\right)^{\dagger} U_{i}^{\top}\left(B_{i} A^{\dagger}\right)} \\ {S_{i}=P_{\Omega}(M), \text { and } M=S_{i-1}-\eta\left(A S_{i-1}-C_{i}\right)}\end{array}\right.<br>$$<br>然后又经过一番变换作者利用QR分解得到一个让$U,V$更快更新的规则：<br>$$<br>\left\{\begin{array}{l}{U_{i}=Q, Q R\left(B_{i} V^{\top}\right)=Q R} \\ {V_{i}=Q^{\top}\left(B_{i} A^{\dagger}\right)}\end{array}\right.<br>$$<br><img src="https://i.loli.net/2019/05/20/5ce2015dee80b29804.png" alt=""></p><p>###2️⃣ Spatial Transformer Networks</p><p>对输入图像进行空间上的变换，以学到图像的不变性(invariance)。配合<a href="https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html" target="_blank" rel="external">PyTorch Tutorial</a>食用。</p><p><img src="https://i.loli.net/2019/05/23/5ce663632bbf215753.png" alt=""></p><p>STN也类似一个插件，主要由两个模块组成：</p><ul><li>Localisation net：输入feature map $U \in \mathbb{R}^{H \times W \times C}$，输出变换参数$\theta=f_{\mathrm{loc}}(U)$。其中$\theta$是一个6维的仿射变换。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Spatial transformer localization-network</span></div><div class="line">self.localization = nn.Sequential(</div><div class="line">nn.Conv2d(<span class="number">1</span>, <span class="number">8</span>, kernel_size=<span class="number">7</span>),</div><div class="line">  nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</div><div class="line">  nn.ReLU(<span class="keyword">True</span>),</div><div class="line">  nn.Conv2d(<span class="number">8</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>),</div><div class="line">  nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</div><div class="line">  nn.ReLU(<span class="keyword">True</span>)</div><div class="line">)</div></pre></td></tr></table></figure><ul><li>Grid generator：对图像用$A_\theta$进行2D仿射变换，其中$(x_i^t, y_I^t)$为target像素点坐标，$\left(x_{i}^{s}, y_{i}^{s}\right)$为source采样点的坐标。</li></ul><p>$$<br>\left( \begin{array}{c}{x_{i}^{s}} \\ {y_{i}^{s}}\end{array}\right)=\mathcal{T}_{\theta}\left(G_{i}\right)=\mathrm{A}_{\theta} \left( \begin{array}{c}{x_{i}^{t}} \\ {y_{i}^{t}} \\ {1}\end{array}\right)=\left[ \begin{array}{ccc}{\theta_{11}} &amp; {\theta_{12}} &amp; {\theta_{13}} \\ {\theta_{21}} &amp; {\theta_{22}} &amp; {\theta_{23}}\end{array}\right] \left( \begin{array}{c}{x_{i}^{t}} \\ {y_{i}^{t}} \\ {1}\end{array}\right)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Regressor for the 3 * 2 affine matrix</span></div><div class="line">self.fc_loc = nn.Sequential(</div><div class="line">  nn.Linear(<span class="number">10</span> * <span class="number">3</span> * <span class="number">3</span>, <span class="number">32</span>),</div><div class="line">  nn.ReLU(<span class="keyword">True</span>),</div><div class="line">  nn.Linear(<span class="number">32</span>, <span class="number">3</span> * <span class="number">2</span>)</div><div class="line">)</div></pre></td></tr></table></figure><p>为了在$U$上应用空间变换输出$V$，需要一个可导的采样函数生成采样点$\mathcal{T}_\theta(G)$。<br>$$<br>V_{i}^{c}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} k\left(x_{i}^{s}-m ; \Phi_{x}\right) k\left(y_{i}^{s}-n ; \Phi_{y}\right) \forall i \in\left[1 \ldots H^{\prime} W^{\prime}\right] \forall c \in[1 \ldots C]<br>$$<br>其中$k$为sampling kernel，可以定义为integer sampling kernel:<br>$$<br>V_{i}^{c}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} \delta\left(\left\lfloor x_{i}^{s}+0.5\right\rfloor- m\right) \delta\left(\left\lfloor y_{i}^{s}+0.5\right\rfloor- n\right)<br>$$<br>也可以定义为bilinear sampling kernel：<br>$$<br>V_{i}^{c}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} \max \left(0,1-\left|x_{i}^{s}-m\right|\right) \max \left(0,1-\left|y_{i}^{s}-n\right|\right)<br>$$<br>对输入求偏导有：<br>$$<br>\frac{\partial V_{i}^{c}}{\partial x_{i}^{s}}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} \max \left(0,1-\left|y_{i}^{s}-n\right|\right) \left\{\begin{array}{ll}{0} &amp; {\text { if }\left|m-x_{i}^{s}\right| \geq 1} \\ {1} &amp; {\text { if } m \geq x_{i}^{s}} \\ {-1} &amp; {\text { if } m<x_{i}^{s}}\end{array}\right. $$="" 把<em="">localisation network, grid generator, sampler结合起来构成一个STN模块：</x_{i}^{s}}\end{array}\right.></p><p><strong>STN</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Spatial transformer network forward function</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stn</span><span class="params">(self, x)</span>:</span></div><div class="line">  xs = self.localization(x)</div><div class="line">  xs = xs.view(<span class="number">-1</span>, <span class="number">10</span> * <span class="number">3</span> * <span class="number">3</span>)</div><div class="line">  theta = self.fc_loc(xs)</div><div class="line">  theta = theta.view(<span class="number">-1</span>, <span class="number">2</span>, <span class="number">3</span>)</div><div class="line"></div><div class="line">  grid = F.affine_grid(theta, x.size())</div><div class="line">  x = F.grid_sample(x, grid)</div><div class="line"></div><div class="line">  <span class="keyword">return</span> x</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse-Decomposition&quot;&gt;&lt;a href=&quot;#1️⃣-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>HEXO主题cactus修改</title>
    <link href="http://yoursite.com/2019/05/19/hexo-theme-cactus/"/>
    <id>http://yoursite.com/2019/05/19/hexo-theme-cactus/</id>
    <published>2019-05-19T03:05:14.000Z</published>
    <updated>2019-05-19T08:55:36.409Z</updated>
    
    <content type="html"><![CDATA[<p>cacuts的主题很简洁，用得蛮久，看到原库有更新，所以fork了新的版本并在上面做一些修改，顺便记录一下过程。</p><h3 id="主题镜像"><a href="#主题镜像" class="headerlink" title="主题镜像"></a>主题镜像</h3><p>首先根据<a href="https://help.github.com/en/articles/duplicating-a-repository" target="_blank" rel="external">Mirrow a repository</a>镜像一个库。在push的时候还遇到了403问题：</p><blockquote><p>remote: Permission to colorjam/hexo-theme-cactus-mirrored.git denied to xxx</p></blockquote><p>通过删除<strong>Keychain Access</strong>中存储的github.com的Internet password得到解决。然后把自己的库再Clone进<code>themes</code>中</p><h3 id="样式编辑"><a href="#样式编辑" class="headerlink" title="样式编辑"></a>样式编辑</h3><ul><li><p>主题颜色</p><p>在<code>source/css/_colors</code>下新建了一个<code>pink.styl</code>，同时修改<code>_config.yml</code>中的<code>colorscheme:pink</code>。</p></li><li><p>logo设置</p><p>把<code>source/images/</code>下的<code>favicon.ico</code>和<code>logo.png</code>换成自己喜欢的图片。修改<code>source/css/_partial/header.styl</code>中的<code>#logo</code> 的<code>background-size: contain</code></p></li><li><p>细节调整</p><p>删除<code>header.styl</code>中html的<code>border-top</code></p><p>链接样式：</p></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">a</span></div><div class="line">  color: $color-text</div><div class="line">  <span class="selector-tag">text-decoration</span>: <span class="selector-tag">none</span></div><div class="line"></div><div class="line">  &amp;<span class="selector-pseudo">:hover</span></div><div class="line">  background-image: linear-gradient(transparent, transparent 4px, $color-link 4px, $color-link)</div><div class="line">  <span class="selector-tag">background-position</span>: <span class="selector-tag">bottom</span></div><div class="line">  <span class="selector-tag">background-size</span>: 100% 6<span class="selector-tag">px</span></div><div class="line">  <span class="selector-tag">background-repeat</span>: <span class="selector-tag">repeat-x</span></div></pre></td></tr></table></figure><p>​    行内代码样式：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">code</span></div><div class="line">  <span class="selector-tag">padding</span>: 0 5<span class="selector-tag">px</span></div><div class="line">  <span class="selector-tag">background</span>: <span class="selector-id">#f6f8fa</span></div><div class="line">  <span class="selector-tag">border-radius</span>: 2<span class="selector-tag">px</span></div><div class="line">  <span class="selector-tag">-webkit-border-radius</span>: 2<span class="selector-tag">px</span></div></pre></td></tr></table></figure><h3 id="会动的粒子"><a href="#会动的粒子" class="headerlink" title="会动的粒子"></a>会动的粒子</h3><p>在背景加上<a href="https://github.com/VincentGarreau/particles.js/" target="_blank" rel="external">会动的粒子</a>，在<code>source/lib</code>里创建一个particles文件夹，把<code>particles.min.js</code>放进去。</p><p>在<code>layout.ejs</code>中加入</p><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"particles-js"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div></pre></td></tr></table></figure><p>在<code>scripts.ejs</code>中添加脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&lt;!-- particles --&gt;</div><div class="line">&lt;%- js(&apos;lib/particles/particles.min&apos;) %&gt;</div><div class="line">&lt;script type=&quot;text/javascript&quot;&gt;</div><div class="line">particlesJS(&apos;particles-js&apos;, &#123;</div><div class="line">        ...</div><div class="line">        &#125;</div><div class="line">      )</div><div class="line">&lt;/script&gt;</div></pre></td></tr></table></figure><p>在<code>style.css</code>中添加样式：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="selector-id">#particles-js</span> &#123;</div><div class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</div><div class="line">  <span class="attribute">position</span>: absolute;</div><div class="line">  <span class="attribute">margin-left</span>: -<span class="number">28%</span>;</div><div class="line">  <span class="attribute">z-index</span>: -<span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;cacuts的主题很简洁，用得蛮久，看到原库有更新，所以fork了新的版本并在上面做一些修改，顺便记录一下过程。&lt;/p&gt;
&lt;h3 id=&quot;主题镜像&quot;&gt;&lt;a href=&quot;#主题镜像&quot; class=&quot;headerlink&quot; title=&quot;主题镜像&quot;&gt;&lt;/a&gt;主题镜像&lt;/h3&gt;&lt;
      
    
    </summary>
    
    
      <category term="维修指南" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow内存泄漏</title>
    <link href="http://yoursite.com/2019/05/18/tf-memory-leak/"/>
    <id>http://yoursite.com/2019/05/18/tf-memory-leak/</id>
    <published>2019-05-18T05:13:31.000Z</published>
    <updated>2019-05-19T06:54:57.626Z</updated>
    
    <content type="html"><![CDATA[<p>用tf经常会出现OOM的现象，查了一下发现了一篇文章<a href="https://dantkz.github.io/How-To-Debug-A-Memory-Leak-In-TensorFlow/" target="_blank" rel="external">How To Debug A Memory Leak In Tensorflow</a></p><p>由于tf存在内存泄漏问题，许多人会用 <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html" target="_blank" rel="external">tcmalloc</a> 来替代 malloc()。</p><p>但是运行程序的时候会报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ERROR: ld.so: object <span class="string">'/usr/lib/libtcmalloc.so.4'</span> from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.</div></pre></td></tr></table></figure><p>踩了一系列坑以后发现，将<code>/usr/lib/libtcmalloc.so.4</code>改为<code>/usr/local/lib/libtcmalloc.so.4</code>即可。</p><p><strong>参考链接：</strong></p><ul><li><a href="https://www.cnblogs.com/Lelouch/p/3365672.html" target="_blank" rel="external">https://www.cnblogs.com/Lelouch/p/3365672.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;用tf经常会出现OOM的现象，查了一下发现了一篇文章&lt;a href=&quot;https://dantkz.github.io/How-To-Debug-A-Memory-Leak-In-TensorFlow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;How
      
    
    </summary>
    
    
      <category term="维修指南" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>pair-wise-loss</title>
    <link href="http://yoursite.com/2019/05/17/pair-wise-loss/"/>
    <id>http://yoursite.com/2019/05/17/pair-wise-loss/</id>
    <published>2019-05-17T05:44:19.000Z</published>
    <updated>2019-05-17T08:08:40.815Z</updated>
    
    <content type="html"><![CDATA[<p>用Tensorflow复现论文中的pair wise loss<br>$$<br>\ell_{p a}(\mathrm{S})=\frac{1}{\left(W^{\prime} \times H{\prime}\right)^{2}} \sum_{i \in \mathcal{R}} \sum_{j \in \mathcal{R}}\left(a_{ij}^{s}-a_{ij}^{t}\right){2}<br>$$<br>其中<br>$$<br>a_{i j}=\mathbf{f}_{i}^{\top} \mathbf{f}_{j} /\left(\left|\mathbf{f}_{i}\right|_{2}\left|\mathbf{f}_{j}\right|_{2}\right)<br>$$<br>$f_i$和$f_j$分别代表ith / jth像素点的c维特征。参考了余弦相似性的计算方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">similarity</span><span class="params">(x)</span>:</span></div><div class="line">    x = tf.reshape(x, [x.shape[<span class="number">0</span>], <span class="number">-1</span>, x.shape[<span class="number">-1</span>]])</div><div class="line">    norm = tf.nn.l2_normalize(x, <span class="number">2</span>)</div><div class="line">    a = tf.matmul(norm, norm, adjoint_b = <span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> a</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_loss</span><span class="params">(x, y)</span>:</span></div><div class="line">    _, h, w, _  = x.shape</div><div class="line">    pa = tf.reduce_sum(tf.pow((similarity(x) - similarity(y)), <span class="number">2</span>)) / tf.pow(tf.cast(h*w, tf.float32),<span class="number">2</span>)</div><div class="line">    <span class="keyword">return</span> pa</div></pre></td></tr></table></figure><p>参考链接：</p><ul><li><a href="https://stackoverflow.com/questions/48485373/pairwise-cosine-similarity-using-tensorflow?rq=1" target="_blank" rel="external">https://stackoverflow.com/questions/48485373/pairwise-cosine-similarity-using-tensorflow?rq=1</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;用Tensorflow复现论文中的pair wise loss&lt;br&gt;$$&lt;br&gt;\ell_{p a}(\mathrm{S})=\frac{1}{\left(W^{\prime} \times H{\prime}\right)^{2}} \sum_{i \in \mathc
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>每周论文 Vol.02</title>
    <link href="http://yoursite.com/2019/05/13/weekly-paper-02/"/>
    <id>http://yoursite.com/2019/05/13/weekly-paper-02/</id>
    <published>2019-05-13T02:50:43.000Z</published>
    <updated>2019-05-19T04:29:39.092Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1️⃣-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATION"><a href="#1️⃣-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATION" class="headerlink" title="1️⃣ ON THE IMPORTANCE OF SINGLE DIRECTIONS FOR GENERALIZATION"></a>1️⃣ ON THE IMPORTANCE OF SINGLE DIRECTIONS FOR GENERALIZATION</h3><p>在《Revisiting the Importance of Individual Units in CNNs via Ablation》的基础上看了这篇论文。</p><p>本文探究的是激活值的单方向依赖对网络泛化性能的影响，通过对units进行抑制/加噪声，表示网络对单反向的依赖能较好的预测其泛化性能。文章讲了一个故事，一个网络只通过记忆每张输入和其对应的输出，泛化性差(memorizing network)，另一个网络能够找到数据中的结构性，泛化性佳(structure-finding network)。memorizing network找到的最小描述长度应该大于structure-finding network。因此，memorizing network会使用更多的单反向，那么，如果随机扰乱单一方向，对memorizing network的影响应该大于structure-finding network。</p><p>通过对dropout和BN实验（两个方法都增强了网络的泛化性），表明尽管dropout能在一定程度上避免记忆随机标签，但不能避免训练过程中的过度单方向依赖。加了BN的网络进行神经元抑制时，训练精度会降得比较慢，说明BN也不鼓励单方向依赖。</p><p>接着文章验证了class selectivity与神经元重要性的关系。提出了两个问题：</p><ol><li><p>BN不鼓励单方向依赖，那么是否会影响单反向的类别信息分布？</p><p>文章使用class selectivity来衡量类别信息分布，high class selectivity说明关注的是单一类别，low class selectivity说明关注的是多个类别。没有BN的网络反而显示出更高的class selectivity。表明BN层鼓励feature map去学习多种类别的信息，而不是关注单一类别。</p></li><li><p>是否能够利用unit的class selectivity，判断unit的重要性？</p><p>文章发现class selectivity和网络浅层的feature map负相关，与网络深层则无关。作者利用互信息也做了相同的实验。得到一致的结果。以此说明class selectiviy并不能代表unit的重要性。</p></li></ol><blockquote><p>🧐 本文的结论是紧凑网络对单方向的依赖性较少，那么如何找到一个衡量unit方向性的函数，来进行网络压缩呢？</p></blockquote><h3 id="2️⃣-MaskConnect-Connectivity-Learning-by-Gradient-Descent"><a href="#2️⃣-MaskConnect-Connectivity-Learning-by-Gradient-Descent" class="headerlink" title="2️⃣  MaskConnect: Connectivity Learning by Gradient Descent"></a>2️⃣  MaskConnect: Connectivity Learning by Gradient Descent</h3><p>用梯度下降自动学习连接。和网络权重一起学习<em>connectivity masks</em>，来决定网络block之间的连接。</p><p>第$j$个block的输入可以由前面所有输出相加而成，用二值的$m$表示是否连接：<br>$$<br>\mathbf{x}_{j}=\sum_{k=1}^{j-1} m_{j, k} \cdot \mathbf{y}_{k}<br>$$<br>本文表示每个block只和$K$个连接效果最好：<br>$$<br>m_{j, k} \in\{0,1\} \forall j, k, \quad and \quad \sum_{k=1}^{j-1} m_{j, k}=K \forall j<br>$$<br>🔺 训练过程：</p><p><strong>Forward Propagation</strong>. 限制实值的mask的和为1，即$\sum_{k=1}^{j-1} \tilde{m}_{j, k}=1$，代表一个多项式分布，从中采样K个样本$a_{1}, a_{2}, \ldots, a_{K} \in\{1, \ldots,(j-1)\}$，激活对应的mask $m_{j, a_{k}} \leftarrow 1$。</p><p><strong>Backward Propagation.</strong> 第$k$个block输出的梯度通过二值$m_{j,k}$和$x_j$的梯度获得。</p><p><strong>Mask Update.</strong> 通过clip实值mask，限制它们在[0,1]的范围。</p><p>🔺 训练结束：</p><p>（1）为每个$m_j$激活$\tilde{m}_{j}$中top-K的连接，</p><p>（2）固定二值mask，ft网络权重$\theta$</p><blockquote><p>🧐 本文算是NAS的分支吧，搜索的只是网络块之间的连接。每个block有一个多项式分布，代表它与之前所有block连接的概率，从这个分布中采样激活的连接。结合我想做的东西，<strong>根据不同的输入图片选择不同的block</strong>，每个block的输出为一个num_classes的分布，每个元素代表某个类激活这个block概率，利用这个概率进行二项式分布的采样。</p></blockquote><h3 id="3️⃣-MODEL-COMPRESSION-VIA-DISTILLATION-AND-QUANTIZATION"><a href="#3️⃣-MODEL-COMPRESSION-VIA-DISTILLATION-AND-QUANTIZATION" class="headerlink" title="3️⃣ MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION"></a>3️⃣ MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION</h3><p>本文提出了两个压缩方法：1.<em> quantized distillation</em>：利用蒸馏训练权重是量化的小网络。 2. <em>differentiable quantization</em>：通过梯度下降优化量化点的位置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1️⃣-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATION&quot;&gt;&lt;a href=&quot;#1️⃣-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATI
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="每周论文" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Revisiting the Importance of Individual Units in CNNs via Ablation</title>
    <link href="http://yoursite.com/2019/05/12/Revisiting%20the%20Importance%20of%20Individual%20Units%20in%20CNNs%20via%20Ablation/"/>
    <id>http://yoursite.com/2019/05/12/Revisiting the Importance of Individual Units in CNNs via Ablation/</id>
    <published>2019-05-12T05:51:59.000Z</published>
    <updated>2019-05-19T09:48:53.400Z</updated>
    
    <content type="html"><![CDATA[<p>之前的一些工作通过可视化每个神经元的方式来理解神经网络，它们选择的是<em>high selectivity</em>的神经元，发现网络浅层识别的是具体的图案（e.g 纹理、图像），网络深层识别的是语义信息（e.g 狗头、车轮），论文[11]似乎打脸了这种方式，表明对于代表整体分类精度，<em>class selectivity</em>属性不能用来预测神经元的重要性。</p><p>本文表明这两种方式都是合理的。用<em>class selectivity</em>或其他属性来预测神经元的重要性从整体分类精度（网络的泛化性）上来看确实不好，但是能作为具体类别的判断依据。</p><p><strong>抑制神经元的方式</strong>：将其weight和bias设置成0。</p><p><strong>两种精度下降类型：</strong>overall accuracy drop &amp; max class accuracy drop</p><p><strong>判断神经元重要性的属性：</strong></p><ul><li><p>L1 Norm：<br>$$<br>\operatorname{norm}_{1}(i)=\left|w_{i}\right|_{1}=\sum_{j}\left|\left(w_{i}\right)_{j}\right|<br>$$</p></li><li><p>Class Correlation：<br>$$<br>\operatorname{corr}(i, k)=\frac{E\left[\left(x_{i}-\overline{x}_{i}\right)\left(p_{k}-\overline{p}_{k}\right)\right]}{\sigma_{x_{i}} \sigma_{p_{k}}}<br>$$</p></li><li><p>Class Selectivity：</p></li></ul><p>$$<br>\operatorname{select}(i, k)=\frac{\overline{x}_{i}^{k}-\overline{x}_{i}^{-k}}{\overline{x}_{i}^{k}+\overline{x}_{i}^{-k}}<br>$$</p><p>​        其中$\overline{x}_{i}^{k}$表示神经元$i$属于kth类别的平均激活值，$\overline{x}_{i}^{-k}$表示神经元$i$属于non-kth类别的平均激活值的均值。这个值的范围是[0, 1]，0表示一个神经元的平均激活值与其他类别都相同，1表示一个神经元只对某个类别的输入有反应。</p><ul><li>Concept Alighment：IoU between unit activation and gt concepts</li><li>Unit Visualization</li></ul><p>🔺 <strong>实验一：</strong>验证抑制单个神经元/一组神经元对两种精度下降类型的影响。</p><ul><li>实验方式：<ul><li>抑制某个神经元，横轴表示CLass，纵轴表示Class Accuracy Drop。</li><li>针对特定的网络层，根据Mac Class Accuracy Drop进行排序，绘制三条曲线（Overal Accuracy Drop / Max Class Accuracy Drop / Min Class Accuracy Drop）。</li><li>利用greedy的方式迭代地移除降低特定类准确率最多的神经元。绘制了特定类别精度下降的曲线，和所有类别平均精度下降的曲线。同时用random作为baseline。</li></ul></li><li>结论：<ul><li>抑制单个神经元对某些类别的分类精度影响很大，但对总体的精度影响不大，并且能通过可视化的形式看出这些抑制的神经元确实展现出了相应类别的特点。</li><li>greedy地抑制一组神经元，能使这个类别的精度大大降低，但是random的方式影响不大。</li></ul></li></ul><p>🔺 <strong>实验二：</strong>验证不同属性与精度下降之间的关系。</p><ul><li>实验方式：<ul><li>用斯皮尔曼相关系数和P值统计了不同属性值与精度下降之间的相关性。</li><li>用不同属性判断出的最重要的那个神经元来预测分类</li></ul></li><li>结论：<ul><li>对于整体精度下降：class selectivity，class correlation和concept alighment表示出正相关，L1是负相关。也就是说，当抑制class selectivity值很大的神经元，对整体网络的精度下降影响较小，与论文[11]中结论一致。</li><li>对于最大类别精度下降：每个属性基本都表现出负相关。说明抑制这些属性值大的神经元，对特定类别精度影响很大。</li><li>Concept Alignment似乎最能代表神经元的重要性</li></ul></li></ul><p>🔺 <strong>实验三：</strong>验证选择的神经元与其方向相关，而不是随机方向。</p><p>🔺 <strong>实验四：</strong>验证BN和Dropout的影响。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前的一些工作通过可视化每个神经元的方式来理解神经网络，它们选择的是&lt;em&gt;high selectivity&lt;/em&gt;的神经元，发现网络浅层识别的是具体的图案（e.g 纹理、图像），网络深层识别的是语义信息（e.g 狗头、车轮），论文[11]似乎打脸了这种方式，表明对于代表
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
</feed>
