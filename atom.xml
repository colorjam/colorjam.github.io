<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Colorjam&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-10-16T14:16:39.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Colorjam</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Machine Learning in Action》学习笔记一</title>
    <link href="http://yoursite.com/2017/10/15/machine-learning-in-action-note1/"/>
    <id>http://yoursite.com/2017/10/15/machine-learning-in-action-note1/</id>
    <published>2017-10-15T13:58:12.000Z</published>
    <updated>2017-10-16T14:16:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>正在学习《Machine Learning in Action》，随笔记录一下，代码基本上都是跟着书本敲的，就不大量复制了，仅写一些自己的理解并对出现的问题进行整理和归纳。</p><a id="more"></a><h1 id="1-kNN分类算法"><a href="#1-kNN分类算法" class="headerlink" title="1/ kNN分类算法"></a>1/ kNN分类算法</h1><p>kNN分类算法（k-Nearest Neighbors classification algorithm）是比较简单的一种分类算法。原理是通过训练集训练出与待预测数据最接近的k个类别，这k个类别中出现最多的类即为预测结果。</p><p>🙂：准确度高／对异常值不敏感／不假设数据</p><p>🙁：计算复杂度高／占用大量内存</p><p>🛠：数值型／标称型</p><h3 id="kNN的一般流程"><a href="#kNN的一般流程" class="headerlink" title="kNN的一般流程"></a>kNN的一般流程</h3><ol><li>收集数据</li><li>准备数据：最好使用结构化数据格式，因为计算距离需要数值。</li><li>分析数据</li><li>训练算法：此步骤不适用于kNN算法</li><li>测试算法：计算错误率</li><li>使用算法：这首先需要获取一些输入数据和结构化的输出数据，然后在输入数据上运行kNN算法并判断它属于哪一类，最后对计算出的分类执行后续处理。</li></ol><h1 id="2-决策树算法"><a href="#2-决策树算法" class="headerlink" title="2/决策树算法"></a>2/决策树算法</h1><p>🙂：计算复杂度不高／便于人们理解学习结果／对中间的缺失值不敏感／可以处理无关的特征值</p><p>🙁：可能会过拟合</p><p>🛠：数值型／标称型</p><h3 id="决策树的一般流程"><a href="#决策树的一般流程" class="headerlink" title="决策树的一般流程"></a>决策树的一般流程</h3><ol><li>数据收集</li><li>准备数据：这个构造树的过程只适用于标称型数据，因此需要离散化连续的数值</li><li>分析数据</li><li>训练算法：构造一个树的数据结构</li><li>测试算法：使用经验树计算错误率</li><li>使用算法：这可以应用于任何监督学习任务。通常，决策树树可以更好的理解数据的内在含义。</li></ol><p>在treePlotter.py中发现一个神奇的地方</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotNode</span><span class="params">(nodeTxt, centerPt, parentPt, nodeType)</span>:</span></div><div class="line">    <span class="comment"># 2 Draws annotations with arrows</span></div><div class="line">    createPlot.ax.annotate(nodeTxt, xy=parentPt, xycoords=<span class="string">'axes fraction'</span>,</div><div class="line">                           xytext = centerPt, textcoords=<span class="string">'axes fraction'</span>,</div><div class="line">                           va=<span class="string">'center'</span>, ha=<span class="string">'center'</span>, bbox=nodeType, arrowprops=arrow_args)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createPlot</span><span class="params">()</span>:</span></div><div class="line">    fig = plt.figure(<span class="number">1</span>, facecolor=<span class="string">'white'</span>)</div><div class="line">    fig.clf()</div><div class="line">    createPlot.ax = plt.subplot(<span class="number">111</span>, frameon=<span class="keyword">False</span>)</div><div class="line">    plotNode(<span class="string">'a decision node'</span>, (<span class="number">.5</span>, <span class="number">.1</span>), (<span class="number">.1</span>, <span class="number">.5</span>), decisionNode)</div><div class="line">    plotNode(<span class="string">'a leaf node'</span>, (<span class="number">.8</span>, <span class="number">.1</span>), (<span class="number">.3</span>, <span class="number">.8</span>), leafNode)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p>Python中一切皆为对象，在createPlot函数中，为这个函数对象绑定了一个属性ax，变成了一个全局的变量，可以在plotNode函数中调用。</p><p>书中作者利用treePlotter中写好的树结构来进行预测，但tree.py里头不有一个createDataSet函数和createTree函数吗？尝试一下利用这两个函数来生成并预测：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">myDat, labels = createDataSet()</div><div class="line">myTree = createTree(myDat, labels)</div></pre></td></tr></table></figure><p>Buuuuuuuut……….<img src="/2017/10/15/machine-learning-in-action-note1/no_surfacing_error.png" alt="no_surfacing_error.png" title=""></p><p>检查了一下调用createTree函数前后labels的值，发现调用前后labels的值发生了变化，因此对原函数createTree稍作修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></div><div class="line"></div><div class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line"></div><div class="line">    <span class="comment"># 1 Stop when all classes are equal</span></div><div class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</div><div class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 2 When just one feature, return majority</span></div><div class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> majorityCnt(classList)</div><div class="line"></div><div class="line">    subLabels = labels[:] <span class="comment"># 将labels全部复制到subLabels，进行接下来的处理</span></div><div class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</div><div class="line">    bestFeatLabel = subLabels[bestFeat] <span class="comment"># 利用subLabels来获取最佳分类特征</span></div><div class="line">    myTree = &#123;bestFeatLabel: &#123;&#125;&#125;</div><div class="line">    <span class="keyword">del</span>(subLabels[bestFeat])</div><div class="line"></div><div class="line">    <span class="comment"># 3 Get list of unique values</span></div><div class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">    uniqueVals = set(featValues)</div><div class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">        <span class="comment">#subLabels = labels[:] 作者在这里才进行参数赋值，会改变labels的值</span></div><div class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)</div><div class="line">    <span class="keyword">return</span> myTree</div></pre></td></tr></table></figure><p>接下来就可以愉快利用该函数进行分类了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> treePlotter</div><div class="line"></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="string">省略一堆作者源代码</span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line"></div><div class="line">myDat, labels = createDataSet()</div><div class="line">myTree = createTree(myDat, labels) <span class="comment"># 训练数据</span></div><div class="line">treePlotter.createPlot(myTree) <span class="comment"># 显示模型</span></div><div class="line">print(classify(myTree, labels, [<span class="number">1</span>, <span class="number">1</span>])) <span class="comment"># 预测数据</span></div></pre></td></tr></table></figure><p>看一看生成的决策树模型：</p><img src="/2017/10/15/machine-learning-in-action-note1/tree1.png" alt="tree1.png" title=""><p>我们可以引入pickle模块来将训练出的模型序列化，保存在磁盘中，以便后续的调用。因为书本作者是使用Python2的，我打算用Python3来完成，在下面的代码中就遇到了问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    <span class="comment">#Python2用法：fw = open(filename,'w')</span></div><div class="line">    <span class="comment">#改为python3:</span></div><div class="line">    <span class="keyword">with</span> open(filename,<span class="string">'wb'</span>) <span class="keyword">as</span> fw:</div><div class="line">        pickle.dump(inputTree, fw)</div><div class="line">    fw.close()</div></pre></td></tr></table></figure><p>接下来就要引入稍微大一点的数据集来进行训练了，然鹅….</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">fr = open(<span class="string">'lenses.txt'</span>)</div><div class="line">lenses = [inst.strip().split(<span class="string">'\t'</span>) <span class="keyword">for</span> inst <span class="keyword">in</span> fr.readline()]</div><div class="line">lensesLables = [<span class="string">'age'</span>, <span class="string">'prescript'</span>, <span class="string">'astigmatic'</span>, <span class="string">'tearRate'</span>]</div><div class="line">print(lenses)</div></pre></td></tr></table></figure><img src="/2017/10/15/machine-learning-in-action-note1/readlines_error.png" alt="readlines_error.png" title=""><p>这输出的啥玩意儿？仔细一看，<strong>fr.readlines()</strong>函数写错了，少了一个<strong>sssssssss</strong>。修改好以后我们就来看看训练完的决策树吧：</p><img src="/2017/10/15/machine-learning-in-action-note1/lenses_tree1.png" alt="lenses_tree1.png" title=""><p>？？？这又啥玩意儿？？这看得下去？？？？那就只能修改一下plotMidText函数了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotMidText</span><span class="params">(cntrPt, parentPt, txtString)</span>:</span></div><div class="line">    xMid = (parentPt[<span class="number">0</span>] - cntrPt[<span class="number">0</span>])/<span class="number">2</span> + cntrPt[<span class="number">0</span>]</div><div class="line">    yMid = (parentPt[<span class="number">1</span>] - cntrPt[<span class="number">1</span>])/<span class="number">2</span> + cntrPt[<span class="number">1</span>]</div><div class="line">    createPlot.ax.text(xMid, yMid, txtString, fontsize=<span class="number">8</span>, horizontalalignment=<span class="string">'center'</span>,verticalalignment=<span class="string">'center'</span>, rotation=<span class="number">30</span>)</div></pre></td></tr></table></figure><img src="/2017/10/15/machine-learning-in-action-note1/lenses_tree2.png" alt="lenses_tree2.png" title=""><p>完美！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正在学习《Machine Learning in Action》，随笔记录一下，代码基本上都是跟着书本敲的，就不大量复制了，仅写一些自己的理解并对出现的问题进行整理和归纳。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>来生成一个中国地图吧</title>
    <link href="http://yoursite.com/2017/07/25/china-map/"/>
    <id>http://yoursite.com/2017/07/25/china-map/</id>
    <published>2017-07-25T02:49:22.000Z</published>
    <updated>2017-10-15T13:59:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>第一部分应该是根据作者2012年的文章进行的，第二部分根据作者2016年新的文章，在命令行显示人口密度。</p><p>&lt;!—more—&gt;</p><h1 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h1><h3 id="1-获取地图文件并转换格式"><a href="#1-获取地图文件并转换格式" class="headerlink" title="1/ 获取地图文件并转换格式"></a>1/ 获取地图文件并转换格式</h3><p>首先据教程<a href="https://sandbox.idre.ucla.edu/sandbox/tutorials/installing-gdal-for-windows安装GDAL，并添加环境变量，要利用GDAL的org2org来转换文件。根据参考链接1，下载好全球地图以后，命令行运行：" target="_blank" rel="external">https://sandbox.idre.ucla.edu/sandbox/tutorials/installing-gdal-for-windows安装GDAL，并添加环境变量，要利用GDAL的org2org来转换文件。根据参考链接1，下载好全球地图以后，命令行运行：</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ogr2ogr -f GeoJSON -where &quot;SU_A3 = &apos;CHN&apos; OR SU_A3 = &apos;TWN&apos;&quot; countries.json ne_10m_admin_0_countries.shp</div></pre></td></tr></table></figure><p>获取我们需要的城市，包括大陆和台湾。-where后面是我们需要筛选的条件，根据参考链接中国家的代码，中国是CHN台湾是TWN。</p><p>接下来是获取省份，命令行运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ogr2ogr -f GeoJSON -where &quot;gu_a3 = &apos;CHN&apos;&quot; provinces_china.json ne_10m_admin_1_states_provinces.shp</div></pre></td></tr></table></figure><h3 id="2-压缩文件"><a href="#2-压缩文件" class="headerlink" title="2/ 压缩文件"></a>2/ 压缩文件</h3><p>链接2给出了一个topojson的方法，不过我npm安装完里没有这玩意儿，仔细看了一下文章说是把GeoJSON文件格式转化为TopoJSON。有geo2topo这个方法，于是运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">geo2topo --id-propety SU_A3 -p name=NAME -p name -o countries_china_topo.json countries.json</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">geo2topo --id-propety SU_A3 -p name=NAME -p name -o provinces_china_topo.json provinces_china.json</div></pre></td></tr></table></figure><p>这个文件格式还是挺大的，继续上<a href="http://mapshaper.org/" target="_blank" rel="external">http://mapshaper.org/</a> 网站压缩，导出后可以看到结尾mini是最小的。</p><img src="/2017/07/25/china-map/cmp_countreis.png" alt="cmp_countreis.png" title=""><img src="/2017/07/25/china-map/cmp_provinces.png" alt="cmp_provinces.png" title=""><h3 id="3-敲代码"><a href="#3-敲代码" class="headerlink" title="3/ 敲代码"></a>3/ 敲代码</h3><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;<span class="selector-tag">style</span>&gt;</div><div class="line">  <span class="selector-id">#china</span> &#123;</div><div class="line">    <span class="attribute">stroke</span>: <span class="number">#fff</span>;</div><div class="line">  &#125;</div><div class="line">  <span class="selector-class">.province</span> &#123;</div><div class="line">    <span class="attribute">fill</span>: <span class="number">#cde</span>;</div><div class="line">    <span class="comment">/* stroke-width: 1; */</span></div><div class="line">    <span class="attribute">stroke-width</span>: <span class="number">2px</span>;</div><div class="line">    <span class="attribute">cursor</span>: pointer;</div><div class="line">  &#125;</div><div class="line">  <span class="selector-class">.province</span><span class="selector-pseudo">:hover</span> &#123;</div><div class="line">    <span class="attribute">fill</span>: lightblue;</div><div class="line">  &#125;</div><div class="line">&lt;/style&gt;</div></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> width = <span class="built_in">window</span>.innerWidth,</div><div class="line">    height = <span class="built_in">window</span>.innerHeight,</div><div class="line">    countreis,</div><div class="line">    state</div><div class="line"></div><div class="line"><span class="keyword">var</span> projection = d3.geoMercator()</div><div class="line">  .center([<span class="number">104</span>, <span class="number">36</span>])</div><div class="line">  .scale(<span class="number">850</span>)</div><div class="line">  .translate([width / <span class="number">2</span>, height / <span class="number">2</span>])</div><div class="line"></div><div class="line"><span class="keyword">var</span> path = d3.geoPath()</div><div class="line">    .projection(projection)</div><div class="line"></div><div class="line"><span class="keyword">var</span> zoom = d3.zoom()</div><div class="line">    .scaleExtent([<span class="number">0.5</span>, <span class="number">10</span>])</div><div class="line">    .on(<span class="string">'zoom'</span>, zoomed)</div><div class="line"></div><div class="line"><span class="keyword">var</span> svg = d3.select(<span class="string">'.china-map'</span>)</div><div class="line">    .attr(<span class="string">"width"</span>, width)</div><div class="line">    .attr(<span class="string">"height"</span>, height)</div><div class="line">    .call(zoom)</div><div class="line"></div><div class="line"><span class="keyword">var</span> g = svg.append(<span class="string">'g'</span>)</div><div class="line"></div><div class="line">d3.json(<span class="string">'./provinces_china_mini.json'</span>, (err, chn) =&gt; &#123;</div><div class="line">  <span class="keyword">if</span>(err) <span class="built_in">console</span>.log(error(err))</div><div class="line">  <span class="built_in">console</span>.log(chn)</div><div class="line"></div><div class="line">  g.append(<span class="string">'g'</span>)</div><div class="line">    .attr(<span class="string">'id'</span>, <span class="string">'china'</span>)</div><div class="line">    <span class="comment">// .attr('id', 'provinces')</span></div><div class="line">    .selectAll(<span class="string">'path'</span>)</div><div class="line">    .data(topojson.feature(chn, chn.objects.provinces_china).features)</div><div class="line">    .enter()</div><div class="line">    .append(<span class="string">'path'</span>)</div><div class="line">    .attr(<span class="string">'class'</span>, <span class="string">'province'</span>)</div><div class="line">    .attr(<span class="string">'d'</span>, path)</div><div class="line">    .on(<span class="string">'click'</span>, clicked)</div><div class="line">    </div><div class="line">  g.selectAll(<span class="string">'.provinces-label'</span>)</div><div class="line">    .data(topojson.feature(chn, chn.objects.provinces_china).features)</div><div class="line">    .enter().append</div><div class="line">&#125;)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">zoomed</span>(<span class="params"></span>) </span>&#123;</div><div class="line">  g.attr(<span class="string">'transform'</span>, <span class="string">`translate(<span class="subst">$&#123;d3.event.transform.x&#125;</span>, <span class="subst">$&#123;d3.event.transform.y&#125;</span>) scale(<span class="subst">$&#123;d3.event.transform.k&#125;</span>)`</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>第一部分参考链接：</p><ol><li><a href="https://yukun.im/javascript/533" target="_blank" rel="external">https://yukun.im/javascript/533</a></li><li><a href="http://www.tnoda.com/blog/2013-12-07" target="_blank" rel="external">Interactive Map with d3.js</a></li><li><a href="https://msdn.microsoft.com/en-us/library/ee783932(v=cs.10" target="_blank" rel="external">Table of Country/Region Names and Codes</a>.aspx)</li></ol><h1 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h1><h3 id="1"><a href="#1" class="headerlink" title="1/"></a>1/</h3><h3 id="2"><a href="#2" class="headerlink" title="2/"></a>2/</h3><p>利用<strong>ndjson-reduce</strong>和<strong>ndjson-map</strong>把转化为GeoJSON格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ndjson-reduce &lt; ca-albers-density.ndjson | ndjson-map &quot;&#123;type: &apos;FeatureCollection&apos;, features: d&#125;&quot; &gt; ca-albers-densi ty.json</div></pre></td></tr></table></figure><p>（没想到windows这么看重单双引号</p><p>看看转换后的地图：</p><img src="/2017/07/25/china-map/ca-albers-density.png" alt="ca-albers-density.png" title=""><p>好像和原先的地图。。。倒了？？？</p><p>接下来安装d3<code>npm install -g d3</code>，通过<code>-r d3</code>引入d3模块，使用 Viridis 主体颜色来填充地区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ndjson-map -r d3 &quot;(d.properties.fill = d3.scaleSequential(d3.interpolateViridis).domain([0, 4000])(d.properties.de nsity), d)&quot; &lt; ca-albers-density.ndjson &gt; ca-albers-color.ndjson</div></pre></td></tr></table></figure><p>把上面生成的GeoJSON文件转化成SVG</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure><p>第二部分参考链接：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;第一部分应该是根据作者2012年的文章进行的，第二部分根据作者2016年新的文章，在命令行显示人口密度。&lt;/p&gt;
&lt;p&gt;&amp;lt;!—more—&amp;gt;&lt;/p&gt;
&lt;h1 id=&quot;第一部分&quot;&gt;&lt;a href=&quot;#第一部分&quot; class=&quot;headerlink&quot; title=&quot;第
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow初体验</title>
    <link href="http://yoursite.com/2017/06/20/Tensorflow-test/"/>
    <id>http://yoursite.com/2017/06/20/Tensorflow-test/</id>
    <published>2017-06-20T02:49:03.000Z</published>
    <updated>2017-06-20T06:19:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>谷歌开源了物体识别系统的API，开源地址：<a href="https://github.com/tensorflow/models/tree/master/object_detection" target="_blank" rel="external">Tensor Flow Object Detectoin</a>，刚好最近也在学ML，学习了python，对sklearn的库也有一丢丢了解，来感受一下google的技术~</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>先抛出<a href="https://github.com/tensorflow/models/blob/master/object_detection/g3doc/installation.md" target="_blank" rel="external">官方安装教程</a>，但是这个安装过程不太完整，比如 protobuf 的安装等，于是自己记录并做一些补充。</p><ol><li><p>安装 Tensorflow 包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install tensorflow</div></pre></td></tr></table></figure></li><li><p>把 github 的 tensorflow/models 克隆下来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/tensorflow/models.git</div></pre></td></tr></table></figure></li><li><p>安装 google protobuf</p><p><strong>Protobuf</strong> 是 google 开发的一种数据结构。它提供了一种灵活、高效、自动序列化结构数据的机制，可以联想 XML，但是比 XML 更小、更快、更简单。</p><p>安装链接：<a href="https://github.com/google/protobuf/releases/tag/v3.3.0。我下载了" target="_blank" rel="external">https://github.com/google/protobuf/releases/tag/v3.3.0。我下载了</a> protoc-3.3.0-win32.zip，专供不想自己配置的懒逼下载，载完后直接将bin目录添加到环境变量PATH中即可。</p></li><li><p>编译 protobuf 库文件</p><p>在 <strong>tensorflow/models</strong> 文件夹下运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">protoc object_detection/protos/*.proto --python_out=.</div></pre></td></tr></table></figure></li><li><p>将目录添加到PYTHONPATH中</p><p>windows下没有export命令，根据文字描述，要把 <strong>slim</strong> 文件夹和 <strong>tensorflow/models/</strong> 和添加到 <strong>PATHONPATH</strong> 中。但是之前我的python目录是直接添加在path中的，于是先创建一个名为PAYTHONPATH的变量：</p><p>&lt;% asset_img pythonpath.png %&gt;</p><p>把关于python的统统添加到这个变量中，以及刚才所说的 slim 和 models：</p><p>&lt;% asset_img pythonpath.png %&gt;</p><p>再把 <strong>%PYTHONPATH%</strong> 添加到 <strong>PATH</strong> 中：</p><p>&lt;% asset_img path.png %&gt;</p></li></ol><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>​    运行<code>python object_detection/builders/model_builder_test.py</code></p><p>​    <img src="/2017/06/20/Tensorflow-test/ok.png" alt="ok.png" title=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;谷歌开源了物体识别系统的API，开源地址：&lt;a href=&quot;https://github.com/tensorflow/models/tree/master/object_detection&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Tensor Fl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex8</title>
    <link href="http://yoursite.com/2017/06/16/machine-learning-ex8/"/>
    <id>http://yoursite.com/2017/06/16/machine-learning-ex8/</id>
    <published>2017-06-16T11:46:41.000Z</published>
    <updated>2017-06-16T13:58:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>以光速刷课。。昨天一天刷完week9，今天又刷完week10，正在向week11进军。。还是要完成一下wee9的编程作业。</p><p>这一章主要是讲了异常检测和推荐系统。异常检测算法使用的是以前概率论学过的正态（高斯）分布。只使用特征值X来计算出概率分布，根据临界值的大小再判断y是否异常。</p><h3 id="Anomaly-detection"><a href="#Anomaly-detection" class="headerlink" title="Anomaly detection"></a>Anomaly detection</h3><p>首先计算出 <strong>μ</strong> 和 <strong>σ^2^ </strong>：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mu = mean(X)';</div><div class="line">sigma2 = var(X)'*(m<span class="number">-1</span>)/m;</div></pre></td></tr></table></figure><p>在这里要注意函数 var() 除以的是m-1所以我们要修改一下函数。然后我们要利用交叉验证样本，计算 F~1~ Score 并挑选临界值 <strong>ε</strong>：</p> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 获取验证集异常值坐标</span></div><div class="line">cvPredictions = (pval &lt; epsilon);</div><div class="line">tp = sum( (cvPredictions == <span class="number">1</span>) &amp; (yval == <span class="number">1</span>) );</div><div class="line">fp = sum( (cvPredictions == <span class="number">1</span>) &amp; (yval == <span class="number">0</span>) );</div><div class="line">fn = sum( (cvPredictions == <span class="number">0</span>) &amp; (yval == <span class="number">1</span>) );</div><div class="line"><span class="comment">% 计算精确率</span></div><div class="line">prec = tp / (tp + fp);</div><div class="line"><span class="comment">% 计算召回率</span></div><div class="line">rec = tp / (tp + fn);</div><div class="line">F1 = <span class="number">2</span> * prec * rec / (prec + rec);</div></pre></td></tr></table></figure><p>然后可以看到红红的圈出的异常值：</p><img src="/2017/06/16/machine-learning-ex8/detected.png" alt="detected.png" title=""><h3 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h3><p>说到推荐系统，以电影为例，一方面要预测用户对于某电影的评分，另一方面要寻找相似的电影，我们经常使用的算法是协同过滤算法。进一步了解这个算法，查了一些中文资料。原本的线性回归，我们只需要根据特征值计算出参数 <strong>θ</strong>，但是现在变态了，我们不光要预测用户的喜好，还要查找相似的特征向量，俩参数（都用矩阵表示）一起学习。</p><p>首先我们完成未正规化的梯度和代价函数的计算：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">X_grad = (X * Theta' - Y) .* R * Theta;</div><div class="line">Theta_grad = (X * Theta' - Y)' .* R' * X;</div><div class="line"></div><div class="line">J = sum(( (X * Theta' - Y).^<span class="number">2</span> .* R )(:)) / <span class="number">2</span>;</div></pre></td></tr></table></figure><p>期间完全忘记梯度是什么鬼。。回顾一下，是代价函数对变量求偏导~ 计算公式完全按照矩阵的大小来判断。接下来我们正规化代价函数，按照公式加上<code>J += lambda / 2 <em> sum(Theta.^2(:)) + lambda / 2 </em> sum(X.^2(:));</code>，但发现J变成了1x3的向量，发现问题在于sum中应该在平方的时候添加括号，修改代码如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">J += lambda / <span class="number">2</span> * sum((Theta.^<span class="number">2</span>)(:)) + lambda / <span class="number">2</span> * sum((X.^<span class="number">2</span>)(:));</div></pre></td></tr></table></figure><p>然后继续完成梯度的正规化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;以光速刷课。。昨天一天刷完week9，今天又刷完week10，正在向week11进军。。还是要完成一下wee9的编程作业。&lt;/p&gt;
&lt;p&gt;这一章主要是讲了异常检测和推荐系统。异常检测算法使用的是以前概率论学过的正态（高斯）分布。只使用特征值X来计算出概率分布，根据临界值的大
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Mmachine Learning ex7</title>
    <link href="http://yoursite.com/2017/06/13/machine-learning-ex7/"/>
    <id>http://yoursite.com/2017/06/13/machine-learning-ex7/</id>
    <published>2017-06-13T01:46:37.000Z</published>
    <updated>2017-06-15T04:38:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一章主要学习了 <strong>K-均值算法</strong> 和 <strong>PCA 算法</strong>，前者用于无监督学习中聚类的训练，后者用于压缩输入特征值的维度。</p><a id="more"></a><h3 id="K-means-Clustering"><a href="#K-means-Clustering" class="headerlink" title="K-means Clustering"></a>K-means Clustering</h3><p>我们先使用2维的数据集来感受一下K均值算法。接着我们要将写好的函数运用到图像压缩上。K-均值算法最核心的步骤如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% Initialize centroids</span></div><div class="line">centroids = kMeansInitCentroids(X, K);</div><div class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:iterations</div><div class="line"><span class="comment">% Cluster assignment step: Assign each data point to the</span></div><div class="line"><span class="comment">% closest centroid. idx(i) corresponds to cˆ(i), the index</span></div><div class="line"><span class="comment">% of the centroid assigned to example i</span></div><div class="line">idx = findClosestCentroids(X, centroids);</div><div class="line"><span class="comment">% Move centroid step: Compute means based on centroid</span></div><div class="line"><span class="comment">% assignments</span></div><div class="line">centroids = computeMeans(X, idx, K);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>第一步完成 <strong>findClosesCentroids</strong> 函数，计算每个样本到中心点的距离，用数值表示其所属类，返回聚类后的向量：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(X,<span class="number">1</span>)</div><div class="line">  min = norm(X(<span class="built_in">i</span>,:) - centroids(<span class="number">1</span>,:), <span class="number">2</span>).^<span class="number">2</span>;</div><div class="line">  min_idx = <span class="number">1</span>;</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">2</span> : K</div><div class="line">    cur = norm(X(<span class="built_in">i</span>,:) - centroids(<span class="built_in">j</span>,:), <span class="number">2</span>).^<span class="number">2</span>;</div><div class="line">    <span class="keyword">if</span>(cur &lt; min)</div><div class="line">      min = cur;</div><div class="line">      min_idx = <span class="built_in">j</span>;</div><div class="line">    <span class="keyword">end</span></div><div class="line">  <span class="keyword">end</span></div><div class="line">  idx(<span class="built_in">i</span>) = min_idx;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>题解里说用一个for循环完成，但我先使用了两个，后面再进行优化好了。这其中出现了一个小问题，计算norm的时候，<code>norm(X(i,:) - centroids(j,:), 2).^2;</code> 主要包含所有列，否则只包含了单个数字。</p><p>接下来完成 <strong>computeMeans</strong> 函数，通过同个类里的样本计算新的中心：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : K</div><div class="line">  <span class="comment">% 查找聚类样本</span></div><div class="line">  examples_idx = <span class="built_in">find</span>(idx == <span class="built_in">i</span>);</div><div class="line">  <span class="comment">% 计算中心值</span></div><div class="line">  X(examples_idx, :);</div><div class="line">  centroids(<span class="built_in">i</span>,:) = sum( X(examples_idx, :) ) / <span class="built_in">size</span>(examples_idx, <span class="number">1</span>);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>这里出现的问题在<code>centroids(i,:) = sum( X(examples_idx, :) ) / size(examples_idx, 1);</code> 。注意包含centroids的所有列，和在计算szie()的时候，选择所有行的大小。</p><p>然后我们就可以运行我们的K-均值算法来聚类了。可以看到初始化的时候三个中心点分别为（3,3）、（6,2）、（8,5）。</p><img src="/2017/06/13/machine-learning-ex7/iter1.png" alt="iter1.png" title=""><p>经过6次迭代可以看到中心点逐渐往好的方向移动：</p><img src="/2017/06/13/machine-learning-ex7/iter6.png" alt="iter6.png" title=""><p>经过10次迭代基本到达有模有样的聚类中心了：</p><img src="/2017/06/13/machine-learning-ex7/iter10.png" alt="iter10.png" title=""><p>接下来我们要使用K均值算法来压缩图像了。每个像素用 <strong>24-bit</strong> 来表示颜色，即3个 <strong>8-bit</strong> 的无符号整形来表示RGB的值，目标压缩成用<strong>16-bit</strong> 来表示。</p><p>我们使用 <strong>imread(A)</strong> 来读入图像，因为我们原始图像的大小为128x128，因此 A 为一个三维矩阵，<strong>size(A) = 128x128x3</strong> ，然后reshape图像变为 <strong>mX3</strong>（m = 16384 = 128x128） 的矩阵，用于后面执行K-均值算法。</p><p>我们将K设置为16，对每个像素点进行聚类。获得最后的图像。原始图像需要 <strong>128 x 128 x 24 = 393,216</strong> bits。而压缩后我们使用 24bits存储16种颜色，但每个像素点只需要4bits 来进行定位。因此压缩后的图像为 <strong>16 x 24+128x128x4 = 65,920</strong> bits。（从pdf里理解是这样，然而真实的情况似乎并没有进行压缩，看了助教在论坛里的回答，完整的压缩过程还要创建一个新的图像，只使用4bit来表示，因为本课程只是关于聚类，而不是关于压缩图像的细节。）因此压缩后的图片如下：</p><img src="/2017/06/13/machine-learning-ex7/compress.png" alt="compress.png" title=""><p>然后我们换一张自己的图片来看看效果：</p><img src="/2017/06/13/machine-learning-ex7/compress2.png" alt="compress2.png" title=""><p>然后修改 <strong>K=5</strong> 再看看效果：</p><img src="/2017/06/13/machine-learning-ex7/compress3.png" alt="compress3.png" title=""><h3 id="Principal-Component-Analysis"><a href="#Principal-Component-Analysis" class="headerlink" title="Principal Component Analysis"></a>Principal Component Analysis</h3><p>我们使用PCA来减少数据集的维度。先实验2D的数据集来了解一下PCA的运作，再将其运用更高的维度上。</p><p>PCA的步骤为：1、正规化数据集。2、计算协方差矩阵。3、利用SVD函数计算主成分（U、S）。</p><p>2、3步骤实现</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Sigma = X' * X / m;</div><div class="line">[U, S, V] = svd(Sigma);</div></pre></td></tr></table></figure><p>可以看到特征向量如下图：</p><p><strong>特征向量1</strong></p><p><strong>特征向量1 &amp; 2</strong></p><p>因为我们要降低到一维，即 <strong>K=1</strong> 因此在这次只会使用到U(:, 1)</p><p>通过SVD函数计算出了主成分后，我们可以就利用特征向量U来将每个样本映射为更低的维度，x^(i)^ -&gt; z^(i)^ 。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">U_reduce = U(:, <span class="number">1</span>:K);</div><div class="line">Z = X * U_reduce;</div></pre></td></tr></table></figure><p>重构出通过PCA映射后的点（红色）：</p><img src="/2017/06/13/machine-learning-ex7/reconstruction.png" alt="reconstruction.png" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一章主要学习了 &lt;strong&gt;K-均值算法&lt;/strong&gt; 和 &lt;strong&gt;PCA 算法&lt;/strong&gt;，前者用于无监督学习中聚类的训练，后者用于压缩输入特征值的维度。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex6</title>
    <link href="http://yoursite.com/2017/06/10/machine-learning-ex6/"/>
    <id>http://yoursite.com/2017/06/10/machine-learning-ex6/</id>
    <published>2017-06-10T01:58:07.000Z</published>
    <updated>2017-06-13T01:46:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>终于来到支持向量机（SVM）了！这一章我们要学习如何使用高斯核SVM来建立一个垃圾邮件分类器。</p><h3 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h3><p>首先显示出我们的数据，很明显地可以看出 <strong>C=1</strong> 时两个分类的决策边界是中间的一条线，但是要注意到左边有一个 <strong>+</strong> 在（0.1,4.1）。</p><img src="/2017/06/10/machine-learning-ex6/dataset1_c1.png" alt="dataset1_c1.png" title=""><a id="more"></a><p>增大C，修改 <strong>C=100</strong> 可以看到决策边界的偏差减小了。</p><img src="/2017/06/10/machine-learning-ex6/dataset1_c100.png" alt="dataset1_c100.png" title=""><p>继续增大C，此时 <strong>C=1000</strong> ，</p><img src="/2017/06/10/machine-learning-ex6/dataset1_c1000.png" alt="dataset1_c1000.png" title=""><p>根据公式即可完成高斯核的代码，没有出现什么大问题。接下来出现了一个样本较大且是非线性的决策边界的数据集，我们利用已完成的高斯核SVM来显示决策边界。</p><img src="/2017/06/10/machine-learning-ex6/dataset2.png" alt="dataset2.png" title=""><p>通过训练集3我们要通过验证集来找到最佳的 C 和 σ，最初的决策分界如下图：</p><img src="/2017/06/10/machine-learning-ex6/dataset3_base.png" alt="dataset3_base.png" title=""><p>经过8864的循环终于得到了最优参数 :-)</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">min = <span class="number">1</span>;</div><div class="line">step = [<span class="number">0.01</span>; <span class="number">0.03</span>; <span class="number">0.1</span>; <span class="number">0.3</span>; <span class="number">1</span>; <span class="number">3</span>; <span class="number">10</span>; <span class="number">30</span>];</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: <span class="built_in">size</span>(step)</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>: <span class="built_in">size</span>(step)</div><div class="line">    model= svmTrain(X, y, step(<span class="built_in">i</span>), @(x1, x2) gaussianKernel(x1, x2, step(<span class="built_in">j</span>)));</div><div class="line">    predictions = svmPredict(model, Xval);</div><div class="line">    cur = mean(double(predictions ~= yval));</div><div class="line">    <span class="keyword">if</span>(cur &lt; min) </div><div class="line">      min = cur;</div><div class="line">      C = step(<span class="built_in">i</span>);</div><div class="line">      sigma = step(<span class="built_in">j</span>);</div><div class="line">    <span class="keyword">end</span> </div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><img src="/2017/06/10/machine-learning-ex6/dataset3_over.png" alt="dataset3_over.png" title=""><h3 id="Spam-Classification"><a href="#Spam-Classification" class="headerlink" title="Spam Classification"></a>Spam Classification</h3><p>在处理垃圾邮件的过程中，需要对邮件进行标准化。包括全部转换为小写字母、移除HTML标签、以及一些表示具体含义的内容（如链接、邮件、符号、数字等）替换为固定的字符串。</p><p>接下来我们的任务是将邮件中出现的单词映射为词典中的索引：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">length</span>(vocabList)</div><div class="line">  <span class="keyword">if</span>(strcmp(str, vocabList&#123;i&#125;))</div><div class="line">      word_indices = [word_indices; i];</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>后来在查看练习资料的时候发现，可以使用<code>ismember()</code>函数来实现同样功能：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[tf, idx] = ismember(str, vocabList);</div><div class="line"><span class="keyword">if</span>(idx)</div><div class="line">  word_indices = [word_indices; idx];</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>然后将邮件转化成一个向量x，如果单词出现过则设特征值 x~i~ 为1，否则为0，i 为词典中的索引。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(word_indices)</div><div class="line">  x(word_indices(<span class="built_in">i</span>)) = <span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>接下来我们就是利用上面完成的两个函数，通过SVM来进行邮件垃圾分类了。测试一下自己收到过的垃圾邮件：</p><img src="/2017/06/10/machine-learning-ex6/evernote.png" alt="evernote.png" title=""><p>果然是垃圾邮件呢：</p><img src="/2017/06/10/machine-learning-ex6/result.png" alt="result.png" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;终于来到支持向量机（SVM）了！这一章我们要学习如何使用高斯核SVM来建立一个垃圾邮件分类器。&lt;/p&gt;
&lt;h3 id=&quot;Support-Vector-Machines&quot;&gt;&lt;a href=&quot;#Support-Vector-Machines&quot; class=&quot;headerlink&quot; title=&quot;Support Vector Machines&quot;&gt;&lt;/a&gt;Support Vector Machines&lt;/h3&gt;&lt;p&gt;首先显示出我们的数据，很明显地可以看出 &lt;strong&gt;C=1&lt;/strong&gt; 时两个分类的决策边界是中间的一条线，但是要注意到左边有一个 &lt;strong&gt;+&lt;/strong&gt; 在（0.1,4.1）。&lt;/p&gt;
&lt;img src=&quot;/2017/06/10/machine-learning-ex6/dataset1_c1.png&quot; alt=&quot;dataset1_c1.png&quot; title=&quot;&quot;&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex5</title>
    <link href="http://yoursite.com/2017/06/05/machine-learning-ex5/"/>
    <id>http://yoursite.com/2017/06/05/machine-learning-ex5/</id>
    <published>2017-06-05T02:33:50.000Z</published>
    <updated>2017-06-06T15:32:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>本次练习是利用正则化的线性回归来学习不同的偏差-方差（bias-variance）模型，并且学会判断其误差类型，能够对算法进行改进。</p><p>根据公式完成线性回归的代价函数和梯度的函数。接下来会根据我们算出来的theta值显示一个模型，如下图</p><img src="/2017/06/05/machine-learning-ex5/line.png" alt="line.png" title=""><p>可以看到模型不太适合我们的训练值，具有高偏差（high-bias），并且可以看出欠拟合（underfitting）。因此接下来我们要通过显示训练和测试的误差学习曲线来诊断偏差-方差问题。</p><a id="more"></a><h3 id="Learning-curves"><a href="#Learning-curves" class="headerlink" title="Learning curves"></a>Learning curves</h3><p>我们可以利用之前写好的函数来计算训练集的θ，并通过这个θ来计算训练集误差和交叉验证误差，显示学习曲线。需要注意的是训练集误差计算时要包括不同的训练集大小，并且两者都不需要正则化。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[theta_train] = trainLinearReg(X, y, lambda);</div><div class="line"></div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  <span class="comment">% use tranLinearReg function to find theta</span></div><div class="line">  [error_train(i)] = linearRegCostFunction(X(<span class="number">1</span>:<span class="built_in">i</span>,:), y(<span class="number">1</span>:<span class="built_in">i</span>), theta_train, lambda);</div><div class="line">  error_val = linearRegCostFunction(Xval, yval, theta_train, lambda);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>运行完图像如下：</p><img src="/2017/06/05/machine-learning-ex5/cross1.png" alt="cross1.png" title=""><p>和pdf中的示例还差挺多的，我应该是哪里理解错了。修改for循环中交叉验证误差<code>error_val(i) = linearRegCostFunction(Xval(1:i, :), yval(1:i), theta_train, lambda);</code>，图像如下</p><img src="/2017/06/05/machine-learning-ex5/cross2.png" alt="cross2.png" title=""><p>结果还是不正确，交叉验证误差的error值不应该这么小。而且pdf里面也说了</p><blockquote><p>When you are computing the training set error, make sure you compute it on the training subset (i.e., X(1:n,:) and y(1:n))(instead of the entire training set). However, for the cross validation error,you should compute it over the entire cross validation set.  </p></blockquote><p>也就是说交叉验证误差要用到全部的交叉验证训练集，而不是X(1:n,:) and y(1:n)。看了一下论坛，应该不同大小的训练集计算不同的θ，因此才有正确的结果：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  <span class="comment">% use tranLinearReg function to find theta</span></div><div class="line">  [theta_train] = trainLinearReg(X(<span class="number">1</span>:<span class="built_in">i</span>,:), y(<span class="number">1</span>:<span class="built_in">i</span>), lambda);</div><div class="line">  [error_train(i)] = linearRegCostFunction(X(<span class="number">1</span>:<span class="built_in">i</span>,:), y(<span class="number">1</span>:<span class="built_in">i</span>), theta_train, lambda);</div><div class="line">  error_val(<span class="built_in">i</span>) = linearRegCostFunction(Xval, yval, theta_train, lambda);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><img src="/2017/06/05/machine-learning-ex5/cross3.png" alt="cross3.png" title=""><p>但是submit以后发现并没有获得分数，上论坛找找答案：</p><div class="tip"><br><br>我们不需要在学习曲线的函数中自己添加<code>lambda = 0</code>，λ用于正则化θ，当我们在计算 Jtrain, Jcv以及 Jtest的时候，我们需要的是真正的误差，而不需要额外的惩罚项。<br><br></div><p>因此修改4句为<code>  [error_train(i)] = linearRegCostFunction(X(1:i,:), y(1:i), theta_train, 0);</code>，第5句同理。</p><h3 id="Polynomial-regression"><a href="#Polynomial-regression" class="headerlink" title="Polynomial regression"></a>Polynomial regression</h3><p>本来以为这个函数很简单，简单的用一个循环次方计算出每一列就可以了：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : p</div><div class="line">  X_poly(:, <span class="built_in">i</span>) = X .^ p</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>但是结果却不尽如人意，把计算的结果显示出来，发现每一行的值都是一样的，并且看上去与X好像毫无关系</p><img src="/2017/06/05/machine-learning-ex5/poly.png" alt="poly.png" title=""><p>发现问题了！mdzz…无视了循环，就一句代码也会错。。应该改成<code>X_poly(:, i) = X .^ i</code>就对了！</p><p>在利用多项式回归函数来计算theta值之前，我们必须对训练集进行特征缩放，不然后面的数据会变得炒鸡大。</p><p>在 λ= 0的 情况下，我们发现多项式回归函数可以很好的拟合我们的训练集（下图1），并且可以看到多项式回归的学习曲线（下图2）</p><img src="/2017/06/05/machine-learning-ex5/poly_plot.png" alt="poly_plot.png" title=""><img src="/2017/06/05/machine-learning-ex5/poly_learning.png" alt="poly_learning.png" title=""><p>接下来我们通过修改不同的λ值来看一下正则化对偏差-方差的影响。</p><p>λ = 1 时：</p><img src="/2017/06/05/machine-learning-ex5/poly_plot_lambda1.png" alt="poly_plot_lambda1.png" title=""><img src="/2017/06/05/machine-learning-ex5/poly_learning_lambda1.png" alt="poly_learning_lambda1.png" title=""><p>λ = 100 时：</p><img src="/2017/06/05/machine-learning-ex5/poly_plot_lambda100.png" alt="poly_plot_lambda100.png" title=""><img src="/2017/06/05/machine-learning-ex5/poly_learning_lambda100.png" alt="poly_learning_lambda100.png" title=""><p>通过上面两个例子可以看出，λ = 1 的时候最好的适应了训练集，并且训练集误差和验证误差都挺小的，比 λ = 0 的时候来得优秀，而λ= 100 的时候就严重失控了，不但欠拟合，而且误差也高的要死。</p><h3 id="Selecting-λ-using-a-cross-validation-set"><a href="#Selecting-λ-using-a-cross-validation-set" class="headerlink" title="Selecting λ using a cross validation set"></a>Selecting λ using a cross validation set</h3><p>前面我们通过训练集大小的变化来训练θ，并显示学习曲线，现在我们要通过改变λ来显示学习曲线。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">length</span>(lambda_vec)</div><div class="line">  lambda = lambda_vec(<span class="built_in">i</span>);</div><div class="line">  [theta] = trainLinearReg(X, y, lambda);</div><div class="line">  error_train(<span class="built_in">i</span>) = linearRegCostFunction(X, y, theta, <span class="number">0</span>);</div><div class="line">  error_val(<span class="built_in">i</span>) = linearRegCostFunction(Xval, yval, theta, <span class="number">0</span>);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>在使用每个函数的时候应该注意参数的带入，在使用<em>linearRegCostFunction</em>漏了θ参数，活生生的报错了。显示的学习曲线如下：</p><img src="/2017/06/05/machine-learning-ex5/lambda_learning.png" alt="lambda_learning.png" title=""><p>可以看出随着λ的逐渐增加，交叉验证误差先减小后增大，有一个极值点，这个极值点便是我们应该选择的λ。</p><h3 id="Computing-test-set-error"><a href="#Computing-test-set-error" class="headerlink" title="Computing test set error"></a>Computing test set error</h3><p>测试集误差的计算对于评估最终模型来说很重要，我们使用前面看出来的最优λ = 3来计算测试集误差。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">best_lambda = <span class="number">3</span>;</div><div class="line">[best_theta] = trainLinearReg(X, y, best_lambda);</div><div class="line">error_test = linearRegCostFunction(Xtest, ytest, best_theta, <span class="number">0</span>)</div></pre></td></tr></table></figure><p>在这里要注意主函数里已经对Xtest进行了多项式化，在传参的时候要传<strong>X_poly_test</strong>。</p><h3 id="Plotting-learning-curves-with-randomly-selected-examples"><a href="#Plotting-learning-curves-with-randomly-selected-examples" class="headerlink" title="Plotting learning curves with randomly selected examples"></a>Plotting learning curves with randomly selected examples</h3><p>随机选择样本来计算θ并显示学习曲线。我使用了双重循环，外面一重i定义为样本的数量error(i)返回样本为i时的误差，内层j为误差迭代次数，每次计算便存入一个error(j)中，循环完成后用这个向量来计算平均值。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="params">[aver_error_train, aver_error_val]</span> = ...</span></div><div class="line">   randlyExamplesCurve(X, y, Xval, yval, lambda)</div><div class="line"></div><div class="line">mx = <span class="built_in">size</span>(X, <span class="number">1</span>);</div><div class="line">mxal = <span class="built_in">size</span>(Xval, <span class="number">1</span>);</div><div class="line">   </div><div class="line">aver_error_train = <span class="built_in">zeros</span>(mx, <span class="number">1</span>);</div><div class="line">aver_error_val = <span class="built_in">zeros</span>(mx, <span class="number">1</span>);</div><div class="line"></div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : mx</div><div class="line">  <span class="comment">% 随机选择i个样本</span></div><div class="line">  rndIDX1= randperm(mx);</div><div class="line">  rndIDX2 = randperm(mxal);</div><div class="line">  rand_X = X(rndIDX1(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line">  rand_y = y(rndIDX1(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line">  rand_Xval = Xval(rndIDX2(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line">  rand_yval = yval(rndIDX2(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line"></div><div class="line">  <span class="comment">% 使用随机生成的样本计算theta</span></div><div class="line">  theta = trainLinearReg(rand_X, rand_y, lambda);</div><div class="line"></div><div class="line">  <span class="comment">% 计算误差值</span></div><div class="line">  iter = <span class="number">50</span>;</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span> : iter</div><div class="line">    error_train(<span class="built_in">j</span>) = linearRegCostFunction(rand_X, rand_y, theta, <span class="number">0</span>);</div><div class="line">    error_val(<span class="built_in">j</span>) = linearRegCostFunction(rand_Xval, rand_yval, theta, <span class="number">0</span>);</div><div class="line">  <span class="keyword">end</span></div><div class="line">  </div><div class="line">  <span class="comment">% 计算误差平均值</span></div><div class="line">  aver_error_train(<span class="built_in">i</span>) = mean(error_train);</div><div class="line">  aver_error_val(<span class="built_in">i</span>) = mean(error_val);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>最后显示出来的学习曲线。。。五花八门。。。</p><img src="/2017/06/05/machine-learning-ex5/randly1.png" alt="randly1.png" title=""> <img src="/2017/06/05/machine-learning-ex5/randly2.png" alt="randly2.png" title=""><p>再仔细看一下论坛，计算误差值时theta如果不改变是没有意义的，并且无需使用全部的样本，i个就使用前i个样本，因此修改代码</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : mx</div><div class="line">  </div><div class="line">  <span class="comment">% 计算误差值</span></div><div class="line">  iter = <span class="number">50</span>;</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span> : iter</div><div class="line">    <span class="comment">% 随机选择i个样本</span></div><div class="line">    rndIDX1= randperm(mx);</div><div class="line">    rndIDX2 = randperm(mxal);</div><div class="line">    rand_X = X(rndIDX1(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line">    rand_y = y(rndIDX1(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line">    rand_Xval = Xval(rndIDX2(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line">    rand_yval = yval(rndIDX2(<span class="number">1</span>:<span class="built_in">i</span>), :);</div><div class="line"></div><div class="line">    <span class="comment">% 使用随机生成的样本计算theta</span></div><div class="line">    theta = trainLinearReg(rand_X, rand_y, lambda);</div><div class="line">    error_train(<span class="built_in">j</span>) = linearRegCostFunction(rand_X(<span class="number">1</span>:<span class="built_in">i</span>, :), rand_y(<span class="number">1</span>:<span class="built_in">i</span>, :), theta, <span class="number">0</span>);</div><div class="line">    error_val(<span class="built_in">j</span>) = linearRegCostFunction(rand_Xval(<span class="number">1</span>:<span class="built_in">i</span>, :), rand_yval(<span class="number">1</span>:<span class="built_in">i</span>, :), theta, <span class="number">0</span>);</div><div class="line">  <span class="keyword">end</span></div><div class="line">  </div><div class="line">  <span class="comment">% 计算误差平均值</span></div><div class="line">  aver_error_train(<span class="built_in">i</span>) = mean(error_train);</div><div class="line">  aver_error_val(<span class="built_in">i</span>) = mean(error_val);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><img src="/2017/06/05/machine-learning-ex5/randly3.png" alt="randly3.png" title=""> <img src="/2017/06/05/machine-learning-ex5/randly4.png" alt="randly4.png" title=""><p>要运行老长的时间了，试了两次，这下好像比较像样咯~</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次练习是利用正则化的线性回归来学习不同的偏差-方差（bias-variance）模型，并且学会判断其误差类型，能够对算法进行改进。&lt;/p&gt;
&lt;p&gt;根据公式完成线性回归的代价函数和梯度的函数。接下来会根据我们算出来的theta值显示一个模型，如下图&lt;/p&gt;
&lt;img src=&quot;/2017/06/05/machine-learning-ex5/line.png&quot; alt=&quot;line.png&quot; title=&quot;&quot;&gt;
&lt;p&gt;可以看到模型不太适合我们的训练值，具有高偏差（high-bias），并且可以看出欠拟合（underfitting）。因此接下来我们要通过显示训练和测试的误差学习曲线来诊断偏差-方差问题。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex4</title>
    <link href="http://yoursite.com/2017/05/31/machine-learning-ex4/"/>
    <id>http://yoursite.com/2017/05/31/machine-learning-ex4/</id>
    <published>2017-05-31T03:06:22.000Z</published>
    <updated>2017-06-01T15:06:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一章主要学习了神经网络中的反向传播算法（Backpropagation algorithm ）。相对于线性回归（Linear Regression）、逻辑回归（Logistic Regression）BP确实很复杂了。但是今天刚看的《Don’t make me think》里面作者所言</p><blockquote><p><strong>我们不是追根究底，而是勉强应付。 因为这对我们来说并不重要。</strong>对于我们中大多数人来说，只要我们能够正常使用，是否明白事物背后的运行机制并没有关系。这并不是智力低下的表现，而是我们并不关心。总之，它对我们来说没那么重要。</p></blockquote><p>那么现阶段，对于BP算法有一个整体的概念，懂得如何使用它便是关键。上一章我们用已经给定的theta矩阵来进行预测，这一章我们将通过BP算法来学习参数。这一章的练习主要分为两个部分，第一部分：我们通过给定的神经网络权重，前馈计算正则化的代价函数。第二部分：我们自己训练神经网络的权重。</p><a id="more"></a><p>此次用于训练的神经网络如下图：</p><img src="/2017/05/31/machine-learning-ex4/model.png" alt="model.png" title=""><h3 id="Feedforward-and-cost-function"><a href="#Feedforward-and-cost-function" class="headerlink" title="Feedforward and cost function"></a>Feedforward and cost function</h3><p>首先我们需要通过给定的Theta1、Theta2，用以下公式来计算代价函数（cost function）。</p><img src="/2017/05/31/machine-learning-ex4/cost.png" alt="cost.png" title=""><ul><li><p>第一次尝试</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% compute the output value</span></div><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line">z2 = X * Theta1';</div><div class="line">a2 = [ones(m, <span class="number">1</span>), sigmoid(z2)];</div><div class="line">z3 = a2 * Theta2';</div><div class="line">a3 = sigmoid(z3);</div><div class="line"></div><div class="line"><span class="comment">% recode the labels</span></div><div class="line">recode_y = <span class="built_in">zeros</span>(m, num_labels);</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  <span class="built_in">j</span> = y(<span class="built_in">i</span>);</div><div class="line">  recode_y(<span class="built_in">i</span>, <span class="built_in">j</span>) = <span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="comment">% compute cost</span></div><div class="line">J  = sum(-y' * <span class="built_in">log</span>(a3) - (<span class="number">1</span> - y)' * <span class="built_in">log</span>(<span class="number">1</span> - a3));</div></pre></td></tr></table></figure><p>算出来的J可有1523995.662855那么大。。。第一次尝试失败。。。</p></li><li><p>第二次尝试：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  <span class="comment">% compute the output value</span></div><div class="line">  z2 = X(<span class="built_in">i</span>, :) * Theta1';</div><div class="line">  a2 = [ones(<span class="number">1</span>,<span class="number">1</span>) sigmoid(z2)];</div><div class="line">  z3 = a2 * Theta2';</div><div class="line">  a3 = sigmoid(z3);</div><div class="line">  </div><div class="line">  <span class="comment">% recode the labels as vectors</span></div><div class="line">  recode_y = <span class="built_in">zeros</span>(num_labels, <span class="number">1</span>);</div><div class="line">  recode_y(y(<span class="built_in">i</span>)) = <span class="number">1</span>;</div><div class="line">  J += -recode_y' * <span class="built_in">log</span>(a3)' - (<span class="number">1</span> - recode_y)' * <span class="built_in">log</span>(<span class="number">1</span> - a3)';</div><div class="line"><span class="keyword">end</span></div><div class="line">J /= m;</div></pre></td></tr></table></figure><p>对公式进行分解：for循环是用来执行公式最外层的m的累加，通过矩阵的相乘来执行内层的k的累加。</p><p>不过我不死心认为第一次尝试的思路并没有错。。用大矩阵来完成两个相加。。我要再回去尝试一下。</p></li><li><p>第三次尝试</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% compute the output value</span></div><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line">z2 = X * Theta1';</div><div class="line">a2 = [ones(m, <span class="number">1</span>), sigmoid(z2)];</div><div class="line">z3 = a2 * Theta2';</div><div class="line">a3 = sigmoid(z3);</div><div class="line"></div><div class="line"><span class="comment">% recode the labels</span></div><div class="line">recode_y = <span class="built_in">zeros</span>(m, num_labels);</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  recode_y(<span class="built_in">i</span>, y(<span class="built_in">i</span>)) = <span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="comment">% compute cost</span></div><div class="line">J  = sum(sum(-recode_y' * <span class="built_in">log</span>(a3) - (<span class="number">1</span> - recode_y)' * <span class="built_in">log</span>(<span class="number">1</span> - a3)));</div><div class="line">J /= m;</div></pre></td></tr></table></figure><p>修改了一下第一次尝试中错误的变量（比如最后一步忘记代入recode_y等），但是发现结果还是不对。把矩阵画出来自己试着相乘了一下，发现这样不能实现内层的 y~k~ 和 a~k~ 的一一对应相乘。而是一个y~k~会和另外a~k~都相乘然后累加。事实证明，目前还是用第二次尝试的办法实现吧。</p><p>​</p></li></ul><h3 id="Regularized-cost-function"><a href="#Regularized-cost-function" class="headerlink" title="Regularized cost function"></a>Regularized cost function</h3><p>接着我们要正则化代价函数。这个公式看起来更可怕了：</p><img src="/2017/05/31/machine-learning-ex4/regularized.png" alt="regularized.png" title=""><p>这里注意到在累加的时候k是从1到400而不是401，那么就不能单纯的用 sum() 把所有数通通加一起了。因此尝试代码如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Theta1_t = Theta1(<span class="number">1</span>:hidden_layer_size, <span class="number">1</span>:input_layer_size);</div><div class="line">Theta2_t = Theta2(<span class="number">1</span>:num_labels, <span class="number">1</span>:hidden_layer_size);</div><div class="line"></div><div class="line">J += lambda * ((sum((Theta1_t.^<span class="number">2</span>)(:)) + sum((Theta2_t.^<span class="number">2</span>)(:)))) / (<span class="number">2</span> * m);</div></pre></td></tr></table></figure><p>当然。。不会第一次就那么顺利的。。啊。。。想不通哪里错啊。。。。再仔细看一下文档，</p><blockquote><p>For the matrices Theta1 and Theta2, this corresponds to the first column of each matrix. </p></blockquote><p>那么应该把<code>Theta1_t = Theta1(1:hidden_layer_size, 1:input_layer_size);</code>改为 <code>Theta1_t = Theta1(1:hidden_layer_size, 2:input_layer_size+1);</code>Theta2_2同理。</p><h3 id="Sigmoid-gradient"><a href="#Sigmoid-gradient" class="headerlink" title="Sigmoid gradient"></a>Sigmoid gradient</h3><p>我们从前往后算出来了最终输出的值，接下来要通过后向传播来计算delta了。那么首先我们需要根据下面这个方程来完成sigmoidGradient函数。</p><img src="/2017/05/31/machine-learning-ex4/sigmoid.png" alt="sigmoid.png" title=""><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">size</span>(z, <span class="number">1</span>)</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:<span class="built_in">size</span>(z, <span class="number">2</span>)</div><div class="line">    g(<span class="built_in">i</span>, <span class="built_in">j</span>) = sigmoid(z(<span class="built_in">i</span>,<span class="built_in">j</span>)) * (<span class="number">1</span> - sigmoid(z(<span class="built_in">i</span>,<span class="built_in">j</span>)));</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>按照4个步骤，在每个循环里计算从后向前的delta值。论坛里面说这是最具有挑战的一次练习，果然调了好久，我们从修改for循环开始：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  <span class="comment">% compute the output value</span></div><div class="line">  a1 = X(<span class="built_in">i</span>, :);</div><div class="line">  z2 = a1 * Theta1';</div><div class="line">  a2 = [<span class="number">1</span> sigmoid(z2)];</div><div class="line">  z3 = a2 * Theta2';</div><div class="line">  a3 = sigmoid(z3);</div><div class="line">  </div><div class="line">  <span class="comment">% recode the labels as vectors</span></div><div class="line">  recode_y = <span class="built_in">zeros</span>(num_labels, <span class="number">1</span>);</div><div class="line">  recode_y(y(<span class="built_in">i</span>)) = <span class="number">1</span>;</div><div class="line">  J += -recode_y' * <span class="built_in">log</span>(a3)' - (<span class="number">1</span> - recode_y)' * <span class="built_in">log</span>(<span class="number">1</span> - a3)';</div><div class="line">  </div><div class="line">  <span class="comment">% step2</span></div><div class="line">  delta3 = a3' - recode_y;</div><div class="line">  </div><div class="line">  <span class="comment">% step3</span></div><div class="line"></div><div class="line">  delta2 = Theta2(:, <span class="number">2</span>:<span class="keyword">end</span>)'*delta3.*sigmoidGradient(z2)';</div><div class="line">  </div><div class="line">  <span class="comment">% step4</span></div><div class="line">  Theta2_grad += delta3 * a2;</div><div class="line">  Theta1_grad += delta2 * a1;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">grad = [Theta1_grad(:); Theta2_grad(:)] / m;</div></pre></td></tr></table></figure><p>但是上面的答案和给出的还差挺多的。。。然后发现问题竟然出现在最后。。同时也修改了一下recode函数。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line"></div><div class="line"><span class="comment">% Feedforward</span></div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  <span class="comment">% step1.compute the output value</span></div><div class="line">  a1 = X(<span class="built_in">i</span>, :);</div><div class="line">  z2 = a1 * Theta1';</div><div class="line">  a2 = [<span class="number">1</span> sigmoid(z2)];</div><div class="line">  z3 = a2 * Theta2';</div><div class="line">  a3 = sigmoid(z3);</div><div class="line">  </div><div class="line">  <span class="comment">% recode the y</span></div><div class="line">  recode_y = [<span class="number">1</span>:num_labels] == y(<span class="built_in">i</span>);</div><div class="line">  <span class="comment">% compute cost function</span></div><div class="line">  J += -recode_y * <span class="built_in">log</span>(a3)' - (<span class="number">1</span> - recode_y) * <span class="built_in">log</span>(<span class="number">1</span> - a3)';</div><div class="line">  </div><div class="line">  <span class="comment">% step2.compute error term delta3</span></div><div class="line">  delta3 = a3 - recode_y;</div><div class="line">  <span class="comment">% size(delta3) = 1 x 10</span></div><div class="line">  </div><div class="line">  <span class="comment">% step3.compute error term delta2</span></div><div class="line">  delta2 = delta3 * Theta2(:, <span class="number">2</span>:<span class="keyword">end</span>) .* sigmoidGradient(z2);</div><div class="line">  <span class="comment">% size(delta2) = 1 x 25</span></div><div class="line">  </div><div class="line">  <span class="comment">% step4.accumulate the gradient</span></div><div class="line">  Theta1_grad += delta2' * a1;</div><div class="line">  <span class="comment">% size(Theta1_grad) = 25 x 401</span></div><div class="line">  Theta2_grad += delta3' * a2;</div><div class="line">  <span class="comment">% size(Theta2_grad) = 10 x 26</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">J /= m; </div><div class="line"></div><div class="line"><span class="comment">% regularized the cost function</span></div><div class="line">Theta1_t = Theta1(<span class="number">1</span>:hidden_layer_size, <span class="number">2</span>:input_layer_size+<span class="number">1</span>);</div><div class="line">Theta2_t = Theta2(<span class="number">1</span>:num_labels, <span class="number">2</span>:hidden_layer_size+<span class="number">1</span>);</div><div class="line"></div><div class="line">J += lambda * ((sum((Theta1_t.^<span class="number">2</span>)(:)) + sum((Theta2_t.^<span class="number">2</span>)(:)))) / (<span class="number">2</span> * m);</div><div class="line"></div><div class="line">Theta1_grad /= m;</div><div class="line">Theta2_grad /= m;</div><div class="line">grad = [Theta1_grad(:); Theta2_grad(:)];</div></pre></td></tr></table></figure><p>完美！</p><p>并且通过查资料，get了trace（）函数，可以不用for循环完成函数了~~</p><p>修改Feedfoorward</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% Feedforward</span></div><div class="line">a1 = [ones(m, <span class="number">1</span>) X];</div><div class="line">z2 = a1 * Theta1';</div><div class="line">a2 = [ones(m,<span class="number">1</span>) sigmoid(z2)];</div><div class="line">z3 = a2 * Theta2';</div><div class="line">a3 = sigmoid(z3);</div><div class="line"></div><div class="line"><span class="comment">% recode the y</span></div><div class="line"><span class="comment">%recode_y = zeros(m, num_labels);</span></div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m</div><div class="line">  recode_y(<span class="built_in">i</span>, :) = [<span class="number">1</span>:num_labels] == y(<span class="built_in">i</span>);</div><div class="line"><span class="keyword">end</span></div><div class="line"><span class="comment">% compute cost function</span></div><div class="line">J = trace(-recode_y * <span class="built_in">log</span>(a3)' - (<span class="number">1</span> - recode_y) * <span class="built_in">log</span>(<span class="number">1</span> - a3)');</div><div class="line">J /= m;</div></pre></td></tr></table></figure><h3 id="Regularized-Neural-Networks"><a href="#Regularized-Neural-Networks" class="headerlink" title="Regularized Neural Networks"></a>Regularized Neural Networks</h3><p>接下来是正则化神经网络，根据公式则可以敲出代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% rregularized neural networks</span></div><div class="line">Theta1_grad(:, <span class="number">2</span>:<span class="keyword">end</span>) += lambda * Theta1(:, <span class="number">2</span>:<span class="keyword">end</span>) / m;</div><div class="line">Theta2_grad(:, <span class="number">2</span>:<span class="keyword">end</span>) += lambda * Theta2(:, <span class="number">2</span>:<span class="keyword">end</span>) / m;</div></pre></td></tr></table></figure><p>lambda = 1，Maxiter = 50时隐藏层为下图，准确率94.6%：</p><img src="/2017/05/31/machine-learning-ex4/lambda1_iter50.png" alt="lambda1_iter50.png" title=""><p>接下来我们改变lambda的数值和迭代次数来看一下隐藏层的变化。首先修改lambda为0，迭代次数不变，准确率96.4%。</p><img src="/2017/05/31/machine-learning-ex4/lambda0_iter50.png" alt="lambda0_iter50.png" title=""><p>lambda为0，迭代次数为100，准确率可高了99.38%：</p><img src="/2017/05/31/machine-learning-ex4/lambda0_iter100.png" alt="lambda0_iter100.png" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一章主要学习了神经网络中的反向传播算法（Backpropagation algorithm ）。相对于线性回归（Linear Regression）、逻辑回归（Logistic Regression）BP确实很复杂了。但是今天刚看的《Don’t make me think》里面作者所言&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;我们不是追根究底，而是勉强应付。 因为这对我们来说并不重要。&lt;/strong&gt;对于我们中大多数人来说，只要我们能够正常使用，是否明白事物背后的运行机制并没有关系。这并不是智力低下的表现，而是我们并不关心。总之，它对我们来说没那么重要。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;那么现阶段，对于BP算法有一个整体的概念，懂得如何使用它便是关键。上一章我们用已经给定的theta矩阵来进行预测，这一章我们将通过BP算法来学习参数。这一章的练习主要分为两个部分，第一部分：我们通过给定的神经网络权重，前馈计算正则化的代价函数。第二部分：我们自己训练神经网络的权重。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex3</title>
    <link href="http://yoursite.com/2017/05/29/machine-learning-ex3/"/>
    <id>http://yoursite.com/2017/05/29/machine-learning-ex3/</id>
    <published>2017-05-29T07:43:51.000Z</published>
    <updated>2017-05-30T02:20:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一章练习也有两大部分，第一部分是正则化逻辑回归方程的多类分类，识别图像中的数字。觉得逻辑回归应该也是神经网络的一部分吧，只是没有hidden layer，直接就final了。第二部分需要解决的问题是一样的，识别图像中的文字，只通过是神经网络来达到这个目的。</p><a id="more"></a><h1 id="1-Multi-Class-Classification"><a href="#1-Multi-Class-Classification" class="headerlink" title="1/ Multi-Class Classification"></a>1/ Multi-Class Classification</h1><h3 id="Vectorizing-Logistic-Regression"><a href="#Vectorizing-Logistic-Regression" class="headerlink" title="Vectorizing Logistic Regression"></a>Vectorizing Logistic Regression</h3><p>按照pdf的步骤，先写出不正则化的逻辑回归方程，打印了一下这时函数参数的X </p><img src="/2017/05/29/machine-learning-ex3/Xt.png" alt="Xt.png" title=""><p>发现这一节要求不使用循环，全部向量化，那我上一章就基本实现了耶，我真棒~ 稍微修改了一下方程，用一下hint的.*和sum，终于懂星号前面有一点是什么鬼了，是不使用矩阵乘法，而是对应的元素相乘。方程如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算unregulized cost function</span></div><div class="line">J = sum(-y .* <span class="built_in">log</span>(sigmoid(X*theta)) - (<span class="number">1</span>-y) .* <span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta))) / m;</div></pre></td></tr></table></figure><p>此时输出J的值为0.734819，但是参考值是2.534819，等正则化了看看结果。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算gradient</span></div><div class="line">grad = X' * (sigmoid(X * theta) - y);</div></pre></td></tr></table></figure><p> 接下来就要开始正则化cost function和gradient了。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 正则化cost function</span></div><div class="line">J += lambda * sum(theta(<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>) / (<span class="number">2</span> * m);</div></pre></td></tr></table></figure><p>上一章傻傻的用循环来避开对theta~0~的处理，现在get了用冒号来限制处理范围。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 正则化gradient</span></div><div class="line">temp = theta;</div><div class="line">temp(<span class="number">1</span>) = <span class="number">0</span>;</div><div class="line">grad += lambda * temp / m;</div></pre></td></tr></table></figure><p>提交发现咋不对啊。对照了一下ex2发现gradient忘记 / m了，我这粗心的小脑袋啊。。。</p><h3 id="oneVsAll"><a href="#oneVsAll" class="headerlink" title="oneVsAll"></a>oneVsAll</h3><p>看完毫无头绪要怎么训练啊。。我回顾一下one-vs-all是什么鬼。嗯。。再回来理解一下题目，把每个训练集分成K个类，返回一个Kx(N+1)的矩阵theta，矩阵的每一行是通过逻辑回归方程学习到的theta值。继续仔细看，没让你直接用一个函数就完成预测，这个函数只是用来生训练分类器tehta矩阵的，并且还提示使用一个给定函数fmincg来生成theta，只是循环K次，每次生成一个向量。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: num_labels</div><div class="line">  <span class="keyword">if</span> <span class="built_in">i</span> == <span class="built_in">i</span> </div><div class="line">  c = <span class="number">10</span>;</div><div class="line">  <span class="keyword">else</span> </div><div class="line">  c = <span class="built_in">i</span>;</div><div class="line">  initial_theta = <span class="built_in">zeros</span>(n + <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">  options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</div><div class="line">  [theta] = ...</div><div class="line">    fmincg(@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</div><div class="line">                initial_theta, options);</div><div class="line">   all_theta(c, :) = theta';</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>一开始对于c的概念有一些模糊，在经过测试以后发现 一个向量==一个数值 时，返回一个向量，其中与这个值相等的位置为1，其他位置均为0。再回顾一下上课的笔记，那么根据这个函数的意思，在num_labels个循环中y == c 就生成了num_labels个1位置不同的向量，这个向量作为判断结果，对于每一个结果通过fmincg函数来生成一个theta向量，但是这个向量是(n+1)x1的，因此要把theta转置成all_theta对应的那一行。</p><img src="/2017/05/29/machine-learning-ex3/multiy.png" alt="multiy.png" title=""><p>修改代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> c = <span class="number">1</span>: num_labels</div><div class="line">  initial_theta = <span class="built_in">zeros</span>(n + <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">  options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</div><div class="line">  [theta] = ...</div><div class="line">    fmincg(@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</div><div class="line">                initial_theta, options);</div><div class="line">   all_theta(c, :) = theta';</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>理解了c的值以后，就知道0为什么要用10来表示啦。</p><p>接下来完成进行预测的函数。要对所有训练集进行训练，也就是h = X * theta’，然后与y进行比较，判断所属类型。不过我们已经知道了y就是一个向量，1在不同的位置为不同的类别。那么就是每一个训练集得到的 h 向量中数值最大的那一个就是我们的类别。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算hypothesis</span></div><div class="line">h = X * all_theta';</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : m</div><div class="line">  [maxn, maxi] = max(h(<span class="built_in">i</span>));</div><div class="line">  p(<span class="built_in">i</span>) = maxi;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>但是结果又不对，思路应该是没错的，检查了一下size(theta)，是一个10x401的矩阵没错，h计算出来的结果肯定也没错。那么问题肯定就出现在查找最大值上。输出了一下h(1)发现只是一个数值，我们要查找的应该是一行中的最大值，把max(h(i))改成max(h(i, :))就对啦。</p><h1 id="2-Neural-Networks"><a href="#2-Neural-Networks" class="headerlink" title="2/ Neural Networks"></a>2/ Neural Networks</h1><p>上一部分我们通过多类分类的逻辑回归方程来识别手写的数字。但是由于逻辑回归仅仅是一个线性分类器，对于更复杂的行为很难处理，因此在这个部分我们实践一下神经网络。这个神经网络有3层，输入层，隐藏层，输出层。我们使用已经训练完成的权重来进行预测。</p><h3 id="Feedforward-Propagation-and-Prediction"><a href="#Feedforward-Propagation-and-Prediction" class="headerlink" title="Feedforward Propagation and Prediction"></a>Feedforward Propagation and Prediction</h3><p>这个预测函数通过给定的Theta1、Theta2来对输入层进行训练，判断结果和one-vs-all通过最大值来分类是一样的。</p><p>我们先来看下训练集X、Theta1、Theta2的大小</p><img src="/2017/05/29/machine-learning-ex3/size.png" alt="size.png" title=""><p>如上图所示，也就是说训练集有5000个，400个项（不包含x~0~ = 1），因此加上x~0~以后，Theta1把401个项训练成25个，再加上x~0~ = 1，最后训练出10个分类结果。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% add x0 = 1</span></div><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line"></div><div class="line"><span class="comment">% compute hidden layer</span></div><div class="line">layer2 = [ones(m, <span class="number">1</span>), X * Theta1<span class="string">'];</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">% compute output layer</span></div><div class="line"><span class="string">layer3 = layer2 * Theta2'</span>;</div><div class="line"></div><div class="line">% predict</div><div class="line">for i = <span class="number">1</span> : m</div><div class="line">  [maxn, maxi] = max(layer3(<span class="built_in">i</span>, :));</div><div class="line">  p(<span class="built_in">i</span>) = maxi;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>自信满满写完submit发现还是错的 orz…准确率不对，回去看一下训练模型，好像每一层训练的时候都要用到sigmodi函数？</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% add x0 = 1</span></div><div class="line">X = [ones(m, <span class="number">1</span>) X];</div><div class="line"></div><div class="line"><span class="comment">% compute hidden layer</span></div><div class="line">z2 = [ones(m, <span class="number">1</span>) X * Theta1<span class="string">'];</span></div><div class="line"><span class="string">a2 = sigmoid(z2);</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">% compute output layer</span></div><div class="line"><span class="string">z3 = a2 * Theta2'</span>;</div><div class="line">a3 = sigmoid(z3);</div><div class="line"></div><div class="line">% predict</div><div class="line">for i = <span class="number">1</span> : m</div><div class="line">  [maxn, maxi] = max(z3(<span class="built_in">i</span>, :));</div><div class="line">  p(<span class="built_in">i</span>) = maxi;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>啊。。。明明准确率对，结果也对为什么submit以后还是没有分数呢。。。再回去认真看模型。。</p><img src="/2017/05/29/machine-learning-ex3/model.png" alt="model.png" title=""><p>好像隐藏层是先逻辑回归，再添加a~0~嗯。。。got it。。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% compute output layer</span></div><div class="line">z3 = a2 * Theta2';</div><div class="line">a3 = sigmoid(z3);</div></pre></td></tr></table></figure><img src="/2017/05/29/machine-learning-ex3/nice.png" alt="nice.png" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一章练习也有两大部分，第一部分是正则化逻辑回归方程的多类分类，识别图像中的数字。觉得逻辑回归应该也是神经网络的一部分吧，只是没有hidden layer，直接就final了。第二部分需要解决的问题是一样的，识别图像中的文字，只通过是神经网络来达到这个目的。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex2</title>
    <link href="http://yoursite.com/2017/05/28/machine-learning-ex2/"/>
    <id>http://yoursite.com/2017/05/28/machine-learning-ex2/</id>
    <published>2017-05-28T07:08:36.000Z</published>
    <updated>2017-05-30T02:20:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一章是实践逻辑回归。两个大题目，一个就是正常的逻辑回归，另外一个是正则化的逻辑回归。记录下做作业的心路历程。</p><a id="more"></a><h3 id="plotData"><a href="#plotData" class="headerlink" title="plotData"></a>plotData</h3><p>一开始就感觉被难住，X是mx2的矩阵，y是m行向量。对于如何来显示图像示毫无头绪，然后发现pdf里给出了答案。get了两个函数，一个是find，另一个是plot。</p><img src="/2017/05/28/machine-learning-ex2/find.png" alt="find.png" title=""><p>简单的看一下find根据查找条件返回查找矩阵的下标</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pos = <span class="built_in">find</span>(y == <span class="number">1</span>);</div><div class="line">neg = <span class="built_in">find</span>(y == <span class="number">0</span>);</div></pre></td></tr></table></figure><p>因此这两句结果分类返回对应的训练集所在行数。</p><img src="/2017/05/28/machine-learning-ex2/pos.png" alt="pos.png" title=""><p>看一下pos~就是返回一个向量，包括结果为1的行数。</p><img src="/2017/05/28/machine-learning-ex2/plot.png" alt="plot.png" title=""><p>接下来就是显示啦，第一个参数是x轴的数值，第二个参数是y坐标的数值，分别取自对应分类的第一项成绩和第二项成绩。然后显示结果。</p><img src="/2017/05/28/machine-learning-ex2/plot_result.png" alt="plot_result.png" title=""><h3 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h3><p>这个用下图这个公式变换一下函数</p><img src="/2017/05/28/machine-learning-ex2/sigmoid.png" alt="sigmoid.png" title=""><p>一步一步来，先实现一个数字的转换：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g = <span class="number">1</span> / (<span class="number">1</span> + <span class="built_in">exp</span>(x));</div></pre></td></tr></table></figure><p>然后发现结果不正确，发现x还有可能是矩阵，也就是说矩阵的每一位都要做相应的变换</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:r</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:c</div><div class="line">  g(<span class="built_in">i</span>, <span class="built_in">j</span>) = <span class="number">1</span> / (<span class="number">1</span> + <span class="built_in">exp</span>(-z(<span class="built_in">i</span>,<span class="built_in">j</span>)));</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><h3 id="costFunction"><a href="#costFunction" class="headerlink" title="costFunction"></a>costFunction</h3><p>首先公式很复杂，但是其实实现很简单</p><img src="/2017/05/28/machine-learning-ex2/cost.png" alt="cost.png" title=""><img src="/2017/05/28/machine-learning-ex2/grad.png" alt="grad.png" title=""><p>我一开始弄了两层循环来遍历i和m，后面意识到，我们用了矩阵啊，然后变成了一层只对m的循环，然后发现还是不对，其实就。。。非常简单</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% 计算hypothesis</span></div><div class="line">para =  X * theta;</div><div class="line"><span class="comment">% 计算cost</span></div><div class="line">J = (-y' * <span class="built_in">log</span>(sigmoid(para)) - (<span class="number">1</span> - y)' * (<span class="built_in">log</span>(<span class="number">1</span> - sigmoid(para)))) / m;</div><div class="line"><span class="comment">% 计算gradient</span></div><div class="line">grad = X' * (sigmoid(para) - y)/ m;</div></pre></td></tr></table></figure><h3 id="costFunctionReg"><a href="#costFunctionReg" class="headerlink" title="costFunctionReg"></a>costFunctionReg</h3><p>正则化逻辑回归的函数，这里要注意的是，计算cost和gradient的时候都不能把theta~0~ 算进去，复杂的公式用矩阵带入就好简单呀，虽然花了一个下午完成练习，主要都花在纠结矩阵谁乘以谁，但是完成了就成就感满满~~</p><p>修改一下lambda的值来测试一下整体化到底是什么鬼</p><img src="/2017/05/28/machine-learning-ex2/lamda0.png" alt="lamda0.png" title=""><img src="/2017/05/28/machine-learning-ex2/lamda1.png" alt="lamda1.png" title=""><img src="/2017/05/28/machine-learning-ex2/lamda50.png" alt="lamda50.png" title=""><p>从图形的变化可以看出lamda太小会overfitting，1的时候切好是最正确的分界线，50就开始under fitting了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一章是实践逻辑回归。两个大题目，一个就是正常的逻辑回归，另外一个是正则化的逻辑回归。记录下做作业的心路历程。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>复习一下单片机吧</title>
    <link href="http://yoursite.com/2017/05/24/Microcontrollermd/"/>
    <id>http://yoursite.com/2017/05/24/Microcontrollermd/</id>
    <published>2017-05-23T16:00:00.000Z</published>
    <updated>2017-05-28T10:44:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>在了解无线键盘监听装置的实验原理中，还是先理解一下一直没搞懂的单片机吧。顺便小小复习一下以前计算机组成原理的内容。</p><a id="more"></a><h1 id="单片机"><a href="#单片机" class="headerlink" title="单片机"></a>单片机</h1><p>全称单片微型计算机，又称微控制器，是把中央处理器、存储器、定时/计数器、各种输入输出接口等都集成在一块集成电路芯片上的微型计算机。与电脑中的通用型微处理器相比，它更强调自供应（不用外接硬件）和节约成本，最大优势是体积小，可放在仪表内部，但存储量小，输入输出接口简单，功能较低。</p><p>大多数使用冯诺依曼结构，即定义了嵌入式系统所必须的四个基本部分：1、中央处理器核心，程序存储器（只读存储器或闪存）。2、数据存储器（随机存储器）。3、一个或者多个定时/计算器。4、用来与外围设备以及扩展资源进行通信的输入/输出端口。</p><h3 id="与CPU的区别"><a href="#与CPU的区别" class="headerlink" title="与CPU的区别"></a>与CPU的区别</h3><p>CPU是一个运算处理器，主要负责计算、处理数据。单片机包括运算单元、存储单元、输入输出单元。单片机是一种微处理器，可以执行某些功能。但是CPU还要有主板、内存、硬盘等辅助。</p><h3 id="常用单片机"><a href="#常用单片机" class="headerlink" title="常用单片机"></a>常用单片机</h3><p>微芯（Microchip）公司的PIC系列出货量居于业界领导者地位；Atmel的51系列AVR系列种类众多，受支持面广；Arduino就是基于Atmel的AVR系列；德州仪器的MSP430系列以低功耗闻名，常用于医疗电子产品以及仪器仪表中；瑞萨单片机在日本使用广泛。还有比如Intel、飞思、卡尔半导体，NEC，NXP等等厂牌。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在了解无线键盘监听装置的实验原理中，还是先理解一下一直没搞懂的单片机吧。顺便小小复习一下以前计算机组成原理的内容。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Little Things / 01</title>
    <link href="http://yoursite.com/2017/05/23/Little-Things-01/"/>
    <id>http://yoursite.com/2017/05/23/Little-Things-01/</id>
    <published>2017-05-23T07:15:48.000Z</published>
    <updated>2017-05-23T07:36:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>开了一个新话题啦啦啦 ，用来记录平常看到的有意思的小细节。今天记录一下Tezign官网和支付宝的小可爱，会动的小人实在太有趣啦~</p><a id="more"></a><img src="/2017/05/23/Little-Things-01/tesign.gif" alt="tesign.gif" title=""><h3 id="特赞官网"><a href="#特赞官网" class="headerlink" title="特赞官网"></a>特赞官网</h3><p>打开特赞官网下滑的的第二个界面是一幅插画，原先以为只是一幅插画，没想到一些小人还会动，着实是小彩蛋的惊喜。</p><p>从左到右分别是两个正在比赞自拍的汉子 / 拿着本子在记录的妹子 / 正在专注手绘但是会蜜汁转头的小哥 / 和一只趴在电视机上摇尾巴的猫 /  最后可以打开电视机播放视频。</p><h3 id="支付宝"><a href="#支付宝" class="headerlink" title="支付宝"></a>支付宝</h3><p>愿意是为了截加载时预留空间的图（如下图</p><p>但是因为切换的速度太快了，为了截成功，截了好多次，发现了一个小惊喜，对正常界面截图会出现一个[我要建议]的小方块</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开了一个新话题啦啦啦 ，用来记录平常看到的有意思的小细节。今天记录一下Tezign官网和支付宝的小可爱，会动的小人实在太有趣啦~&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>为什么草图对于设计如此重要？</title>
    <link href="http://yoursite.com/2017/05/14/Daily-Translation-04/"/>
    <id>http://yoursite.com/2017/05/14/Daily-Translation-04/</id>
    <published>2017-05-14T07:31:19.000Z</published>
    <updated>2017-05-30T03:08:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>在知乎上看到这篇文章是是同济2015年的英语面试题，就翻译来看看。 原文链接： <a href="https://crowdfavorite.com/why-is-sketching-such-an-important-aspect-of-design/" target="_blank" rel="external">Why is sketching such an important aspect of design?</a></p><p>在大学的时候，我的设计教授鼓励我手绘，但我不想听。为什么当我拥有一台含所有设计可视化软件以及比我所知更多的字体的电脑，我还要在幼稚的小本子上画画呢？</p><p>多年来我一直与这个观点作斗争。每当一个新的设计项目到来，我会拿出我的手绘本，寻找最棒的笔，然后开始手绘。结果通常是一部分时间在画草图，接着是耗费无数小时在电脑上完善一个想法。</p><blockquote><p>当我匆忙地拿起电脑开始完善，我失去了草图提供的机会。</p></blockquote><p>随着时间的推移，我慢慢开始越来越多的理解了这个观点。没有人强迫我。我意识到为了使我的想法更加具体，在电脑上浪费了多少时间。如今，手绘是我工作中很的重要组成部分，不仅是对客户，也是对我自己。更好的设计现在来得也更快。</p><a id="more"></a><h3 id="为什么草图很棒："><a href="#为什么草图很棒：" class="headerlink" title="为什么草图很棒："></a>为什么草图很棒：</h3><p><strong>你的第一个想法很难是最佳的</strong></p><p>你有一个项目想法感觉很棒。这是开始。画出来！它只需要几秒钟。现在手绘出更多的想法。你不会知道你最初的想法是否是最好的直到你探索出其他的想法。如果你发现你更喜欢的东西，你会立马感激你没有浪费5个小时在Illustrator中，只是像调整一个不好的logo的字母间距上这样的事上。</p><p><strong>手绘是快速的、粗糙的、脏乱的。</strong></p><p>学会拥抱你的纸和笔，你将会对你产生想法的速度感到十分惊喜。你会想知道为什么你从未想到过。通过给你自己自由去潦草地画出想法，你会到达你从未想象过的充满创意的地方。</p><p><strong>你会节省时间。</strong></p><p>在四十年代，我们让客户参与进设计的的每一步。我们不喜欢“大透露”，因为当过程保持神秘时，结果经常会让人失望。我们给客户展示我们许多的草图以展示我们的意图。当一个过程需要更改，我们会用几秒钟手绘出一个修订版，而不是花费好几个小时在photoshop中来移动图层。</p><p><strong>草图从细节中分离出观点。</strong></p><p>当你第一次呈现一个概念时，人们会很自然地关注错误的细节。如果你直接把你的想法用一个设计程序展示，人们倾向于关注单一的蓝色，或是呈现的第一种排版风格。当你只需弄懂“我们的方向是否正确？”时，会让沟通交流产生障碍。</p><p><strong>手绘是属于所有人的。</strong></p><p>我经常听到人们对于手绘的担忧，因为他们对自己手绘能力缺乏信心。不要担心！可以看看这本Dan Roam](<a href="http://www.thebackofthenapkin.com/" target="_blank" rel="external">http://www.thebackofthenapkin.com/</a>) <a href="http://www.thebackofthenapkin.com/" target="_blank" rel="external">“The Back of the Napkin” </a>写的书。基础的形状（圆形，正方形，矩形），线条，箭头，以及粘贴的图像足以展示你的想法。与团队或者客户一起手绘是很有益的，因为你可以在手绘的同时阐述你的观点，让你可以把握团队的努力重点。</p><p>灵感来源，可以看看SXSW 2010的 <a href="http://sketchnotearmy.com/2010/05/13/visual-note-taking-101-at-sxsw-slides-audio/" target="_blank" rel="external">Visual Note-Taking 101</a> 。只想看图片的话，请跳到27页，惊奇于阴影使图片更有趣。</p><p><strong>最后，手绘很有意思！</strong></p><p>当你停止焦虑，让你的想法发展时，你会发现手绘多么有趣。特别是当你找到完美的笔和纸组合！我的完美组合是 black Pilot Precise V7 配上 方眼Moleskine.</p><p>接下来是我给你的挑战：下一次你接到任何形式的沟通任务，不管是一个logo，一个品牌概念，甚至是一个导向你喜爱的咖啡店的地图，尝试手绘草图。让手绘融入你每天的任务，你会发现它也符合你的职业惯例。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在知乎上看到这篇文章是是同济2015年的英语面试题，就翻译来看看。 原文链接： &lt;a href=&quot;https://crowdfavorite.com/why-is-sketching-such-an-important-aspect-of-design/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Why is sketching such an important aspect of design?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在大学的时候，我的设计教授鼓励我手绘，但我不想听。为什么当我拥有一台含所有设计可视化软件以及比我所知更多的字体的电脑，我还要在幼稚的小本子上画画呢？&lt;/p&gt;
&lt;p&gt;多年来我一直与这个观点作斗争。每当一个新的设计项目到来，我会拿出我的手绘本，寻找最棒的笔，然后开始手绘。结果通常是一部分时间在画草图，接着是耗费无数小时在电脑上完善一个想法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当我匆忙地拿起电脑开始完善，我失去了草图提供的机会。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;随着时间的推移，我慢慢开始越来越多的理解了这个观点。没有人强迫我。我意识到为了使我的想法更加具体，在电脑上浪费了多少时间。如今，手绘是我工作中很的重要组成部分，不仅是对客户，也是对我自己。更好的设计现在来得也更快。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>从心理学角度来看待用户体验设计</title>
    <link href="http://yoursite.com/2017/05/02/Daily-Translation-03/"/>
    <id>http://yoursite.com/2017/05/02/Daily-Translation-03/</id>
    <published>2017-05-02T04:41:30.000Z</published>
    <updated>2017-05-30T03:06:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>五一小长假的最后一天把portfolio赶粗！来！了！下午睡了一会儿晚上去了超市，缺席了一天的翻译，今天死也不能落下了。（对不起距离信誓旦旦说下这话落下两天了）。本来想翻译 <a href="https://medium.com/swlh/the-current-state-of-adaptive-design-6b2b89b258c4" target="_blank" rel="external">The Current State of Adaptive Design</a> 翻译了一半发现不对劲，是对比工具的使用，然而这些工具我都没有用过，我又没有mac:( 睡了一觉起来放弃这篇文章（压箱底），换成<a href="http://uxmag.com/articles/the-psychologists-view-of-ux-design" target="_blank" rel="external">The Psychologist’s View of UX Design</a>。</p><p>你可能听说过这关于大象的故事：</p><blockquote><p>一个国王把六个人带进一个黑暗的建筑。他们看不见任何东西。国王对他们说，”我从野生地带买下这只动物并带回东方。它被称为大象。”人们问道：”大象是什么？”国王说：”你们摸一下大象，描述给我听。”摸到腿的人说大象像一根柱子，摸到尾巴的说大象像一根绳子，摸到躯干的说像一根树枝，摸到耳朵的说像一把扇子，摸到肚子的说像一堵墙，摸到象牙的说像一根硬管道。”你们说的都是对的”，国王说道，”你们每个人都摸到了大象的一部分。”</p></blockquote><p>这个大象的故事使我想起了不同背景、教育、经历的人对于设计的不同看法。视觉设计师从一个角度来看待交互设计，交互设计师换了另一个角度，而程序员又是另外一个角度。了解甚至是体验别人正在体验的大象的部分是很有帮助的。</p><p>我是一个受过教育和训练的心理学家。因此我体验的那部分大象就是我们对人的了解以及我们如何将其应用于用户体验设计。我对大脑、视觉系统、记忆、动机做了研究和学习，并从中推出用户设计体验的原则。</p><p>这篇文章是从心理学家的视角对大象进行简单描述。</p><a id="more"></a><h3 id="1-除非必要，人们不想工作或思考"><a href="#1-除非必要，人们不想工作或思考" class="headerlink" title="1.除非必要，人们不想工作或思考"></a>1.除非必要，人们不想工作或思考</h3><ul><li>人们会做<strong>尽可能少的工作</strong>来完成任务</li><li>最好只展示一点点信息并让他们选择是否需要查看更多。<strong>渐近展开</strong>是不错的选择，最近我也写了一篇与其相关的博文。</li><li>不要光描述事物，给人们看例子。</li><li>当你在设计时，注意对象在屏幕、页面、设备上的承担特质。如果某个对象是可点击的，请确保它看起来像是可点击的。</li><li>只提供<strong>人们确实需要的功能</strong>。不要用你的想法来衡量他们需要什么；做用户研究去找到他们的真实需求。给人们超过他们的需要的只会搞砸用户体验。</li><li>提供默认值。<strong>默认值让人们做更少的事</strong>就能完成任务。</li></ul><h3 id="2-人有局限性"><a href="#2-人有局限性" class="headerlink" title="2.人有局限性"></a>2.人有局限性</h3><ul><li>人们只能在屏幕上看有限的信息或读有限的文本而<strong>不失去兴趣</strong>。在当下只提供需要的信息（看上面的渐近展开）。</li><li>让信息<strong>容易浏览</strong>。</li><li>信息或文本使用<strong>标题</strong>或者<strong>短块</strong>。</li><li>人们<strong>不能同时进行多项任务</strong>。研究非常明确的说明了这点，所以别指望人们能够做到。</li><li>人们更喜欢<strong>短小的文案</strong>，但他们<strong>长文本能帮助他们更好的理解</strong>。这是个难题，所以在你的项目中决定偏好还是性能更重要，但记住<strong>人们会要求那些实际上对他们不是最好的东西</strong>。</li></ul><h3 id="3-人们会犯错误"><a href="#3-人们会犯错误" class="headerlink" title="3.人们会犯错误"></a>3.人们会犯错误</h3><ul><li>假设人们犯错误。<strong>预测</strong>他们可能犯的错误并避免它们发生。</li><li>如果一个错误的结果是非常严重的，那么在用户操作前请<strong>提供确认</strong>。</li><li>让<strong>撤销</strong>非常容易</li><li>避免错误的产生永远比帮助人们纠正它来得好。<strong>最好的错误消息就是完全没有消息</strong>。</li><li>如果一个任务容易出错，<strong>将它拆分成小块</strong>。</li><li>如果用户犯了错并且你能<strong>纠正它</strong>，那么就这么做，并且展示你做了什么。</li><li>设计用户体验的人也会犯错，所以确保有时间和精力来进行迭代、用户反馈和测试。</li></ul><h3 id="4-人类记忆是复杂的"><a href="#4-人类记忆是复杂的" class="headerlink" title="4.人类记忆是复杂的"></a>4.人类记忆是复杂的</h3><ul><li>人们会重构记忆，这意味着记忆是一直在变化的。你只能相信用户所说的极少的一部分，<strong>观察他们的行为</strong>比听从他们所说比来得更好。</li><li>记忆也是很脆弱的。它退化得很快并容易导致很多错误。<strong>不要让人们记忆从一个任务到另外一个任务</strong>或者一个页面到另外一个页面的东西。</li><li>人们只能同时记住大概3-4个项目。<strong>7±2法则是一个都市传奇</strong>。研究表明真实的数字就是3-4个。</li></ul><h3 id="5-人们都是社会的"><a href="#5-人们都是社会的" class="headerlink" title="5.人们都是社会的"></a>5.人们都是社会的</h3><ul><li>人们总是尝试<strong>使用科技来社交</strong>。这是一个千年来的真理。</li><li>人们对于<strong>他们应该做什么会咨询他人的意见</strong>，特别在他们不确定的时候。这被叫做<strong>社会确认</strong>。举个例子，这就是为什么，打分和评论在各网站中这么强大。</li><li>如果人们在同一时间一起做事（同步行为），这会将他们联系在一起。同时大脑中也会产生化学反应。笑声同样使人们紧密联系。</li><li>如果你帮助了我那么我也会感激并反过来帮助你（互助）。研究表明，如果你希望人们填一个表格，<strong>先给他们想要的东西，再请求他们填写表格</strong>，而不是先填后给。</li><li>当你看到某些人做某些事，在你大脑里的某些部分会亮起，并认为你也正在做这件事（镜像神经元）。我们生性就是会模仿的动物。如果你想要人们做某些事那么让其他人做这件事。</li><li>你最多只能与150个人有强联系。强联系指与其有身体邻近的亲切的关系。但是<strong>弱联系可以成千上万</strong>并且是非常有影响力的。（就像Facebook）</li></ul><h3 id="6-注意力"><a href="#6-注意力" class="headerlink" title="6.注意力"></a>6.注意力</h3><ul><li>我开始认为<strong>注意力这个概念是设计有趣的用户界面的关键</strong>。接下来我会写更多的关于这方面文章。抓住并且保持专注，不转移正专注于某事的人的注意力，是非常关键的。</li><li>人们天生就会关注<strong>不同或者新奇</strong>的事物。如果你做出与众不同的事情，它将会脱颖而出。</li><li>话说回来，人们事实上会忽视他们视野之内的变化。这被称为<strong>变化失明</strong>。有一些很有趣的视频，当人们走在街上与向他们问路的人谈话，然后完全没有注意到，问路人已经变了。</li><li>你可以利用感官来抓住注意力。<strong>亮丽的颜色，较大的字体，喇叭声以及语调</strong>会吸引注意力。</li><li><strong>人们很容易分心</strong>。如果你不想他们被转移，不要在页面上闪烁或播放视频。反之如果你想吸引他们的注意力，可以这么做。</li></ul><h3 id="7-人们渴望信息"><a href="#7-人们渴望信息" class="headerlink" title="7.人们渴望信息"></a>7.人们渴望信息</h3><ul><li>多巴胺是一种让人们寻找食物、性爱、信息的化学物质。学习是具有多巴胺能的，我们无法控制地想获取更多信息。</li><li>人们经常<strong>想获取超出他们实际处理范围的信息</strong>。具备更多信息让人们感觉他们有更多的选择；有了更多的选择人们感觉一切尽在掌控之中，感觉掌握了一切使人们感觉生存的更好。</li><li>人们需要反馈。计算机不需要告诉人们它正在加载文件。<strong>人们需要知道接下来会发生什么</strong>。</li></ul><h3 id="8-无意识过程"><a href="#8-无意识过程" class="headerlink" title="8.无意识过程"></a>8.无意识过程</h3><ul><li>大多数思想过程是无意识发生的。</li><li>如果你能让人们做出很小的动作（注册成为免费会员），<strong>之后他们会做出更大的动作</strong>（升级成付费用户）。</li><li>​</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;五一小长假的最后一天把portfolio赶粗！来！了！下午睡了一会儿晚上去了超市，缺席了一天的翻译，今天死也不能落下了。（对不起距离信誓旦旦说下这话落下两天了）。本来想翻译 &lt;a href=&quot;https://medium.com/swlh/the-current-state-of-adaptive-design-6b2b89b258c4&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;The Current State of Adaptive Design&lt;/a&gt; 翻译了一半发现不对劲，是对比工具的使用，然而这些工具我都没有用过，我又没有mac:( 睡了一觉起来放弃这篇文章（压箱底），换成&lt;a href=&quot;http://uxmag.com/articles/the-psychologists-view-of-ux-design&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;The Psychologist’s View of UX Design&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;你可能听说过这关于大象的故事：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一个国王把六个人带进一个黑暗的建筑。他们看不见任何东西。国王对他们说，”我从野生地带买下这只动物并带回东方。它被称为大象。”人们问道：”大象是什么？”国王说：”你们摸一下大象，描述给我听。”摸到腿的人说大象像一根柱子，摸到尾巴的说大象像一根绳子，摸到躯干的说像一根树枝，摸到耳朵的说像一把扇子，摸到肚子的说像一堵墙，摸到象牙的说像一根硬管道。”你们说的都是对的”，国王说道，”你们每个人都摸到了大象的一部分。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个大象的故事使我想起了不同背景、教育、经历的人对于设计的不同看法。视觉设计师从一个角度来看待交互设计，交互设计师换了另一个角度，而程序员又是另外一个角度。了解甚至是体验别人正在体验的大象的部分是很有帮助的。&lt;/p&gt;
&lt;p&gt;我是一个受过教育和训练的心理学家。因此我体验的那部分大象就是我们对人的了解以及我们如何将其应用于用户体验设计。我对大脑、视觉系统、记忆、动机做了研究和学习，并从中推出用户设计体验的原则。&lt;/p&gt;
&lt;p&gt;这篇文章是从心理学家的视角对大象进行简单描述。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>虚拟现实中的手势设计</title>
    <link href="http://yoursite.com/2017/04/30/Daily-Translation-02/"/>
    <id>http://yoursite.com/2017/04/30/Daily-Translation-02/</id>
    <published>2017-04-30T00:36:55.000Z</published>
    <updated>2017-05-30T03:06:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天的翻译来源于 <a href="http://facebook.design" target="_blank" rel="external">http://facebook.design</a> ，一直觉得未来的VR会超屌的，就进一步了解一下。先是来到 <a href="http://facebook.design/virtual-hands#scroll" target="_blank" rel="external">http://facebook.design/virtual-hands#scroll</a> 下载了Virtual Hands，各种手势的png麻溜的存起来，保不准以后有用呢。页面上有一个链接跳转到Christophe Tauziet制作VR手势交互的文章 <a href="https://medium.com/facebook-design/designing-for-hands-in-vr-61e6815add99" target="_blank" rel="external">Designing for Hands in VR</a> 这篇文章。那今天就翻译这篇吧~</p><a id="more"></a><blockquote><p>建立自然人机交互下一步</p></blockquote><p>年初我加入了Facebook的Social VR团队。我们团队的目标是探索虚拟现实如何帮助人们创造新的有趣的、有意义的方式来与你关心的人沟通。</p><p>在十月，Mark Zuckerberg在Oculus Connetct 主题演讲中对我们最近的一些探索进行了现场演示（然后有一段超屌的视频，看完简直惊叹）。</p><p>VR由于不同的头戴式识图器和输入控制器仍然是一个非常分散和多样的媒介。我们团队决定工作重点放在近期发布的<a href="https://www3.oculus.com/en-us/rift/" target="_blank" rel="external">Oculus Touch</a> 控制器。我们在早期认识到通过这些控制器将整个手的能力带入VR，为有意义的社交创造了独特的机会。</p><p>在接下来的几年，VR的发展很可能会超出我们的认知，但我们已经知道的设计仍然是一个很有价值的经验教训。以下是我们在VR中为手创造自然和舒适的互动的一些经验教训。按照我们每周发现的速度，其中的一些发现在未来几年可能毫不相干或者看起来很蠢，但我们希望它能够帮助任何人取得进一步成果。</p><h2 id="创造自然的互动"><a href="#创造自然的互动" class="headerlink" title="创造自然的互动"></a>创造自然的互动</h2><p>我有时会将VR的设计描述成掉进海洋里，不知道如何游泳。你真的不知道如何游，也不知道往哪个方向游。唯一避免溺死的事就是重用一些我们在产品设计中用来解决复杂问题时使用的解决技巧，寻找任何的机会发展每一个对这种媒介有用的新技能，并帮助彼此。在传统的产品设计背景下，大多数互动具有许多已建立和经过验证的模式。迄今为止我发现最有效的能取得进步的方式，就是在VR中学到的通过不断测试和犯错。</p><p>当我们在为Oculus Touch设计时，我们最早意识到任何人刚接触VR时，不得不在他们的思维模式中做出两个转变。一个是沉浸式方面：环顾四周，有一种存在感，并将虚拟空间和物理空间区分开来。另一个是这种新型的输入控制器如何立即给你虚拟的手并且让你与周围的环境互动。</p><img src="/2017/04/30/Daily-Translation-02/1-A9-pLXWmEOBdF8I29NUK5w.gif" alt="1-A9-pLXWmEOBdF8I29NUK5w.gif" title=""><p>在设计控制时，通过做一个特定的动作来查看最自然和直观的方式是非常重要的。这么做使你产生容易理解、令人愉悦的体验，不管是伸手、拾物、与2D面板交互、远距离物体等等。</p><p>通过无数的试验和可用性研究，我们发现依赖控制器按钮有一些缺点。没有玩过过电子游戏的人看不见控制器时查找按钮有点麻烦。使用无形的按钮会提醒你虚拟的手不是真实的，潜意识里打破这种体验。这个问题在社交环境下更加明显，因为人们在VR中与他人对话时试图执行动作。</p><img src="/2017/04/30/Daily-Translation-02/1-Obf0CZsSdkg-W38MdS756w.jpeg" alt="Mark Zuckerberg using Oculus Touch in our Social VR demo" title="Mark Zuckerberg using Oculus Touch in our Social VR demo"><p>我们决定始终使用虚拟手本身做出默认的互动，不需要任何控制器的前置按钮。拿起并握住一个物体通过按下并握住手柄；与2D用户界面互动通过简单的触碰它；选择远距离的物体通过食指指向；滚动列表可以通过用你的手抓住列表上下移动，或通过抓取并移动其滚动条来完成。</p><p>我们还了解了视觉、听觉、触觉反馈在创造自然交互中的重要意义。当你用手接触一个物体时，通过打开或其他手势获得诸如物体变大、变亮，或是看见你的手适应的反馈，有助于理解该物体是可与之交互的。当触摸物体时，获得触觉和听觉上的反馈会增加身临其境的感觉，并且创建虚拟手与物理手之间的连接。想象你拍手发出的声音，或拿起和放下手机时的微妙感觉。</p><img src="/2017/04/30/Daily-Translation-02/1-iYe7d8lyj4-Jgw1_Ejq3YA.jpeg" alt="1-iYe7d8lyj4-Jgw1_Ejq3YA.jpeg" title=""><h2 id="设计舒适的体验"><a href="#设计舒适的体验" class="headerlink" title="设计舒适的体验"></a>设计舒适的体验</h2><p>使用手在虚拟世界进行互动是难以置信的激动和沉浸的，也为设计人员的思考提供了物理上的挑战。这里有一些我学到的东西：</p><ul><li>抬高手臂进行互动的程度越高，交互应该越快，以避免疲劳。</li><li>手臂抬起足够高以至于肘部不再与身体连接，会造成疲劳。</li><li>与一个移动界面进行交互（比如连接到辅助手的用户界面，像手表）具有挑战性，应主要用于快速操作。</li><li>一些人在视觉解读深度方面有困难，可能需要一些时间和时间才能了解他们需要多远来接触并操作VR中的物体。</li><li>坐着的时候，伸手接触与虚拟身体很近的物体可能具有挑战。</li><li>视觉上看起来真实的手可能会令人感觉怪异。它们带来一种在别人身体里的感觉。它们也可能会打破沉浸感，当那些相同的手穿透一个似乎是物理上的对象，比如桌子。</li><li>一个熟悉的对象需要经常沟通如何拿起、握住和使用。比如人们期望使用一个枪支型道具来瞄准东西。</li><li>一个物理对象在被抓住时可能需要不同物理学。如果拿着一把比穿过一个桌子，你可能不希望笔撞到桌子并且弹跳，反而是用手穿透桌子。</li><li>在VR中人们会不再掌握真实物理环境的最新情况。手势可能导致人们达到墙壁或者扔掉他们的控制器。</li><li>手势本身就是社交的。当你的朋友正在VR中与虚拟对象进行互动，可以直观的看到他们正在进行的交互，从而消除了看到他们的手在空中挥动却不知道他们正在干嘛的尴尬。</li></ul><img src="/2017/04/30/Daily-Translation-02/1-xQT0OFhsrbsifbFC6zCTcg.jpeg" alt="1-xQT0OFhsrbsifbFC6zCTcg.jpeg" title=""><h2 id="更多的资源"><a href="#更多的资源" class="headerlink" title="更多的资源"></a>更多的资源</h2><p>希望这些观点能帮助你思考VR中手的设计。我们仍然处在初期阶段，就像我们在这过程中取得的进展，我们的设计过程也在发展和改善。今天，我们很高兴发布一套我们创建的虚拟手，可以帮助设计师在传统的设计工具中模拟VR手的互动。如果你对构建一个社会虚拟现实体验其他方面感到好奇，可以看看<a href="https://www.youtube.com/watch?v=0EZn50XCueI" target="_blank" rel="external">Mike Booth’s talk</a>在Oculus Connect上的演讲。</p><img src="/2017/04/30/Daily-Translation-02/1-Zu9yKwrbBvn5QEFAMqGcBg.jpeg" alt="1-Zu9yKwrbBvn5QEFAMqGcBg.jpeg" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天的翻译来源于 &lt;a href=&quot;http://facebook.design&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://facebook.design&lt;/a&gt; ，一直觉得未来的VR会超屌的，就进一步了解一下。先是来到 &lt;a href=&quot;http://facebook.design/virtual-hands#scroll&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://facebook.design/virtual-hands#scroll&lt;/a&gt; 下载了Virtual Hands，各种手势的png麻溜的存起来，保不准以后有用呢。页面上有一个链接跳转到Christophe Tauziet制作VR手势交互的文章 &lt;a href=&quot;https://medium.com/facebook-design/designing-for-hands-in-vr-61e6815add99&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Designing for Hands in VR&lt;/a&gt; 这篇文章。那今天就翻译这篇吧~&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何设计更好的按钮</title>
    <link href="http://yoursite.com/2017/04/29/Daily-Translation-01/"/>
    <id>http://yoursite.com/2017/04/29/Daily-Translation-01/</id>
    <published>2017-04-28T23:03:14.000Z</published>
    <updated>2017-05-30T03:05:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接<a href="https://www.smashingmagazine.com/2016/11/a-quick-guide-for-designing-better-buttons/" target="_blank" rel="external">How To Design Better Buttons</a>。按钮是交互设计中最常见的元素。尽管它们看起来可能是一个非常简单的用户界面元素，它们却是最重要的元素之一。在今天的文章中，我们将讨论为了<strong>提升用户体验而创建有效的控件</strong>你应该知道的基本的要点。</p><a id="more"></a><h2 id="让按钮看起来像一个按钮"><a href="#让按钮看起来像一个按钮" class="headerlink" title="让按钮看起来像一个按钮"></a>让按钮看起来像一个按钮</h2><p>人们如何理解一个元素是一个按钮？回答很简单。<em>视觉暗示</em>帮助人们确认其可点击性。使用恰当的指示在可点击的元素上使它们看起来像按钮。</p><p><strong>形状</strong></p><p>一个安全牌是让按钮为矩形或带有圆角的矩形，这取决于网站或app的风格。矩形的按钮在很久以前就被引入数字世界，用户对它们非常熟悉。</p><img src="/2017/04/29/Daily-Translation-01/Windows-95-at-first-run-large-opt.png" alt="Windows 95" title="Windows 95"><p>当然，你可以更富创造性使用其他形状（圆形、三角形甚至定制形状），但是记住独特的想法可以证明有点儿有危险。你需要确保人们能够容易的辨认出每一个变化的形状是一个按钮。</p><img src="/2017/04/29/Daily-Translation-01/Floating-Action-Button-preview-opt.png" alt="Floating-Action-Button-preview-opt.png" title=""><p>不管你选择了什么形状，确保<em>一致性</em>贯穿你的界面控件，用户才能够发现和认出所有是按钮的界面元素。</p><p><strong>为什么一致性如此重要？</strong>因为不管是否一致人们会记住细节。比如，人们会联想一个特殊形状的元素是“按钮”。因此，保持一致不仅是为了一个好看的设计，还为用户提供了一个熟悉的体验。</p><p>下面的图片完美说明了这个栗子。在你的app的一部分（比如系统工具栏）使用三个不一样的形状（比如系统工具栏）不仅会使用户难以理解，也是不正确的设计实例。</p><img src="/2017/04/29/Daily-Translation-01/consistent-preview-opt.png" alt="consistent-preview-opt.png" title=""><p><strong>阴影和高亮</strong></p><p>阴影是很有用的线索，告诉用户他们正在寻找哪个界面元素。阴影使元素从背景中脱颖而出并能简单辨认出是一个可敲击或可点击的元素，因为目标元素呈现凸起好像他们能被按下（敲击或点击）。即使扁平的按钮（准确的说，是几乎扁平），它们依然给出轻微的暗示。</p><img src="/2017/04/29/Daily-Translation-01/button-casts-a-subtle-shadow-preview-opt.png" alt="button-casts-a-subtle-shadow-preview-opt.png" title=""><h2 id="明确按钮标签"><a href="#明确按钮标签" class="headerlink" title="明确按钮标签"></a>明确按钮标签</h2><p>用户会避开没有清楚含义的界面元素。因此，在你的界面的每个按钮应该有一个恰当的标签获图标。这种选择基于最少惊讶原则是一个很好的想法：如果一个必需的按钮具有高度的惊讶因素，那么可能需要更换这个按钮的标签获图标。</p><p><strong>清晰的标签</strong></p><p>动作界面元素的标签，比如按钮，应该一直与它将为用户做什么绑定。用户会感到更舒适当他们理解一个按钮会做什么<em>动作</em>。不明确的标签像’提交’,或者如下面栗子显示的抽象标签，不能为动作提供足够的信息。</p><img src="/2017/04/29/Daily-Translation-01/designing-interface-elements-that-make-people-wonder-what-they-do-preview-opt.png" alt="避免设计的界面元素使人们思考他们将做什么" title="避免设计的界面元素使人们思考他们将做什么"><p>动作按钮应该申明它们的任务，因此用户能准确知道他们点击按钮将会发生什么。<em>使用动词</em>表明按钮的作用是很重要的。比如，如果用户注册一个账号，按钮写着’创建账户’，表明了按下按钮后会输出什么。这是很清晰和具体的任务。像这样准确的标签提供即时的帮助，给用户选择正确动作的信息。</p><img src="/2017/04/29/Daily-Translation-01/button’s-label-preview-opt.png" alt="一个按钮标签应该说明准确按下它以后将会发生什么" title="一个按钮标签应该说明准确按下它以后将会发生什么"><h2 id="把按钮放在用户可以找到它们的地方"><a href="#把按钮放在用户可以找到它们的地方" class="headerlink" title="把按钮放在用户可以找到它们的地方"></a>把按钮放在用户可以找到它们的地方</h2><p>不要让用户寻找按钮；把按钮放在用户容易找到或者期望看到的地方。</p><p><strong>位置和顺序</strong></p><p>如果你正在设计一个本地app，当你为按钮选择合适的位置和顺序时，你应该遵循平台的图形界面指南。为什么？因为应用<em>一致的设计遵循用户的期望</em> ，节约用户的时间。</p><img src="/2017/04/29/Daily-Translation-01/web-based-apps-preview-opt.png" alt="web-based-apps-preview-opt.png" title=""><p>基于网页的app，你应该考虑哪个布局真正适合你的用户。最正确的方法来决定布局是通过<em>测试</em> 。</p><p>如果你设计移动端导航那么很值得注意按钮位置的最佳做法。文章<a href="https://www.smashingmagazine.com/2016/11/the-golden-rules-of-mobile-navigation-design/" target="_blank" rel="external">[The Golden Rules Of Bottom Navigation Design]</a>讨论了这个话题。</p><h2 id="让用户与按钮的交互更简单"><a href="#让用户与按钮的交互更简单" class="headerlink" title="让用户与按钮的交互更简单"></a>让用户与按钮的交互更简单</h2><p>按钮的尺寸和视觉反馈扮演很重要的角色帮助用户与按钮交互。</p><p><strong>尺寸和间隔</strong></p><p>考虑一个按钮多大与页面中其他元素相关。同时，你需要保证你设计的按钮足够大让人们能够与之交互。</p><img src="/2017/04/29/Daily-Translation-01/Smaller-touch-targets-preview-opt.png" alt="较小的接触目标相对于较大的对用户来说更难点击" title="较小的接触目标相对于较大的对用户来说更难点击"><p>在你的app或网站中，当一个点击被用做主要的输入方法，你可以依赖<a href="http://touchlab.mit.edu/publications/2003_009.pdf" target="_blank" rel="external">MIT Touch Lab</a> 的研究为你的按钮选择一个合适的尺寸。这个研究发现平均指垫的尺寸在10 - 14mm，指尖为8 - 10mm，使用10mm x 10mm是一个最优且最小的接触目标尺寸。当一个鼠标和键盘是主要的输入方法时，按钮尺寸可以稍微减小以容纳密集的界面元素。</p><img src="/2017/04/29/Daily-Translation-01/10mm-x-10mm-is-a-good-minimum-touch-target-size-preview-opt.png" alt="10mm-x-10mm-is-a-good-minimum-touch-target-size-preview-opt.png" title=""><p>在考虑按钮元素尺寸的同时，你也应该考虑可点击元素之间的间隔，因为间隔帮助分离空间并给你的用户界面足够的呼吸空间。</p><img src="/2017/04/29/Daily-Translation-01/Padding-between-buttons-preview-opt.png" alt="Padding-between-buttons-preview-opt.png" title=""><p><strong>提供视觉反馈</strong></p><p>这个需求不是关于按钮最初给用户的看法，而是关于用户界面元素的交互体验。通常，一个按钮不是一个一种状态的对象。它有很多种状态，提供视觉反馈给用户以指示当前的状态应该是一个首要任务。下面有用的示例图来自<a href="https://material.google.com/" target="_blank" rel="external">Material Design</a>说明了如何表达不同按钮的状态：</p><img src="/2017/04/29/Daily-Translation-01/hover-tap-states-and-active-states-of-the-button-preview-opt.png" alt="hover-tap-states-and-active-states-of-the-button-preview-opt.png" title=""><h2 id="视觉高亮最重要的按钮"><a href="#视觉高亮最重要的按钮" class="headerlink" title="视觉高亮最重要的按钮"></a>视觉高亮最重要的按钮</h2><p>确保设计强调主要的和最重要的动作。使用颜色和对比使用户关注动作，把按钮放置在用户容易注意到的显眼的位置。</p><p><strong>呼叫动作按钮</strong></p><p>重要的按钮（比如CTAs）意在指导用户做出你想让他们做出的动作。为了创建一个有效的呼叫动作按钮（抓住用户注意力并引导他们点击的按钮），你应该使用与背景形成强烈对比的颜色并把按钮放置在用户的路径中。</p><p>我们看一下 <a href="https://mail.google.com/" target="_blank" rel="external">Gmail’s UI</a>，界面非常简单并几乎是一色的，带有期望按钮’Send’。只要人们写完一条信息，就会立即注意到这个吸引人的蓝色的按钮。</p><img src="/2017/04/29/Daily-Translation-01/Adding-one-color-to-a-grayscale-UI-preview-opt.png" alt="Adding-one-color-to-a-grayscale-UI-preview-opt.png" title=""><p>同样的规则也适用于网页。我们以<a href="https://www.behance.net/" target="_blank" rel="external">Behance</a>作为栗子，抓住你注意力的第一件事是”Sign Up”呼叫动作按钮。在这个案例中，按钮的颜色和位置比它的文字更重要。</p><img src="/2017/04/29/Daily-Translation-01/The-most-important-call-to-action-button-preview-opt.png" alt="The-most-important-call-to-action-button-preview-opt.png" title=""><p><strong>视觉上区别主要和次要的按钮</strong></p><p>你可以在窗体和对话框中找到其他抓住用户注意力的栗子。当选择主要和次要的动作时，视觉上的区分是一个很有用的帮助人们做出坚实的选择的方法：</p><ul><li>主要积极的动作相关联的按钮需要承载一个<em>更强的视觉重量</em> 。它应该在视觉上起主导作用。</li><li>次要动作（比如选项‘Cancel’ 或者 ‘Go Back），应该使用更弱的视觉重量，因为减少次要按钮在视觉上的突出能将发生潜在错误的危险降到最低，并进一步指引人们前往预期的结果。</li></ul><h2 id="按钮设计清单"><a href="#按钮设计清单" class="headerlink" title="按钮设计清单"></a>按钮设计清单</h2><p>尽管每一个设计都是独特的，每一个设计也有一系列共有的要素。因此一个好的设计清单应运而生。确保你的按钮设计对你的用户是有利的，并且你需要回答以下几个问题：</p><ul><li><strong>用户能够辨认出你的元素是一个按钮吗？</strong>思考如何使设计传达实际的用途。让一个按钮像一个按钮（使用尺寸、形状、阴影和颜色达到这个目的）。</li><li><strong>按钮标签提供一个清晰的信息</strong>关于点击后会发生的事吗？命名一个按钮，解释它是做什么的，比使用一个一般的标签（像”OK”）来得更好。</li><li><strong>你的用户容易找到按钮吗？</strong>你把按钮放在页面中的什么位置与它的形状、颜色、标签同样重要。思考用户在页面上的路径并且把按钮放在用户能够容易找到或者期望找到的位置。</li><li>如果在你的界面上你有两个或更多的按钮（比如对话框），<strong>主要动作按钮是否有最强的视觉重量？</strong>通过在每一个按钮上使用不同的视觉重量来使两个选项的区别更明显。</li></ul><img src="/2017/04/29/Daily-Translation-01/visual-distinctions-opt.jpg" alt="visual-distinctions-opt.jpg" title=""><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>按钮在创造一个平滑的用户体验中是最基本的元素，因此值得注意按钮的最佳实践。一个快速回顾：</p><ul><li>让按钮看起来像一个按钮</li><li>按钮的标签清晰表明他们为用户做什么</li><li>把按钮放在用户能找到或者期望看到的位置</li><li>让用户与每个按钮的交互更简单</li><li>让最重要的按钮清晰辨认</li></ul><p>当你设计你自己的按钮时，从最重要的开始，并且牢记按钮的设计一直与<em>识别和明确</em>相关。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文链接&lt;a href=&quot;https://www.smashingmagazine.com/2016/11/a-quick-guide-for-designing-better-buttons/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;How To Design Better Buttons&lt;/a&gt;。按钮是交互设计中最常见的元素。尽管它们看起来可能是一个非常简单的用户界面元素，它们却是最重要的元素之一。在今天的文章中，我们将讨论为了&lt;strong&gt;提升用户体验而创建有效的控件&lt;/strong&gt;你应该知道的基本的要点。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Proxifier配置</title>
    <link href="http://yoursite.com/2017/02/02/Proxifier/"/>
    <id>http://yoursite.com/2017/02/02/Proxifier/</id>
    <published>2017-02-02T05:35:53.000Z</published>
    <updated>2017-05-30T03:15:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>npm install真是像大姨妈一样，安装包的时候阴晴不定 :triumph:<br>于是想起之前向大神问到的处理源的问题。Proxifier + shadowsocks。</p><a id="more"></a><p>Proxifier的设置很简单</p><img src="/2017/02/02/Proxifier/201702021.png" alt="server" title="server"><img src="/2017/02/02/Proxifier/201702022.png" alt="configure" title="configure"><p>​:point_right: 点击check</p><img src="/2017/02/02/Proxifier/201702023.png" alt="test" title="test"><p>在这里要注意Port是<strong>本地端口</strong>，之前一直设置成服务器端口结果就报错了。<br>然后进行规则设置</p><img src="/2017/02/02/Proxifier/201702024.png" alt="rules" title="rules"><img src="/2017/02/02/Proxifier/201702025.png" alt="rules" title="rules"><p>我的npm就复活啦 :sparkles:</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;npm install真是像大姨妈一样，安装包的时候阴晴不定 :triumph:&lt;br&gt;于是想起之前向大神问到的处理源的问题。Proxifier + shadowsocks。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
