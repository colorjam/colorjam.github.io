<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Colorjam</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-06-27T11:48:18.266Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Colorjam</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>weekly-paper-07</title>
    <link href="http://yoursite.com/2019/06/25/weekly-paper-07/"/>
    <id>http://yoursite.com/2019/06/25/weekly-paper-07/</id>
    <published>2019-06-25T00:55:36.000Z</published>
    <updated>2019-06-27T11:48:18.266Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Universally-Slimmable-Networks-and-Improved-Training-Techniques"><a href="#1ï¸âƒ£-Universally-Slimmable-Networks-and-Improved-Training-Techniques" class="headerlink" title="1ï¸âƒ£  Universally Slimmable Networks and Improved Training Techniques"></a>1ï¸âƒ£  Universally Slimmable Networks and Improved Training Techniques</h3><p>This work extending slimmable networks to execute at arbitrary width, the contributions can list as</p><ol><li><p>Post-Statistics of Batch Normalization</p><p>Instead of using moving averages to test model, calculating BN statistics of all widths after training (exact averages).</p><ul><li>moving averagesï¼š</li></ul><p>$$<br>\begin{aligned} \mu_{t} &amp;=m \mu_{t-1}+(1-m) E_{B}\left[x_{B}\right] \\ \sigma_{t}^{2} &amp;=m \sigma_{t-1}^{2}+(1-m) \operatorname{Var}_{B}\left[x_{B}\right] \end{aligned}<br>$$</p><ul><li>exact averagesï¼š</li></ul><p>$$<br>\begin{aligned} m &amp;=(t-1) / t \\ \mu_{t} &amp;=m \mu_{t-1}+(1-m) E_{B}\left[x_{B}\right] \\ \sigma_{t}^{2} &amp;=m \sigma_{t-1}^{2}+(1-m) \operatorname{Var}_{B}\left[x_{B}\right] \end{aligned}<br>$$</p></li></ol><ol><li><p>Sandwich Rule</p><p>This paper assumes that the performances at all widths are bounded by performance of the model at smallest width $0.25 \times$ and largest width $1.0 \times$ , so during training just sample n widths between [min-width, max-width]</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1ï¸âƒ£-Universally-Slimmable-Networks-and-Improved-Training-Techniques&quot;&gt;&lt;a href=&quot;#1ï¸âƒ£-Universally-Slimmable-Networks-and-Improved-Train
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflowä¸­çš„PixelShuffle(depth_to_space)</title>
    <link href="http://yoursite.com/2019/06/23/tf-pixshuffle/"/>
    <id>http://yoursite.com/2019/06/23/tf-pixshuffle/</id>
    <published>2019-06-23T08:31:38.000Z</published>
    <updated>2019-06-28T02:10:01.249Z</updated>
    
    <content type="html"><![CDATA[<p>åœ¨å°è¯•å¯¹PixelShuffleå‰çš„å·ç§¯å±‚åšå‰ªææ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œå¯¹PixelShuffleçš„å…·ä½“æ“ä½œæœ‰äº†è¿›ä¸€æ­¥çš„äº†è§£ã€‚</p><p>PixelShuffleé€šè¿‡å°†é€šé“é‡æ’å¯¹å›¾åƒè¿›è¡Œä¸Šé‡‡æ ·ï¼Œtfä¸­çš„å‡½æ•°æ˜¯<code>tf.depth_to_sapce</code>ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯<code>Tensor</code>ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯éœ€è¦æ”¾å¤§å€æ•°ã€‚å½“è¾“å…¥<code>X</code>çš„å¤§å°ä¸º<code>[1 2 2 16]</code>ï¼Œæ”¾å¤§å€æ•°ä¸º2ï¼ŒHå’ŒWå„ä¹˜2ï¼ŒCé™¤ä»¥4ï¼ŒPixelShuffleåçš„ç»“æœå°±ä¸º<code>[1 4 4 4]</code>ã€‚</p><p>ğŸ”ºå‘ç‚¹1ï¼šæƒ³å½“ç„¶çš„ä»¥ä¸ºå‚ä¸é‡æ’çš„é€šé“æ˜¯<code>[:, :, :, i:i+4]</code></p><p>æµ‹è¯•ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">x = tf.range(<span class="number">64</span>)</div><div class="line">x = tf.reshape(x, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">16</span>])</div><div class="line">y = tf.depth_to_space(x, <span class="number">2</span>) <span class="comment"># [1, 4, 4, 4]</span></div></pre></td></tr></table></figure><p>ä¸‹é¢çœ‹ä¸€ä¸‹å…·ä½“xå’Œyæ¯ä¸ªé€šé“çš„å€¼ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x[:, :, :, <span class="number">0</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">0</span>, <span class="number">16</span>],</div><div class="line">[<span class="number">32</span>, <span class="number">48</span>]]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x[:, :, :, <span class="number">1</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">1</span>, <span class="number">17</span>],</div><div class="line">[<span class="number">33</span>, <span class="number">49</span>]]]</div><div class="line"> </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>y[:, :, :, <span class="number">0</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">0</span>,  <span class="number">4</span>, <span class="number">16</span>, <span class="number">20</span>],</div><div class="line">[ <span class="number">8</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">28</span>],</div><div class="line">[<span class="number">32</span>, <span class="number">36</span>, <span class="number">48</span>, <span class="number">52</span>],</div><div class="line">[<span class="number">40</span>, <span class="number">44</span>, <span class="number">56</span>, <span class="number">60</span>]]]</div></pre></td></tr></table></figure><p>å¯ä»¥çœ‹å‡º<code>y</code>çš„ç¬¬0ç»´é€šé“åŒ…å«çš„æ˜¯<code>x</code>é€šé“æ•°ä¸º0ã€4ã€8ã€12çš„ç‰¹å¾å›¾ã€‚å¯è§†åŒ–ä¸€ä¸‹å°±æ˜¯è¿™æ ·çš„æ•ˆæœï¼š</p><p><img src="https://i.loli.net/2019/06/27/5d14b6a1d9bbf35069.png" alt=""></p><p>å°†Yçš„ä¸€ä¸ªé€šé“å•ç‹¬å–å‡ºï¼Œçœ‹ä¸€ä¸‹æ¯ä¸ªç‚¹å±äºåŸæ¥Xçš„å“ªä¸ªåæ ‡ï¼š</p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190628095308642.png" alt="image-20190628095308642"></p><p>å¯ä»¥çœ‹åˆ°Yçš„ä¸€ä¸ªé€šé“å®é™…ä¸Šåˆ†æˆ4ä¸ªè±¡é™ï¼Œåœ¨ç©ºé—´ä¸Šç”±<code>(0,0)(0,1)(1,0)(1,1)</code>æ„æˆã€‚åœ¨é€šé“ä¸Šæ¯4ä¸ªé—´éš”æå–å¯¹åº”é€šé“ã€‚è¿™é‡Œçš„é—´éš”å¯¹åº”çš„æ˜¯Pixshuffleåçš„é€šé“æ•°ã€‚</p><p>å‡è®¾åŸå§‹é€šé“æ•°ä¸º<code>c_out</code>ï¼ŒPSåçš„é€šé“æ•°ä¸º<code>ps_out</code>ï¼Œå®é™…ä¸Š<code>y</code>çš„ç¬¬<code>i</code>é€šé“å¯¹åº”çš„æ˜¯<code>x</code>çš„<code>[i, i+ps_out, i+2*ps_out, i+3*ps_out]</code></p><p>è€Œæˆ‘åŸå…ˆç†è§£çš„é€šé“æ’åˆ—æ–¹å¼æ˜¯âŒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>y[:, :, :, <span class="number">0</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">5</span>],</div><div class="line">[ <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">6</span>,  <span class="number">7</span>],</div><div class="line">[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">12</span>, <span class="number">13</span>],</div><div class="line">[<span class="number">10</span>, <span class="number">11</span>, <span class="number">14</span>, <span class="number">15</span>]]]</div></pre></td></tr></table></figure><p>ğŸ”ºå‘ç‚¹2ï¼šæå–kä¸ªä¿ç•™çš„é€šé“æ—¶ï¼Œåªéœ€å–ç´¢å¼•çš„å‰kä¸ªå€¼</p><p>å‡è®¾æ”¾å¤§å€ç‡æ˜¯4ï¼Œç”¨L1çš„å‰ªææ–¹å¼ï¼Œéœ€è¦ä¿ç•™çš„é€šé“æ•°ä¸º<code>c_keep</code>ã€‚å½“å¯¹åº”åˆ°å…·ä½“çš„å‰ªæé€šé“çš„æ—¶å€™ï¼Œéœ€è¦æ‰¾åˆ°PixShuffleåå‰ªæ‰é€šé“æ‰€å¯¹åº”çš„åŸå§‹å·ç§¯è¾“å‡ºçš„4ä¸ªé€šé“ã€‚ä»ä¸Šé¢çš„åæ ‡æˆ‘ä»¬å°±å¯ä»¥çœ‹å‡ºï¼Œå‰ªæ‰Yçš„0é€šé“æ—¶ï¼Œéœ€è¦å¯¹åº”å‰ªæ‰Xçš„0ã€4ã€8ã€12é€šé“ã€‚æ¥çœ‹çœ‹å…·ä½“çš„å®ç°ã€‚ä¸»è¦åˆ†ä¸ºå‡ æ­¥ï¼š</p><ol><li>è®¡ç®—Yå¯¹åº”Xçš„é€šé“</li><li>è®¡ç®—Yéœ€è¦ä¿ç•™çš„é€šé“</li><li>å°†Yçš„é€šé“æ˜ å°„å›X</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1. è®¡ç®—Yå¯¹åº”Xçš„é€šé“</span></div><div class="line">norm_list, shuffled_idx_list = [], []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(ps_out):</div><div class="line">shuffled_idx = [i+k*ps_out <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">4</span>)]  <span class="comment"># Yé€šé“å¯¹åº”çš„4ä¸ªXé€šé“</span></div><div class="line">shuffled_idx_list.append(shuffled_idx)</div><div class="line">  norm_sum = tf.reduce_sum(tf.gather(norm_value, shuffled_idx)) <span class="comment"># æå–å¯¹åº”ç´¢å¼•çš„é€šé“</span></div><div class="line">  norm_list.append(sess.run(norm_sum))</div><div class="line">  </div><div class="line"><span class="comment"># 2. è®¡ç®—éœ€è¦ä¿ç•™çš„é€šé“</span></div><div class="line">remain_idx = np.sort(np.argsort(norm_list)[::<span class="number">-1</span>][:int(c_keep/<span class="number">4</span>)])</div><div class="line"></div><div class="line">remain_list = []</div><div class="line"><span class="comment"># 3. å°†Yçš„é€šé“æ˜ å°„å›X</span></div><div class="line"><span class="keyword">for</span> remain <span class="keyword">in</span> remain_idx:</div><div class="line">  remain_list.extend(shuffled_idx_list[remain])</div><div class="line">remain_list = np.sort(remain_list)</div></pre></td></tr></table></figure><p>è¿™æ ·<code>remain_list</code>å³åŸå§‹å·ç§¯è¾“å‡ºéœ€è¦å‰ªæ‰çš„é€šé“ç´¢å¼•ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;åœ¨å°è¯•å¯¹PixelShuffleå‰çš„å·ç§¯å±‚åšå‰ªææ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œå¯¹PixelShuffleçš„å…·ä½“æ“ä½œæœ‰äº†è¿›ä¸€æ­¥çš„äº†è§£ã€‚&lt;/p&gt;
&lt;p&gt;PixelShuffleé€šè¿‡å°†é€šé“é‡æ’å¯¹å›¾åƒè¿›è¡Œä¸Šé‡‡æ ·ï¼Œtfä¸­çš„å‡½æ•°æ˜¯&lt;code&gt;tf.depth_to_sapce&lt;/code&gt;ï¼Œç¬¬ä¸€ä¸ª
      
    
    </summary>
    
    
      <category term="ç»´ä¿®æŒ‡å—" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨è®ºæ–‡ Vol.06</title>
    <link href="http://yoursite.com/2019/06/18/weekly-paper-06/"/>
    <id>http://yoursite.com/2019/06/18/weekly-paper-06/</id>
    <published>2019-06-18T01:49:16.000Z</published>
    <updated>2019-06-21T09:12:49.701Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-AutoSlim-Towards-One-Shot-Architecture-Search-for-Channel-Numbers"><a href="#1ï¸âƒ£-AutoSlim-Towards-One-Shot-Architecture-Search-for-Channel-Numbers" class="headerlink" title="1ï¸âƒ£ AutoSlim: Towards One-Shot Architecture Search for Channel Numbers"></a>1ï¸âƒ£ AutoSlim: Towards One-Shot Architecture Search for Channel Numbers</h3><p>è¿™ç¯‡å’Œ<a href="https://arxiv.org/abs/1812.08928" target="_blank" rel="external">ICLR2019</a>ã€<a href="https://arxiv.org/abs/1903.05134" target="_blank" rel="external">Universally Slimmable Networks</a>æ˜¯åŒä¸€ä¸ªä½œè€…ï¼Œè§£å†³çš„é—®é¢˜éƒ½æ˜¯é€šé“å‰ªæã€‚ä¸‹é¢å…ˆäº†è§£ä¸€ä¸‹æœ¬æ–‡ã€‚</p><p><strong>Why?</strong></p><p>Most channel pruning methods are grouneded on <strong>the importance of trained weights</strong>, so the slimmed layer usually consists channels of discrete index. Most NAS methods have high computational cost and time cost.</p><p><strong>How?</strong></p><p>Extending the work of slimmable networks and propose AutoSlim. The training process is as following:</p><ol><li><p>Train a slimmable model for a few epochs to get a benchmark performance estimator.</p><ul><li><p>Searching space is defined between the upper bound and lower bound of channel numbers. In each training iteration, randomly sample the number of channels in each layer. In each layer remove a group of channels. </p><blockquote><p>in resents, first sample the channel number of residual dentity pathway and then randomly and independenly sample channel number inside each residual block.</p></blockquote></li></ul></li><li><p>Evaluate the trained slimmable model and greedily slim the layer with minimal accuracy drop on validation set.</p></li><li><p>Obtain the optimized channel configurations under different resource constraints.</p></li><li><p>Train optimized architectures individually or slimmable network for full training epochs.</p></li></ol><p>The paper is based on the assumption that <strong>the importance of weight is implicitly ranked by its index</strong>, which means that the smaller index of one filter the more important of this filter.</p><h3 id="2ï¸âƒ£-AutoGrow-Automatic-Layer-Growing-in-Deep-Convolutional-Networks"><a href="#2ï¸âƒ£-AutoGrow-Automatic-Layer-Growing-in-Deep-Convolutional-Networks" class="headerlink" title="2ï¸âƒ£ AutoGrow: Automatic Layer Growing in Deep Convolutional Networks"></a>2ï¸âƒ£ AutoGrow: Automatic Layer Growing in Deep Convolutional Networks</h3><p>The method can be easily found in the title, to gradually grow the depth of DNN.</p><p>The  <em>network</em> is  composed of <em>sub-netwok</em>, and <em>sub-network</em> is composed of <em>sub-modules</em>.<br>$$<br>g\left(\mathcal{X}_{0}\right)=l\left(\boldsymbol{f}_{M-1}\left(\boldsymbol{f}_{M-2}\left(\cdots \boldsymbol{f}_{1}\left(\boldsymbol{f}_{0}\left(\mathcal{X}_{0}\right)\right) \cdots\right)\right)\right)<br>$$<br>AutoGrow is based on Network Morphism, but propose to initilize the last Batch Normalization layer in a residual block of <em>AdamInit</em> insted of <em>ZeroInit</em></p><p><strong>AdamInit</strong></p><p>given the new layers $\mathcal{W}$, we have:<br>$$<br>g\left(\mathcal{X}_{0} ; \mathbb{W}\right)=g\left(\mathcal{X}_{0} ; \mathbb{W} \cup \mathcal{W}\right) \forall \mathcal{X}_{0}<br>$$<br>freeze all parameters except the last Batch Normalization layer in $\mathcal{W}$, use Adam optimizer to optimize the last Batch Normalization layer.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1ï¸âƒ£-AutoSlim-Towards-One-Shot-Architecture-Search-for-Channel-Numbers&quot;&gt;&lt;a href=&quot;#1ï¸âƒ£-AutoSlim-Towards-One-Shot-Architecture-Search-f
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨è®ºæ–‡ Vol.05</title>
    <link href="http://yoursite.com/2019/06/10/weekly-paper-05/"/>
    <id>http://yoursite.com/2019/06/10/weekly-paper-05/</id>
    <published>2019-06-10T02:29:31.000Z</published>
    <updated>2019-06-18T01:49:25.901Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Dynamic-Capacity-Networks"><a href="#1ï¸âƒ£-Dynamic-Capacity-Networks" class="headerlink" title="1ï¸âƒ£ Dynamic Capacity Networks"></a>1ï¸âƒ£ Dynamic Capacity Networks</h3><p>use two alternative sub-networks: </p><ol><li>coarse layers $f_c$ on the whole input $\mathbf {x}$  </li><li>fine layers $f_f$ at salient regions </li></ol><p><strong>coarse representation vectors</strong><br>$$<br>f_{c}(\mathbf{x})=\left\{\mathbf{c}_{i, j} |(i, j) \in\left[1, s_{1}\right] \times\left[1, s_{2}\right]\right\}<br>$$</p><p>$$<br>h_{c}(\mathbf{x})= \mathbf{o}_c = g\left(f_{c}(\mathbf{x})\right)<br>$$</p><p>$\mathbf{c}_{i, j}=f_{c}\left(\mathbf{x}_{i, j}\right) \in \mathbb{R}^{D}$ </p><p><strong>salient input regions</strong><br>$$<br>H=-\sum_{l=1}^{C} \mathbf{o}_{c}^{(l)} \log \mathbf{o}_{c}^{(l)}<br>$$</p><p>$$<br>M_{i, j}=\left|\nabla_{\mathbf{c}_{i, j}} H\right|_{2}<br>$$</p><p>$C$ is the number of class labels, $\mathbf{M} \in \mathbb{R}^{s_{1} \times s_{2}}$</p><p>select top $k$ input regions $\mathbf{X}^{s}=\left\{\mathbf{x}_{i, j} |(i, j) \in \mathbf{I}^{s}\right\}$ based on $\mathbf{M}$</p><p><strong>fine representation vectors</strong><br>$$<br>f_{f}\left(\mathbf{X}^{s}\right)=\left\{\mathbf{f}_{i, j} |(i, j) \in \mathbf{I}^{s}\right\}<br>$$<br>refined representation $f_r(\mathbf {x})$ by combining $f_c(\mathbf{x})$ and $f_f(\mathbf{X}^s)$</p><p><strong>loss</strong></p><ol><li><p>Cross Entropy<br>$$<br>J=-\sum_{i=1}^{m} \log p\left(y^{(i)} | \mathbf{x}^{(i)} ; \theta\right)<br>$$</p></li><li><p>encourage similarity between the coarse and fine representations</p></li></ol><p>$$<br>\sum_{\mathbf{x}_{i, j} \in \mathbf{X}^{s}}\left|f_{c}\left(\mathbf{x}_{i, j}\right)-f_{f}\left(\mathbf{x}_{i, j}\right)\right|_{2}^{2}<br>$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1ï¸âƒ£-Dynamic-Capacity-Networks&quot;&gt;&lt;a href=&quot;#1ï¸âƒ£-Dynamic-Capacity-Networks&quot; class=&quot;headerlink&quot; title=&quot;1ï¸âƒ£ Dynamic Capacity Networks&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Gumbel Softmax</title>
    <link href="http://yoursite.com/2019/05/28/gumbel-softmax/"/>
    <id>http://yoursite.com/2019/05/28/gumbel-softmax/</id>
    <published>2019-05-28T07:29:09.000Z</published>
    <updated>2019-05-30T03:18:19.159Z</updated>
    
    <content type="html"><![CDATA[<p>åœ¨PAGé‡Œå‘ç°äº†Gumbel Sampling Trickï¼ŒæŠŠç¦»æ•£çš„é‡‡æ ·è¿‡ç¨‹ç”¨å…¬å¼è¡¨è¾¾å‡ºæ¥ï¼Œäºæ˜¯å¯ä»¥æ”¾è¿›ç¥ç»ç½‘ç»œä¸­è¿›è¡Œæ±‚å¯¼å’Œåå‘ï¼Œè§‰å¾—æ˜¯å¾ˆæœ‰æ„æ€çš„å·¥ä½œï¼Œæƒ³è¦å¤šåŠ æ·±ä¸€äº›äº†è§£ã€‚</p><h3 id="é—®é¢˜å¼•å…¥"><a href="#é—®é¢˜å¼•å…¥" class="headerlink" title="é—®é¢˜å¼•å…¥"></a>é—®é¢˜å¼•å…¥</h3><p>é€šè¿‡<a href="https://www.cnblogs.com/initial-h/p/9468974.html" target="_blank" rel="external">åšå®¢</a>å…¥äº†ä¸€ä¸‹å°é—¨ï¼Œç»“åˆ<a href="https://www.zhihu.com/question/62631725/answer/201338234" target="_blank" rel="external">çŸ¥ä¹</a>ï¼Œé¦–å…ˆæ¥ç†è§£ä¸€ä¸‹Gumbel Sampling Trickç”¨æ¥åšä»€ä¹ˆã€‚</p><blockquote><p>å·²çŸ¥ä¸€ä¸ªç¦»æ•£éšæœºå˜é‡Xçš„åˆ†å¸ƒï¼Œæˆ‘ä»¬æƒ³å¾—åˆ°ä¸€äº›æœä»è¿™ä¸ªåˆ†å¸ƒçš„ç¦»æ•£çš„xçš„å€¼ã€‚</p></blockquote><p>æ¯”è¾ƒç®€å•çš„æ–¹æ³•æ˜¯ç”¨<code>np.random.choice</code>ã€‚æ¯”å¦‚æˆ‘ä»¬ç°åœ¨æœ‰5ä¸ªå€¼ï¼Œæ¦‚ç‡åˆ†å¸ƒæ˜¯<code>[0.1, 0, 0.3, 0.6, 0]</code>ï¼Œå³ç¬¬4ä¸ªå…ƒç´ æœ€æœ‰å¯èƒ½è¢«é‡‡æ ·åˆ°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">5</span>, <span class="number">3</span>, p=[<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0</span>])</div><div class="line">array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>])</div></pre></td></tr></table></figure><p>è¿™æ ·æˆ‘ä»¬æ˜¯è·å–åˆ°äº†å€¼ï¼Œä½†æ˜¯è¿™ä¸ªè¿‡ç¨‹åœ¨ç¥ç»ç½‘ç»œä¸­æ— æ³•æ±‚å¯¼å’Œæ–¹å‘ã€‚äºæ˜¯gumbel-maxå‡ºç°äº†ï¼š</p><blockquote><p>å°†é‡‡æ ·çš„è¿‡ç¨‹å…¬å¼åŒ–ï¼Œå…¬å¼ä¸­çš„å‚æ•°ä¸ºç¦»æ•£éšæœºå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒã€‚</p></blockquote><p>$$<br>z_{i}=\left\{\begin{array}{l}{1, i=\operatorname{argmax}_{j}\left(\log \left(p_{j}\right)+g_{j}\right)} \\ {0, \text { otherwise }}\end{array}\right.<br>$$</p><p>å…¶ä¸­$g_{i}$ä»£è¡¨gumbelå™ªå£°ï¼Œ$g_{i}=-\log \left(-\log \left(u_{i}\right)\right), u_{i} \sim U n i f o r m(0,1)$ã€‚è¾“å‡º$z_i$æ˜¯ä¸€ä¸ª$j$ç»´çš„one-hotå‘é‡ã€‚</p><p>ç”±äºargmaxä¸å¯å¯¼ï¼Œç”¨å¯å¯¼çš„softmaxæ›¿ä»£argmax<br>$$<br>\boldsymbol{z}=\operatorname{softmax}((\log (\boldsymbol{p})+\boldsymbol{g}) / \tau)<br>$$<br>å‚æ•°$ \tau$è¶Šå°ï¼Œ$z$è¶Šæ¥è¿‘one-hotå‘é‡ã€‚</p><blockquote><p>æˆ‘ä»¬æŠŠä¸å¯å¯¼çš„é‡‡æ ·è¿‡ç¨‹ï¼Œä»xæœ¬èº«è½¬å«åˆ°äº†æ±‚å–xçš„å…¬å¼ä¸­çš„ä¸€é¡¹gä¸Šé¢ï¼Œè€Œgä¸ä¾èµ–äºæ¦‚ç‡åˆ†å¸ƒpã€‚è¿™æ ·ä¸€æ¥ï¼Œxå¯¹pä»ç„¶æ˜¯å¯å¯¼çš„ï¼Œè€Œæˆ‘ä»¬å¾—åˆ°çš„xä»ç„¶æ˜¯ç¦»æ•£å€¼çš„é‡‡æ ·ã€‚è¿™æ ·çš„é‡‡æ ·è¿‡ç¨‹è½¬å«çš„æŠ€å·§å«å†å‚åŒ–æŠ€å·§(reparameterization trick)</p></blockquote><p>é‚£ä¹ˆç½‘ç»œæœ‰å“ªäº›åœ°æ–¹éœ€è¦é‡‡æ ·å‘¢ï¼Ÿæ¥ä¸‹æ¥äº†è§£ä¸€ä¸‹VAEçš„ç›¸å…³åº”ç”¨ã€‚</p><h3 id="ç›¸å…³åº”ç”¨"><a href="#ç›¸å…³åº”ç”¨" class="headerlink" title="ç›¸å…³åº”ç”¨"></a>ç›¸å…³åº”ç”¨</h3><p><strong>å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨VAE</strong></p><p><a href="http://kvfrans.com/variational-autoencoders-explained/" target="_blank" rel="external">è¿™ç¯‡åšå®¢</a> è§£é‡Šå¾—å¾ˆå¥½ï¼Œè‡ªåŠ¨ç¼–ç å™¨ç”±ç¼–ç å™¨(encoder, E)å’Œè§£ç å™¨(decoder, D)æ„æˆï¼ŒEå¯¹è¾“å…¥å›¾åƒè¿›è¡Œç¼–ç ï¼Œç”Ÿæˆéšå‘é‡ï¼Œ Då¯¹éšå‘é‡è¿›è¡Œè§£ç ï¼Œè¾“å‡ºå›¾åƒã€‚</p><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165000500-1207992534.jpg" alt="img"></p><p>ä½†æ˜¯è¿™æ ·æˆ‘ä»¬å¿…é¡»é€šè¿‡å›¾åƒæ¥ç”Ÿæˆéšå‘é‡ï¼Œå±€é™æ€§è¾ƒå¤§ï¼Œå¯ä¸å¯ä»¥éšä¾¿æ¥ä¸€ä¸ªéšå‘é‡ï¼Œè¾“å…¥è¿›Då°±èƒ½ç”Ÿæˆå›¾ç‰‡å‘¢ï¼Ÿäºæ˜¯VAEå°±å‡ºç°äº†ã€‚</p><blockquote><p>é™åˆ¶ç¼–ç å™¨ç”Ÿæˆæœä»å•å…ƒé«˜æ–¯åˆ†å¸ƒçš„éšå‘é‡ã€‚</p></blockquote><p>å› æ­¤å­¦ä¹ ç›®æ ‡å°±å¯ä»¥åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š1ï¼‰ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒå°½å¯èƒ½æ¥è¿‘ï¼› 2ï¼‰éšå˜é‡æœä»å•å…ƒé«˜æ–¯åˆ†å¸ƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">generation_loss = mean(square(generated_image - real_image))  </div><div class="line">latent_loss = KL-Divergence(latent_variable, unit_gaussian)  </div><div class="line">loss = generation_loss + latent_loss</div></pre></td></tr></table></figure><p>ä¸ºäº†ä¼˜åŒ–KLæ•£åº¦ï¼Œéœ€è¦å¼•å…¥ğŸ‘†ğŸ»æåˆ°è¿‡çš„å†å‚åŒ–æŠ€å·§ã€‚</p><blockquote><p>Eä¸ç›´æ¥ç”Ÿæˆéšå‘é‡ï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ä¸ªå‡å€¼å‘é‡å’Œä¸€ä¸ªæ–¹å·®å‘é‡ã€‚å†é€šè¿‡å‡å€¼å’Œæ–¹å·®é‡‡æ ·å‡ºéšå‘é‡ã€‚</p></blockquote><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165407236-1369432498.png" alt="img"> </p><p>è‡³æ­¤æˆ‘ä»¬æ˜ç™½äº†<strong>é‡‡æ ·</strong>æ˜¯ä¸ºäº†è®©æ•°æ®å°½å¯èƒ½æœä»æŸä¸€åˆ†å¸ƒï¼Œé€šè¿‡<strong>å†å‚åŒ–æŠ€å·§</strong>æ¥å­¦ä¹ è¿™ä¸ªåˆ†å¸ƒçš„å‚æ•°ã€‚é«˜æ–¯åˆ†å¸ƒæ˜¯è¿ç»­çš„ï¼Œç›´æ¥å¯æ±‚å¯¼ï¼Œé‚£ä¸€äº›ä¸è¿ç»­çš„ç¦»æ•£åˆ†å¸ƒæ€ä¹ˆåŠå‘€ï¼Ÿè¿™å°±å›åˆ°äº†ä¸€å¼€å§‹çš„é—®é¢˜ã€ŒGumbel Sampling Trickã€ã€‚</p><p><strong>åˆ†ç±»å†å‚åŒ–(Categorical reparameterization)</strong></p><p>ICLR 2017çš„<a href="https://arxiv.org/pdf/1611.01144.pdf" target="_blank" rel="external">è¿™ç¯‡æ–‡ç« </a> å°±åˆ©ç”¨Gumbel-Softmaxåˆ†å¸ƒï¼Œå°†ç¦»æ•£çš„åˆ†ç±»æ¦‚ç‡åˆ†å¸ƒé‡‡æ ·è¿‡ç¨‹è½¬åŒ–ä¸ºäº†å¯æ±‚å¯¼çš„è¿‡ç¨‹ã€‚</p><p><img src="https://i.loli.net/2019/05/30/5cef4476d308a17728.png" alt=""></p><p>ä¸Šå›¾åæ˜ äº†å‚æ•°$ \tau$å¯¹è¿ç»­æ¦‚ç‡åˆ†å¸ƒ(a)å’Œç¦»æ•£çš„one-hotç±»åˆ«åˆ†å¸ƒçš„å½±å“ã€‚å½“$ \tau$å¤ªå°æ—¶ä¼šå¯¼è‡´æ¢¯åº¦çš„æ–¹å·®è¿‡å¤§ï¼Œæ‰€ä»¥æ–‡ç« åœ¨å®éªŒä¸­ç”¨äº†é€€ç«çš„ç­–ç•¥æ¥é€æ¸å‡å°å‚æ•°$ \tau$ã€‚è¿˜å¯ä»¥åˆ©ç”¨ç†µæ­£åˆ™æ¥å­¦ä¹ $\tau$ï¼Œè‡ªåŠ¨è°ƒæ•´Gumbel-Softmaxåˆ†å¸ƒé‡‡æ ·çš„ç½®ä¿¡åº¦ã€‚</p><p>æœ¬æ–‡çš„è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨Straight-Through (ST) Gumbel Estimatorï¼Œå³å‰å‘ç”¨argmaxï¼Œæ¢¯åº¦å›ä¼ æ—¶ç”¨softmaxçš„æ¢¯åº¦ã€‚</p><p><strong>å‚è€ƒé“¾æ¥ï¼š</strong></p><ul><li><p><a href="https://www.cnblogs.com/initial-h/p/9468974.html" target="_blank" rel="external">Gumbel-Softmax Trickå’ŒGumbelåˆ†å¸ƒ</a></p></li><li><p><a href="https://lips.cs.princeton.edu/the-gumbel-max-trick-for-discrete-distributions/" target="_blank" rel="external">The Gumbel-Max Trick for Discrete Distributions</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;åœ¨PAGé‡Œå‘ç°äº†Gumbel Sampling Trickï¼ŒæŠŠç¦»æ•£çš„é‡‡æ ·è¿‡ç¨‹ç”¨å…¬å¼è¡¨è¾¾å‡ºæ¥ï¼Œäºæ˜¯å¯ä»¥æ”¾è¿›ç¥ç»ç½‘ç»œä¸­è¿›è¡Œæ±‚å¯¼å’Œåå‘ï¼Œè§‰å¾—æ˜¯å¾ˆæœ‰æ„æ€çš„å·¥ä½œï¼Œæƒ³è¦å¤šåŠ æ·±ä¸€äº›äº†è§£ã€‚&lt;/p&gt;
&lt;h3 id=&quot;é—®é¢˜å¼•å…¥&quot;&gt;&lt;a href=&quot;#é—®é¢˜å¼•å…¥&quot; class=&quot;headerlin
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>weekly-paper-04</title>
    <link href="http://yoursite.com/2019/05/25/weekly-paper-04/"/>
    <id>http://yoursite.com/2019/05/25/weekly-paper-04/</id>
    <published>2019-05-25T08:30:05.000Z</published>
    <updated>2019-05-27T12:12:52.191Z</updated>
    
    <content type="html"><![CDATA[<p>ä¸ºäº†é”»ç‚¼è‡ªå·±çš„è‹±è¯­å†™ä½œèƒ½åŠ›ï¼Œä»¥åå°½é‡ç”¨è‹±æ–‡åšè¿›è¡Œå½’çº³ï¼ˆâŒ˜+C &amp; âŒ˜+Vï¼‰ï½</p><h3 id="1ï¸âƒ£-To-prune-or-not-to-prune-exploring-the-efficacy-of-pruning-for-model-compression"><a href="#1ï¸âƒ£-To-prune-or-not-to-prune-exploring-the-efficacy-of-pruning-for-model-compression" class="headerlink" title="1ï¸âƒ£ To prune, or not to prune: exploring the efficacy of pruning for model compression"></a>1ï¸âƒ£ To prune, or not to prune: exploring the efficacy of pruning for model compression</h3><p>è¿™ç¯‡æ˜¯TensorFlowè‡ªå·±å‡ºçš„ï¼Œç›´æ¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èåˆL1å‰ªæã€‚é€šè¿‡å°†æ“ä½œèå…¥TensoFlowçš„training graphï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹æƒé‡è¿›è¡Œæ’åºï¼Œç”¨ä¸€ä¸ªmaskå°†æœ€å°çš„weightsç½®0ã€‚ä»inital sparsity values $s_i$å¼€å§‹ï¼Œä»¥$\Delta t$ çš„å‰ªæé¢‘ç‡ï¼Œæœ€ç»ˆè¾¾åˆ°final sparsity value $s_f$<br>$$<br>s_{t}=s_{f}+\left(s_{i}-s_{f}\right)\left(1-\frac{t-t_{0}}{n \Delta t}\right)^{3} \text { for } t \in\left\{t_{0}, \quad t_{0}+\Delta t, \ldots, t_{0}+n \Delta t\right\}<br>$$<br>masksæ¯éš”$\Delta t$æ›´æ–°ä¸€æ¬¡ï¼Œç›´åˆ°è¾¾åˆ°$s_f$åä¸å†æ›´æ–°ã€‚åŒæ—¶æ–‡ç« è¡¨æ˜ï¼Œ$n$çš„é€‰æ‹©ä¸å­¦ä¹ ç‡çš„ä¸‹é™ç­–ç•¥å¯†åˆ‡ç›¸å…³ã€‚</p><h3 id="2ï¸âƒ£-OBJECT-DETECTORS-EMERGE-IN-DEEP-SCENE-CNNS"><a href="#2ï¸âƒ£-OBJECT-DETECTORS-EMERGE-IN-DEEP-SCENE-CNNS" class="headerlink" title="2ï¸âƒ£ OBJECT DETECTORS EMERGE IN DEEP SCENE CNNS"></a>2ï¸âƒ£ OBJECT DETECTORS EMERGE IN DEEP SCENE CNNS</h3><p>ğŸ“<a href="https://github.com/metalbubble/cnnvisualizer" target="_blank" rel="external">Github Repo</a></p><p><strong>Contributions</strong></p><ul><li>object detection emerges inside a CNN trained to recognize scenes, even more than when trained with ImageNet</li><li>the same network can do both object localization and scene recognition in a single forward-pass.</li></ul><p><strong>Experiments</strong></p><ul><li><p>identify the differences in the type of images preferred at the different layers of each network</p></li><li><p>Places-CNN and ImageNet-CNN  prefer similar images in the earlier layers, while the later layers tend to be more specialized to the specific task of scene or object categorization.</p></li><li><p>understand the nature of the representation that the network is learning</p><ul><li><em>simplifying the input images:</em> 1) removing segments from the image to produce the smallest decrease of the correct classification score until the image is incorrectly classified 2) generate the minimal image representations using image set of SUN database. =&gt; use minimal image representations as inputs to show the contribute important information for the network to recognize the scene.</li><li><em>visualize the receptive fields (RFs) of units and their activatoin patterns:</em> use sliding-window to identify which regions of the image led to the high unit activations. =&gt; as the layers go deeper the RF size gradually increases and the activation regions become more semantically meaningful.</li><li><em>understan and quantify the precise semantic learnd by each unit: </em>ask AMT to indentify the common concepts that exists between the top scoring segmentations for each unit.</li></ul></li><li><p>emergence of objects as the internal representation</p><ul><li><p>what object classes emerge? =&gt; use pool5 to show the distribution of objects</p></li><li><p>why do those obejcts emerge? </p><ul><li><p>possibility 1:  the objects correspond to the most frequent ones in the database. (correlation is 0.54)</p></li><li><p>possibility 2:  the objects that allow discriminatin among scene categories. (correlation is 0.84)</p><p>=&gt; the network is automatically identifying the most discriminative object categories to a large extent</p></li></ul></li></ul></li></ul><h3 id="3ï¸âƒ£-Network-Dissection-Quantifying-Interpretability-of-Deep-Visual-Representations"><a href="#3ï¸âƒ£-Network-Dissection-Quantifying-Interpretability-of-Deep-Visual-Representations" class="headerlink" title="3ï¸âƒ£ Network Dissection: Quantifying Interpretability of Deep Visual Representations"></a>3ï¸âƒ£ Network Dissection: Quantifying Interpretability of Deep Visual Representations</h3><p>ğŸ“<a href="https://github.com/CSAILVision/NetDissect-Lite" target="_blank" rel="external">Github Repo</a></p><p><strong>Questions</strong></p><ul><li>What is a disentangled representation, and how can its factors be quantified and detected?</li><li><p>Do interpretable hidden units reflect a special alignment of feature space, or are interpretations a chimera?</p></li><li><p>What conditions in state-of-the-art training lead to representations with greater or lesser entanglement?</p></li></ul><p><strong>Measurement of interpretability: three-step process of Network Dissection</strong></p><ol><li><p>Identify a broad set of human-labeld visual concepts.</p></li><li><p>Gather hidden variablesâ€™ response to known concepts.</p><ul><li>draw concepts $c$ from the Broden dataset.</li></ul></li><li><p>Quantify alignment of hidden variable â€” concept pairs.</p><ul><li><p>Scoring Unit Interpretability</p><p>input image $x$, activation map $A_{k}(\mathbf{x}) \stackrel{scale up}{\longrightarrow}S_k(x) $ï¼Œindividual unit activations $a_k$</p><p>top quantile level $T_k$ï¼š $P\left(a_{k}&gt;T_{k}\right)=0.005$</p><p>binary segmentationï¼š$M_{k}(\mathbf{x}) \equiv S_{k}(\mathbf{x}) \geq T_{k}$</p><p>input annotaion mask $L_c$ </p><p>scoreï¼šthe accuracy of unit $k$ in detecting concept $c$<br>$$<br>I o U_{k, c}=\frac{\sum\left|M_{k}(\mathbf{x}) \cap L_{c}(\mathbf{x})\right|}{\sum\left|M_{k}(\mathbf{x}) \cup L_{c}(\mathbf{x})\right|}<br>$$</p></li></ul></li></ol><h3 id="4ï¸âƒ£-Pixel-wise-Attentional-Gating-for-Scene-Parsing"><a href="#4ï¸âƒ£-Pixel-wise-Attentional-Gating-for-Scene-Parsing" class="headerlink" title="4ï¸âƒ£ Pixel-wise Attentional Gating for Scene Parsing"></a>4ï¸âƒ£ Pixel-wise Attentional Gating for Scene Parsing</h3><p><strong>Contributions:</strong></p><ul><li>Dynamic computation depth: insert PAG at multiple lyaers of ResNet to control computational parsimony.</li><li>Dynamic spatial pooling: adaptively chooses the proper pooling size for each pixel to aggregate information for inference.</li><li>Experimetns on various pixel labeling tasks, including semantic segmentation, boundary detection, monocular depth and surface normal estimation.</li></ul><p><img src="https://i.loli.net/2019/05/27/5ceb52642beaa24177.png" alt=""></p><p>binary spatial mask $\mathbf{G}$ on ResBottleneck:<br>$$<br>\begin{array}{ll}{\mathbf{X}=\mathcal{F}^{1}(\mathbf{I})} &amp; {\mathbf{X}=\mathcal{F}^{1}(\mathbf{I}), \mathbf{G}=\mathcal{G}(\mathbf{I})} \\ {\mathbf{Y}=\mathcal{F}^{2}(\mathbf{X})} &amp; {\mathbf{Y}=\mathcal{F}_{\mathbf{G}}^{2}(\mathbf{X})} \\ {\mathbf{Z}=\mathcal{F}^{3}(\mathbf{Y})} &amp; {\mathbf{Z}=\mathcal{F}_{\mathbf{G}}^{3}(\overline{\mathbf{G}} \odot \mathbf{X}+\mathbf{G} \odot \mathbf{Y})} \\ {\mathbf{O}=\mathbf{I}+\mathbf{Z}} &amp; {\mathbf{O}=\mathbf{I}+\mathbf{Z}}\end{array}<br>$$<br><strong>Methods:</strong></p><ul><li><p>Learning attention maps</p><blockquote><p>The key to the proposed PAG is the gating function G that produces a discrete (binary) mask which allows for reduced computation. However, producing the binary mask using hard thresholding is non-differentiable, and thus cannot be simply incorporated in CNN where gradient descent is used for training. To bridge the gap, we exploit the Gumbel-Max trick [19] and its recent continuous relaxation [39, 28].</p></blockquote><p>Gumbel distribution  $m \equiv-\log (-\log (u))$, where $u \sim \mathcal{U}[0,1]$</p><p>$g$ is a discrete random variable with probabilities  $P(g=k) \propto a_{k}$</p><p>$\left\{m_{k}\right\}_{k=1, \dots, K}$ is a sequence of i.i.d Gumbel random variables </p><p>sample from the discrete variable:<br>$$<br>g=\underset{k=1, \ldots, K}{\operatorname{argmax}}\left(\log \alpha_{k}+m_{k}\right)<br>$$<br>Gumbel Sampling Trick (replaces the argmax operation with a softmax): </p></li></ul><p>$$<br>\mathbf{g}=\operatorname{softmax}((\log (\boldsymbol{\alpha})+\mathbf{m}) / \tau)<br>$$</p><p>â€‹        <strong>forwardd pass</strong>: discrete smaples of the argmax </p><p>â€‹        <strong>backward pass</strong>: compute gradient of the softmax relaxation</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ä¸ºäº†é”»ç‚¼è‡ªå·±çš„è‹±è¯­å†™ä½œèƒ½åŠ›ï¼Œä»¥åå°½é‡ç”¨è‹±æ–‡åšè¿›è¡Œå½’çº³ï¼ˆâŒ˜+C &amp;amp; âŒ˜+Vï¼‰ï½&lt;/p&gt;
&lt;h3 id=&quot;1ï¸âƒ£-To-prune-or-not-to-prune-exploring-the-efficacy-of-pruning-for-model-compressi
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨è®ºæ–‡ Vol.03</title>
    <link href="http://yoursite.com/2019/05/19/weekly-paper-03/"/>
    <id>http://yoursite.com/2019/05/19/weekly-paper-03/</id>
    <published>2019-05-19T13:09:17.000Z</published>
    <updated>2019-05-23T10:42:12.181Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse-Decomposition"><a href="#1ï¸âƒ£-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse-Decomposition" class="headerlink" title="1ï¸âƒ£ On Compressing Deep Models by Low Rank and Sparse Decomposition"></a>1ï¸âƒ£ On Compressing Deep Models by Low Rank and Sparse Decomposition</h3><p>æœ¬æ–‡å°†ç½‘ç»œæƒé‡åˆ†è§£æˆä½ç§©å’Œç¨€ç–çš„æˆåˆ†ï¼Œåˆ©ç”¨è´ªå¿ƒåŒè¾¹åˆ†è§£ï¼ˆGreBdecï¼‰ç®—æ³•è¿›è¡Œæ¨¡å‹å‹ç¼©ã€‚</p><p>ç›®æ ‡å‡½æ•°ï¼š<br>$$<br>\begin{array}{cl}{\min _{L, S}} &amp; {\frac{1}{2}|W-L-S|_{F}^{2}} \\ {\text {s.t.}} &amp; {\operatorname{rank}(L) \leq r} \\ &amp;card(S) \leq c \end{array}<br>$$<br>å‡è®¾$L=UV$ï¼Œå…¶ä¸­$U \in R^{m \times r}, V \in R^{r \times k}$ã€‚æœ¬æ–‡ç”¨ä¸¤ä¸ªå·ç§¯å±‚è¿›è¡Œä½ç§©è¿‘ä¼¼ï¼Œ$V$å°†é€šé“æ•°æ˜ å°„åˆ°$r$ï¼Œ$U$ä»£è¡¨$1\times1$å·ç§¯ã€‚ç„¶åæŠŠä½ç§©è¿‘ä¼¼çš„ç»“æœå’Œç¨€ç–çš„ç»“æœç›¸åŠ åˆ©ç”¨maskä¹˜åˆ°åŸfiltersä¸Šï¼Œä¿®æ”¹ç›®æ ‡å‡½æ•°ï¼š<br>$$<br>\begin{array}{cl}{\min _{L, S}} &amp; {\frac{1}{2 n}|Y-(L+S) X|_{F}^{2}} \\ {\text {s.t.}} &amp; {\frac{1}{2}|W-L-S|_{F}^{2} \leq \gamma} \\ &amp; rank(L) \leq r, \\ &amp; card(S) \leq c.\end{array}<br>$$<br>ç­‰åŒäºåˆ©ç”¨è¿­ä»£ä¼˜åŒ–ç­–ç•¥ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼š<br>$$<br>\frac{1}{2 n}|Y-(L+S) X|_{2}^{2}+\frac{\lambda}{2}|W-L-S|_{F}^{2}<br>$$<br>å…¶ä¸­<br>$$<br>\left\{\begin{array}{l}{L_{i}=\text { TruncatedGSVD }\left(B_{i} A^{\dagger}, r\right)} \\ {S_{i}=P_{\Omega}(M), \text { and } M=S_{i-1}-\eta\left(A S_{i-1}-C_{i}\right)}\end{array}\right.<br>$$<br>æœ¬æ–‡ç”¨SVD-freeçš„GreBdecç®—æ³•è¿›è¡Œä¼˜åŒ–ï¼Œä»¤$L=UV$<br>$$<br>\begin{array}{cl}{\min _{U, V, S}} &amp; {\frac{1}{2 n}|Y-(U V+S) X|_{F}^{2}+\frac{\lambda}{2}|W-U V-S|_{F}^{2}} \\ {\text {s.t.}} &amp; {\operatorname{card}(S) \leq c}\end{array}<br>$$<br>$U,V,S$é€šè¿‡ä»¥ä¸‹å…¬å¼æ›´æ–°ï¼š<br>$$<br>\left\{\begin{array}{l}{U_{i}=B_{i} V_{i-1}^{\top}\left(V_{i-1} A V_{i-1}^{\top}\right)^{\dagger}} \\ {V_{i}=\left(U_{i}^{\top} U_{i}\right)^{\dagger} U_{i}^{\top}\left(B_{i} A^{\dagger}\right)} \\ {S_{i}=P_{\Omega}(M), \text { and } M=S_{i-1}-\eta\left(A S_{i-1}-C_{i}\right)}\end{array}\right.<br>$$<br>ç„¶ååˆç»è¿‡ä¸€ç•ªå˜æ¢ä½œè€…åˆ©ç”¨QRåˆ†è§£å¾—åˆ°ä¸€ä¸ªè®©$U,V$æ›´å¿«æ›´æ–°çš„è§„åˆ™ï¼š<br>$$<br>\left\{\begin{array}{l}{U_{i}=Q, Q R\left(B_{i} V^{\top}\right)=Q R} \\ {V_{i}=Q^{\top}\left(B_{i} A^{\dagger}\right)}\end{array}\right.<br>$$<br><img src="https://i.loli.net/2019/05/20/5ce2015dee80b29804.png" alt=""></p><p>###2ï¸âƒ£ Spatial Transformer Networks</p><p>å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç©ºé—´ä¸Šçš„å˜æ¢ï¼Œä»¥å­¦åˆ°å›¾åƒçš„ä¸å˜æ€§(invariance)ã€‚é…åˆ<a href="https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html" target="_blank" rel="external">PyTorch Tutorial</a>é£Ÿç”¨ã€‚</p><p><img src="https://i.loli.net/2019/05/23/5ce663632bbf215753.png" alt=""></p><p>STNä¹Ÿç±»ä¼¼ä¸€ä¸ªæ’ä»¶ï¼Œä¸»è¦ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼š</p><ul><li>Localisation netï¼šè¾“å…¥feature map $U \in \mathbb{R}^{H \times W \times C}$ï¼Œè¾“å‡ºå˜æ¢å‚æ•°$\theta=f_{\mathrm{loc}}(U)$ã€‚å…¶ä¸­$\theta$æ˜¯ä¸€ä¸ª6ç»´çš„ä»¿å°„å˜æ¢ã€‚</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Spatial transformer localization-network</span></div><div class="line">self.localization = nn.Sequential(</div><div class="line">nn.Conv2d(<span class="number">1</span>, <span class="number">8</span>, kernel_size=<span class="number">7</span>),</div><div class="line">  nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</div><div class="line">  nn.ReLU(<span class="keyword">True</span>),</div><div class="line">  nn.Conv2d(<span class="number">8</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>),</div><div class="line">  nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</div><div class="line">  nn.ReLU(<span class="keyword">True</span>)</div><div class="line">)</div></pre></td></tr></table></figure><ul><li>Grid generatorï¼šå¯¹å›¾åƒç”¨$A_\theta$è¿›è¡Œ2Dä»¿å°„å˜æ¢ï¼Œå…¶ä¸­$(x_i^t, y_I^t)$ä¸ºtargetåƒç´ ç‚¹åæ ‡ï¼Œ$\left(x_{i}^{s}, y_{i}^{s}\right)$ä¸ºsourceé‡‡æ ·ç‚¹çš„åæ ‡ã€‚</li></ul><p>$$<br>\left( \begin{array}{c}{x_{i}^{s}} \\ {y_{i}^{s}}\end{array}\right)=\mathcal{T}_{\theta}\left(G_{i}\right)=\mathrm{A}_{\theta} \left( \begin{array}{c}{x_{i}^{t}} \\ {y_{i}^{t}} \\ {1}\end{array}\right)=\left[ \begin{array}{ccc}{\theta_{11}} &amp; {\theta_{12}} &amp; {\theta_{13}} \\ {\theta_{21}} &amp; {\theta_{22}} &amp; {\theta_{23}}\end{array}\right] \left( \begin{array}{c}{x_{i}^{t}} \\ {y_{i}^{t}} \\ {1}\end{array}\right)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Regressor for the 3 * 2 affine matrix</span></div><div class="line">self.fc_loc = nn.Sequential(</div><div class="line">  nn.Linear(<span class="number">10</span> * <span class="number">3</span> * <span class="number">3</span>, <span class="number">32</span>),</div><div class="line">  nn.ReLU(<span class="keyword">True</span>),</div><div class="line">  nn.Linear(<span class="number">32</span>, <span class="number">3</span> * <span class="number">2</span>)</div><div class="line">)</div></pre></td></tr></table></figure><p>ä¸ºäº†åœ¨$U$ä¸Šåº”ç”¨ç©ºé—´å˜æ¢è¾“å‡º$V$ï¼Œéœ€è¦ä¸€ä¸ªå¯å¯¼çš„é‡‡æ ·å‡½æ•°ç”Ÿæˆé‡‡æ ·ç‚¹$\mathcal{T}_\theta(G)$ã€‚<br>$$<br>V_{i}^{c}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} k\left(x_{i}^{s}-m ; \Phi_{x}\right) k\left(y_{i}^{s}-n ; \Phi_{y}\right) \forall i \in\left[1 \ldots H^{\prime} W^{\prime}\right] \forall c \in[1 \ldots C]<br>$$<br>å…¶ä¸­$k$ä¸ºsampling kernelï¼Œå¯ä»¥å®šä¹‰ä¸ºinteger sampling kernel:<br>$$<br>V_{i}^{c}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} \delta\left(\left\lfloor x_{i}^{s}+0.5\right\rfloor- m\right) \delta\left(\left\lfloor y_{i}^{s}+0.5\right\rfloor- n\right)<br>$$<br>ä¹Ÿå¯ä»¥å®šä¹‰ä¸ºbilinear sampling kernelï¼š<br>$$<br>V_{i}^{c}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} \max \left(0,1-\left|x_{i}^{s}-m\right|\right) \max \left(0,1-\left|y_{i}^{s}-n\right|\right)<br>$$<br>å¯¹è¾“å…¥æ±‚åå¯¼æœ‰ï¼š<br>$$<br>\frac{\partial V_{i}^{c}}{\partial x_{i}^{s}}=\sum_{n}^{H} \sum_{m}^{W} U_{n m}^{c} \max \left(0,1-\left|y_{i}^{s}-n\right|\right) \left\{\begin{array}{ll}{0} &amp; {\text { if }\left|m-x_{i}^{s}\right| \geq 1} \\ {1} &amp; {\text { if } m \geq x_{i}^{s}} \\ {-1} &amp; {\text { if } m<x_{i}^{s}}\end{array}\right. $$="" æŠŠ<em="">localisation network, grid generator, samplerç»“åˆèµ·æ¥æ„æˆä¸€ä¸ªSTNæ¨¡å—ï¼š</x_{i}^{s}}\end{array}\right.></p><p><strong>STN</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Spatial transformer network forward function</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stn</span><span class="params">(self, x)</span>:</span></div><div class="line">  xs = self.localization(x)</div><div class="line">  xs = xs.view(<span class="number">-1</span>, <span class="number">10</span> * <span class="number">3</span> * <span class="number">3</span>)</div><div class="line">  theta = self.fc_loc(xs)</div><div class="line">  theta = theta.view(<span class="number">-1</span>, <span class="number">2</span>, <span class="number">3</span>)</div><div class="line"></div><div class="line">  grid = F.affine_grid(theta, x.size())</div><div class="line">  x = F.grid_sample(x, grid)</div><div class="line"></div><div class="line">  <span class="keyword">return</span> x</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1ï¸âƒ£-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse-Decomposition&quot;&gt;&lt;a href=&quot;#1ï¸âƒ£-On-Compressing-Deep-Models-by-Low-Rank-and-Sparse
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>HEXOä¸»é¢˜cactusä¿®æ”¹</title>
    <link href="http://yoursite.com/2019/05/19/hexo-theme-cactus/"/>
    <id>http://yoursite.com/2019/05/19/hexo-theme-cactus/</id>
    <published>2019-05-19T03:05:14.000Z</published>
    <updated>2019-05-19T08:55:36.409Z</updated>
    
    <content type="html"><![CDATA[<p>cacutsçš„ä¸»é¢˜å¾ˆç®€æ´ï¼Œç”¨å¾—è›®ä¹…ï¼Œçœ‹åˆ°åŸåº“æœ‰æ›´æ–°ï¼Œæ‰€ä»¥forkäº†æ–°çš„ç‰ˆæœ¬å¹¶åœ¨ä¸Šé¢åšä¸€äº›ä¿®æ”¹ï¼Œé¡ºä¾¿è®°å½•ä¸€ä¸‹è¿‡ç¨‹ã€‚</p><h3 id="ä¸»é¢˜é•œåƒ"><a href="#ä¸»é¢˜é•œåƒ" class="headerlink" title="ä¸»é¢˜é•œåƒ"></a>ä¸»é¢˜é•œåƒ</h3><p>é¦–å…ˆæ ¹æ®<a href="https://help.github.com/en/articles/duplicating-a-repository" target="_blank" rel="external">Mirrow a repository</a>é•œåƒä¸€ä¸ªåº“ã€‚åœ¨pushçš„æ—¶å€™è¿˜é‡åˆ°äº†403é—®é¢˜ï¼š</p><blockquote><p>remote: Permission to colorjam/hexo-theme-cactus-mirrored.git denied to xxx</p></blockquote><p>é€šè¿‡åˆ é™¤<strong>Keychain Access</strong>ä¸­å­˜å‚¨çš„github.comçš„Internet passwordå¾—åˆ°è§£å†³ã€‚ç„¶åæŠŠè‡ªå·±çš„åº“å†Cloneè¿›<code>themes</code>ä¸­</p><h3 id="æ ·å¼ç¼–è¾‘"><a href="#æ ·å¼ç¼–è¾‘" class="headerlink" title="æ ·å¼ç¼–è¾‘"></a>æ ·å¼ç¼–è¾‘</h3><ul><li><p>ä¸»é¢˜é¢œè‰²</p><p>åœ¨<code>source/css/_colors</code>ä¸‹æ–°å»ºäº†ä¸€ä¸ª<code>pink.styl</code>ï¼ŒåŒæ—¶ä¿®æ”¹<code>_config.yml</code>ä¸­çš„<code>colorscheme:pink</code>ã€‚</p></li><li><p>logoè®¾ç½®</p><p>æŠŠ<code>source/images/</code>ä¸‹çš„<code>favicon.ico</code>å’Œ<code>logo.png</code>æ¢æˆè‡ªå·±å–œæ¬¢çš„å›¾ç‰‡ã€‚ä¿®æ”¹<code>source/css/_partial/header.styl</code>ä¸­çš„<code>#logo</code> çš„<code>background-size: contain</code></p></li><li><p>ç»†èŠ‚è°ƒæ•´</p><p>åˆ é™¤<code>header.styl</code>ä¸­htmlçš„<code>border-top</code></p><p>é“¾æ¥æ ·å¼ï¼š</p></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">a</span></div><div class="line">  color: $color-text</div><div class="line">  <span class="selector-tag">text-decoration</span>: <span class="selector-tag">none</span></div><div class="line"></div><div class="line">  &amp;<span class="selector-pseudo">:hover</span></div><div class="line">  background-image: linear-gradient(transparent, transparent 4px, $color-link 4px, $color-link)</div><div class="line">  <span class="selector-tag">background-position</span>: <span class="selector-tag">bottom</span></div><div class="line">  <span class="selector-tag">background-size</span>: 100% 6<span class="selector-tag">px</span></div><div class="line">  <span class="selector-tag">background-repeat</span>: <span class="selector-tag">repeat-x</span></div></pre></td></tr></table></figure><p>â€‹    è¡Œå†…ä»£ç æ ·å¼ï¼š</p><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">code</span></div><div class="line">  <span class="selector-tag">padding</span>: 0 5<span class="selector-tag">px</span></div><div class="line">  <span class="selector-tag">background</span>: <span class="selector-id">#f6f8fa</span></div><div class="line">  <span class="selector-tag">border-radius</span>: 2<span class="selector-tag">px</span></div><div class="line">  <span class="selector-tag">-webkit-border-radius</span>: 2<span class="selector-tag">px</span></div></pre></td></tr></table></figure><h3 id="ä¼šåŠ¨çš„ç²’å­"><a href="#ä¼šåŠ¨çš„ç²’å­" class="headerlink" title="ä¼šåŠ¨çš„ç²’å­"></a>ä¼šåŠ¨çš„ç²’å­</h3><p>åœ¨èƒŒæ™¯åŠ ä¸Š<a href="https://github.com/VincentGarreau/particles.js/" target="_blank" rel="external">ä¼šåŠ¨çš„ç²’å­</a>ï¼Œåœ¨<code>source/lib</code>é‡Œåˆ›å»ºä¸€ä¸ªparticlesæ–‡ä»¶å¤¹ï¼ŒæŠŠ<code>particles.min.js</code>æ”¾è¿›å»ã€‚</p><p>åœ¨<code>layout.ejs</code>ä¸­åŠ å…¥</p><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"particles-js"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div></pre></td></tr></table></figure><p>åœ¨<code>scripts.ejs</code>ä¸­æ·»åŠ è„šæœ¬ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&lt;!-- particles --&gt;</div><div class="line">&lt;%- js(&apos;lib/particles/particles.min&apos;) %&gt;</div><div class="line">&lt;script type=&quot;text/javascript&quot;&gt;</div><div class="line">particlesJS(&apos;particles-js&apos;, &#123;</div><div class="line">        ...</div><div class="line">        &#125;</div><div class="line">      )</div><div class="line">&lt;/script&gt;</div></pre></td></tr></table></figure><p>åœ¨<code>style.css</code>ä¸­æ·»åŠ æ ·å¼ï¼š</p><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="selector-id">#particles-js</span> &#123;</div><div class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</div><div class="line">  <span class="attribute">position</span>: absolute;</div><div class="line">  <span class="attribute">margin-left</span>: -<span class="number">28%</span>;</div><div class="line">  <span class="attribute">z-index</span>: -<span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;cacutsçš„ä¸»é¢˜å¾ˆç®€æ´ï¼Œç”¨å¾—è›®ä¹…ï¼Œçœ‹åˆ°åŸåº“æœ‰æ›´æ–°ï¼Œæ‰€ä»¥forkäº†æ–°çš„ç‰ˆæœ¬å¹¶åœ¨ä¸Šé¢åšä¸€äº›ä¿®æ”¹ï¼Œé¡ºä¾¿è®°å½•ä¸€ä¸‹è¿‡ç¨‹ã€‚&lt;/p&gt;
&lt;h3 id=&quot;ä¸»é¢˜é•œåƒ&quot;&gt;&lt;a href=&quot;#ä¸»é¢˜é•œåƒ&quot; class=&quot;headerlink&quot; title=&quot;ä¸»é¢˜é•œåƒ&quot;&gt;&lt;/a&gt;ä¸»é¢˜é•œåƒ&lt;/h3&gt;&lt;
      
    
    </summary>
    
    
      <category term="ç»´ä¿®æŒ‡å—" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflowå†…å­˜æ³„æ¼</title>
    <link href="http://yoursite.com/2019/05/18/tf-memory-leak/"/>
    <id>http://yoursite.com/2019/05/18/tf-memory-leak/</id>
    <published>2019-05-18T05:13:31.000Z</published>
    <updated>2019-05-19T06:54:57.626Z</updated>
    
    <content type="html"><![CDATA[<p>ç”¨tfç»å¸¸ä¼šå‡ºç°OOMçš„ç°è±¡ï¼ŒæŸ¥äº†ä¸€ä¸‹å‘ç°äº†ä¸€ç¯‡æ–‡ç« <a href="https://dantkz.github.io/How-To-Debug-A-Memory-Leak-In-TensorFlow/" target="_blank" rel="external">How To Debug A Memory Leak In Tensorflow</a></p><p>ç”±äºtfå­˜åœ¨å†…å­˜æ³„æ¼é—®é¢˜ï¼Œè®¸å¤šäººä¼šç”¨ <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html" target="_blank" rel="external">tcmalloc</a> æ¥æ›¿ä»£ malloc()ã€‚</p><p>ä½†æ˜¯è¿è¡Œç¨‹åºçš„æ—¶å€™ä¼šæŠ¥é”™ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ERROR: ld.so: object <span class="string">'/usr/lib/libtcmalloc.so.4'</span> from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.</div></pre></td></tr></table></figure><p>è¸©äº†ä¸€ç³»åˆ—å‘ä»¥åå‘ç°ï¼Œå°†<code>/usr/lib/libtcmalloc.so.4</code>æ”¹ä¸º<code>/usr/local/lib/libtcmalloc.so.4</code>å³å¯ã€‚</p><p><strong>å‚è€ƒé“¾æ¥ï¼š</strong></p><ul><li><a href="https://www.cnblogs.com/Lelouch/p/3365672.html" target="_blank" rel="external">https://www.cnblogs.com/Lelouch/p/3365672.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ç”¨tfç»å¸¸ä¼šå‡ºç°OOMçš„ç°è±¡ï¼ŒæŸ¥äº†ä¸€ä¸‹å‘ç°äº†ä¸€ç¯‡æ–‡ç« &lt;a href=&quot;https://dantkz.github.io/How-To-Debug-A-Memory-Leak-In-TensorFlow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;How
      
    
    </summary>
    
    
      <category term="ç»´ä¿®æŒ‡å—" scheme="http://yoursite.com/tags/%E7%BB%B4%E4%BF%AE%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>pair-wise-loss</title>
    <link href="http://yoursite.com/2019/05/17/pair-wise-loss/"/>
    <id>http://yoursite.com/2019/05/17/pair-wise-loss/</id>
    <published>2019-05-17T05:44:19.000Z</published>
    <updated>2019-05-17T08:08:40.815Z</updated>
    
    <content type="html"><![CDATA[<p>ç”¨Tensorflowå¤ç°è®ºæ–‡ä¸­çš„pair wise loss<br>$$<br>\ell_{p a}(\mathrm{S})=\frac{1}{\left(W^{\prime} \times H{\prime}\right)^{2}} \sum_{i \in \mathcal{R}} \sum_{j \in \mathcal{R}}\left(a_{ij}^{s}-a_{ij}^{t}\right){2}<br>$$<br>å…¶ä¸­<br>$$<br>a_{i j}=\mathbf{f}_{i}^{\top} \mathbf{f}_{j} /\left(\left|\mathbf{f}_{i}\right|_{2}\left|\mathbf{f}_{j}\right|_{2}\right)<br>$$<br>$f_i$å’Œ$f_j$åˆ†åˆ«ä»£è¡¨ith / jthåƒç´ ç‚¹çš„cç»´ç‰¹å¾ã€‚å‚è€ƒäº†ä½™å¼¦ç›¸ä¼¼æ€§çš„è®¡ç®—æ–¹æ³•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">similarity</span><span class="params">(x)</span>:</span></div><div class="line">    x = tf.reshape(x, [x.shape[<span class="number">0</span>], <span class="number">-1</span>, x.shape[<span class="number">-1</span>]])</div><div class="line">    norm = tf.nn.l2_normalize(x, <span class="number">2</span>)</div><div class="line">    a = tf.matmul(norm, norm, adjoint_b = <span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> a</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_loss</span><span class="params">(x, y)</span>:</span></div><div class="line">    _, h, w, _  = x.shape</div><div class="line">    pa = tf.reduce_sum(tf.pow((similarity(x) - similarity(y)), <span class="number">2</span>)) / tf.pow(tf.cast(h*w, tf.float32),<span class="number">2</span>)</div><div class="line">    <span class="keyword">return</span> pa</div></pre></td></tr></table></figure><p>å‚è€ƒé“¾æ¥ï¼š</p><ul><li><a href="https://stackoverflow.com/questions/48485373/pairwise-cosine-similarity-using-tensorflow?rq=1" target="_blank" rel="external">https://stackoverflow.com/questions/48485373/pairwise-cosine-similarity-using-tensorflow?rq=1</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ç”¨Tensorflowå¤ç°è®ºæ–‡ä¸­çš„pair wise loss&lt;br&gt;$$&lt;br&gt;\ell_{p a}(\mathrm{S})=\frac{1}{\left(W^{\prime} \times H{\prime}\right)^{2}} \sum_{i \in \mathc
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>LQ-Nets</title>
    <link href="http://yoursite.com/2019/05/14/LQ-Nets/"/>
    <id>http://yoursite.com/2019/05/14/LQ-Nets/</id>
    <published>2019-05-14T09:02:31.000Z</published>
    <updated>2019-05-18T08:21:12.014Z</updated>
    
    <content type="html"><![CDATA[<p>ä¼ ç»Ÿçš„é‡åŒ–æ–¹æ³•ä¸»è¦ä½¿ç”¨å›ºå®šçš„æˆ–è€…æ‰‹å·¥è®¾è®¡çš„é‡åŒ–æ–¹æ¡ˆï¼ˆå‡åŒ€é‡åŒ–/å¯¹æ•°é‡åŒ–ï¼‰ï¼š<br>$$<br>Q(x)=q_{l}, \text { if } x \in\left(t_{l}, t_{l+1}\right]<br>$$<br>æœ¬æ–‡æå‡ºäº†å¯å­¦ä¹ çš„é‡åŒ–æ–¹å¼ï¼š<br>$$<br>Q_{\text { ours }}(x, \mathbf{v})=\mathbf{v}^{\mathrm{T}} \mathbf{e}_{l}, \quad \text { if } x \in\left(t_{l}, t_{l+1}\right]<br>$$<br>å…¶ä¸­ $\mathbf{v} \in \mathbb{R}^{K}$æ˜¯$\mathbf{e}_{l} \in\{-1,1\}^{K}$, $K$ä»£è¡¨bitæ•°ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ä¼ ç»Ÿçš„é‡åŒ–æ–¹æ³•ä¸»è¦ä½¿ç”¨å›ºå®šçš„æˆ–è€…æ‰‹å·¥è®¾è®¡çš„é‡åŒ–æ–¹æ¡ˆï¼ˆå‡åŒ€é‡åŒ–/å¯¹æ•°é‡åŒ–ï¼‰ï¼š&lt;br&gt;$$&lt;br&gt;Q(x)=q_{l}, \text { if } x \in\left(t_{l}, t_{l+1}\right]&lt;br&gt;$$&lt;br&gt;æœ¬æ–‡æå‡ºäº†å¯å­¦ä¹ çš„é‡åŒ–æ–¹å¼ï¼š&lt;br&gt;$$&lt;br
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨è®ºæ–‡ Vol.02</title>
    <link href="http://yoursite.com/2019/05/13/weekly-paper-02/"/>
    <id>http://yoursite.com/2019/05/13/weekly-paper-02/</id>
    <published>2019-05-13T02:50:43.000Z</published>
    <updated>2019-05-19T04:29:39.092Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATION"><a href="#1ï¸âƒ£-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATION" class="headerlink" title="1ï¸âƒ£ ON THE IMPORTANCE OF SINGLE DIRECTIONS FOR GENERALIZATION"></a>1ï¸âƒ£ ON THE IMPORTANCE OF SINGLE DIRECTIONS FOR GENERALIZATION</h3><p>åœ¨ã€ŠRevisiting the Importance of Individual Units in CNNs via Ablationã€‹çš„åŸºç¡€ä¸Šçœ‹äº†è¿™ç¯‡è®ºæ–‡ã€‚</p><p>æœ¬æ–‡æ¢ç©¶çš„æ˜¯æ¿€æ´»å€¼çš„å•æ–¹å‘ä¾èµ–å¯¹ç½‘ç»œæ³›åŒ–æ€§èƒ½çš„å½±å“ï¼Œé€šè¿‡å¯¹unitsè¿›è¡ŒæŠ‘åˆ¶/åŠ å™ªå£°ï¼Œè¡¨ç¤ºç½‘ç»œå¯¹å•åå‘çš„ä¾èµ–èƒ½è¾ƒå¥½çš„é¢„æµ‹å…¶æ³›åŒ–æ€§èƒ½ã€‚æ–‡ç« è®²äº†ä¸€ä¸ªæ•…äº‹ï¼Œä¸€ä¸ªç½‘ç»œåªé€šè¿‡è®°å¿†æ¯å¼ è¾“å…¥å’Œå…¶å¯¹åº”çš„è¾“å‡ºï¼Œæ³›åŒ–æ€§å·®(memorizing network)ï¼Œå¦ä¸€ä¸ªç½‘ç»œèƒ½å¤Ÿæ‰¾åˆ°æ•°æ®ä¸­çš„ç»“æ„æ€§ï¼Œæ³›åŒ–æ€§ä½³(structure-finding network)ã€‚memorizing networkæ‰¾åˆ°çš„æœ€å°æè¿°é•¿åº¦åº”è¯¥å¤§äºstructure-finding networkã€‚å› æ­¤ï¼Œmemorizing networkä¼šä½¿ç”¨æ›´å¤šçš„å•åå‘ï¼Œé‚£ä¹ˆï¼Œå¦‚æœéšæœºæ‰°ä¹±å•ä¸€æ–¹å‘ï¼Œå¯¹memorizing networkçš„å½±å“åº”è¯¥å¤§äºstructure-finding networkã€‚</p><p>é€šè¿‡å¯¹dropoutå’ŒBNå®éªŒï¼ˆä¸¤ä¸ªæ–¹æ³•éƒ½å¢å¼ºäº†ç½‘ç»œçš„æ³›åŒ–æ€§ï¼‰ï¼Œè¡¨æ˜å°½ç®¡dropoutèƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šé¿å…è®°å¿†éšæœºæ ‡ç­¾ï¼Œä½†ä¸èƒ½é¿å…è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¿‡åº¦å•æ–¹å‘ä¾èµ–ã€‚åŠ äº†BNçš„ç½‘ç»œè¿›è¡Œç¥ç»å…ƒæŠ‘åˆ¶æ—¶ï¼Œè®­ç»ƒç²¾åº¦ä¼šé™å¾—æ¯”è¾ƒæ…¢ï¼Œè¯´æ˜BNä¹Ÿä¸é¼“åŠ±å•æ–¹å‘ä¾èµ–ã€‚</p><p>æ¥ç€æ–‡ç« éªŒè¯äº†class selectivityä¸ç¥ç»å…ƒé‡è¦æ€§çš„å…³ç³»ã€‚æå‡ºäº†ä¸¤ä¸ªé—®é¢˜ï¼š</p><ol><li><p>BNä¸é¼“åŠ±å•æ–¹å‘ä¾èµ–ï¼Œé‚£ä¹ˆæ˜¯å¦ä¼šå½±å“å•åå‘çš„ç±»åˆ«ä¿¡æ¯åˆ†å¸ƒï¼Ÿ</p><p>æ–‡ç« ä½¿ç”¨class selectivityæ¥è¡¡é‡ç±»åˆ«ä¿¡æ¯åˆ†å¸ƒï¼Œhigh class selectivityè¯´æ˜å…³æ³¨çš„æ˜¯å•ä¸€ç±»åˆ«ï¼Œlow class selectivityè¯´æ˜å…³æ³¨çš„æ˜¯å¤šä¸ªç±»åˆ«ã€‚æ²¡æœ‰BNçš„ç½‘ç»œåè€Œæ˜¾ç¤ºå‡ºæ›´é«˜çš„class selectivityã€‚è¡¨æ˜BNå±‚é¼“åŠ±feature mapå»å­¦ä¹ å¤šç§ç±»åˆ«çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯å…³æ³¨å•ä¸€ç±»åˆ«ã€‚</p></li><li><p>æ˜¯å¦èƒ½å¤Ÿåˆ©ç”¨unitçš„class selectivityï¼Œåˆ¤æ–­unitçš„é‡è¦æ€§ï¼Ÿ</p><p>æ–‡ç« å‘ç°class selectivityå’Œç½‘ç»œæµ…å±‚çš„feature mapè´Ÿç›¸å…³ï¼Œä¸ç½‘ç»œæ·±å±‚åˆ™æ— å…³ã€‚ä½œè€…åˆ©ç”¨äº’ä¿¡æ¯ä¹Ÿåšäº†ç›¸åŒçš„å®éªŒã€‚å¾—åˆ°ä¸€è‡´çš„ç»“æœã€‚ä»¥æ­¤è¯´æ˜class selectiviyå¹¶ä¸èƒ½ä»£è¡¨unitçš„é‡è¦æ€§ã€‚</p></li></ol><blockquote><p>ğŸ§ æœ¬æ–‡çš„ç»“è®ºæ˜¯ç´§å‡‘ç½‘ç»œå¯¹å•æ–¹å‘çš„ä¾èµ–æ€§è¾ƒå°‘ï¼Œé‚£ä¹ˆå¦‚ä½•æ‰¾åˆ°ä¸€ä¸ªè¡¡é‡unitæ–¹å‘æ€§çš„å‡½æ•°ï¼Œæ¥è¿›è¡Œç½‘ç»œå‹ç¼©å‘¢ï¼Ÿ</p></blockquote><h3 id="2ï¸âƒ£-MaskConnect-Connectivity-Learning-by-Gradient-Descent"><a href="#2ï¸âƒ£-MaskConnect-Connectivity-Learning-by-Gradient-Descent" class="headerlink" title="2ï¸âƒ£  MaskConnect: Connectivity Learning by Gradient Descent"></a>2ï¸âƒ£  MaskConnect: Connectivity Learning by Gradient Descent</h3><p>ç”¨æ¢¯åº¦ä¸‹é™è‡ªåŠ¨å­¦ä¹ è¿æ¥ã€‚å’Œç½‘ç»œæƒé‡ä¸€èµ·å­¦ä¹ <em>connectivity masks</em>ï¼Œæ¥å†³å®šç½‘ç»œblockä¹‹é—´çš„è¿æ¥ã€‚</p><p>ç¬¬$j$ä¸ªblockçš„è¾“å…¥å¯ä»¥ç”±å‰é¢æ‰€æœ‰è¾“å‡ºç›¸åŠ è€Œæˆï¼Œç”¨äºŒå€¼çš„$m$è¡¨ç¤ºæ˜¯å¦è¿æ¥ï¼š<br>$$<br>\mathbf{x}_{j}=\sum_{k=1}^{j-1} m_{j, k} \cdot \mathbf{y}_{k}<br>$$<br>æœ¬æ–‡è¡¨ç¤ºæ¯ä¸ªblockåªå’Œ$K$ä¸ªè¿æ¥æ•ˆæœæœ€å¥½ï¼š<br>$$<br>m_{j, k} \in\{0,1\} \forall j, k, \quad and \quad \sum_{k=1}^{j-1} m_{j, k}=K \forall j<br>$$<br>ğŸ”º è®­ç»ƒè¿‡ç¨‹ï¼š</p><p><strong>Forward Propagation</strong>. é™åˆ¶å®å€¼çš„maskçš„å’Œä¸º1ï¼Œå³$\sum_{k=1}^{j-1} \tilde{m}_{j, k}=1$ï¼Œä»£è¡¨ä¸€ä¸ªå¤šé¡¹å¼åˆ†å¸ƒï¼Œä»ä¸­é‡‡æ ·Kä¸ªæ ·æœ¬$a_{1}, a_{2}, \ldots, a_{K} \in\{1, \ldots,(j-1)\}$ï¼Œæ¿€æ´»å¯¹åº”çš„mask $m_{j, a_{k}} \leftarrow 1$ã€‚</p><p><strong>Backward Propagation.</strong> ç¬¬$k$ä¸ªblockè¾“å‡ºçš„æ¢¯åº¦é€šè¿‡äºŒå€¼$m_{j,k}$å’Œ$x_j$çš„æ¢¯åº¦è·å¾—ã€‚</p><p><strong>Mask Update.</strong> é€šè¿‡clipå®å€¼maskï¼Œé™åˆ¶å®ƒä»¬åœ¨[0,1]çš„èŒƒå›´ã€‚</p><p>ğŸ”º è®­ç»ƒç»“æŸï¼š</p><p>ï¼ˆ1ï¼‰ä¸ºæ¯ä¸ª$m_j$æ¿€æ´»$\tilde{m}_{j}$ä¸­top-Kçš„è¿æ¥ï¼Œ</p><p>ï¼ˆ2ï¼‰å›ºå®šäºŒå€¼maskï¼Œftç½‘ç»œæƒé‡$\theta$</p><blockquote><p>ğŸ§ æœ¬æ–‡ç®—æ˜¯NASçš„åˆ†æ”¯å§ï¼Œæœç´¢çš„åªæ˜¯ç½‘ç»œå—ä¹‹é—´çš„è¿æ¥ã€‚æ¯ä¸ªblockæœ‰ä¸€ä¸ªå¤šé¡¹å¼åˆ†å¸ƒï¼Œä»£è¡¨å®ƒä¸ä¹‹å‰æ‰€æœ‰blockè¿æ¥çš„æ¦‚ç‡ï¼Œä»è¿™ä¸ªåˆ†å¸ƒä¸­é‡‡æ ·æ¿€æ´»çš„è¿æ¥ã€‚ç»“åˆæˆ‘æƒ³åšçš„ä¸œè¥¿ï¼Œ<strong>æ ¹æ®ä¸åŒçš„è¾“å…¥å›¾ç‰‡é€‰æ‹©ä¸åŒçš„block</strong>ï¼Œæ¯ä¸ªblockçš„è¾“å‡ºä¸ºä¸€ä¸ªnum_classesçš„åˆ†å¸ƒï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨æŸä¸ªç±»æ¿€æ´»è¿™ä¸ªblockæ¦‚ç‡ï¼Œåˆ©ç”¨è¿™ä¸ªæ¦‚ç‡è¿›è¡ŒäºŒé¡¹å¼åˆ†å¸ƒçš„é‡‡æ ·ã€‚</p></blockquote><h3 id="3ï¸âƒ£-MODEL-COMPRESSION-VIA-DISTILLATION-AND-QUANTIZATION"><a href="#3ï¸âƒ£-MODEL-COMPRESSION-VIA-DISTILLATION-AND-QUANTIZATION" class="headerlink" title="3ï¸âƒ£ MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION"></a>3ï¸âƒ£ MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION</h3><p>æœ¬æ–‡æå‡ºäº†ä¸¤ä¸ªå‹ç¼©æ–¹æ³•ï¼š1.<em> quantized distillation</em>ï¼šåˆ©ç”¨è’¸é¦è®­ç»ƒæƒé‡æ˜¯é‡åŒ–çš„å°ç½‘ç»œã€‚ 2. <em>differentiable quantization</em>ï¼šé€šè¿‡æ¢¯åº¦ä¸‹é™ä¼˜åŒ–é‡åŒ–ç‚¹çš„ä½ç½®ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1ï¸âƒ£-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATION&quot;&gt;&lt;a href=&quot;#1ï¸âƒ£-ON-THE-IMPORTANCE-OF-SINGLE-DIRECTIONS-FOR-GENERALIZATI
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Revisiting the Importance of Individual Units in CNNs via Ablation</title>
    <link href="http://yoursite.com/2019/05/12/Revisiting%20the%20Importance%20of%20Individual%20Units%20in%20CNNs%20via%20Ablation/"/>
    <id>http://yoursite.com/2019/05/12/Revisiting the Importance of Individual Units in CNNs via Ablation/</id>
    <published>2019-05-12T05:51:59.000Z</published>
    <updated>2019-05-19T09:48:53.400Z</updated>
    
    <content type="html"><![CDATA[<p>ä¹‹å‰çš„ä¸€äº›å·¥ä½œé€šè¿‡å¯è§†åŒ–æ¯ä¸ªç¥ç»å…ƒçš„æ–¹å¼æ¥ç†è§£ç¥ç»ç½‘ç»œï¼Œå®ƒä»¬é€‰æ‹©çš„æ˜¯<em>high selectivity</em>çš„ç¥ç»å…ƒï¼Œå‘ç°ç½‘ç»œæµ…å±‚è¯†åˆ«çš„æ˜¯å…·ä½“çš„å›¾æ¡ˆï¼ˆe.g çº¹ç†ã€å›¾åƒï¼‰ï¼Œç½‘ç»œæ·±å±‚è¯†åˆ«çš„æ˜¯è¯­ä¹‰ä¿¡æ¯ï¼ˆe.g ç‹—å¤´ã€è½¦è½®ï¼‰ï¼Œè®ºæ–‡[11]ä¼¼ä¹æ‰“è„¸äº†è¿™ç§æ–¹å¼ï¼Œè¡¨æ˜å¯¹äºä»£è¡¨æ•´ä½“åˆ†ç±»ç²¾åº¦ï¼Œ<em>class selectivity</em>å±æ€§ä¸èƒ½ç”¨æ¥é¢„æµ‹ç¥ç»å…ƒçš„é‡è¦æ€§ã€‚</p><p>æœ¬æ–‡è¡¨æ˜è¿™ä¸¤ç§æ–¹å¼éƒ½æ˜¯åˆç†çš„ã€‚ç”¨<em>class selectivity</em>æˆ–å…¶ä»–å±æ€§æ¥é¢„æµ‹ç¥ç»å…ƒçš„é‡è¦æ€§ä»æ•´ä½“åˆ†ç±»ç²¾åº¦ï¼ˆç½‘ç»œçš„æ³›åŒ–æ€§ï¼‰ä¸Šæ¥çœ‹ç¡®å®ä¸å¥½ï¼Œä½†æ˜¯èƒ½ä½œä¸ºå…·ä½“ç±»åˆ«çš„åˆ¤æ–­ä¾æ®ã€‚</p><p><strong>æŠ‘åˆ¶ç¥ç»å…ƒçš„æ–¹å¼</strong>ï¼šå°†å…¶weightå’Œbiasè®¾ç½®æˆ0ã€‚</p><p><strong>ä¸¤ç§ç²¾åº¦ä¸‹é™ç±»å‹ï¼š</strong>overall accuracy drop &amp; max class accuracy drop</p><p><strong>åˆ¤æ–­ç¥ç»å…ƒé‡è¦æ€§çš„å±æ€§ï¼š</strong></p><ul><li><p>L1 Normï¼š<br>$$<br>\operatorname{norm}_{1}(i)=\left|w_{i}\right|_{1}=\sum_{j}\left|\left(w_{i}\right)_{j}\right|<br>$$</p></li><li><p>Class Correlationï¼š<br>$$<br>\operatorname{corr}(i, k)=\frac{E\left[\left(x_{i}-\overline{x}_{i}\right)\left(p_{k}-\overline{p}_{k}\right)\right]}{\sigma_{x_{i}} \sigma_{p_{k}}}<br>$$</p></li><li><p>Class Selectivityï¼š</p></li></ul><p>$$<br>\operatorname{select}(i, k)=\frac{\overline{x}_{i}^{k}-\overline{x}_{i}^{-k}}{\overline{x}_{i}^{k}+\overline{x}_{i}^{-k}}<br>$$</p><p>â€‹        å…¶ä¸­$\overline{x}_{i}^{k}$è¡¨ç¤ºç¥ç»å…ƒ$i$å±äºkthç±»åˆ«çš„å¹³å‡æ¿€æ´»å€¼ï¼Œ$\overline{x}_{i}^{-k}$è¡¨ç¤ºç¥ç»å…ƒ$i$å±äºnon-kthç±»åˆ«çš„å¹³å‡æ¿€æ´»å€¼çš„å‡å€¼ã€‚è¿™ä¸ªå€¼çš„èŒƒå›´æ˜¯[0, 1]ï¼Œ0è¡¨ç¤ºä¸€ä¸ªç¥ç»å…ƒçš„å¹³å‡æ¿€æ´»å€¼ä¸å…¶ä»–ç±»åˆ«éƒ½ç›¸åŒï¼Œ1è¡¨ç¤ºä¸€ä¸ªç¥ç»å…ƒåªå¯¹æŸä¸ªç±»åˆ«çš„è¾“å…¥æœ‰ååº”ã€‚</p><ul><li>Concept Alighmentï¼šIoU between unit activation and gt concepts</li><li>Unit Visualization</li></ul><p>ğŸ”º <strong>å®éªŒä¸€ï¼š</strong>éªŒè¯æŠ‘åˆ¶å•ä¸ªç¥ç»å…ƒ/ä¸€ç»„ç¥ç»å…ƒå¯¹ä¸¤ç§ç²¾åº¦ä¸‹é™ç±»å‹çš„å½±å“ã€‚</p><ul><li>å®éªŒæ–¹å¼ï¼š<ul><li>æŠ‘åˆ¶æŸä¸ªç¥ç»å…ƒï¼Œæ¨ªè½´è¡¨ç¤ºCLassï¼Œçºµè½´è¡¨ç¤ºClass Accuracy Dropã€‚</li><li>é’ˆå¯¹ç‰¹å®šçš„ç½‘ç»œå±‚ï¼Œæ ¹æ®Mac Class Accuracy Dropè¿›è¡Œæ’åºï¼Œç»˜åˆ¶ä¸‰æ¡æ›²çº¿ï¼ˆOveral Accuracy Drop / Max Class Accuracy Drop / Min Class Accuracy Dropï¼‰ã€‚</li><li>åˆ©ç”¨greedyçš„æ–¹å¼è¿­ä»£åœ°ç§»é™¤é™ä½ç‰¹å®šç±»å‡†ç¡®ç‡æœ€å¤šçš„ç¥ç»å…ƒã€‚ç»˜åˆ¶äº†ç‰¹å®šç±»åˆ«ç²¾åº¦ä¸‹é™çš„æ›²çº¿ï¼Œå’Œæ‰€æœ‰ç±»åˆ«å¹³å‡ç²¾åº¦ä¸‹é™çš„æ›²çº¿ã€‚åŒæ—¶ç”¨randomä½œä¸ºbaselineã€‚</li></ul></li><li>ç»“è®ºï¼š<ul><li>æŠ‘åˆ¶å•ä¸ªç¥ç»å…ƒå¯¹æŸäº›ç±»åˆ«çš„åˆ†ç±»ç²¾åº¦å½±å“å¾ˆå¤§ï¼Œä½†å¯¹æ€»ä½“çš„ç²¾åº¦å½±å“ä¸å¤§ï¼Œå¹¶ä¸”èƒ½é€šè¿‡å¯è§†åŒ–çš„å½¢å¼çœ‹å‡ºè¿™äº›æŠ‘åˆ¶çš„ç¥ç»å…ƒç¡®å®å±•ç°å‡ºäº†ç›¸åº”ç±»åˆ«çš„ç‰¹ç‚¹ã€‚</li><li>greedyåœ°æŠ‘åˆ¶ä¸€ç»„ç¥ç»å…ƒï¼Œèƒ½ä½¿è¿™ä¸ªç±»åˆ«çš„ç²¾åº¦å¤§å¤§é™ä½ï¼Œä½†æ˜¯randomçš„æ–¹å¼å½±å“ä¸å¤§ã€‚</li></ul></li></ul><p>ğŸ”º <strong>å®éªŒäºŒï¼š</strong>éªŒè¯ä¸åŒå±æ€§ä¸ç²¾åº¦ä¸‹é™ä¹‹é—´çš„å…³ç³»ã€‚</p><ul><li>å®éªŒæ–¹å¼ï¼š<ul><li>ç”¨æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•°å’ŒPå€¼ç»Ÿè®¡äº†ä¸åŒå±æ€§å€¼ä¸ç²¾åº¦ä¸‹é™ä¹‹é—´çš„ç›¸å…³æ€§ã€‚</li><li>ç”¨ä¸åŒå±æ€§åˆ¤æ–­å‡ºçš„æœ€é‡è¦çš„é‚£ä¸ªç¥ç»å…ƒæ¥é¢„æµ‹åˆ†ç±»</li></ul></li><li>ç»“è®ºï¼š<ul><li>å¯¹äºæ•´ä½“ç²¾åº¦ä¸‹é™ï¼šclass selectivityï¼Œclass correlationå’Œconcept alighmentè¡¨ç¤ºå‡ºæ­£ç›¸å…³ï¼ŒL1æ˜¯è´Ÿç›¸å…³ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“æŠ‘åˆ¶class selectivityå€¼å¾ˆå¤§çš„ç¥ç»å…ƒï¼Œå¯¹æ•´ä½“ç½‘ç»œçš„ç²¾åº¦ä¸‹é™å½±å“è¾ƒå°ï¼Œä¸è®ºæ–‡[11]ä¸­ç»“è®ºä¸€è‡´ã€‚</li><li>å¯¹äºæœ€å¤§ç±»åˆ«ç²¾åº¦ä¸‹é™ï¼šæ¯ä¸ªå±æ€§åŸºæœ¬éƒ½è¡¨ç°å‡ºè´Ÿç›¸å…³ã€‚è¯´æ˜æŠ‘åˆ¶è¿™äº›å±æ€§å€¼å¤§çš„ç¥ç»å…ƒï¼Œå¯¹ç‰¹å®šç±»åˆ«ç²¾åº¦å½±å“å¾ˆå¤§ã€‚</li><li>Concept Alignmentä¼¼ä¹æœ€èƒ½ä»£è¡¨ç¥ç»å…ƒçš„é‡è¦æ€§</li></ul></li></ul><p>ğŸ”º <strong>å®éªŒä¸‰ï¼š</strong>éªŒè¯é€‰æ‹©çš„ç¥ç»å…ƒä¸å…¶æ–¹å‘ç›¸å…³ï¼Œè€Œä¸æ˜¯éšæœºæ–¹å‘ã€‚</p><p>ğŸ”º <strong>å®éªŒå››ï¼š</strong>éªŒè¯BNå’ŒDropoutçš„å½±å“ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ä¹‹å‰çš„ä¸€äº›å·¥ä½œé€šè¿‡å¯è§†åŒ–æ¯ä¸ªç¥ç»å…ƒçš„æ–¹å¼æ¥ç†è§£ç¥ç»ç½‘ç»œï¼Œå®ƒä»¬é€‰æ‹©çš„æ˜¯&lt;em&gt;high selectivity&lt;/em&gt;çš„ç¥ç»å…ƒï¼Œå‘ç°ç½‘ç»œæµ…å±‚è¯†åˆ«çš„æ˜¯å…·ä½“çš„å›¾æ¡ˆï¼ˆe.g çº¹ç†ã€å›¾åƒï¼‰ï¼Œç½‘ç»œæ·±å±‚è¯†åˆ«çš„æ˜¯è¯­ä¹‰ä¿¡æ¯ï¼ˆe.g ç‹—å¤´ã€è½¦è½®ï¼‰ï¼Œè®ºæ–‡[11]ä¼¼ä¹æ‰“è„¸äº†è¿™ç§æ–¹å¼ï¼Œè¡¨æ˜å¯¹äºä»£è¡¨
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨è®ºæ–‡ Vol.01</title>
    <link href="http://yoursite.com/2019/05/11/weekly-paper-01/"/>
    <id>http://yoursite.com/2019/05/11/weekly-paper-01/</id>
    <published>2019-05-10T23:57:11.000Z</published>
    <updated>2019-05-12T09:01:21.046Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-SNIP-SINGLE-SHOT-NETWORK-PRUNING-BASED-ON-CONNECTION-SENSITIVITY-ICLR2019"><a href="#1ï¸âƒ£-SNIP-SINGLE-SHOT-NETWORK-PRUNING-BASED-ON-CONNECTION-SENSITIVITY-ICLR2019" class="headerlink" title="1ï¸âƒ£ SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY (ICLR2019)"></a>1ï¸âƒ£ SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY (ICLR2019)</h3><p>åŸºäºåº¦é‡çš„ä¸€ç§å‰ªææ–¹æ³•ã€‚åº¦é‡çš„æ˜¯æƒé‡ä¹‹é—´çš„è¿æ¥æ•æ„Ÿåº¦ã€‚ä¼˜ç‚¹åœ¨äºä¸éœ€è¦layer-by-layerçš„è®­ç»ƒè¿‡ç¨‹ã€‚</p><p>ç æ‰æŸä¸ªè¿æ¥$j$å¯¹lossçš„å½±å“ï¼š<br>$$<br>\Delta L_{j}(\mathbf{w} ; \mathcal{D})=L(\mathbf{1} \odot \mathbf{w} ; \mathcal{D})-L\left(\left(\mathbf{1}-\mathbf{e}_{j}\right) \odot \mathbf{w} ; \mathcal{D}\right)<br>$$<br>ä½†æ˜¯ä¸Šå¼ä¸å¯å¯¼ï¼Œä½œè€…ç”¨$g_j$æ¥ä»£è¡¨è¯„ä¼°æŒ‡æ ‡ï¼Œå°†ç¦»æ•£çš„$e_j$æ¾å¼›ä¸ºè¿ç»­å€¼$\delta e_j$ï¼š<br>$$<br>\Delta L_{j}(\mathbf{w} ; \mathcal{D}) \approx g_{j}(\mathbf{w} ; \mathcal{D})=\left.\frac{\partial L(\mathbf{c} \odot \mathbf{w} ; \mathcal{D})}{\partial c_{j}}\right|_{\mathbf{c}=1}=\lim _{\delta \rightarrow 0}\left.\frac{L(\mathbf{c} \odot \mathbf{w} ; \mathcal{D})-L\left(\left(\mathbf{c}-\delta \mathbf{e}_{j}\right) \odot \mathbf{w} ; \mathcal{D}\right)}{\delta}\right|_{\mathbf{c}=1}<br>$$<br>å®šä¹‰äº†è¿æ¥æ•æ„Ÿåº¦ï¼š<br>$$<br>s_{j}=\frac{\left|g_{j}(\mathbf{w} ; \mathcal{D})\right|}{\sum_{k=1}^{m}\left|g_{k}(\mathbf{w} ; \mathcal{D})\right|}<br>$$<br>ç®—æ³•è¿‡ç¨‹ï¼š</p><p><img src="https://i.loli.net/2019/05/09/5cd3a33306172.png" alt=""></p><blockquote><p>è¿æ¥æ•æ„Ÿåº¦çš„è®¡ç®—æ–¹å¼ç®€å•ï¼Œå°±åƒæ˜¯åœ¨æƒé‡ä¸ŠåŠ äº†ä¸€äº›å™ªéŸ³ï¼Œçœ‹ä¸€ä¸‹å®ƒå¯¹lossçš„å½±å“ã€‚ä½†æ˜¯å®ƒçš„ç®—æ³•è¿‡ç¨‹æ˜¯å¯¹éšæœºåˆå§‹åŒ–çš„ç½‘ç»œæƒé‡è¿›è¡Œå‰ªæï¼Œå†è®­ç»ƒqã€‚è¿™æ ·çš„å‰ªææ˜¯å¦æœ‰æ„ä¹‰ï¼Ÿ</p></blockquote><h3 id="2ï¸âƒ£-Numerical-Coordinate-Regression-with-Convolutional-Neural-Networks"><a href="#2ï¸âƒ£-Numerical-Coordinate-Regression-with-Convolutional-Neural-Networks" class="headerlink" title="2ï¸âƒ£ Numerical Coordinate Regression with Convolutional Neural Networks"></a>2ï¸âƒ£ Numerical Coordinate Regression with Convolutional Neural Networks</h3><p>ğŸ“<a href="https://github.com/anibali/dsntnn" target="_blank" rel="external">https://github.com/anibali/dsntnn</a></p><p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç©ºé—´å¯å¾®çš„æ•°å€¼è½¬æ¢æ“ä½œ(DSNT)æ¥æ‰¾åˆ°è¾“å…¥å›¾åƒçš„æ˜¾è‘—ç‚¹åæ ‡ã€‚</p><p>ä¼ ç»Ÿæ–¹æ³•æœ‰<strong>Heatmap matching</strong>å’Œ<strong>Fully connected</strong>ï¼Œä»£è¡¨æ€§çš„è¿ç”¨æ˜¯<em>Human pose estimation</em>å’Œ<em>STN</em>ã€‚å‰è€…ä¸å®Œå…¨å¯å¾®ï¼Œåè€…ç¼ºä¹ç©ºé—´æ³›åŒ–èƒ½åŠ›ã€‚</p><p><img src="https://i.loli.net/2019/05/07/5cd10b71062f2.png" alt=""></p><p>DSNTçš„è¾“å…¥æ˜¯ä¸€ä¸ªå•é€šé“å½’ä¸€åŒ–çš„å¤§å°ä¸º$m \times n$ çš„ heatmap $\hat{Z}$ï¼Œä»£è¡¨äº†æ¦‚ç‡åˆ†å¸ƒã€‚è¾“å‡ºæ˜¯æ˜¾è‘—ç‚¹çš„åæ ‡ï¼Œå³æ¦‚ç‡åˆ†å¸ƒæœ€å¤§ç‚¹çš„é‚£ä¸ªåæ ‡å€¼ã€‚ç”¨ä¸¤ä¸ªç›¸åŒå¤§å°çš„çŸ©é˜µ$X$å’Œ$Y$åˆ†åˆ«ä»£è¡¨$x-$å’Œ$y-$åæ ‡ï¼Œè®©åæ ‡åˆ†å¸ƒå˜ä¸ºå·¦ä¸Šè§’æ˜¯(-1, -1)ï¼Œå³ä¸‹è§’æ˜¯(1,1)ã€‚</p><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡åæ ‡$c$è®¡ç®—å‡ºè¿™ä¸ªæ¦‚ç‡å‡½æ•°ï¼š<br>$$<br>\operatorname{Pr}\left(\mathbf{c}=\left[ \begin{array}{ll}{X_{i, j}} &amp; {Y_{i, j}}\end{array}\right]\right)=\hat{Z}_{i, j}<br>$$<br>ä¼ ç»Ÿæ–¹æ³•åˆ©ç”¨çš„æ˜¯$c$çš„æ¨¡ï¼ŒDSNTåˆ©ç”¨çš„æ˜¯$c$çš„æœŸæœ›$\boldsymbol{\mu}=\mathbb{E}[\mathbf{c}]$ï¼Œå¯ä»¥ç”¨å¦‚ä¸‹å…¬å¼è¡¨ç¤ºï¼š<br>$$<br>\operatorname{DSNT}(\hat{Z})=\boldsymbol{\mu}=\left[\langle\hat{Z}, \boldsymbol{X}\rangle_{F}<br>\quad\langle\hat{\boldsymbol{Z}}, \boldsymbol{Y}\rangle_{F}\right]<br>$$</p><blockquote><p>The â€œmodeâ€ is the value that occurs most often. The â€œmeanâ€ is the â€œaverageâ€ youâ€™re used to, where you add up all the numbers and then divide by the number of numbers.</p></blockquote><p>ä¸€ä¸ªç›´è§‚çš„ä¾‹å­ï¼š</p><p><img src="https://i.loli.net/2019/05/07/5cd1422432340.png" alt=""></p><p>DSNTçš„æŸå¤±å‡½æ•°ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼š<br>$$<br>\mathcal{L}(\hat{Z}, \boldsymbol{p})=\mathcal{L}_{e u c}(\operatorname{DSNT}(\hat{Z}), \boldsymbol{p})+\lambda \mathcal{L}_{r e g}(\hat{Z})<br>$$<br>ç¬¬ä¸€éƒ¨åˆ†ç›´æ¥è®¡ç®—é¢„æµ‹åæ ‡å’Œgtçš„æ¬§å¼è·ç¦»ï¼š<br>$$<br>\mathcal{L}_{e u c}(\boldsymbol{\mu}, \boldsymbol{p})=|\boldsymbol{p}-\boldsymbol{\mu}|_{2}<br>$$<br>ç¬¬äºŒéƒ¨åˆ†æ˜¯æ­£åˆ™é¡¹ï¼Œæ–‡ç« å¯¹æ¯”äº†ä¸¤ç§æ­£åˆ™æ–¹æ³•ï¼š</p><ol><li><p>æ–¹å·®æ­£åˆ™ï¼š<br>$$<br>\begin{aligned} \operatorname{Var}\left[\mathrm{c}_{x}\right] &amp;=\mathbb{E}\left[\left(\mathrm{c}_{x}-\mathbb{E}\left[\mathrm{c}_{x}\right]\right)^{2}\right] \\ &amp;=\left\langle\hat{Z},\left(\boldsymbol{X}-\mu_{x}\right) \odot\left(\boldsymbol{X}-\mu_{x}\right)\right\rangle_{F} \end{aligned}<br>$$</p><p>$$<br>\mathcal{L}_{v a r}(\hat{Z})=\left(\operatorname{Var}\left[c_{x}\right]-\sigma_{t}^{2}\right)^{2}+\left(\operatorname{Var}\left[\mathrm{c}_{y}\right]-\sigma_{t}^{2}\right)^{2}<br>$$</p></li><li><p>åˆ†å¸ƒæ­£åˆ™ï¼ˆKLæ•£åº¦/JSæ•£åº¦ï¼‰ï¼š<br>$$<br>\mathcal{L}_{D}(\hat{Z}, \boldsymbol{p})=D\left(p(\mathbf{c}) | \mathcal{N}\left(\boldsymbol{p}, \sigma_{t}^{2} \boldsymbol{I}_{2}\right)\right)<br>$$</p></li></ol><h3 id="3ï¸âƒ£-Searching-for-MobileNetV3"><a href="#3ï¸âƒ£-Searching-for-MobileNetV3" class="headerlink" title="3ï¸âƒ£ Searching for MobileNetV3"></a>3ï¸âƒ£ Searching for MobileNetV3</h3><ul><li><p>ç”¨æœç´¢çš„æ–¹å¼æœç´¢ç½‘ç»œç»“æ„</p><ul><li>Block-wiseï¼šç”¨MnasNet-A1ä½œä¸ºåˆå§‹å¤§ç½‘ç»œï¼Œä¿®æ”¹äº†åé¦ˆ$A C C(m) \times[L A T(m) / T A R]^{w}$</li><li>Layer-wiseï¼šNetAdaptçš„å‰ªææ–¹å¼ï¼Œä¿®æ”¹äº†è¯„ä¼°æŒ‡æ ‡$\frac{\Delta \mathrm{Acc}}{|\Delta \mathrm{latency}|}$</li></ul></li><li><p>åŠ å…¥äº†SEblockï¼Œé‡æ–°è®¾è®¡äº†ç½‘ç»œçš„è¾“å‡ºå±‚</p><p><img src="https://i.loli.net/2019/05/09/5cd39f284e1fb.png" alt=""></p><p><img src="https://i.loli.net/2019/05/09/5cd39f84c5807.png" alt=""></p></li><li><p>åŸºäºswishæå‡ºäº†h-swishæ›¿ä»£ReLU<br>$$<br>\mathrm{h}-\operatorname{swish}[x]=x \frac{\operatorname{Re} \mathrm{LU} 6(x+3)}{6}<br>$$</p></li><li><p>åœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸ŠåŸºäºR-ASPPï¼Œæå‡ºäº†LR-ASSPã€‚</p><p><img src="https://i.loli.net/2019/05/09/5cd3a1b27ccf1.png" alt=""></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1ï¸âƒ£-SNIP-SINGLE-SHOT-NETWORK-PRUNING-BASED-ON-CONNECTION-SENSITIVITY-ICLR2019&quot;&gt;&lt;a href=&quot;#1ï¸âƒ£-SNIP-SINGLE-SHOT-NETWORK-PRUNING-BASED-
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="æ¯å‘¨è®ºæ–‡" scheme="http://yoursite.com/tags/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>namesiloåŸŸåè´­ä¹° &amp; github pagesåŸŸåè®¾ç½®</title>
    <link href="http://yoursite.com/2019/05/10/set-blog-domain/"/>
    <id>http://yoursite.com/2019/05/10/set-blog-domain/</id>
    <published>2019-05-10T15:42:05.000Z</published>
    <updated>2019-05-12T10:56:08.729Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-åŸŸåè´­ä¹°å’Œè®¾ç½®"><a href="#1-åŸŸåè´­ä¹°å’Œè®¾ç½®" class="headerlink" title="1. åŸŸåè´­ä¹°å’Œè®¾ç½®"></a>1. åŸŸåè´­ä¹°å’Œè®¾ç½®</h3><p>é¦–å…ˆåœ¨<a href="http://xn--eqrt2g.xn--vuq861b/#" target="_blank" rel="external">å·¥ä¿¡éƒ¨å…¬ç¤º</a>æŸ¥çœ‹å¯å¤‡æ¡ˆçš„ç½‘ç«™åç¼€ï¼Œåœ¨<a href="https://www.namesilo.com/" target="_blank" rel="external">namesilo</a>ä¸Šè´­ä¹°å–œæ¬¢çš„åŸŸåï¼Œå¯ä»¥ä½¿ç”¨æ”¯ä»˜å®ä»˜æ¬¾ã€‚</p><ul><li>è¿›å…¥ã€ŒåŸŸåç®¡ç†ã€ï¼Œç‚¹å‡»åˆšç”³è¯·åˆ°çš„åŸŸå</li></ul><p><img src="https://i.loli.net/2019/05/11/5cd613b55c18e.png" alt=""></p><ul><li>æ›´æ–°ã€ŒDNSè®°å½•ã€</li></ul><p><img src="https://i.loli.net/2019/05/11/5cd612451ffa6.png" alt=""></p><p>åœ¨å…¶ä¸­æ·»åŠ ä»¥ä¸‹ä¸‰æ¡è®°å½•ï¼š</p><p><img src="https://i.loli.net/2019/05/11/5cd612ba05f60.png" alt=""></p><blockquote><p>Aè®°å½•ç±»å‹åœ¨<a href="https://help.github.com/en/articles/troubleshooting-custom-domains#dns-configuration-errors" target="_blank" rel="external">è¿™é‡Œ</a>æŸ¥çœ‹Githubçš„åœ°å€ï¼Œæœ€åä¸€è¡ŒCNAMEæ˜¯è‡ªå·±çš„<code>usernmae.github.io</code>ï¼Œå®é™…ä¸ŠAè®°å½•å’ŒCNAMEæŒ‡å‘çš„æ˜¯ç›¸åŒçš„IPåœ°å€ï¼Œè®¾ç½®ä¸€é¡¹å³å¯ã€‚</p></blockquote><h3 id="2-ä¿®æ”¹åŸŸåDNSæœåŠ¡å™¨"><a href="#2-ä¿®æ”¹åŸŸåDNSæœåŠ¡å™¨" class="headerlink" title="2. ä¿®æ”¹åŸŸåDNSæœåŠ¡å™¨"></a>2. ä¿®æ”¹åŸŸåDNSæœåŠ¡å™¨</h3><ul><li>åœ¨namesiloä¸Šå°†åŸŸåæœåŠ¡å•†ä¿®æ”¹ä¸º<a href="https://www.dnspod.cn/console/dns" target="_blank" rel="external">DNSpod</a></li></ul><p><img src="https://i.loli.net/2019/05/11/5cd6152a1859a.png" alt=""></p><blockquote><p>DNSpodæä¾›äº†ä¸¤ä¸ªå…è´¹çš„DNSåœ°å€ï¼šf1g1ns1.dnspod.net / f1g1ns2.dnspod.net</p></blockquote><ul><li>ç™»é™†DNSpodï¼Œæ·»åŠ åŸŸåå’Œè®°å½•</li></ul><p><img src="https://i.loli.net/2019/05/11/5cd6160b109d2.png" alt=""></p><p><img src="/Users/colorjam/Library/Application Support/typora-user-images/image-20190511082546709.png" alt="image-20190511082546709"></p><h3 id="3-æ›´æ–°Githubä¸Šçš„è‡ªå®šä¹‰åŸŸå"><a href="#3-æ›´æ–°Githubä¸Šçš„è‡ªå®šä¹‰åŸŸå" class="headerlink" title="3. æ›´æ–°Githubä¸Šçš„è‡ªå®šä¹‰åŸŸå"></a>3. æ›´æ–°Githubä¸Šçš„è‡ªå®šä¹‰åŸŸå</h3><p>è¿›å…¥æœ¬åœ°å­˜å‚¨åšå®¢çš„æ–‡ä»¶å¤¹</p><p><img src="https://i.loli.net/2019/05/11/5cd6186e83770.png" alt=""></p><p>åˆ›å»ºä¸€ä¸ªæ²¡æœ‰åç¼€çš„<code>CNAME</code>æ–‡ä»¶ï¼Œè¾“å…¥è´­ä¹°çš„åŸŸåã€‚</p><p><img src="https://i.loli.net/2019/05/11/5cd6190c11dab.png" alt=""></p><p>éƒ¨ç½²åˆ°githubä¸Šï¼Œå°±å¯ä»¥åˆ©ç”¨è‡ªå®šä¹‰çš„åŸŸåè®¿é—®åšå®¢å•¦ï½</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy</div></pre></td></tr></table></figure><p><strong>å‚è€ƒé“¾æ¥ï¼š</strong></p><ul><li><a href="http://cps.ninja/2016/10/09/customize-your-blog-domain/" target="_blank" rel="external">http://cps.ninja/2016/10/09/customize-your-blog-domain/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-åŸŸåè´­ä¹°å’Œè®¾ç½®&quot;&gt;&lt;a href=&quot;#1-åŸŸåè´­ä¹°å’Œè®¾ç½®&quot; class=&quot;headerlink&quot; title=&quot;1. åŸŸåè´­ä¹°å’Œè®¾ç½®&quot;&gt;&lt;/a&gt;1. åŸŸåè´­ä¹°å’Œè®¾ç½®&lt;/h3&gt;&lt;p&gt;é¦–å…ˆåœ¨&lt;a href=&quot;http://xn--eqrt2g.xn--vuq861
      
    
    </summary>
    
    
      <category term="æŒ‡å—" scheme="http://yoursite.com/tags/%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>æ²¿ç€æŸä¸ªç»´åº¦è¿›è¡Œæ“ä½œ</title>
    <link href="http://yoursite.com/2019/05/10/along-axis/"/>
    <id>http://yoursite.com/2019/05/10/along-axis/</id>
    <published>2019-05-10T04:40:24.000Z</published>
    <updated>2019-05-10T04:57:27.083Z</updated>
    
    <content type="html"><![CDATA[<p>ä¸€ç›´å¯¹æ²¿ç€axisè¿›è¡Œæ“ä½œä¸å¤ªç†è§£ï¼Œä»Šå¤©å†³å®šè¿˜æ˜¯è¦ææ˜ç™½ã€‚</p><p>æ¯”å¦‚<code>np.sum(a, aixs=1)</code>ï¼Œä»£è¡¨æ²¿ç€1ç»´æ“ä½œã€‚è¿™ä¸ªæ²¿ç€æŒ‡çš„æ˜¯ä¸‹æ ‡å˜åŒ–çš„æ–¹å‘ï¼Œå…¶ä»–ç»´åº¦ä¸åŠ¨<code>a[0][0],a[0][1], a[0][2]â€‹</code>ã€‚<br><img src="https://pic3.zhimg.com/80/v2-7a0716230a6f3d4840a6098001b1d2a2_hd.jpg" alt="img"></p><p>äºæ˜¯å°†çº¢è‰²æ¡†çš„å…ƒç´ ç›¸åŠ å¾—åˆ°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[<span class="number">6</span>],</div><div class="line">[<span class="number">9</span>],</div><div class="line">[<span class="number">16</span>]</div></pre></td></tr></table></figure><p>å¦‚æœæ˜¯<code>np.sum(a, axis=0)</code>ï¼Œå³<code>a[0][0],a[1][0], a[2][0]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="number">6</span>],[<span class="number">9</span>],[<span class="number">16</span>]</div></pre></td></tr></table></figure><p>å‚è€ƒé“¾æ¥ï¼š</p><p><a href="https://zhuanlan.zhihu.com/p/31275071" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/31275071</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ä¸€ç›´å¯¹æ²¿ç€axisè¿›è¡Œæ“ä½œä¸å¤ªç†è§£ï¼Œä»Šå¤©å†³å®šè¿˜æ˜¯è¦ææ˜ç™½ã€‚&lt;/p&gt;
&lt;p&gt;æ¯”å¦‚&lt;code&gt;np.sum(a, aixs=1)&lt;/code&gt;ï¼Œä»£è¡¨æ²¿ç€1ç»´æ“ä½œã€‚è¿™ä¸ªæ²¿ç€æŒ‡çš„æ˜¯ä¸‹æ ‡å˜åŒ–çš„æ–¹å‘ï¼Œå…¶ä»–ç»´åº¦ä¸åŠ¨&lt;code&gt;a[0][0],a[0][1], a[0][2]â€‹&lt;/code
      
    
    </summary>
    
    
      <category term="çŸ¥è¯†å£è¢‹" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%8F%A3%E8%A2%8B/"/>
    
  </entry>
  
  <entry>
    <title>Linuxå‘½ä»¤ - æ˜¾ç¤ºæ–‡ä»¶æŒ‡å®šè¡Œ</title>
    <link href="http://yoursite.com/2019/05/05/linux-cat/"/>
    <id>http://yoursite.com/2019/05/05/linux-cat/</id>
    <published>2019-05-05T01:42:07.000Z</published>
    <updated>2019-05-12T05:29:04.159Z</updated>
    
    <content type="html"><![CDATA[<h3 id="cat"><a href="#cat" class="headerlink" title="cat"></a>cat</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">head -n [è¡Œæ•°a] # æ˜¾ç¤ºå¼€å§‹aè¡Œ</div><div class="line">tail -n [è¡Œæ•°a] # æ˜¾ç¤ºæœ€åaè¡Œ</div><div class="line">tail -n +[è¡Œæ•°a] # ä»aè¡Œä»¥åå¼€å§‹æ˜¾ç¤º</div></pre></td></tr></table></figure><p>å•ç‹¬ä½¿ç”¨ <code>tail</code> å’Œ <code>head</code> æ¯”è¾ƒç®€å•ï¼Œç»„åˆä½¿ç”¨æ—¶å®ƒä»¬çš„é¡ºåºæ˜¯æœ‰è®²ç©¶çš„ã€‚</p><p>ä»200è¡Œå¼€å§‹æ˜¾ç¤º10è¡Œï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat [filename] | tail -n +200 | head -n 10</div></pre></td></tr></table></figure><p>ç­‰åŒäºæ˜¾ç¤º200è¡Œåˆ°210è¡Œï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat [filename] | head -n 210 | tail -n +200</div></pre></td></tr></table></figure><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><p>è¿˜æœ‰ä¸€ç§ä½¿ç”¨<code>sed</code>å‘½ä»¤çš„æ–¹å¼ï¼Œä»200è¡Œå¼€å§‹ç°å®10è¡Œï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sed -n <span class="string">'200, 210p'</span> [filename]</div></pre></td></tr></table></figure><p>å‚è€ƒé“¾æ¥ï¼š</p><ul><li><a href="https://blog.csdn.net/vitaminc4/article/details/78136696" target="_blank" rel="external">https://blog.csdn.net/vitaminc4/article/details/78136696</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;cat&quot;&gt;&lt;a href=&quot;#cat&quot; class=&quot;headerlink&quot; title=&quot;cat&quot;&gt;&lt;/a&gt;cat&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;d
      
    
    </summary>
    
    
      <category term="çŸ¥è¯†å£è¢‹" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%8F%A3%E8%A2%8B/"/>
    
  </entry>
  
  <entry>
    <title>å‹ç¼©ç½‘ç»œæ¨¡å‹ä¹‹ç»“æ„æ¢ç´¢åˆè¾‘</title>
    <link href="http://yoursite.com/2018/08/06/adversiarial-compression/"/>
    <id>http://yoursite.com/2018/08/06/adversiarial-compression/</id>
    <published>2018-08-06T02:13:32.000Z</published>
    <updated>2018-08-17T07:36:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="å¯¹æŠ—ç½‘ç»œå‹ç¼©"><a href="#å¯¹æŠ—ç½‘ç»œå‹ç¼©" class="headerlink" title="å¯¹æŠ—ç½‘ç»œå‹ç¼©"></a>å¯¹æŠ—ç½‘ç»œå‹ç¼©</h2><p><img src="https://ws3.sinaimg.cn/large/0069RVTdly1ftzrfwrb0vj314e0fwq4u.jpg" alt="network_architecture"></p><p>å¯¹æŠ—ç½‘ç»œå‹ç¼©è¿‡ç¨‹æ˜¯åœ¨è€å¸ˆå’Œå­¦ç”Ÿä¹‹é—´è¿›è¡Œåšå¼ˆï¼Œåˆ¤åˆ«å™¨çš„ä»»åŠ¡æ˜¯åˆ¤åˆ«è¾“å…¥æ ·æœ¬æ˜¯æ¥è‡ªè€å¸ˆorå­¦ç”Ÿã€‚è€å¸ˆç½‘ç»œäº‹å…ˆç”¨æ ‡ç­¾è®­ç»ƒå®Œæˆï¼Œåœ¨å¯¹æŠ—å‹ç¼©çš„è¿‡ç¨‹ä¸­ä¸æ›´æ–°ã€‚</p><h3 id="è®­ç»ƒè¿‡ç¨‹ï¼š"><a href="#è®­ç»ƒè¿‡ç¨‹ï¼š" class="headerlink" title="è®­ç»ƒè¿‡ç¨‹ï¼š"></a>è®­ç»ƒè¿‡ç¨‹ï¼š</h3><ol><li>Dæ¥å—ä¸¤ä¸ªç½‘ç»œæœ€åä¸€å±‚çš„ç‰¹å¾å›¾$f^k_{t}(x)$å’Œ$f^l_s(x)$ä½œä¸ºè¾“å…¥ï¼Œåˆ©ç”¨äº¤å‰ç†µè¿›è¡Œreal/fakeåˆ¤åˆ«ï¼ˆè“è‰²çº¿ï¼‰</li><li>åˆ©ç”¨å­¦ç”Ÿå’Œè€å¸ˆçš„logitsè®¡ç®—L2æŸå¤±ï¼Œå¼•å¯¼å­¦ç”Ÿæ¨¡ä»¿è€å¸ˆï¼Œäº§ç”Ÿè¾“å‡ºï¼ˆç»¿è‰²çº¿ï¼‰</li><li>Dæ¥å—å­¦ç”Ÿç½‘ç»œdropoutåçš„ç‰¹å¾ä½œä¸ºè¾“å…¥ï¼ˆçº¢è‰²çº¿ï¼‰ï¼Œæ¬ºéª—Då°†å…¶åˆ¤åˆ«ä¸ºrealã€‚</li></ol><h3 id="ç›®æ ‡å‡½æ•°ï¼š"><a href="#ç›®æ ‡å‡½æ•°ï¼š" class="headerlink" title="ç›®æ ‡å‡½æ•°ï¼š"></a>ç›®æ ‡å‡½æ•°ï¼š</h3><p>å€Ÿé‰´cGANçš„æ€æƒ³ï¼Œå®šä¹‰å¯¹æŠ—å‹ç¼©çš„æŸå¤±å‡½æ•°ä¸ºï¼š</p><p><img src="https://ws3.sinaimg.cn/large/0069RVTdly1ftzrynfkouj316e04cdgr.jpg" alt=""></p><p>ç”±äºåˆ©ç”¨çš„æ˜¯ç‰¹å¾å›¾ä½œä¸ºDçš„è¾“å…¥ï¼Œå­¦ç”Ÿç½‘ç»œä¸­è¿˜æœ‰è®¸å¤šå‚æ•°éœ€è¦æ›´æ–°ï¼Œå› æ­¤éœ€è¦åŠ å…¥ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œå‡å°‘è€å¸ˆç½‘ç»œå’Œå­¦ç”Ÿç½‘ç»œè¾“å‡ºæ•°æ®çš„å·®å¼‚ï¼š</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftzs7ncxe2j315o03c0t5.jpg" alt=""></p><p>æœ€åå†åŠ ä¸Šæ­£åˆ™é¡¹ï¼Œå¾—å‡ºæœ€ç»ˆçš„ä¼˜åŒ–ç›®æ ‡ï¼š</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftzs779uxaj315i03m0t9.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;å¯¹æŠ—ç½‘ç»œå‹ç¼©&quot;&gt;&lt;a href=&quot;#å¯¹æŠ—ç½‘ç»œå‹ç¼©&quot; class=&quot;headerlink&quot; title=&quot;å¯¹æŠ—ç½‘ç»œå‹ç¼©&quot;&gt;&lt;/a&gt;å¯¹æŠ—ç½‘ç»œå‹ç¼©&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://ws3.sinaimg.cn/large/0069RVTdly1ftzr
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>å‹ç¼©ç½‘ç»œæ¨¡å‹ä¹‹ç»“æ„æ¢ç´¢åˆè¾‘</title>
    <link href="http://yoursite.com/2018/07/29/compression_models/"/>
    <id>http://yoursite.com/2018/07/29/compression_models/</id>
    <published>2018-07-29T06:39:32.000Z</published>
    <updated>2018-11-12T08:00:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>æ€»ç»“äº†è¿‘æœŸä¸€äº›è½»é‡ç½‘ç»œæ¨¡å‹åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œçš„æ¢ç´¢ã€‚è¿™äº›è®ºæ–‡çš„å®ç°æ–¹æ³•ä¸»è¦æ˜¯åˆ©ç”¨ä¸€ç³»åˆ—å·ç§¯å±‚æ„æˆç»„ä»¶ï¼Œåˆ©ç”¨å †å çš„ç»„ä»¶æ„æˆæ¨¡å‹â˜Ÿ</p><h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet</h2><h2 id="Xception"><a href="#Xception" class="headerlink" title="Xception"></a>Xception</h2><h2 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h2><h2 id="ShuffleNet"><a href="#ShuffleNet" class="headerlink" title="ShuffleNet"></a>ShuffleNet</h2><h2 id="ResNeXt"><a href="#ResNeXt" class="headerlink" title="ResNeXt"></a>ResNeXt</h2><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/1611.05431" target="_blank" rel="external">Aggregated Residual Transformations for Deep Neural Networks</a></p><p>ResNeXtæå‡ºäº†èšé›†å˜æ¢(aggregated transofrmations)ï¼š<br>$$<br>\mathcal { F } ( \mathbf { x } ) = \sum _ { i = 1 } ^ { C } \mathcal { T } _ { i } ( \mathbf { x } )<br>$$<br>$C$ä¸ºåŸºæ•°(cardinality)ï¼Œè¡¨æ˜è¿›è¡Œèšé›†å˜æ¢çš„é›†åˆå¤§å°ã€‚$\mathcal { T } _ { i } ( \mathbf { x } )$ä»£è¡¨ä¸€ç³»åˆ—å˜æ¢ã€‚</p><p><strong>ResNextä¸ResNet</strong></p><p>ResNet blockï¼š$\mathbf { y } = \mathcal { F } \left( \mathbf { x } , \left\{ W _ { i } \right\} \right) + \mathbf { x }$</p><p>ResNeXt blockï¼š$\mathbf { y } = \sum _ { i = 1 } ^ { C } \mathcal { T } _ { i } ( \mathbf { x } ) + \mathbf { x }$</p><p>åœ¨è®¡ç®—ä»£ä»·ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œç”»å‡ºæ¥å°±æ˜¯ä¸‹å›¾çš„ä¸œä¸œï¼ˆå·¦è¾¹çš„ä»£è¡¨ResNet blockï¼Œå³è¾¹ä»£è¡¨ResNeXt blockï¼‰ï¼š</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1ftrwnc8rz2j30t60cuq4s.jpg" alt="resnet_resnext"></p><p>ResNeXtå°†ResNetçš„ä¸€ä¸ªå¤§å˜æ¢ï¼Œåˆ†è§£ä¸ºä¸€ç³»åˆ—å°å˜æ¢ï¼Œç„¶åå°†ç»“æœèšé›†èµ·æ¥ï¼ˆç›¸åŠ ï¼‰ã€‚ä¸¤ä¸ªç»“æ„éƒ½åšäº†è·³è·ƒè¿æ¥ã€‚</p><p><strong>ResNeXtã€Inceptionã€Group Convolution</strong></p><p>æ–‡ç« è¿˜æ¯”è¾ƒäº†ä¸Inceptionç»„ä»¶å’Œç»„å·ç§¯çš„å…³ç³»ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftrwicz2c8j31f80fs0wu.jpg" alt=""></p><p>æ–‡ç« åœ¨åç»­çš„å®éªŒä¸­è¡¨æ˜ï¼Œåœ¨è®¡ç®—ä»£ä»·è¿‘ä¼¼çš„æƒ…å†µä¸‹ï¼ŒåŸºæ•°$C$è¶Šå¤šï¼Œå‡†ç¡®ç‡è¶Šé«˜ã€‚</p><h2 id="clcNet"><a href="#clcNet" class="headerlink" title="clcNet"></a>clcNet</h2><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/1712.06145" target="_blank" rel="external">clcNet: Improving the Efficiency of Convolutional Neural Network using Channel Local Convolutions</a></p><p>æœ¬æ–‡å°†æ·±åº¦å·ç§¯å’Œç»„å·ç§¯å½’ä¸ºä¸€ç§é€šç”¨å·ç§¯æ“ä½œâ€”â€”é€šé“å±€éƒ¨å·ç§¯(channel local convolution, CLC)ï¼Œå¹¶æå‡ºäº†é€šé“ä¾èµ–å›¾(channel dependency graph, CDG)çš„è¡¨ç¤ºæ–¹æ³•ã€‚ä¸‹å›¾è¡¨ç¤ºäº†å¸¸è§„å·ç§¯(a)ã€ç»„å·ç§¯(b)ã€æ·±åº¦å·ç§¯(c)çš„CDGã€‚</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1ftry0ix2cwj30vm0b8q4u.jpg" alt=""></p><blockquote><p>CDGè¿™ä¸ªæ¦‚å¿µä¹‹å‰çœ‹çš„ä¸€ç¯‡æ–‡ç« ä¸­ä¹Ÿæåˆ°äº†ï¼š<a href="https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d" target="_blank" rel="external">Why MobileNet and Its Variants (e.g. ShuffleNet) Are Fast</a>ï¼Œå¾ˆç›´è§‚åœ°å¯¹æ¯”äº†ResNetã€ResNeXtã€MobileNetä»¥åŠShuffleNetçš„ç»„ä»¶ã€‚</p></blockquote><p>é€šè¿‡CDGå¯ä»¥å¾ˆæ˜æ˜¾çš„çœ‹å‡ºé€šé“ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼ˆç®­å¤´ç”±è¾“å‡ºæŒ‡å‘è¾“å…¥ï¼‰ã€‚è¿™ä¸ªä¾èµ–å…³ç³»å¯ä»¥ç”¨é€šé“æ„ŸçŸ¥åŸŸ(channel receptive field, CRF)æ¥è¡¨ç¤ºã€‚CRFä»£è¡¨æ¯ä¸ªè¾“å‡ºé€šé“æ‰€ä¾èµ–çš„è¾“å…¥é€šé“ï¼ŒCRFå¤§å°ä¸ºæ¯ä¸ªè¾“å‡ºé€šé“ä¾èµ–çš„è¾“å…¥é€šé“æ•°é‡ã€‚</p><p>åˆ†æä¸Šå›¾ä¸‰ç§å·ç§¯æ“ä½œçš„CRFå¤§å°ï¼ˆsizeï¼‰ï¼š(a) $size = 6$ï¼Œ(b) $size =6/3 = 2$ï¼Œ(c) $size=1$</p><p>åœ¨è¿™äº›æ¦‚å¿µçš„åŸºç¡€ä¸Šï¼Œä½œè€…æå‡ºäº†<strong>å…¨é€šé“æ„ŸçŸ¥åŸŸ(full channel receptive field, FCRF)</strong>ï¼ŒFCRFæ„å‘³ç€_CRFå¤§å° = è¾“å…¥é€šé“æ•°_ï¼Œå³æ¯ä¸ªè¾“å‡ºé€šé“éƒ½ä¾èµ–äºæ‰€æœ‰çš„è¾“å…¥é€šé“ã€‚ä½œè€…è¡¨æ˜FCRFèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¡¨ç¤ºç‰¹å¾ï¼Œå¹¶ä¸”åœ¨å®éªŒä¸­èƒ½è·å¾—æ›´é«˜çš„å‡†ç¡®ç‡ã€‚</p><p>ä½œè€…è¿˜æå‡ºäº†äº¤å‰ç»„å·ç§¯(interlaced group convolution, IGC)ï¼Œå¦‚ä¸‹å›¾(b)æ‰€ç¤ºï¼š</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1ftt3uwgee8j30vq0ikac6.jpg" alt="igc"></p><p>ä¸ç»„å·ç§¯(a)è¿›è¡Œæ¯”è¾ƒï¼Œå¯ä»¥çœ‹å‡ºfiledæ•°é‡å³ä¸ºæ¯ç»„çš„é€šé“æ•°ã€‚IGCå®é™…ä¸Šå°±æ˜¯å°†æ¯ç»„çš„è¾“å‡ºé€šé“ï¼Œåˆ†åˆ°ä¸åŒçš„fieldé‡Œå»ã€‚å› æ­¤äº¤å‰ç»„å·ç§¯çš„CRFå¤§å°å’Œç»„å·ç§¯æ˜¯ç›¸åŒçš„ã€‚</p><p><strong>CLC block</strong>æ˜¯æœ¬æ–‡æå‡ºçš„ç»„ä»¶ï¼Œç”±3x3çš„IGCå’Œ1x1çš„GCæ„æˆï¼Œç»„ä»¶ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1ftt48c72dkj30x80hqq54.jpg" alt="clcblock"></p><p>åœ¨CLC blockçš„åŸºç¡€ä¸Šï¼Œä½œè€…æ¢ç´¢äº†FCRFçš„è§„åˆ™ï¼Œå‡è®¾IGCçš„åˆ†ç»„æ•°ä¸º$g_1$ï¼Œ$Mã€Lã€N$åˆ†åˆ«ä¸ºè¾“å…¥ã€ä¸­é—´é˜¶æ®µã€è¾“å‡ºçš„é€šé“æ•°ï¼ŒGCçš„åˆ†ç»„æ•°ä¸º$g_2$ï¼Œè¦è¾¾åˆ°FCRFï¼Œåº”æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š<br>$$<br>L/g_2 \geq  g_1  \quad or  \quad  g _ { 1 } g _ { 2 } \leq L<br>$$<br>åŸºäºFCRFè§„åˆ™ï¼Œä½¿å¾—è®¡ç®—ä»£ä»·æœ€å°ï¼š</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftt4m3cte8j30x808y3zy.jpg" alt="computational_cost"></p><h2 id="ShuffleNet-v2"><a href="#ShuffleNet-v2" class="headerlink" title="ShuffleNet v2"></a>ShuffleNet v2</h2><p>æœ¬æ–‡æŒ‡å‡ºæ¨¡å‹çš„è¿ç®—é€Ÿåº¦ä¸å•å•å–å†³äºæ¯ç§’æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼ˆFLOPSï¼‰ï¼Œè¿˜æœ‰å…¶ä»–çš„è€ƒè™‘å› ç´ ï¼Œæ¯”å¦‚å†…å­˜è®¿é—®ä»£ä»·ï¼ˆMACï¼‰ã€è¿ç®—å¹³å°ç­‰ã€‚é€šè¿‡ä¸€ç³»åˆ—çš„æ§åˆ¶å®éªŒï¼Œå¯¹äºæ¨¡å‹çš„è®¾è®¡æå‡ºäº†4ä¸ªæŒ‡å¯¼æ–¹é’ˆï¼š</p><ol><li>ç›¸åŒçš„è¾“å…¥è¾“å‡ºé€šé“å®½åº¦ï¼Œèƒ½å‡å°‘å†…å­˜è®¿é—®ä»£ä»·ã€‚</li><li>åˆ†ç»„è¿‡å¤§ï¼Œä¼šå¢åŠ å†…å­˜è®¿é—®ä»£ä»·ã€‚</li><li>ç½‘ç»œåˆ†å‰²ä¼šé™ä½å¹¶è¡Œåº¦ã€‚</li><li>ä¸èƒ½å¿½ç•¥é€å…ƒç´ æ“ä½œã€‚</li></ol><p>åŸºäºæŒ‡å¯¼æ–¹é’ˆï¼Œè®¾è®¡äº†æ–°çš„ShuffleNetå•å…ƒï¼š</p><p>é’ˆå¯¹è¾“å…¥è¾“å‡ºç›¸åŒçš„å•å…ƒï¼Œåœ¨ä¸€å¼€å§‹åŠ å…¥äº†é€šé“åˆ†å‰²ï¼ˆChannel Splitï¼‰ï¼Œå–æ¶ˆäº†ç»„å·ç§¯å’Œç›¸åŠ æ“ä½œï¼Œä»¥ç¬¦åˆæå‡ºçš„æŒ‡å¯¼æ–¹é’ˆ2å’Œ4ï¼›é’ˆå¯¹é™é‡‡æ ·çš„å•å…ƒï¼Œåˆ©ç”¨ä¸¤è·¯ç›¸ä¼¼çš„æ“ä½œè¿›è¡Œã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;æ€»ç»“äº†è¿‘æœŸä¸€äº›è½»é‡ç½‘ç»œæ¨¡å‹åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œçš„æ¢ç´¢ã€‚è¿™äº›è®ºæ–‡çš„å®ç°æ–¹æ³•ä¸»è¦æ˜¯åˆ©ç”¨ä¸€ç³»åˆ—å·ç§¯å±‚æ„æˆç»„ä»¶ï¼Œåˆ©ç”¨å †å çš„ç»„ä»¶æ„æˆæ¨¡å‹â˜Ÿ&lt;/p&gt;
&lt;h2 id=&quot;SqueezeNet&quot;&gt;&lt;a href=&quot;#SqueezeNet&quot; class=&quot;headerlink&quot; title=&quot;Sq
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Network compression, speedup</title>
    <link href="http://yoursite.com/2018/07/27/Network-compression-speedup/"/>
    <id>http://yoursite.com/2018/07/27/Network-compression-speedup/</id>
    <published>2018-07-27T03:19:32.000Z</published>
    <updated>2018-07-27T03:30:13.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h2><h3 id="Singular-value-Decomposition-SVD"><a href="#Singular-value-Decomposition-SVD" class="headerlink" title="Singular value Decomposition(SVD)"></a>Singular value Decomposition(SVD)</h3><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto95l6e4aj30w60cajt9.jpg" alt=""><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto96k0qcsj30uy04e755.jpg" alt=""></p><h3 id="Flattened-Convolutions"><a href="#Flattened-Convolutions" class="headerlink" title="Flattened Convolutions"></a>Flattened Convolutions</h3><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fto96skp45j30vo0aoac6.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto98lg9m4j30w00asac3.jpg" alt=""></p><h2 id="Weight-Pruning"><a href="#Weight-Pruning" class="headerlink" title="Weight Pruning"></a>Weight Pruning</h2><h3 id="Magnitude-based-method"><a href="#Magnitude-based-method" class="headerlink" title="Magnitude-based method"></a>Magnitude-based method</h3><ul><li>Iterative Pruning + Retraining<br>ğŸ„ . Algorithm<br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto99b7u7hj30x8084dh3.jpg" alt=""></li><li>Dynamic Network Surgery<br>ğŸ’«  . Motivation<br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fto99ja0soj30vm06ogml.jpg" alt=""><br>â›“ . Formulation<br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto99q0hilj30wi0cyq5s.jpg" alt=""><br>ğŸ„ . Algorithm<br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto99wbecrj30wm082dh2.jpg" alt=""></li></ul><h3 id="Hessian-based-method"><a href="#Hessian-based-method" class="headerlink" title="Hessian-based method"></a>Hessian-based method</h3><ul><li>Diagonal Hessian-based method: Optimal Brain Damage<br>ğŸ’«  . Motivation<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9a3vy26j30yy04s3zc.jpg" alt=""><br>â›“ . Formulation<br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto9a9srdtj310s0dqac9.jpg" alt=""><br>ğŸ„ . Algorithm<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9ae9ircj30zo0d040y.jpg" alt=""></li><li>Full Hessian-based method: Optimal Brain Surgeon<br>ğŸ’«  . Motivation<br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto9ajoj63j310s0d4q5t.jpg" alt=""><br>â›“ . Formulation<br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto9aof4apj310s0dutbh.jpg" alt=""><br>ğŸ„ . Algorithm<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9atm2jzj311c0aiwgd.jpg" alt=""></li></ul><h2 id="Quantization-method"><a href="#Quantization-method" class="headerlink" title="Quantization method"></a>Quantization method</h2><h3 id="Full-Quantization"><a href="#Full-Quantization" class="headerlink" title="Full Quantization"></a>Full Quantization</h3><ul><li>Fixed-point format<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9ay9ggsj310o0b4tbh.jpg" alt=""><br>â›“ .  Rounding Modes<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9b5dkn2j310u0c6taq.jpg" alt=""><br>ğŸ„ . Multiply and accumulate (MACC) operation<br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto9b9p5z4j30zs0ceq5c.jpg" alt=""></li><li>Code book<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9begz5mj30zc0feq7k.jpg" alt=""></li></ul><h3 id="Quantization-with-full-precision-copy"><a href="#Quantization-with-full-precision-copy" class="headerlink" title="Quantization with full-precision copy"></a>Quantization with full-precision copy</h3><ul><li>Binnaryconnect<br>ğŸ’«  . Motivation<br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto9c757zjj31000ag0ue.jpg" alt=""><br>â›“ .  Binarization<br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto9ccdumnj31080eetbw.jpg" alt=""><br>ğŸ„ . Algorithm<br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fto9cijm0jj30zo07o3zt.jpg" alt=""><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto9cmyf5sj311i082gnq.jpg" alt=""></li><li>Binarized Neural Network (BNN)<br>ğŸ’«  . Motivation<br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fto9css9thj3114066gn9.jpg" alt=""><br>â›“ .  Method<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fto9cxe89pj311k0ecgoo.jpg" alt=""></li></ul><p>â€‹    </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Matrix-Factorization&quot;&gt;&lt;a href=&quot;#Matrix-Factorization&quot; class=&quot;headerlink&quot; title=&quot;Matrix Factorization&quot;&gt;&lt;/a&gt;Matrix Factorization&lt;/h2&gt;&lt;
      
    
    </summary>
    
    
  </entry>
  
</feed>
