<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Colorjam</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-05-21T13:04:56.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Colorjam</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/05/21/paper-ngpr/"/>
    <id>http://yoursite.com/2018/05/21/paper-ngpr/</id>
    <published>2018-05-21T02:56:25.000Z</published>
    <updated>2018-05-21T13:04:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>å¤§éƒ¨åˆ†ä½¿ç”¨GPRçš„SRæ–¹æ³•æ˜¯å±€éƒ¨é‡‡æ ·çš„ï¼Œè¿™äº›æ–¹æ³•å°†å›¾åƒåˆ†æˆå‡ ä¸ªå›ºå®šå¤§å°ï¼ˆe.g  $45\times45$ï¼‰å¹¶ä¸”æœ‰ä¸€å°éƒ¨åˆ†é‡å çš„å¤§å—ï¼Œå¯¹æ¯ä¸ªå¤§å—ï¼Œåªä½¿ç”¨åˆ°å…¶ä¸­å°å—çš„è‡ªç›¸ä¼¼æ€§ï¼ˆe.g $3\times3$ï¼‰æ¥å»ºç«‹GPRæ¨¡å‹ï¼Œå› æ­¤å¾ˆéš¾å®Œå…¨åˆ©ç”¨åˆ°è‡ªç„¶å›¾åƒä¸­çš„è‡ªç›¸ä¼¼æ€§ã€‚æœ¬æ–‡ä½œè€…æå‡ºäº†ä¸€ç§éå±€éƒ¨çš„åŸºäºGPRæ¨¡å‹çš„NGPRè¶…åˆ†è¾¨ç‡é‡å»ºæ–¹æ³•ã€‚</p><h2 id="ç³»ç»Ÿæ€»è§ˆ"><a href="#ç³»ç»Ÿæ€»è§ˆ" class="headerlink" title="ç³»ç»Ÿæ€»è§ˆ"></a>ç³»ç»Ÿæ€»è§ˆ</h2><p>è¯¥ç³»ç»ŸåŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼š</p><ol><li>å­¦ä¹ é˜¶æ®µï¼šåœ¨LRå±‚é¢å­¦ä¹ NGPRæ¨¡å‹ç”¨äºç»†èŠ‚åˆæˆ</li><li>é¢„æµ‹é˜¶æ®µï¼šåœ¨HRå±‚é¢é¢„æµ‹é«˜é¢‘ç»†èŠ‚ç”¨äºSRä¼°è®¡</li></ol><p>ç³»ç»Ÿæµç¨‹å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1frj17sdk7qj31180iidqf.jpg" alt=""></p><p>å…·ä½“åœ°ï¼Œåœ¨å­¦ä¹ é˜¶æ®µå¯ä»¥åˆ†æˆä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1ï¼‰ç”Ÿæˆè®­ç»ƒå›¾åƒå¯¹ï¼›2ï¼‰å­¦ä¹ NGPRæ¨¡å‹ã€‚</p><p>é¦–å…ˆè·å–ç”±åŸå§‹å›¾åƒ $I$ è¿›è¡Œä¸Šé‡‡æ ·å†ä¸‹é‡‡æ ·ç”Ÿæˆçš„è¾…åŠ©å·®å€¼å›¾åƒ $I_I$ ï¼Œå°† $I$ å’Œ  $I_I$ åˆ†åˆ«å‡å»å‡å€¼å›¾åƒ $I_M$ï¼Œæå–å‡ºé«˜é¢‘ç‰¹å¾ $Iâ€™$ å’Œ $Iâ€™_I$ ã€‚å…¶ä¸­ $I_M$ æ˜¯ç”¨ $3\times3$ çš„å¹³å‡è¿‡æ»¤å™¨åœ¨ $I_I$ ä¸Šçš„è¿‡æ»¤ç»“æœã€‚æ¥ä¸‹æ¥æå–å‡º $Iâ€™_I$ ä¸­å›¾åƒå—çš„é‚»è¿‘åƒç´ åºåˆ— $\left\{ {x_i}\right\}^n_{i=1}$ ï¼Œä»¥åŠ $Iâ€™$ ä¸­å¯¹åº”å›¾åƒå—çš„ä¸­å¿ƒåƒç´ åºåˆ— $\left\{ {y_i}\right\}^n_{i=1}$ ä½œä¸ºè®­ç»ƒé›†ï¼Œç”¨äºå­¦ä¹ NGPRæ¨¡å‹çš„æ˜ å°„å…³ç³»ã€‚</p><p>åœ¨é¢„æµ‹é˜¶æ®µï¼Œåˆ©ç”¨æ’å€¼æ³•è·å¾—ä¸Šé‡‡æ ·å›¾åƒ $S_I$ï¼Œå‡å»å‡å€¼å›¾åƒ $S_M$ ä»¥æå–å›¾åƒçš„é«˜é¢‘ç‰¹å¾ $Sâ€™_I$ ã€‚åˆ©ç”¨å­¦ä¹ é˜¶æ®µå­¦ä¹ å‡ºçš„æ¨¡å‹ï¼Œå°† $Sâ€™_I$ ä¸­å›¾åƒå—çš„é‚»è¿‘åƒç´ åºåˆ— $\left\{ x _ { j * } \right\} _ { j = 1} ^ { m } $ æ˜ å°„ä¸ºç¼ºå¤±çš„é«˜é¢‘ç»†èŠ‚ $\left\{ { f(x_{j*}) } \right\}^m_{j=1}$ã€‚</p><h2 id="ç‰¹å¾æå–"><a href="#ç‰¹å¾æå–" class="headerlink" title="ç‰¹å¾æå–"></a>ç‰¹å¾æå–</h2><p>ä½œè€…æå‡ºäº†åœ¨ç‰¹å¾æå–è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨åˆ°çš„ä¸‰ä¸ªæ–¹æ³•ã€‚</p><h4 id="1ï¼‰éå±€éƒ¨é‡‡æ ·"><a href="#1ï¼‰éå±€éƒ¨é‡‡æ ·" class="headerlink" title="1ï¼‰éå±€éƒ¨é‡‡æ ·"></a>1ï¼‰éå±€éƒ¨é‡‡æ ·</h4><p>åœ¨ç”Ÿæˆè®­ç»ƒå›¾åƒå¯¹çš„æ—¶å€™ï¼Œé‡‡æ ·é—´éš”ä¸º4ï¼Œå°†è®­ç»ƒé›†å¤§å°é™ä½ä¸ºåŸæ¥çš„1/16ã€‚åœ¨æé«˜é‡å»ºæ•ˆç‡çš„åŒæ—¶ä¿æŒé‡å»ºå›¾åƒçš„è´¨é‡ã€‚</p><h4 id="2ï¼‰å—å‰ªæ"><a href="#2ï¼‰å—å‰ªæ" class="headerlink" title="2ï¼‰å—å‰ªæ"></a>2ï¼‰å—å‰ªæ</h4><p>åœ¨è®­ç»ƒæ ·æœ¬ä¸­æ’é™¤äº†æ ‡å‡†å·®æ¥è¿‘0çš„å›¾åƒå—ï¼Œé¿å…ä¸€äº›ä¸å«æœ‰ä¿¡æ¯çš„å›¾åƒå—å½±å“å­¦ä¹ è¿‡ç¨‹ã€‚</p><h4 id="3ï¼‰å—æ ‡å‡†åŒ–"><a href="#3ï¼‰å—æ ‡å‡†åŒ–" class="headerlink" title="3ï¼‰å—æ ‡å‡†åŒ–"></a>3ï¼‰å—æ ‡å‡†åŒ–</h4><p>åœ¨è®­ç»ƒå‰å¯¹è®­ç»ƒå›¾åƒå¯¹è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼š<br>$$<br>&lt; x _ { i } ,y _ { i } &gt; \leftarrow &lt; x _ { i } / || x _ { i } || ,y _ { i } / || y _ { i } || &gt; ,\quad \forall i = 1,2,\dots ,n<br>$$</p><p>åŒæ—¶ä¹Ÿå¯¹æµ‹è¯•æ ·æœ¬$\left\{ x _ { j * } \right\} _ { j = 1} ^ { m } $ è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œå¹¶ä¸”åœ¨é¢„æµ‹åè¿›è¡Œæ¢å¤ï¼š</p><p>$$<br>f \left( \mathbf { x } _ { j * } \right) \leftarrow f \left( \mathbf { x } _ { j * } \right) \times || \mathbf { x } _ { j * } || ,\quad \forall j = 1,2,\dots ,m<br>$$</p><h2 id="NGPRæ¨¡å‹"><a href="#NGPRæ¨¡å‹" class="headerlink" title="NGPRæ¨¡å‹"></a>NGPRæ¨¡å‹</h2><p>ä½œè€…æåˆ°äº†ä¸‰ä¸ªæ ¸å‡½æ•°ï¼š</p><h4 id="1-å¾„å‘åŸºå‡½æ•°æ ¸ï¼ˆRBF-kernelï¼‰"><a href="#1-å¾„å‘åŸºå‡½æ•°æ ¸ï¼ˆRBF-kernelï¼‰" class="headerlink" title="1)  å¾„å‘åŸºå‡½æ•°æ ¸ï¼ˆRBF kernelï¼‰"></a>1)  å¾„å‘åŸºå‡½æ•°æ ¸ï¼ˆRBF kernelï¼‰</h4><p>$$<br>k _ { S E i so} \left( \mathbf { x } ,\mathbf { x } ^ { \prime } \right) = \sigma _ { f } ^ { 2} \exp \left( - \frac { 1} { 2l ^ { 2} } \left( \mathbf { x } - \mathbf { x } ^ { \prime } \right) ^ { T } \left( \mathbf { x } - \mathbf { x } ^ { \prime } \right) \right)<br>$$</p><p>å…¶ä¸­ï¼Œ$ \sigma _ { f } ^ { 2}$  ä»£è¡¨ä¿¡å·æ–¹å·®ï¼Œ $l$ ä»£è¡¨é•¿åº¦å°ºåº¦ã€‚RBFæ ¸æ˜¯å„å‘åŒæ€§çš„ï¼Œå¯ä»¥ç”¨æ¥æè¿°å…·æœ‰è¾ƒå°æ¬§æ‹‰è·ç¦»çš„æ ·æœ¬ã€‚ä½†æ˜¯å„å‘åŒæ€§ä¼šå¿½è§†å›¾åƒå—çš„ç»“æ„ä¿¡æ¯ï¼Œå¯¼è‡´åæ–¹å·®çŸ©é˜µäº§ç”Ÿçº¿æ€§ä¾èµ–ã€‚</p><h4 id="2ï¼‰åŠ æ€§æµ‹é‡å™ªå£°æ ¸ï¼ˆAdditive-measurement-noise-kernelï¼‰"><a href="#2ï¼‰åŠ æ€§æµ‹é‡å™ªå£°æ ¸ï¼ˆAdditive-measurement-noise-kernelï¼‰" class="headerlink" title="2ï¼‰åŠ æ€§æµ‹é‡å™ªå£°æ ¸ï¼ˆAdditive measurement noise kernelï¼‰"></a>2ï¼‰åŠ æ€§æµ‹é‡å™ªå£°æ ¸ï¼ˆAdditive measurement noise kernelï¼‰</h4><p>$$<br>k _ { N o i s e } \left( \mathbf { x } ,\mathbf { x } ^ { \prime } \right) = \sigma _ { n } ^ { 2} \delta \left( \mathbf { x } - \mathbf { x } ^ { \prime } \right)<br>$$</p><p>å…¶ä¸­ï¼Œ$\sigma _ { n } ^ { 2}$ ä»£è¡¨å™ªå£°æ–¹å·®ï¼Œ$\delta$ ä»£è¡¨å…‹ç½—å†…å…‹å‡½æ•°ã€‚</p><h4 id="3ï¼‰çº¿æ€§æ ¸ï¼ˆLinear-kernelï¼‰"><a href="#3ï¼‰çº¿æ€§æ ¸ï¼ˆLinear-kernelï¼‰" class="headerlink" title="3ï¼‰çº¿æ€§æ ¸ï¼ˆLinear kernelï¼‰"></a>3ï¼‰çº¿æ€§æ ¸ï¼ˆLinear kernelï¼‰</h4><p>$$<br>k _ { L I N } \left( \mathbf { x } ,\mathbf { x } ^ { \prime } \right) = \mathbf { x} ^ { T } \mathbf { x} ^ { \prime }<br>$$</p><p>çº¿æ€§æ ¸æ˜¯å¯¹ç§°ä½†æ˜¯å„å‘å¼‚æ€§çš„ï¼Œå¯ä»¥ç”¨æ¥æµ‹é‡ç»“æ„ä¿¡æ¯ã€‚RBFæ ¸çš„åæ–¹å·®æ€»æ˜¯å¤§äº0ï¼Œå¿½ç•¥äº†è´Ÿåæ–¹å·®ä¹Ÿå¯è·å¾—çš„äº‹å®ã€‚çº¿æ€§æ ¸æ¯”RBFæ ¸æ›´æœ‰åˆ©äºåå‘ç›¸å…³çš„è®­ç»ƒæ ·æœ¬ã€‚å› æ­¤çº¿æ€§æ ¸æ¯”RBFæ ¸èƒ½æ­ç¤ºæ›´å†…åœ¨çš„ç»“æ„ã€‚</p><p>æœ€åä½œè€…å°†ä¸‰ä¸ªæ ¸å‡½æ•°è¿›è¡Œç»„åˆï¼Œæå‡ºäº†ä¸€ä¸ªæ–°çš„æ ¸å‡½æ•°ï¼š<br>$$<br>k = k_{SEiso} + k_{Noise} + c \times k_{LIN}<br>$$<br>å…¶ä¸­ $c$ æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œç”¨æ¥è°ƒæ•´çº¿æ€§æ ¸çš„é‡è¦æ€§ã€‚</p><h2 id="è¶…å‚æ•°ç¡®å®š"><a href="#è¶…å‚æ•°ç¡®å®š" class="headerlink" title="è¶…å‚æ•°ç¡®å®š"></a>è¶…å‚æ•°ç¡®å®š</h2><h4 id="1ï¼‰å™ªå£°æ ‡å‡†å·®-sigma-n"><a href="#1ï¼‰å™ªå£°æ ‡å‡†å·®-sigma-n" class="headerlink" title="1ï¼‰å™ªå£°æ ‡å‡†å·® $\sigma _ { n }$"></a>1ï¼‰å™ªå£°æ ‡å‡†å·® $\sigma _ { n }$</h4><p>ç”±äº $Iâ€™_I$ å¯ä»¥çœ‹ä½œ $Iâ€™$ çš„ä¼°è®¡ï¼Œé‚£ä¹ˆ $Iâ€™-Iâ€™_I$ å¯ä»¥çœ‹ä½œå™ªå£°çš„ä¼°è®¡ã€‚å› æ­¤æˆ‘ä»¬åˆ©ç”¨ $Iâ€™-Iâ€™_I$ çš„æ ‡å‡†å·®å¯¹ $\sigma _ { n }$è¿›è¡Œåˆå§‹åŒ–ã€‚<br>$$<br>\sigma _ { n } ^ { 2} = \frac { 1} { R _ { L R } \times C _ { L R } - 1} \sum _ { i = 1} ^ { R _ { 1k } \times C _ { 18} } \left[ \left( I ^ { \prime } ( i ) - I _ { I } ^ { \prime } ( i ) \right) - \left( \overline { I } ^ { \prime } - \overline { I } _ { I } ^ { \prime } \right) \right] ^ { 2}<br>$$</p><h4 id="2ï¼‰é•¿åº¦å°ºåº¦-l"><a href="#2ï¼‰é•¿åº¦å°ºåº¦-l" class="headerlink" title="2ï¼‰é•¿åº¦å°ºåº¦ $l$"></a>2ï¼‰é•¿åº¦å°ºåº¦ $l$</h4><p>$l$ æ˜¯RBFæ ¸çš„æ ‡å‡†å·®ï¼Œå¯ä»¥é€šè¿‡è¾“å…¥è®­ç»ƒæ ·æœ¬ä¹‹é—´è·ç¦»çŸ©é˜µçš„æ ‡å‡†å·®æ¥è¿›è¡Œåˆå§‹åŒ–ã€‚<br>$$<br>l ^ { 2} = \frac { 1} { (R _ { L R } \times C _ { L R })^2 - 1} \sum _ { i, j=1} ^{ { R _ { L R } \times C _ { L R } }}(||P(i)-P(j)|| - m_d)^2<br>$$</p><p>$$<br>m_d = \frac { 1} { (R _ { L R } \times C _ { L R })^2 } \sum _ { i, j=1} ^{ { R _ { L R } \times C _ { L R } }}(||P_E(i)-P_E(j)||)<br>$$</p><h4 id="3ï¼‰-ä¿¡å·æ ‡å‡†å·®-sigma-f"><a href="#3ï¼‰-ä¿¡å·æ ‡å‡†å·®-sigma-f" class="headerlink" title="3ï¼‰ ä¿¡å·æ ‡å‡†å·® $ \sigma _ { f }$"></a>3ï¼‰ ä¿¡å·æ ‡å‡†å·® $ \sigma _ { f }$</h4><p>é€šè¿‡ä» $Iâ€™$ ä¸­æå–çš„æ ·æœ¬çš„æ ‡å‡†å·®æ¥è¿›è¡Œåˆå§‹åŒ–ã€‚<br>$$<br>\sigma _ { n } ^ { 2} = \frac { 1} { R _ { L R } \times C _ { L R } - 1} \sum _ { i = 1} ^{ { R _ { L R } \times C _ { L R } }}(Iâ€™(i) -\overline { Iâ€™ })^2<br>$$</p><h4 id="4-å¸¸æ•°-c"><a href="#4-å¸¸æ•°-c" class="headerlink" title="4) å¸¸æ•° $c$"></a>4) å¸¸æ•° $c$</h4><p>$$<br>c = \tau \sigma_f^2<br>$$</p><p>å…¶ä¸­ï¼Œ$R_{LR}$ ï¼Œ$ C_{LR}$ åˆ†åˆ«ä»£è¡¨ $Iâ€™$ çš„è¡Œæ•°å’Œåˆ—æ•°ã€‚$P(i)$ ä»£è¡¨ $Iâ€™_I$ çš„ $i$ ä¸ªå—ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;å¤§éƒ¨åˆ†ä½¿ç”¨GPRçš„SRæ–¹æ³•æ˜¯å±€éƒ¨é‡‡æ ·çš„ï¼Œè¿™äº›æ–¹æ³•å°†å›¾åƒåˆ†æˆå‡ ä¸ªå›ºå®šå¤§å°ï¼ˆe.g  $45\times45$ï¼‰å¹¶ä¸”æœ‰ä¸€å°éƒ¨åˆ†é‡å çš„å¤§å—ï¼Œå¯¹æ¯ä¸ªå¤§å—ï¼Œåªä½¿ç”¨åˆ°å…¶ä¸­å°å—çš„è‡ªç›¸ä¼¼æ€§ï¼ˆe.g $3\times3$ï¼‰æ¥å»ºç«‹GPRæ¨¡å‹ï¼Œå› æ­¤å¾ˆéš¾å®Œå…¨åˆ©ç”¨åˆ°è‡ªç„¶å›¾åƒä¸­çš„è‡ªç›¸ä¼¼æ€§ã€‚æœ¬æ–‡ä½œè€…æå‡º
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>è¯»è®ºæ–‡ã€ŠSingle Image Super-Resolution using Gaussian Process Regressionã€‹</title>
    <link href="http://yoursite.com/2018/05/16/paper-ssir-using-gpr/"/>
    <id>http://yoursite.com/2018/05/16/paper-ssir-using-gpr/</id>
    <published>2018-05-16T07:01:06.000Z</published>
    <updated>2018-05-21T03:06:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡çš„ä½œè€…æå‡ºäº†åˆ©ç”¨é«˜æ–¯å›å½’è¿‡ç¨‹æ¥å®ç°è¶…åˆ†è¾¨ç‡é‡å»ºçš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åªéœ€è¦è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒï¼Œè€Œä¸éœ€è¦é¢å¤–çš„æ•°æ®é›†å’Œæ ·æœ¬å›¾åƒã€‚</p><p>ä½œè€…çš„çµæ„Ÿæ¥è‡ªäºè‡ªç„¶å›¾åƒä¸­çš„ç»“æ„å†—ä½™ã€‚ä¸¤ä¸ªåƒç´ ä¹‹é—´çš„ç›¸ä¼¼æ€§å¯ä»¥å®šä¹‰ä¸ºå®ƒä»¬å±€éƒ¨å‡ ä½•ç»“æ„çš„å·®å¼‚ã€‚ä¸€ä¸ªåƒç´ çš„é‚»è¿‘åƒç´ å¯ä»¥è¡¨æ˜è¯¥åƒç´ çš„å±€éƒ¨ç‰¹å¾ï¼ˆæ¯”å¦‚å¹³æ»‘æˆ–è¾¹ç¼˜åŒºåŸŸï¼‰ï¼Œå› æ­¤å¯ä»¥é¢„æµ‹åŸºäºå›å½’çš„æ¨¡å‹ã€‚</p><h2 id="é«˜æ–¯è¿‡ç¨‹å›å½’"><a href="#é«˜æ–¯è¿‡ç¨‹å›å½’" class="headerlink" title="é«˜æ–¯è¿‡ç¨‹å›å½’"></a>é«˜æ–¯è¿‡ç¨‹å›å½’</h2><p>é«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰å®šä¹‰äº†å‡½æ•° $f$ çš„åˆ†å¸ƒï¼Œ$f$ å°†è¾“å…¥ç©ºé—´ä» ğ’³ æ˜ å°„åˆ° â„›ã€‚å¯¹äº ğ’³ çš„ä»»æ„æœ‰é™å­é›†ï¼Œå…¶è¾¹ç¼˜åˆ†å¸ƒ $P(f(x_1), f(x_2)â€¦f(x_n))$ æ˜¯ä¸€ä¸ªå¤šå…ƒé«˜æ–¯åˆ†å¸ƒï¼Œå…¶ä¸­ $x$ ä»£è¡¨ä¸€ä¸ªè¾“å…¥å‘é‡ã€‚é€šè¿‡å‡å€¼å‡½æ•° $m(x)$ å’Œåæ–¹å·®å‡½æ•° $k(x_i, x_j)$ æˆ‘ä»¬æœ‰ï¼š<br>$$<br>f(x) \sim \mathcal{GP}(m(x), k(x_i,x_j))<br>$$<br>å…¶ä¸­çŸ©é˜µ $Xâ€‹$ çš„æ¯ä¸€è¡Œä¸ºè¾“å…¥å‘é‡ï¼Œ$fâ€‹$ æ˜¯å‡½æ•°å€¼çš„å‘é‡ï¼Œ$K(X, X)â€‹$ ä»£è¡¨ $n \times nâ€‹$ çš„åæ–¹å·®çŸ©é˜µï¼Œå…¶ä¸­ $K_(i,j) = k(x_i, x_j)â€‹$</p><p>é«˜æ–¯è¿‡ç¨‹å›å½’ï¼ˆGPRï¼‰å³æˆ‘ä»¬å‡è®¾äº†ç›®æ ‡å‡½æ•°ä¸ºé«˜æ–¯è¿‡ç¨‹çš„å…ˆéªŒåˆ†å¸ƒã€‚ä»¤ $y$ è¡¨ç¤ºä¸€ä¸ªè§‚æµ‹å€¼ï¼Œ$\epsilon$ ä¸ºé«˜æ–¯å™ªå£°ï¼Œé«˜æ–¯è¿‡ç¨‹å›å½’æ¨¡å‹è¡¨ç¤ºå¦‚ä¸‹ï¼š<br>$$<br>y = f(x) + \epsilon, \epsilon \sim \mathcal{N}(n, \sigma^2_n)<br>$$<br>å‡å€¼å‡½æ•°ä¸ºé›¶çš„è§‚æµ‹å€¼ $\mathbf { y }$ å’Œè¾“å‡º $f_*$ çš„è”åˆåˆ†å¸ƒä¸ºï¼š<br>$$<br>\left[\begin{array}{c} \mathbf { y } \\ f_*\end{array}\right] \sim \mathcal{N}\left( \begin{array}{cc}0, \left[\begin{array}{cc}K(X,X)+\sigma^2_nI &amp; K(X,X_*)\\K(X_*,X) &amp; K(X_*,X_*)\end{array} \right]\end{array} \right)<br>$$<br>å…¶ä¸­$X$ä»£è¡¨è®­ç»ƒé›†ï¼Œ$X_*$ä»£è¡¨æµ‹è¯•é›†ã€‚æˆ‘ä»¬å¯ä»¥æ¨å¯¼å‡ºæ¡ä»¶åˆ†å¸ƒï¼š<br>$$<br>f_*|X,y,X_* \sim \mathcal{N}(\bar{f}_x, V(f_*))ï¼Œ<br>$$<br>å…¶ä¸­ï¼Œ<br>$$<br>f_* = K(X_*, X)[K(X,X) + \sigma^2_nI]^{-1}\mathbf { y }<br>$$</p><p>$$<br>V(f_*) = K(X_*, X_*) -K(X_*, X)[K(X,X) + \sigma^2_nI]^{-1}K(X,X_*)<br>$$</p><h2 id="å•å¸§å›¾åƒé‡å»º"><a href="#å•å¸§å›¾åƒé‡å»º" class="headerlink" title="å•å¸§å›¾åƒé‡å»º"></a>å•å¸§å›¾åƒé‡å»º</h2><p>é«˜åˆ†è¾¨ç‡å›¾åƒå—ç”±å¯¹åº”çš„ä½åˆ†è¾¨ç‡å›¾åƒå—é€åƒç´ åœ°é¢„æµ‹å¾—å‡ºã€‚å– $ 3\times3$ å¤§å°çš„ä½åˆ†è¾¨ç‡å›¾åƒå—ï¼Œè§‚æµ‹å€¼ $\mathbf { y }$ ä¸ºå›¾åƒå—çš„ä¸­å¿ƒåƒç´ ï¼Œ$x$ æ˜¯ä¸€ä¸ª8ç»´å‘é‡ï¼Œä»£è¡¨è§‚æµ‹å€¼çš„ä¸´è¿‘åƒç´ ã€‚</p><p>é«˜åˆ†è¾¨ç‡å›¾åƒçš„é¢„æµ‹ç”±ä¸¤ä¸ªç”±ç²—åˆ°ç»†çš„é˜¶æ®µç»„æˆã€‚</p><ol><li>ä¸Šé‡‡æ ·é˜¶æ®µï¼šé¦–å…ˆåˆ©ç”¨åŒçº¿æ€§æ’å€¼æ³•è·å¾—å·®å€¼åçš„å›¾åƒ $H_b$ã€‚ç„¶åå°†ä½åˆ†è¾¨ç‡å›¾åƒ $L$ åˆ†å—ï¼Œåˆ©ç”¨æ¯ä¸ªå—çš„ä¸­å¿ƒåƒç´  $\mathbf { y }$ ï¼ˆç›®æ ‡åƒç´ ï¼‰å’Œå®ƒçš„ä¸´è¿‘åƒç´  $X_{NL}$ è®­ç»ƒGPRæ¨¡å‹ $M$ ã€‚å°† $H_b$ ä¸­æ¯ä¸ªåƒç´ çš„ä¸´è¿‘åƒç´ $X_{NH_b}$ è¾“å…¥ $M$ è®¡ç®—å‡ºé¢„æµ‹å€¼ $p_\tilde{H}$ã€‚æœ€åé€šè¿‡ $p_\tilde{H}$è·å¾—å¤§è‡´çš„ä¸Šé‡‡æ ·å›¾åƒ $\tilde{H}$ã€‚</li><li>å»æ¨¡ç³Šé˜¶æ®µï¼šè®¡ç®— $\tilde{H}$  çš„ä¸‹é‡‡æ ·å›¾åƒ $\tilde{L}$ ï¼Œå¹¶å¯¹å…¶è¿›è¡Œåˆ†å—ï¼ˆåŒä¸Šé‡‡æ ·é˜¶æ®µ $L$ çš„åˆ†å—æ“ä½œï¼‰ã€‚åˆ©ç”¨æ¯ä¸ªå—çš„ç›®æ ‡åƒç´  $\mathbf { y }$ å’Œä¸å…¶å¯¹åº”çš„ $\tilde{L}$ ä¸­çš„ä¸´è¿‘åƒç´  $X_{N\tilde{L}}$ è®­ç»ƒGPRæ¨¡å‹ $M$ã€‚å°† $\tilde{H}$ ä¸­æ¯ä¸ªåƒç´ çš„ä¸´è¿‘åƒç´ $X_{N\tilde{H}}$ è¾“å…¥ $M$ è®¡ç®—å‡ºé¢„æµ‹å€¼ $p_H$ã€‚æœ€åé€šè¿‡ $ p_H$è·å¾—æœ€ç»ˆçš„é‡å»ºå›¾åƒ $H$ ã€‚</li></ol><p>å®Œæ•´çš„ç®—æ³•æè¿°è¿‡ç¨‹å¦‚ä¸‹ï¼š</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fre5esj0u5j30l00riaf8.jpg" alt=""></p><h2 id="åæ–¹å·®å‡½æ•°"><a href="#åæ–¹å·®å‡½æ•°" class="headerlink" title="åæ–¹å·®å‡½æ•°"></a>åæ–¹å·®å‡½æ•°</h2><p>åœ¨é«˜æ–¯è¿‡ç¨‹å›å½’ä¸­ï¼Œåæ–¹å·®å‡½æ•°é€šè¿‡å®šä¹‰å‡½æ•°çš„ç›¸ä¼¼æ€§ï¼Œç¼–ç äº†æ½œåœ¨çš„é¢„æµ‹è¿‡ç¨‹ï¼Œå› æ­¤æ˜¯ç›¸å½“é‡è¦çš„ã€‚ä½œè€…é€‰æ‹©äº†å¹³æ–¹æŒ‡æ•°åæ–¹å·®å‡½æ•°ï¼š</p><p>$$<br>k(x_i, x_j) = \sigma_f^2 exp(-\frac{1}{2}\frac{(x_i-x_j)â€™(x_i-x_j)}{â„“^2})<br>$$<br>å…¶ä¸­ $\sigma^2_f$ ä»£è¡¨ä¿¡å·æ–¹å·®(signal variance)ï¼Œ$â„“$ ä»£è¡¨ç‰¹å¾é•¿åº¦å°ºåº¦(characteristic length scale)ã€‚ç”±äºç›®æ ‡åƒç´ å‘¨å›´å¼ºåº¦å€¼(intensity values)çš„å·®å¼‚è¡¨æ˜äº†å…¶æ‰€å¤„ä½ç½®ï¼Œå› æ­¤ç›¸ä¼¼æ€§çš„è®¡ç®—åŸºäºä¸¤ä¸ª8ç»´ä¸´è¿‘åƒç´ å‘é‡ç´§å¼ å€¼çš„æ¬§æ‹‰è·ç¦»ã€‚</p><p>é€šè¿‡å¯è§†åŒ–åæ–¹å·®çŸ©é˜µ $K$ï¼Œ ä½œè€…è¡¨ç¤ºå¹³æ–¹æŒ‡æ•°åæ–¹å·®å‡½æ•°èƒ½å¾ˆå¥½åœ°æ•æ‰åˆ°å›¾åƒå—ä¹‹é—´å±€éƒ¨çš„ä»¥åŠå…¨å±€çš„ç›¸ä¼¼æ€§ã€‚</p><p>åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æˆ‘ä»¬ä¸»è¦éœ€è¦å­¦ä¹ çš„å‚æ•°æœ‰ï¼š</p><ol><li>ä¿¡å·æ–¹å·® $\sigma^2_f$</li><li>å…¸å‹é•¿åº¦å€æ•° $â„“$ ï¼šå¯ä»¥çœ‹ä½œæ˜¯æ§åˆ¶ä¸€ä¸ªçº§åˆ« $u$ åœ¨ä¸€ä¸ª1ç»´é«˜æ–¯è¿‡ç¨‹ä¸­å‘ä¸Šäº¤å‰æ•°é‡çš„å‚æ•°</li><li>å™ªå£°æ–¹å·® $\sigma^2_n$</li></ol><p>åœ¨è´å¶æ–¯å›å½’æ¨¡å‹ä¸­ï¼Œè¶…å‚æ•° $\theta$ çš„åéªŒæ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸ºï¼š<br>$$<br>p ( \mathbf { \theta } | \mathbf { X } ,\mathbf { y } ,\mathcal { H } ) = \frac { p ( \mathbf { y } | \mathbf { X } ,\theta ,\mathcal { H } ) p ( \mathbf { \theta } | \mathcal { H } ) } { \int p ( \mathbf { y } | \mathbf { X } ,\theta ,\mathcal { H } ) p ( \theta | \mathcal { H } ) d \theta }<br>$$<br>ä½†æ˜¯è¿™ä¸ªåéªŒæ¦‚ç‡å¾ˆéš¾æ±‚è§£ã€‚åœ¨è¶…åˆ†è¾¨ç‡é—®é¢˜ä¸­ï¼Œå¯ä»¥é€šè¿‡æœ€å¤§åŒ–è¾¹é™…ä¼¼ç„¶(marginal likelihood)æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œè¾¹é™…ä¼¼ç„¶å¯ä»¥è¡¨ç¤ºä¸ºï¼š<br>$$<br>p ( \mathbf { y } | \mathbf { X } ) = \int p ( \mathbf { y } | \mathbf { f } ,\mathbf { X } ) p ( \mathbf { f } | \mathbf { X } ) d \mathbf { f }<br>$$<br>å·²çŸ¥ $\mathbf { y } | \mathbf { f } \sim \mathcal { N } \left( \mathbf { f } ,\sigma _ { n } ^ { 2} I \right)$ å’Œé«˜æ–¯è¿‡ç¨‹å…ˆéªŒåˆ†å¸ƒ $f(x) \sim \mathcal{GP}(m(x), k(x_i,x_j))$ï¼Œå¯ä»¥å°†ä¸Šå¼è½¬åŒ–ä¸º<br>$$<br>\log p ( \mathbf { y } | \mathbf { X } ,\theta ) = - \frac { 1} { 2} \mathbf { y } ^ { T } \mathbf { K } _ { y } ^ { - 1} \mathbf { y } - \frac { 1} { 2} \log | \mathbf { K } _ { y } | - \frac { n } { 2} \log 2\pi<br>$$<br>å…¶ä¸­$ K _ { y } = K ( \mathbf { X } ,\mathbf { X } ) + \sigma _ { n } ^ { 2} I $ï¼Œå¯¹å‚æ•°æ±‚åå¯¼å¾—åˆ°ï¼š<br>$$<br>\frac { \partial \mathcal { L } } { \partial \theta _ { i } } = \frac { 1} { 2} \mathbf { y } ^ { T } \mathbf { K } ^ { - 1} \frac { \partial \mathbf { K } } { \partial \theta _ { i } } \mathbf { K } ^ { - 1} \mathbf { y } - \frac { 1} { 2} \operatorname{tr} \left( \mathbf { K } ^ { - 1} \frac { \partial \mathbf { K } } { \partial \theta _ { i } } \right)<br>$$<br>ç„¶åæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ±‚è§£æœ€ä¼˜å‚æ•°ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;æœ¬æ–‡çš„ä½œè€…æå‡ºäº†åˆ©ç”¨é«˜æ–¯å›å½’è¿‡ç¨‹æ¥å®ç°è¶…åˆ†è¾¨ç‡é‡å»ºçš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åªéœ€è¦è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒï¼Œè€Œä¸éœ€è¦é¢å¤–çš„æ•°æ®é›†å’Œæ ·æœ¬å›¾åƒã€‚&lt;/p&gt;
&lt;p&gt;ä½œè€…çš„çµæ„Ÿæ¥è‡ªäºè‡ªç„¶å›¾åƒä¸­çš„ç»“æ„å†—ä½™ã€‚ä¸¤ä¸ªåƒç´ ä¹‹é—´çš„ç›¸ä¼¼æ€§å¯ä»¥å®šä¹‰ä¸ºå®ƒä»¬å±€éƒ¨å‡ ä½•ç»“æ„çš„å·®å¼‚ã€‚ä¸€ä¸ªåƒç´ çš„é‚»è¿‘åƒç´ å¯ä»¥è¡¨æ˜è¯¥åƒç´ çš„å±€éƒ¨ç‰¹å¾ï¼ˆæ¯”
      
    
    </summary>
    
    
      <category term="SISR" scheme="http://yoursite.com/tags/SISR/"/>
    
      <category term="GPR" scheme="http://yoursite.com/tags/GPR/"/>
    
  </entry>
  
  <entry>
    <title>cs231n-assignment3-gan</title>
    <link href="http://yoursite.com/2018/03/14/cs231n-assignment3-gan/"/>
    <id>http://yoursite.com/2018/03/14/cs231n-assignment3-gan/</id>
    <published>2018-03-14T11:44:48.000Z</published>
    <updated>2018-05-16T02:13:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>æœ€åä¸€ä»½ä½œä¸šæ¥ä¼šä¸€ä¼šç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œï¼ˆGenerative Adversarial Networks, GANï¼‰ã€‚ç½‘ç»œä¸­æœ‰ä¸¤ä¸ªæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ \(G\)ï¼ˆGeneratorï¼‰å’Œåˆ¤åˆ«æ¨¡å‹ \(D\)ï¼ˆDiscriminatorï¼‰ã€‚\(D\) çš„ç›®æ ‡æ˜¯åˆ¤æ–­ä¸€ä¸ªå›¾åƒæ˜¯çœŸçš„è¿˜æ˜¯å‡çš„ï¼Œ\(G\) çš„ç›®æ ‡æ˜¯æ¬ºéª— \(D\) ä½¿å…¶ç›¸ä¿¡å®ƒç”Ÿæˆçš„å›¾åƒæ˜¯çœŸçš„ã€‚ <a href="https://www.msra.cn/zh-cn/news/features/gan-20170511" target="_blank" rel="external">åˆ°åº•ä»€ä¹ˆæ˜¯ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œGANï¼Ÿ</a> å…¶ä¸­ä»¥ç”·å¥³æœ‹å‹åšæ¯”å–»è¿˜è›®å¯çˆ±çš„ã€‚ </p><a id="more"></a><p><img src="/2018/03/14/cs231n-assignment3-gan/model.png" alt="cross-validation"></p><p>æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å…¶å®æ˜¯ \(G\) å’Œ \(D\) ä¹‹é—´çš„åšå¼ˆï¼Œåœ¨è¿™ä¸ªåšå¼ˆä¸­æœ‰ä¸¤ä¸ªåœºæ™¯ã€‚ç¬¬ä¸€ä¸ªåœºæ™¯çš„è¾“å…¥æ˜¯çœŸå®å›¾åƒ <strong>x</strong>ï¼Œè¾“å‡ºæ¦‚ç‡ \(D(x)\) æŒ‡ä¸€ä¸ªå›¾ç‰‡æ˜¯çœŸå®å›¾ç‰‡çš„æ¦‚ç‡ï¼Œåœ¨è¿™ä¸ªåœºæ™¯ä¸­ \(D(x)\) åŠªåŠ›æ¥è¿‘1ã€‚ç¬¬äºŒåœºæ™¯çš„è¾“å…¥æ˜¯å™ªéŸ³ <strong>z</strong>ï¼Œ \(G\) ç”Ÿæˆä¸€ä¸ªæ–°çš„å›¾åƒ \(G(z)\) åŠªåŠ›æ¬ºéª— \(D\) ä½¿ \(D(G(z))\) æ¥è¿‘1ï¼Œ \(D\) åŠªåŠ›è®© \(D(G(z))\) æ¥è¿‘0ã€‚ </p><p>åœ¨æœ¬æ¬¡ä½œç”¨ä¸­æˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹çš„æ›´æ–°è§„åˆ™ï¼š</p><ol><li>æ›´æ–°ç”Ÿæˆæ¨¡å‹ (\(G\)) ï¼Œæœ€å¤§åŒ–åˆ¤åˆ«æ¨¡å‹å¯¹äºç”Ÿæˆçš„å›¾åƒï¼Œä½œå‡º<strong>é”™è¯¯é€‰æ‹©</strong>çš„æ¦‚ç‡ï¼š<br>$$\underset{G}{\text{maximize}}\;  \mathbb{E}_{z \sim p(z)}\left[\log D(G(z))\right]$$</li><li>æ›´æ–°åˆ¤åˆ«æ¨¡å‹ (\(D\))ï¼Œæœ€å¤§åŒ–åˆ¤åˆ«æ¨¡å‹å¯¹äºçœŸå®å’Œç”Ÿæˆçš„å›¾åƒï¼Œä½œå‡º<strong>æ­£ç¡®é€‰æ‹©</strong>çš„æ¦‚ç‡ï¼š<br>$$\underset{D}{\text{maximize}}\; \mathbb{E}_{x \sim p_\text{data}}\left[\log D(x)\right] + \mathbb{E}_{z \sim p(z)}\left[\log \left(1-D(G(z))\right)\right]$$</li></ol><h3 id="Vanilla-GAN"><a href="#Vanilla-GAN" class="headerlink" title="Vanilla GAN"></a>Vanilla GAN</h3><p>å›¾åƒåˆ¤åˆ«æ¨¡å‹çš„æŸå¤±å‡½æ•°ï¼š</p><p>$$ \ell_D = -\mathbb{E}_{x \sim p_\text{data}}\left[\log D(x)\right] - \mathbb{E}_{z \sim p(z)}\left[\log \left(1-D(G(z))\right)\right]$$</p><p>å›¾åƒç”Ÿæˆæ¨¡å‹Gï¼ˆGeneratorï¼‰çš„æŸå¤±å‡½æ•°ï¼š</p><p>$$\ell_G  =  -\mathbb{E}_{z \sim p(z)}\left[\log D(G(z))\right]$$</p><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—äºŒå…ƒäº¤å‰ç†µæŸå¤±ï¼ˆbinary cross entropy lossï¼‰æ¥è®¡ç®—logitsçš„å¯¹æ•°æ¦‚ç‡ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bce_loss</span><span class="params">(input, target)</span>:</span></div><div class="line">    neg_abs = - input.abs()</div><div class="line">    loss = input.clamp(min=<span class="number">0</span>) - input * target + (<span class="number">1</span> + neg_abs.exp()).log()</div><div class="line">    <span class="keyword">return</span> loss.mean()</div></pre></td></tr></table></figure><p>äº¤å‰ç†µç”¨äºè¡¡é‡ä¸¤ä¸ªå–å€¼ä¸ºæ­£æ•°çš„å‡½æ•°çš„ç›¸ä¼¼æ€§ï¼Œå–å€¼è¶Šå°å·®å¼‚è¶Šå°ï¼Œå› æ­¤æœ€å°åŒ–æŸå¤±å‡½æ•°ç›¸å½“äºæœ€å°åŒ–äº¤å‰ç†µã€‚</p><p>å¯¹åº”ä¸Šé¢çš„ä¸¤ä¸ªåœºæ™¯ï¼Œ<strong>D</strong> åˆ¤æ–­çœŸå®å›¾ç‰‡çš„labelséƒ½ä¸º1ï¼Œç”Ÿæˆå›¾ç‰‡çš„labelséƒ½ä¸º0ï¼Œå¯ä»¥å¾—åˆ°ä¸‹é¢çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator_loss</span><span class="params">(logits_real, logits_fake)</span>:</span></div><div class="line">    N = logits_real.shape[<span class="number">0</span>]</div><div class="line">    real_labels = Variable(torch.ones(N)).type(dtype)</div><div class="line">    fake_labels = Variable(torch.zeros(N)).type(dtype)</div><div class="line">    loss = bce_loss(logits_real, real_labels) + bce_loss(logits_fake, fake_labels)</div><div class="line">    <span class="keyword">return</span> loss</div></pre></td></tr></table></figure><p>ä¸Šé¢æˆ‘ä»¬è¯´åˆ° <strong>G</strong> åŠªåŠ›æ¬ºéª— <strong>D</strong> ä½¿ <strong>D(G(z))</strong> æ¥è¿‘1ï¼Œå› æ­¤è¦å°†labelséƒ½è®¾ç½®ä¸º1ï¼Œå¾—åˆ°ä¸‹é¢çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator_loss</span><span class="params">(logits_fake)</span>:</span></div><div class="line">    N = logits_fake.shape[<span class="number">0</span>]</div><div class="line">    fake_labels = Variable(torch.ones(N)).type(dtype)</div><div class="line">    loss = bce_loss(logits_fake, fake_labels)</div><div class="line">    <span class="keyword">return</span> loss</div></pre></td></tr></table></figure><p>æœ€ç»ˆè®­ç»ƒç»“æœï¼š</p><p><img src="/2018/03/14/cs231n-assignment3-gan/vanilla_result.png" alt="cross-validation"></p><h3 id="Least-Square-GAN"><a href="#Least-Square-GAN" class="headerlink" title="Least Square GAN"></a>Least Square GAN</h3><p>å›¾ç‰‡ç”Ÿæˆæ¨¡å‹Gï¼ˆGeneratorï¼‰çš„æŸå¤±å‡½æ•°ï¼š</p><p>$$\ell_G  =  \frac{1}{2}\mathbb{E}_{z \sim p(z)}\left[\left(D(G(z))-1\right)^2\right]$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ls_generator_loss</span><span class="params">(scores_fake)</span>:</span></div><div class="line">    loss = ((scores_fake<span class="number">-1</span>)**<span class="number">2</span>).mean()</div><div class="line">    <span class="keyword">return</span> loss / <span class="number">2</span></div></pre></td></tr></table></figure><p>å›¾åƒåˆ¤åˆ«æ¨¡å‹çš„æŸå¤±å‡½æ•°ï¼š<br>$$ \ell_D = \frac{1}{2}\mathbb{E}_{x \sim p_\text{data}}\left[\left(D(x)-1\right)^2\right] + \frac{1}{2}\mathbb{E}_{z \sim p(z)}\left[ \left(D(G(z))\right)^2\right]$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ls_discriminator_loss</span><span class="params">(scores_real, scores_fake)</span>:</span></div><div class="line">    loss = ((scores_real<span class="number">-1</span>)**<span class="number">2</span>).mean() + (scores_fake**<span class="number">2</span>).mean()</div><div class="line">    <span class="keyword">return</span> loss / <span class="number">2</span></div></pre></td></tr></table></figure><p><img src="/2018/03/14/cs231n-assignment3-gan/ls_result.png" alt="cross-validation"></p><p>ä½œä¸šä¸­æå‡ºäº†å‡ ä¸ªé—®é¢˜</p><blockquote><p>Describe how the visual quality of the samples changes over the course of training. Do you notice anything about the distribution of the samples? How do the results change across different training runs?</p></blockquote><p>å¯ä»¥çœ‹åˆ°é€šè¿‡è®­ç»ƒï¼Œç”Ÿæˆå›¾åƒä»å™ªéŸ³é€æ¸å˜ä¸ºèƒ½è¾¨è®¤å‡ºæ¥çš„æ•°å­—ã€‚ç”Ÿæˆçš„å›¾åƒä¸­ä¼¼ä¹1ã€3ã€9æ¯”è¾ƒå¤šã€‚</p><h3 id="Deeply-Convolutional-GANs"><a href="#Deeply-Convolutional-GANs" class="headerlink" title="Deeply Convolutional GANs"></a>Deeply Convolutional GANs</h3><p>å‰é¢çš„ç½‘ç»œç»“æ„éƒ½æ˜¯ä½¿ç”¨å…¨è¿æ¥ç½‘ç»œï¼Œæäº‹çš„ç§‘å­¦å®¶ä»¬åŠ ä¸Šäº†å‡ å±‚å·ç§¯ç½‘ç»œï¼Œè™½ç„¶è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢ï¼Œä½†ç”Ÿæˆçš„å›¾ç‰‡å¯éª—äººäº†ã€‚ã€‚</p><p><img src="/2018/03/14/cs231n-assignment3-gan/dc_result.png" alt="cross-validation"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æœ€åä¸€ä»½ä½œä¸šæ¥ä¼šä¸€ä¼šç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œï¼ˆGenerative Adversarial Networks, GANï¼‰ã€‚ç½‘ç»œä¸­æœ‰ä¸¤ä¸ªæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ \(G\)ï¼ˆGeneratorï¼‰å’Œåˆ¤åˆ«æ¨¡å‹ \(D\)ï¼ˆDiscriminatorï¼‰ã€‚\(D\) çš„ç›®æ ‡æ˜¯åˆ¤æ–­ä¸€ä¸ªå›¾åƒæ˜¯çœŸçš„è¿˜æ˜¯å‡çš„ï¼Œ\(G\) çš„ç›®æ ‡æ˜¯æ¬ºéª— \(D\) ä½¿å…¶ç›¸ä¿¡å®ƒç”Ÿæˆçš„å›¾åƒæ˜¯çœŸçš„ã€‚ &lt;a href=&quot;https://www.msra.cn/zh-cn/news/features/gan-20170511&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;åˆ°åº•ä»€ä¹ˆæ˜¯ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œGANï¼Ÿ&lt;/a&gt; å…¶ä¸­ä»¥ç”·å¥³æœ‹å‹åšæ¯”å–»è¿˜è›®å¯çˆ±çš„ã€‚ &lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>cs231n-assignment3-styletransfer</title>
    <link href="http://yoursite.com/2018/03/14/cs231n-assignment3-styletransfer/"/>
    <id>http://yoursite.com/2018/03/14/cs231n-assignment3-styletransfer/</id>
    <published>2018-03-14T01:42:13.000Z</published>
    <updated>2018-04-12T00:55:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>ç”¨ç¥ç»ç½‘ç»œåŸºäºä¸¤å¼ ç”»æ¥ç”Ÿæˆä¸€å‰¯æ–°çš„ç”»ï¼Œä¸€å¼ ç”»è¡¨ç°å†…å®¹ï¼Œä¸€å¼ ç”»ä»£è¡¨é£æ ¼ï¼Œç§‘å­¦å®¶çš„è„‘æ´ä¹Ÿæ˜¯å¤§ï¼ä½œä¸šé‡Œå°±å®ç°äº†è¿™ç§æŠ€æœ¯ï¼Œä¸‹é¢ä¸€èµ·æ¥å­¦ä¹ ä¸€ä¸‹å§ï½</p><p><img src="/2018/03/14/cs231n-assignment3-styletransfer/style_content.png" alt=""></p><a id="more"></a><p>æˆ‘ä»¬çŸ¥é“ç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°éå¸¸é‡è¦ï¼Œåœ¨å›¾åƒé£æ ¼è½¬æ¢çš„æŠ€æœ¯ä¸­ï¼ŒæŸå¤±å‡½æ•°ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼š<strong>content loss + style loss + total variation loss</strong></p><h3 id="å†…å®¹æŸå¤±ï¼ˆContent-lossï¼‰"><a href="#å†…å®¹æŸå¤±ï¼ˆContent-lossï¼‰" class="headerlink" title="å†…å®¹æŸå¤±ï¼ˆContent lossï¼‰"></a>å†…å®¹æŸå¤±ï¼ˆContent lossï¼‰</h3><p>å†…å®¹æŸå¤±ä»£è¡¨ç”Ÿæˆå›¾çš„ç‰¹å¾å›¾(feature map)å’ŒåŸå›¾çš„ç‰¹å¾å›¾çš„å·®å¼‚ã€‚æˆ‘ä»¬ä»…å…³æ³¨ç½‘ç»œçš„ä¸€å±‚\(\ell\)ï¼Œå®ƒçš„ç‰¹å¾å›¾ä¸º \(A^\ell \in \mathbb{R}^{1 \times C_\ell \times H_\ell \times W_\ell}\)ã€‚æˆ‘ä»¬ä¼šå°†ç‰¹å¾å›¾åœ¨ç©ºé—´ä¸Šåˆå¹¶åˆ°ä¸€ä¸ªç»´åº¦ï¼Œå¹¶åˆ©ç”¨è¿™ä¸ªå˜å½¢åçš„ç‰ˆæœ¬ã€‚ç”¨ \(F^\ell \in \mathbb{R}^{N_\ell \times M_\ell}\) ä»£è¡¨å½“å‰å›¾åƒçš„ç‰¹å¾å›¾ï¼Œ\(P^\ell \in \mathbb{R}^{N_\ell \times M_\ell}\) ä»£è¡¨åŸå›¾çš„ç‰¹å¾å›¾ï¼Œå…¶ä¸­ \(M_\ell=H_\ell\times W_\ell\)ã€‚\(F^\ell\) å’Œ \(P^\ell\) çš„æ¯ä¸€è¡Œä»£è¡¨ç‰¹å®šæ»¤æ³¢å™¨çš„æ¿€æ´»å‘é‡ï¼Œæ˜¯ç”±å›¾åƒçš„æ‰€æœ‰ä½ç½®å·ç§¯è€Œæˆçš„ã€‚\(w_c\) æ˜¯å†…å®¹æŸå¤±çš„æƒé‡ã€‚</p><p>å†…å®¹æŸå¤±ç”¨å…¬å¼è¡¨ç¤ºä¸ºï¼š</p><p>\(L_c = w_c \times \sum_{i,j} (F_{ij}^{\ell} - P_{ij}^{\ell})^2\)</p><p>ä¸å¤ªç†è§£ä½œä¸šé‡Œå…³äºç‰¹å¾å›¾çš„è§£é‡Šï¼Œå› æ­¤ç»“åˆä¹‹å‰æ•´ç†è¿‡çš„CNNå­¦ä¹ ç¬”è®°ï¼Œè¯´ä¸€ä¸‹è‡ªå·±ç†è§£çš„ç‰¹å¾å›¾ã€‚æˆ‘è§‰å¾—ç‰¹å¾å›¾å…¶å®å°±æ˜¯å·ç§¯å±‚çš„è¾“å‡ºï¼Œå·ç§¯å±‚é€šè¿‡æ»‘åŠ¨æ»¤æ³¢å™¨ï¼ˆfilterï¼Œå³å·ç§¯å±‚çš„å‚æ•°ï¼‰æ¥å¾—åˆ°ç‰¹å¾å›¾ã€‚é€šå¸¸ä¼šæœ‰Nä¸ªæ»¤æ³¢å™¨ï¼Œæ¯ä¸ªæ»¤æ³¢å™¨çš„æ·±åº¦éƒ½æ˜¯Cã€‚å°†æ¯ä¸ªæ»¤æ³¢å™¨çš„è¾“å‡ºç»„åˆåˆ°ä¸€èµ·æ„æˆçš„Nè¡ŒçŸ©é˜µï¼Œå› æ­¤<strong>æ¯ä¸€è¡Œä»£è¡¨ç‰¹å®šæ»¤æ³¢å™¨çš„æ¿€æ´»å‘é‡</strong>ã€‚æ‰€ä»¥æœ€ç»ˆçš„ä»£ç å¾ˆç®€æ´ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">return</span> content_weight * torch.sum((content_current - content_original).pow(<span class="number">2</span>))</div></pre></td></tr></table></figure><h3 id="é£æ ¼æŸå¤±ï¼ˆStyle-lossï¼‰"><a href="#é£æ ¼æŸå¤±ï¼ˆStyle-lossï¼‰" class="headerlink" title="é£æ ¼æŸå¤±ï¼ˆStyle lossï¼‰"></a>é£æ ¼æŸå¤±ï¼ˆStyle lossï¼‰</h3><p>â€‹é¦–å…ˆæˆ‘ä»¬éœ€è¦è®¡ç®—æ ¼æ‹‰å§†çŸ©é˜µ(Gram matrix) G, ä»£è¡¨æ¯ä¸ªè¿‡æ»¤å™¨ä¹‹é—´çš„ç›¸å…³æ€§ã€‚åˆ©ç”¨ä¸Šé¢æåˆ°çš„ \(F^\ell \in \mathbb{R}^ {1 \times C_\ell \times M_\ell} \)ã€‚é‚£ä¹ˆ \(G^\ell \in \mathbb{R}^ {1 \times C_\ell \times C_\ell} \)ï¼š</p><p>$$G_{ij}^\ell  = \sum_k F^{\ell}_{ik} F^{\ell}_{jk}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(features, normalize=True)</span>:</span></div><div class="line">    N, C, H, W = features.shape</div><div class="line">    reshaped_features = features.view(N, C, <span class="number">-1</span>)</div><div class="line">    gram = reshaped_features.matmul(reshaped_features.transpose(<span class="number">1</span>, <span class="number">2</span>))</div><div class="line">    <span class="keyword">if</span>(normalize):</div><div class="line">        gram /= H * W * C</div><div class="line">    <span class="keyword">return</span> gram</div></pre></td></tr></table></figure><p>â—ï¸è®¡ç®—æ ¼æ‹‰å§†çŸ©é˜µæ—¶åº”è¯¥è¦åˆ©ç”¨çŸ©é˜µä¹˜æ³•ï¼Œå³<strong>torch.matmul()</strong></p><p>å‡è®¾ \(G^\ell\) æ˜¯ç”Ÿæˆå›¾çš„ç‰¹å¾å›¾çš„æ ¼æ‹‰å§†çŸ©é˜µï¼Œ\(A^\ell\) æ˜¯åŸå›¾çš„ç‰¹å¾å›¾çš„æ ¼æ‹‰å§†çŸ©é˜µï¼Œé‚£ä¹ˆ \(\ell\) å±‚çš„æŸå¤±å‡½æ•°ï¼š</p><p>$$L_s^\ell = w_\ell \sum_{i, j} \left(G^\ell_{ij} - A^\ell_{ij}\right)^2$$</p><p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¤šè®¡ç®—å‡ ä¸ªå±‚çš„é£æ ¼æŸå¤±ï¼Œå¹¶æŠŠå®ƒä»¬åŠ èµ·æ¥ï¼š</p><p>$$L_s = \sum_{\ell \in \mathcal{L}} L_s^\ell$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span><span class="params">(feats, style_layers, style_targets, style_weights)</span>:</span></div><div class="line">    layers = len(style_layers)</div><div class="line">    loss = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(layers):</div><div class="line">        layer = style_layers[i]</div><div class="line">        loss += torch.sum(style_weights[i] * (gram_matrix(feats[layer]) - style_targets[i]).pow(<span class="number">2</span>))</div><div class="line">    <span class="keyword">return</span> loss</div></pre></td></tr></table></figure><p>â—ï¸è®¡ç®—æ¯å±‚çš„losså¾—åˆ°çš„æ˜¯ä¸€ä¸ªå¤§å°ç­‰äºGçš„Tensorï¼Œè¦ç”¨<strong>torch.sum()</strong>æŠŠå®ƒä»¬ç»Ÿç»ŸåŠ èµ·æ¥ï¼Œå˜æˆä¸€ä¸ªæ•°å€¼</p><h3 id="æ€»å˜åˆ†æ­£åˆ™åŒ–ï¼ˆTotal-variation-regularizationï¼‰"><a href="#æ€»å˜åˆ†æ­£åˆ™åŒ–ï¼ˆTotal-variation-regularizationï¼‰" class="headerlink" title="æ€»å˜åˆ†æ­£åˆ™åŒ–ï¼ˆTotal-variation regularizationï¼‰"></a>æ€»å˜åˆ†æ­£åˆ™åŒ–ï¼ˆTotal-variation regularizationï¼‰</h3><p>ä¸ºäº†ä½¿å›¾åƒæ›´åŠ å¹³æ»‘ï¼Œæˆ‘ä»¬éœ€è¦åŠ å…¥æ€»å˜åˆ†é¡¹ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—ç›¸é‚»åƒç´ å¯¹ï¼ˆæ°´å¹³å’Œå‚ç›´æ–¹å‘ï¼‰ï¼Œåƒç´ å€¼å·®å¼‚çš„å¹³æ–¹å’Œå¾—åˆ°ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p><p>$L_{tv} = w_t \times \sum_{c=1}^3\sum_{i=1}^{H-1} \sum_{j=1}^{W-1} \left( (x_{i,j+1, c} - x_{i,j,c})^2 + (x_{i+1, j,c} - x_{i,j,c})^2  \right)$</p><p>æ ¹æ®å…¬å¼æˆ‘ä»¬å¯ä»¥å†™å‡ºä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tv_loss</span><span class="params">(img, tv_weight)</span>:</span></div><div class="line">    loss = <span class="number">0.0</span></div><div class="line">    _, _, H, W = img.shape</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(H<span class="number">-1</span>):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(W<span class="number">-1</span>):</div><div class="line">            loss += tv_weight*torch.sum((img[:, :, i, j+<span class="number">1</span>] - img[:, :, i, j]).pow(<span class="number">2</span>) + (img[:, :, i+<span class="number">1</span>, j] - img[:, :, i, j]).pow(<span class="number">2</span>))</div><div class="line">        </div><div class="line">    <span class="keyword">return</span> loss</div></pre></td></tr></table></figure><p>ä½†æ˜¯ä½œä¸šè¦æ±‚ä¸ç”¨å¾ªç¯ï¼Œç„¶åæˆ‘åˆå†™ä¸å‡ºæ¥ï¼Œå‚è€ƒäº†ç½‘ä¸Šçš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">hor = torch.dist(img[:, :, :<span class="number">-1</span>, :], img[:, :, <span class="number">1</span>:, :])**<span class="number">2</span></div><div class="line"><span class="comment"># equivalent to (img[:, :, i+1, j] - img[:, :, i, j]).pow(2)</span></div><div class="line">ver = torch.dist(img[:, :, :, :<span class="number">-1</span>], img[:, :, :, <span class="number">1</span>:])**<span class="number">2</span></div><div class="line"><span class="comment"># equivalent to (img[:, :, i, j+1] - img[:, :, i, j]).pow(2)</span></div><div class="line"><span class="keyword">return</span> tv_weight * (hor + ver)</div></pre></td></tr></table></figure><p>è¿™é‡Œçš„torch.dist()ä½¿ç”¨çš„æ˜¯2èŒƒæ•°ï¼Œç›¸å½“äºå·®å¼‚å¹³æ–¹å’Œå…ˆæ ¹å·å†å¹³æ–¹ï¼Œç†è§£çš„åŸºç¡€ä¸Šå€¾å‘äºä¸‹é¢çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hor = torch.sum((img[:, :, :<span class="number">-1</span>, :] - img[:, :, <span class="number">1</span>:, :])**<span class="number">2</span>)</div><div class="line">ver = torch.sum((img[:, :, :, :<span class="number">-1</span>] - img[:, :, :, <span class="number">1</span>:])**<span class="number">2</span>)</div></pre></td></tr></table></figure><p>å¾ªç¯æ³•å’Œå‘é‡æ³•çš„æ•ˆç‡è¿˜æ˜¯å·®è·å¾ˆå¤§çš„ï¼Œç”¨å¾ªç¯æ³•æµ‹è¯•æ—¶éœ€è¦2.2sï¼Œè€Œç”¨å‘é‡æ³•æµ‹è¯•åªè¦53msï¼Œåœ¨åé¢è®­ç»ƒçš„æ—¶å€™æ•ˆæœå°±å¾ˆæ˜æ˜¾äº†ï¼Œå¾ªç¯æ³•åŸºæœ¬æ˜¯è·‘ä¸åŠ¨çš„ã€‚ã€‚ã€‚</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ç”¨ç¥ç»ç½‘ç»œåŸºäºä¸¤å¼ ç”»æ¥ç”Ÿæˆä¸€å‰¯æ–°çš„ç”»ï¼Œä¸€å¼ ç”»è¡¨ç°å†…å®¹ï¼Œä¸€å¼ ç”»ä»£è¡¨é£æ ¼ï¼Œç§‘å­¦å®¶çš„è„‘æ´ä¹Ÿæ˜¯å¤§ï¼ä½œä¸šé‡Œå°±å®ç°äº†è¿™ç§æŠ€æœ¯ï¼Œä¸‹é¢ä¸€èµ·æ¥å­¦ä¹ ä¸€ä¸‹å§ï½&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2018/03/14/cs231n-assignment3-styletransfer/style_content.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>æ¯ä½è®¡ç®—æœºç§‘å­¦å®¶åº”è¯¥äº†è§£çš„æµ®ç‚¹è®¡ç®—</title>
    <link href="http://yoursite.com/2018/03/11/floating-point/"/>
    <id>http://yoursite.com/2018/03/11/floating-point/</id>
    <published>2018-03-11T08:27:45.000Z</published>
    <updated>2018-03-11T14:09:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>åœ¨cs231nçš„è¯¾ç¨‹ä¸Šçœ‹åˆ°äº†ç›¸å…³å†…å®¹ï¼Œä¸€ç›´æƒ³æ‰¾æœºä¼šçœ‹ä¸€çœ‹ï¼Œç´¢æ€§ç”¨ä¸­æ–‡è®°å½•ä¸‹æ¥ä»¥ä¾¿æ—¥åå¤ä¹ ã€‚</p><p>åŸæ–‡é“¾æ¥ï¼š<a href="https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html" target="_blank" rel="external">What Every Computer Scientist Should Know About Floating-Point Arithmetic</a></p><a id="more"></a><h3 id="èˆå…¥è¯¯å·®ï¼ˆRounding-errorï¼‰"><a href="#èˆå…¥è¯¯å·®ï¼ˆRounding-errorï¼‰" class="headerlink" title="èˆå…¥è¯¯å·®ï¼ˆRounding errorï¼‰"></a>èˆå…¥è¯¯å·®ï¼ˆRounding errorï¼‰</h3><p>å°½ç®¡è®¸å¤šæ•´æ•°è®¡ç®—çš„ç»“æœèƒ½å¤Ÿå­˜å‚¨åœ¨32æ¯”ç‰¹ä¸­ï¼Œä½†å®æ•°çš„è®¡ç®—ç»“æœå¸¸å¸¸æ— æ³•ç²¾ç¡®åœ°ç”¨å›ºå®šæ•°é‡çš„æ¯”ç‰¹è¡¨ç¤ºå‡ºæ¥ã€‚å› æ­¤æµ®ç‚¹è®¡ç®—çš„ç»“æœä¸å¾—ä¸åšä¸€äº›å–èˆæ¥è£…å…¥æœ‰é™çš„æ¯”ç‰¹æ•°ä¸­ï¼Œè¿™ä¸ªå–èˆå¾—åˆ°çš„è¿‘ä¼¼å€¼å’Œç²¾ç¡®å€¼ä¹‹é—´çš„å·®å¼‚å°±æ˜¯èˆå…¥è¯¯å·®ã€‚</p><p><strong>æµ®ç‚¹æ ¼å¼</strong></p><p>æœ€å¸¸è§çš„æµ®ç‚¹è¡¨ç¤ºæ³•ç”±ä¸€ä¸ªåŸºæ•°ğ›ƒï¼ˆé€šå¸¸æ˜¯ä¸ªå¶æ•°ï¼‰å’Œä¸€ä¸ªç²¾åº¦pæ„æˆã€‚å‡è®¾ğ›ƒ=10ï¼Œp=3ï¼Œé‚£ä¹ˆ0.1å¯ä»¥è¡¨ç¤ºä¸º\( 1.00\times 10^ { - 1} \)ï¼Œç”¨ä¸€ä¸ªé€šç”¨å…¬å¼æ¥è¡¨ç¤ºå°±æ˜¯ \(d.dd \dots d \timesğ›ƒ^e \) ï¼Œ\(d.dd\dots d\) å³å°¾æ•°ã€‚</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;åœ¨cs231nçš„è¯¾ç¨‹ä¸Šçœ‹åˆ°äº†ç›¸å…³å†…å®¹ï¼Œä¸€ç›´æƒ³æ‰¾æœºä¼šçœ‹ä¸€çœ‹ï¼Œç´¢æ€§ç”¨ä¸­æ–‡è®°å½•ä¸‹æ¥ä»¥ä¾¿æ—¥åå¤ä¹ ã€‚&lt;/p&gt;
&lt;p&gt;åŸæ–‡é“¾æ¥ï¼š&lt;a href=&quot;https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;What Every Computer Scientist Should Know About Floating-Point Arithmetic&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>cs231n-assignment3-rnn</title>
    <link href="http://yoursite.com/2018/02/08/cs231n-assignment3-rnn/"/>
    <id>http://yoursite.com/2018/02/08/cs231n-assignment3-rnn/</id>
    <published>2018-02-08T10:41:35.000Z</published>
    <updated>2018-02-09T07:51:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>é€’å½’ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Network, RNNï¼‰æ˜¯ä¸ºäº†å¤„ç†åºåˆ—æ•°æ®ã€‚ä¹‹å‰å­¦çš„ä¸€äº›æœºå™¨å­¦ä¹ ç®—æ³•çš„è¾“å…¥æ•°æ®ä¹‹é—´ç›¸äº’æ˜¯æ²¡æœ‰è”ç³»çš„ï¼Œå½“ä¸‹ä¸€ä¸ªæ•°æ®å‡ºç°çš„å¯èƒ½ä¾èµ–äºä¹‹å‰å‡ºç°è¿‡çš„æ•°æ®ï¼Œçˆ±æ…å¹ºè›¾å­çš„ç§‘å­¦å®¶ä»¬å°±æƒ³å‡ºäº†RNNã€‚</p><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>å¯¹æ¯”ä¹‹å‰å­¦ä¹ è¿‡çš„CNNï¼ŒCNNçš„è¾“å…¥ä»…ä¸ºæ•°æ®ï¼Œä¸­é—´ç½‘ç»œå±‚çš„è¾“å…¥å³ä¸Šä¸€å±‚è¾“å‡ºçš„å‘é‡ï¼Œä½¿ç”¨ä¸åŒçš„å‚æ•°è®¡ç®—å¾—åˆ°è¯¥å±‚çš„è¾“å‡ºå‘é‡ï¼Œæœ€åå†ä½¿ç”¨softmaxæˆ–svmå¾—åˆ°è¾“å‡ºå€¼ã€‚</p><p>è€ŒRNNåŠ å…¥äº†ä¸€ä¸ªç©æ„å„¿å«<strong>çŠ¶æ€ï¼ˆstateï¼‰</strong>ï¼ŒRNNçš„è¾“å…¥åŒ…æ‹¬åºåˆ—æ•°æ®çš„ç¬¬ä¸€æ­¥å’Œåˆå§‹çŠ¶æ€ï¼Œä¸­é—´çš„ç½‘ç»œå±‚çš„è¾“å…¥æ˜¯æ—¶é—´åºåˆ—ä¸­å¯¹åº”çš„é‚£ä¸€æ­¥å’Œä¸Šä¸€å±‚çš„çŠ¶æ€ï¼Œä½¿ç”¨<strong>ç›¸åŒçš„å‚æ•°</strong>è®¡ç®—å¾—åˆ°è¯¥å±‚çš„çŠ¶æ€ï¼Œé€šè¿‡è¿™ä¸ªçŠ¶æ€è®¡ç®—è¾“å‡ºã€‚</p><p><img src="/2018/02/08/cs231n-assignment3-rnn/rnn_graph.png" alt=""></p><p>æœ€æ™®é€šçš„RNNä½¿ç”¨tanhä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p><p><img src="/2018/02/08/cs231n-assignment3-rnn/rnn_formula.png" alt=""></p><a id="more"></a><p>å•æ­¥rnnçš„è¿‡ç¨‹æ¯”è¾ƒç®€å•ï¼Œtanhçš„æ±‚å¯¼éœ€è¦åˆ©ç”¨åˆ°çŠ¶æ€å€¼<br>$$<br>f(x) = tanh = \frac{e^{x}-e^{-x}}{e^x+e^{-x}}<br>$$</p><p>$$<br>tanâ€™h = \frac{(e^x-(-e^{-x}))(e^x+e^{-x})-(e^{x}-e^{-x})(e^x-e^{-x})}{(e^x+e^{-x})^2}<br>$$</p><p>æ‰€ä»¥<br>$$<br>tanâ€™h =1-f^2(x)<br>$$<br>åœ¨å¤„ç†æ•´ä¸ªåºåˆ—åå‘ä¼ æ’­çš„æ—¶å€™å‡ºç°äº†é—®é¢˜ï¼Œåœ¨<a href="https://www.reddit.com/r/cs231n/comments/48c7wh/question_about_rnn_backward/" target="_blank" rel="external">Question about RNN backward</a>é‡Œæ˜ç™½äº†æˆ‘å‡ºé—®é¢˜çš„åœ°æ–¹ã€‚</p><p>é¦–å…ˆpythonå‡½æ•°ä¸­ï¼Œå‚æ•°ä¼ é€’çš„æ˜¯å¯¹è±¡(call by object)ï¼Œå½“æˆ‘ä»¬å¼•ç”¨æ•°ç»„å¯¹è±¡å¹¶è¿›è¡Œæ“ä½œæ—¶ï¼Œæ˜¯ä¼šæ”¹å˜è¿™ä¸ªæ•°ç»„çš„ã€‚å› æ­¤åœ¨è¿›è¡Œæ•°å€¼éªŒè¯çš„æ—¶å€™ï¼Œä½¿ç”¨åˆ°çš„dhå®é™…ä¸Šæ”¹å˜äº†ï¼Œç»“æœè‡ªç„¶ä¸æ­£ç¡®ã€‚è§£å†³æ–¹æ³•æ˜¯ä½¿ç”¨<code>dh_copy = dh.copy()</code></p><p>å…¶æ¬¡é€šè¿‡<code>nn_step_backward</code>è®¡ç®—å‡ºçš„dprev_hï¼Œéœ€è¦æ·»åŠ åˆ°dhé‡Œï¼Œå³<code>dh[:, t, :] += dprev_h</code>ï¼Œæœ€åä¸€æ¬¡çš„dprev_hå³ä¸ºdh0ã€‚</p><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><p>å®Œæˆäº†RNNæœ€ä¸»è¦çš„è®¡ç®—æ¥ä¸‹æ¥éœ€è¦è¿›è¡Œè¯åµŒå…¥å•¦ï½</p><p>å‡è®¾è¾“å…¥2ä¸ªå¥å­(N)ï¼Œæ¯ä¸ªå¥å­æœ‰4ä¸ªå•è¯(T)ï¼Œè¯æ±‡è¡¨å…±æœ‰5ä¸ªè¯è¯­(V)ï¼Œè¾“å…¥<code>X = [[0, 3, 1, 2], [2, 1, 0, 3]]</code>ï¼Œè¯åµŒå…¥åçš„ç¬¬ä¸€ä¸ªå¥å­ï¼š<br>$$<br>\begin{bmatrix}<br>1 &amp;0&amp;0&amp;0&amp;0\\<br>0&amp;0&amp;0&amp;1&amp;0\\<br>0&amp;1&amp;0&amp;0&amp;0\\<br>0&amp;0&amp;1&amp;0&amp;0<br>\end{bmatrix}<br>$$<br>æ­£å‘ä¼ æ’­æˆ‘é¦–å…ˆåˆ©ç”¨äº†ä¸€ä¸ªå¾ªç¯æ¥å®Œæˆï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(N):</div><div class="line">    seq[n] = np.zeros((T, V))</div><div class="line">    seq[n][list(range(T)), x] = <span class="number">1</span> <span class="comment">#indexing</span></div><div class="line">    out[n] = seq[n].dot(W)</div></pre></td></tr></table></figure><p>åå‘ä¼ æ’­åˆ©ç”¨seqè¿›è¡Œï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">dW = np.zeros((V, D))</div><div class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(N):</div><div class="line">    dW += seq[n].T.dot(dout[n, :, :])</div></pre></td></tr></table></figure><p>ä½†æ˜¯å½“è¯æ±‡è¡¨å¾ˆå¤§çš„æ—¶å€™ï¼Œå°†seqä¿å­˜åœ¨cacheä¸­ï¼Œä¼šå ç”¨äº†å¾ˆå¤§çš„å†…å­˜ï¼Œä¸€å®šæœ‰æ›´å¥½çš„åŠæ³•ğŸ˜</p><p>å†ä»”ç»†ç ”ç©¶äº†ä¸€ä¸‹pythonçš„indexingï¼Œå…¶å®å¯ä»¥åŒæ—¶æ‰©å±•seqçš„ä¸‰ä¸ªç»´åº¦ï¼Œè¿™æ ·å°±çœç•¥äº†forå¾ªç¯ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">rows = np.array(range(N))[:, np.newaxis] </div><div class="line">seq = np.zeros((N, T, V))</div><div class="line">seq[np.tile(rows, T), [list(range(T))]*N, x] = <span class="number">1</span></div><div class="line">out = seq.dot(W)</div></pre></td></tr></table></figure><p>è‡³äºåå‘ä¼ æ’­æ²¡æœ‰ä½¿ç”¨åˆ°np.add.atï¼Œè¯´æ˜ä»£ç è¿˜ä¸å¤Ÿé«˜æ•ˆã€‚æˆ‘ä»¬å·²ç»å‡è®¾T=4ï¼ŒV=5ï¼Œé‚£ä¹ˆå†™å‡º<code>seq[0].T.dot(dout[0, :, :])</code>ä¸€ä¸ªå…·ä½“å…¬å¼ï¼ˆdoutå½“ç„¶ä¸å¯èƒ½è¿™ä¹ˆå¤§ï¼Œæˆ‘éšä¾¿å†™çš„ï¼‰ï¼š<img src="/2018/02/08/cs231n-assignment3-rnn/word_back1.png" alt=""></p><p>å¯ä»¥çœ‹åˆ°è¿™ä¸ªçŸ©é˜µä¹˜æ³•æ˜¯åœ¨è¿›è¡Œè¡Œå˜åŒ–ï¼Œè¿™å°±æ˜¯çŸ©é˜µå·¦ä¹˜çš„å˜æ¢æ„ä¹‰ã€‚å†æ¥ä»”ç»†åˆ†æä¸€ä¸‹å·¦è¾¹è¿™ä¸ªä¼ªåˆç­‰çŸ©é˜µã€‚<img src="/2018/02/08/cs231n-assignment3-rnn/word_back2.png" alt=""></p><p>å®ƒçš„æ¯ä¸€è¡Œå…¶å®ä»£è¡¨ä¸€ä¸ªå•è¯ï¼Œæ¯ä¸€åˆ—ä»£è¡¨ä¸€ä¸ªæ—¶åˆ»ï¼Œdwçš„ç»“æœå³ä¸ºæ¯ä¸ªå•è¯åœ¨å®ƒå‡ºç°æ—¶åˆ»çš„è¯¯å·®çš„ç´¯åŠ ã€‚è¿˜æ˜¯ç”¨ä¸Šé¢çš„ä¾‹å­æ¥è§£é‡Šï¼Œä¸ºæ–¹ä¾¿è¯´æ˜å‡è®¾ä¸‹æ ‡ä»1å¼€å§‹ã€‚w1åœ¨t1æ—¶åˆ»å‡ºç°ï¼Œdw1å°±åº”è¯¥åŠ ä¸Šdout1ï¼Œw2åœ¨t3æ—¶åˆ»å‡ºç°ï¼Œdw2å°±åº”è¯¥åŠ ä¸Šdout3ï¼Œw5æ²¡æœ‰å‡ºç°ï¼Œå°±æ²¡å•¥å¥½åŠ äº†ã€‚å› æ­¤ä¿ºä»¬çš„ä»£ç ç»ˆäºå¯ä»¥å†™å‡ºæ¥äº†ï¼ï¼ˆç«Ÿç„¶è¿™ä¹ˆç®€æ´ï¼‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">np.add.at(dW, x, dout)</div></pre></td></tr></table></figure><p><strong>å‚è€ƒé“¾æ¥</strong></p><ul><li><a href="https://foofish.net/python-function-args.html" target="_blank" rel="external">Python å‡½æ•°ä¸­ï¼Œå‚æ•°æ˜¯ä¼ å€¼ï¼Œè¿˜æ˜¯ä¼ å¼•ç”¨</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;é€’å½’ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Network, RNNï¼‰æ˜¯ä¸ºäº†å¤„ç†åºåˆ—æ•°æ®ã€‚ä¹‹å‰å­¦çš„ä¸€äº›æœºå™¨å­¦ä¹ ç®—æ³•çš„è¾“å…¥æ•°æ®ä¹‹é—´ç›¸äº’æ˜¯æ²¡æœ‰è”ç³»çš„ï¼Œå½“ä¸‹ä¸€ä¸ªæ•°æ®å‡ºç°çš„å¯èƒ½ä¾èµ–äºä¹‹å‰å‡ºç°è¿‡çš„æ•°æ®ï¼Œçˆ±æ…å¹ºè›¾å­çš„ç§‘å­¦å®¶ä»¬å°±æƒ³å‡ºäº†RNNã€‚&lt;/p&gt;
&lt;h3 id=&quot;RNN&quot;&gt;&lt;a href=&quot;#RNN&quot; class=&quot;headerlink&quot; title=&quot;RNN&quot;&gt;&lt;/a&gt;RNN&lt;/h3&gt;&lt;p&gt;å¯¹æ¯”ä¹‹å‰å­¦ä¹ è¿‡çš„CNNï¼ŒCNNçš„è¾“å…¥ä»…ä¸ºæ•°æ®ï¼Œä¸­é—´ç½‘ç»œå±‚çš„è¾“å…¥å³ä¸Šä¸€å±‚è¾“å‡ºçš„å‘é‡ï¼Œä½¿ç”¨ä¸åŒçš„å‚æ•°è®¡ç®—å¾—åˆ°è¯¥å±‚çš„è¾“å‡ºå‘é‡ï¼Œæœ€åå†ä½¿ç”¨softmaxæˆ–svmå¾—åˆ°è¾“å‡ºå€¼ã€‚&lt;/p&gt;
&lt;p&gt;è€ŒRNNåŠ å…¥äº†ä¸€ä¸ªç©æ„å„¿å«&lt;strong&gt;çŠ¶æ€ï¼ˆstateï¼‰&lt;/strong&gt;ï¼ŒRNNçš„è¾“å…¥åŒ…æ‹¬åºåˆ—æ•°æ®çš„ç¬¬ä¸€æ­¥å’Œåˆå§‹çŠ¶æ€ï¼Œä¸­é—´çš„ç½‘ç»œå±‚çš„è¾“å…¥æ˜¯æ—¶é—´åºåˆ—ä¸­å¯¹åº”çš„é‚£ä¸€æ­¥å’Œä¸Šä¸€å±‚çš„çŠ¶æ€ï¼Œä½¿ç”¨&lt;strong&gt;ç›¸åŒçš„å‚æ•°&lt;/strong&gt;è®¡ç®—å¾—åˆ°è¯¥å±‚çš„çŠ¶æ€ï¼Œé€šè¿‡è¿™ä¸ªçŠ¶æ€è®¡ç®—è¾“å‡ºã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2018/02/08/cs231n-assignment3-rnn/rnn_graph.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;æœ€æ™®é€šçš„RNNä½¿ç”¨tanhä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2018/02/08/cs231n-assignment3-rnn/rnn_formula.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>cs231n-assignment2-pytorch</title>
    <link href="http://yoursite.com/2018/01/26/cs231n-assignment2-pytorch/"/>
    <id>http://yoursite.com/2018/01/26/cs231n-assignment2-pytorch/</id>
    <published>2018-01-26T09:12:01.000Z</published>
    <updated>2018-01-28T05:56:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>ç”¨pytorchæ¥æ„å»ºè‡ªå·±çš„ç½‘ç»œå•¦ï½è®°å½•ä¸€ä¸‹è®­ç»ƒè¿‡ç¨‹</p><a id="more"></a><p>å…ˆæ¬è¿ä¸€ä¸‹ä½œä¸šç»™çš„Hintsï¼š</p><h3 id="Things-you-should-try"><a href="#Things-you-should-try" class="headerlink" title="Things you should try:"></a>Things you should try:</h3><ul><li><strong>Filter size</strong>: Above we used 7x7; this makes pretty pictures but smaller filters may be more efficient</li><li><strong>Number of filters</strong>: Above we used 32 filters. Do more or fewer do better?</li><li><strong>Pooling vs Strided Convolution</strong>: Do you use max pooling or just stride convolutions?</li><li><strong>Batch normalization</strong>: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?</li><li><strong>Network architecture</strong>: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:<ul><li>[conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM]</li><li>[conv-relu-conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM]</li><li>[batchnorm-relu-conv]xN -&gt; [affine]xM -&gt; [softmax or SVM]</li></ul></li><li><strong>Global Average Pooling</strong>: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in <a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="external">Googleâ€™s Inception Network</a> (See Table 1 for their architecture).</li><li><strong>Regularization</strong>: Add l2 weight regularization, or perhaps use Dropout.</li></ul><h3 id="Tips-for-training"><a href="#Tips-for-training" class="headerlink" title="Tips for training"></a>Tips for training</h3><p>For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:</p><ul><li>If the parameters are working well, you should see improvement within a few hundred iterations</li><li>Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.</li><li>Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.</li><li>You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.</li></ul><p>çœ‹å®Œæˆ‘çš„å†…å¿ƒæ˜¯å´©æºƒçš„ï¼Œæ¯æ¬¡æ„å»ºä¸€ä¸ªç½‘ç»œéƒ½è¦è°ƒèŠ‚å­¦ä¹ ç‡ï¼Œæ‰€ä»¥æˆ‘åœ¨<strong>train</strong>å‡½æ•°é‡Œè®¾ç½®è¿­ä»£200æ¬¡å°±é€€å‡ºå¾ªç¯ï¼Œå…ˆé€šè¿‡losså¤§è‡´æ¯”è¾ƒä¸€ä¸‹ä¸åŒç½‘ç»œç»“æ„çš„æ•ˆç‡ï¼Œæœ€åå†ä»”ç»†å­¦ä¹ ï½</p><h3 id="Try-1"><a href="#Try-1" class="headerlink" title="Try 1"></a>Try 1</h3><p>é¦–å…ˆæˆ‘å°†ç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„filter sizeæ”¹æˆäº†3ï¼Œæ”¹å˜å·ç§¯å±‚è¿‡æ»¤å™¨çš„æ•°é‡ã€‚ç„¶åçœ‹äº†åŠå¤©ä¸çŸ¥é“strided convolutionæ˜¯å•¥æ‰¾åˆ°äº†ä¸€ä¸ªå­¦ä¹ ç¬”è®°è§†é¢‘â˜ <a href="http://www.bilibili.com/video/av15968996/" target="_blank" rel="external">ä»€ä¹ˆæ˜¯strided convolution? è·³å‡ºæ ¼æ€ä¹ˆå¤„ç†ï¼Ÿ</a> åŸæ¥strided convolutionå°±æ˜¯strideä¸ä¸º1çš„å·ç§¯å±‚:) </p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Strided convolution</span></div><div class="line">nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</div><div class="line"><span class="comment"># no Max Pooling</span></div><div class="line">...</div><div class="line">nn.Linear(<span class="number">7200</span>, <span class="number">1024</span>), <span class="comment"># affine layer (32-3+1)/2</span></div><div class="line"></div><div class="line"><span class="comment"># Pooling</span></div><div class="line">nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>)</div><div class="line">...</div><div class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</div><div class="line">...</div><div class="line">nn.Linear(<span class="number">7200</span>, <span class="number">1024</span>), <span class="comment"># affine layer</span></div></pre></td></tr></table></figure><p>è®¾ç½®strideä¸º2åˆšå¥½æœ€åè¿›å…¥å…¨è¿æ¥æ—¶éƒ½æ˜¯7200ä¸ªç¥ç»å…ƒï½å…ˆå¤§è‡´æŸ¥æ‰¾äº†ä¸€ä¸‹å­¦ä¹ ç‡çš„èŒƒå›´ï¼Œç„¶åç¼©å°èŒƒå›´learning_rate = [10 ** np.random.uniform(-5, -2) for i in range(20)]åˆ†åˆ«å°è¯•ä¸¤ä¸ªæ¨¡å‹çš„å‡†ç¡®ç‡ã€‚</p><p>Strided convolutionåŒå­¦çš„å‡†ç¡®ç‡åœ¨50%ä»¥ä¸Šçš„ä¸å¤šï¼Œç„¶é¹…PoolingåŒå­¦å‡†ç¡®ç‡è¾¾åˆ°50%çš„å°±æ¯”è¾ƒå¤šäº†ï¼Œè¯´æ˜ä½¿ç”¨Poolingçš„æ•ˆæœæ¯”è¾ƒå¥½ã€‚</p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/strided_conv.png" alt="cross-validation"></p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/pooling.png" alt="cross-validation"></p><p>çŒœæƒ³ï¼šå› ä¸ºStrided convolutionå¤šè·³äº†å‡ ä¸ªæ ¼å­ï¼Œå¯èƒ½ä¼šé—æ¼æŸäº›å›¾åƒç‰¹å¾ï¼Œè€ŒMax-poolingè¿‡æ»¤å‡ºæœ€å¤§çš„åƒç´ å€¼ï¼Œåè€Œå¼ºè°ƒäº†å›¾åƒç‰¹å¾ã€‚</p><h3 id="Try-2"><a href="#Try-2" class="headerlink" title="Try 2"></a>Try 2</h3><p>æ¯”è¾ƒä¸€ä¸‹è¿‡æ»¤å™¨æ•°é‡ä¸º50å’Œ20ä¸¤ä¸ªæ¨¡å‹çš„æ•ˆç‡ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">learning_rate = [<span class="number">10</span> ** np.random.uniform(<span class="number">-5</span>, <span class="number">-3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</div><div class="line"><span class="comment"># Convolution of 50 filters</span></div><div class="line">nn.Conv2d(<span class="number">3</span>, <span class="number">50</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>) </div><div class="line">...</div><div class="line">nn.Linear(<span class="number">11250</span>, <span class="number">1024</span>) <span class="comment"># (32-3+1)/2 **2 x 50</span></div><div class="line"><span class="comment"># Convolution of 20 filters</span></div><div class="line">nn.Conv2d(<span class="number">3</span>, <span class="number">20</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>) </div><div class="line">...</div><div class="line">nn.Linear(<span class="number">4500</span>, <span class="number">1029</span>) <span class="comment"># (32-3+1)/2 **2 x 20</span></div></pre></td></tr></table></figure><p><img src="/2018/01/26/cs231n-assignment2-pytorch/conv_num_filters.jpg" alt="cross-validation"></p><p>éšæœºäº†10ä¸ªå­¦ä¹ ç‡ï¼Œå¯ä»¥çœ‹åˆ°ç›¸å¯¹æ¥è¯´è¿˜æ˜¯è¿‡æ»¤å™¨æ¯”è¾ƒå¤šçš„ç»“æœæ¯”è¾ƒå¥½ï¼Œä½†åŒæ—¶ä¹Ÿæ¯”è¾ƒè€—æ—¶</p><h3 id="Try-3"><a href="#Try-3" class="headerlink" title="Try 3"></a>Try 3</h3><p>ä½¿ç”¨ä¸Šé¢50ä¸ªè¿‡æ»¤å™¨çš„æ¨¡å‹ï¼Œåœ¨ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä¹‹åã€å…¨è¿æ¥å±‚ä¹‹ååŠ Batch normalizationã€‚</p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/batch_norm.png" alt="cross-validation"></p><p>è™½ç„¶å‡†ç¡®ç‡æœ€é«˜çš„æ²¡æœ‰ä¸Šé¢ä¸ä½¿ç”¨Batch normalizationçš„é«˜ï¼Œä½†æ˜¯æ•´ä½“æ°´å¹³æå‡äº†ã€‚ä½†æ˜¯Hintsé‡Œè²Œä¼¼æ˜¯è¯´è®­ç»ƒé€Ÿåº¦å˜å¿«äº†ï¼Ÿä½†æ˜¯ä¿ºå¿˜è®°æ‰“å°å‡ºæ—¶é—´äº†ã€‚ã€‚ã€‚</p><h3 id="Try-4"><a href="#Try-4" class="headerlink" title="Try 4"></a>Try 4</h3><p>ä¹‹å‰æ€»ç»“ç¥ç»ç½‘ç»œçš„æ—¶å€™å°±æ€»ç»“è¿‡ï¼Œsoftmaxä»£è¡¨äº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰ï¼ŒSVMæ˜¯æŠ˜é¡µæŸå¤±ï¼ˆhinge lossï¼‰ï¼Œè¿™ä¸ªåœ¨pytorché‡Œéƒ½æœ‰å¯¹åº”çš„losså‡½æ•°ã€‚æ¥ä¸‹æ¥å°±æ˜¯è¦æ”¹å˜ç½‘ç»œç»“æ„å•¦ï½</p><p>æ¨¡å‹ç»“æ„ï¼š[conv-relu-pool]x2 -&gt; [affine]x2 -&gt; [softmax]ï¼ˆåœ¨æ¯å±‚ä¸­é—´éƒ½æ’å…¥äº†batchnormï¼‰</p><table><thead><tr><th>type</th><th>patch size/stride</th><th>input size</th></tr></thead><tbody><tr><td>conv</td><td>3 x 3 / 1</td><td>32x32x3</td></tr><tr><td>pool</td><td>2 x 2 / 2</td><td>30x30x50</td></tr><tr><td>conv</td><td>3 x 3 / 1</td><td>15x15x50</td></tr><tr><td>pool</td><td>2 x 2 / 2</td><td>13x13x30</td></tr><tr><td>linear</td><td>logits</td><td>1x1x1080</td></tr><tr><td>linear</td><td>logits</td><td>1x1x500</td></tr><tr><td>softmax</td><td>classifier</td><td>1x1x10</td></tr></tbody></table><p>æœç´¢ä¸€ä¸‹åˆé€‚çš„å­¦ä¹ ç‡ï½</p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/network1.png" alt="cross-validation"></p><p>å¯ä»¥çœ‹åˆ°æœ€å¥½çš„å‡†ç¡®ç‡æ¥è¿‘0.6å•¦ï¼Œæ’’èŠ±ï½ç°åœ¨ç”¨å­¦ä¹ ç‡è®­ç»ƒ1ä¸ªepochè¯•è¯•</p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/network1_epoch1.png" alt="cross-validation"></p><p>è®­ç»ƒ5ä¸ªepochï½</p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/network1_epoch5.png" alt="cross-validation"></p><p>å‡†ç¡®ç‡è¾¾åˆ°70%å•¦ï¼Œæ’’èŠ±~</p><h3 id="Try-5"><a href="#Try-5" class="headerlink" title="Try 5"></a>Try 5</h3><p>ç°åœ¨æˆ‘ä»¬å†æ”¹å˜ä¸€ä¸‹ç½‘ç»œç»“æ„ï¼Œå°è¯•ä¸€ä¸‹<strong>æ•´ä½“å¹³å‡æ±‡èš</strong>ï¼Œä¹Ÿå°±æ˜¯ä¸åœ¨ä¸­é—´ä½¿ç”¨å¤šä¸ªå…¨é“¾æ¥å±‚ï¼Œè€Œæ˜¯å°†å›¾ç‰‡è®­ç»ƒå¾—è¶³å¤Ÿå°å¤§çº¦ï¼ˆ7, 7ï¼‰ï¼Œåœ¨æœ€åä½¿ç”¨ä¸€ä¸ªæ±‡èšå±‚ä½¿å¾—å›¾åƒå˜æˆ (1, 1 , Filter#)ã€‚</p><p>æ¨¡å‹ç»“æ„ï¼š[conv-relul]x4 -&gt; [pool]x1 -&gt; [softmax]</p><table><thead><tr><th>type</th><th>patch size/stride</th><th>input size</th></tr></thead><tbody><tr><td>conv</td><td>3 x 3 / 1</td><td>32x32x3</td></tr><tr><td>conv</td><td>3 x 3 / 2</td><td>30x30x32</td></tr><tr><td>conv</td><td>3 x 3 / 1</td><td>14x14x64</td></tr><tr><td>conv</td><td>3 x 3 / 2</td><td>12x12x80</td></tr><tr><td>pool</td><td>5 x 5</td><td>5x5x100</td></tr><tr><td>linear</td><td>logits</td><td>1x1x100</td></tr><tr><td>softmax</td><td>classifier</td><td>1x1x10</td></tr></tbody></table><p>å°è¯•äº†å‡ ä¸ªè¿­ä»£ï¼Œåœ¨ä¸€å¼€å§‹æµ‹è¯•éšæœºå­¦ä¹ ç‡çš„æ—¶å€™éƒ½ä¸å¦‚ä¸Šé¢ä¸€ä¸ªæ¨¡å‹ï¼Œå†³å®šå†æ¢ä¸€ä¸ªç»“æ„ï½</p><h3 id="Try-5-1"><a href="#Try-5-1" class="headerlink" title="Try 5"></a>Try 5</h3><p>[batchnorm-relu-conv]x7 -&gt; [pool]x1 -&gt; [softmax]</p><p>å¤ªä¹…äº†ã€‚ã€‚æ”¾å¼ƒã€‚ã€‚æˆ‘å†³å®šå›åˆ°Try4çš„æ¨¡å‹å¤šæ¥å‡ å±‚ã€‚ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">    </div><div class="line">model1 = nn.Sequential( </div><div class="line">                    nn.Conv2d(<span class="number">3</span>, <span class="number">50</span>, kernel_size=<span class="number">3</span>, stride = <span class="number">1</span>), <span class="comment"># input: 32x32x3</span></div><div class="line">                    nn.BatchNorm2d(<span class="number">50</span>),</div><div class="line">                    nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                    nn.BatchNorm2d(<span class="number">50</span>),</div><div class="line">                    nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), <span class="comment"># input: 28x28x32</span></div><div class="line">                    </div><div class="line">                    nn.Conv2d(<span class="number">50</span>, <span class="number">80</span>, kernel_size=<span class="number">3</span>, stride = <span class="number">1</span>), <span class="comment"># input: 14x14x32</span></div><div class="line">                    nn.BatchNorm2d(<span class="number">80</span>),</div><div class="line">                    nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                    nn.BatchNorm2d(<span class="number">80</span>),</div><div class="line">                    nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), <span class="comment"># 8x8x150</span></div><div class="line">    </div><div class="line">                    Flatten(), </div><div class="line">                    nn.Linear(<span class="number">2880</span>, <span class="number">1000</span>),</div><div class="line">                    nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                    nn.Linear(<span class="number">1000</span>,<span class="number">10</span>)</div><div class="line">            )</div></pre></td></tr></table></figure><p><img src="/2018/01/26/cs231n-assignment2-pytorch/val_accr.png" alt="cross-validation"></p><p>ç»è¿‡10ä¸ªepochï¼Œlosså·²ç»æŒºå°çš„äº†ï¼Œè€Œä¸”è¾¾åˆ°äº†74%çš„å‡†ç¡®ç‡ï¼Œç°åœ¨åœ¨æµ‹è¯•é›†ä¸Šå°è¯•</p><p><img src="/2018/01/26/cs231n-assignment2-pytorch/test_accr.png" alt="cross-validation"></p><p>å®Œæˆå•¦ï½</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ç”¨pytorchæ¥æ„å»ºè‡ªå·±çš„ç½‘ç»œå•¦ï½è®°å½•ä¸€ä¸‹è®­ç»ƒè¿‡ç¨‹&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>å·ç§¯ç¥ç»ç½‘ç»œå­¦ä¹ ç¬”è®°</title>
    <link href="http://yoursite.com/2018/01/23/cnn/"/>
    <id>http://yoursite.com/2018/01/23/cnn/</id>
    <published>2018-01-23T06:53:12.000Z</published>
    <updated>2018-01-24T13:03:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>å·ç§¯ç¥ç»ç½‘ç»œå’Œæ™®é€šçš„ç¥ç»ç½‘ç»œå¾ˆç›¸ä¼¼ï¼Œä½†æ˜¯æ˜ç¡®è¡¨ç¤ºäº†è¾“å…¥æ˜¯å›¾åƒï¼Œå¹¶ä¸”å…è®¸æˆ‘ä»¬ç¼–ç ä¸€äº›ç‰¹å¾ï¼Œå› æ­¤å°±ä½¿å¾—æå‡äº†ç½‘ç»œå‰å‘ä¼ æ’­çš„æ•ˆç‡ï¼Œå¹¶ä¸”å¤§å¤§å‡å°‘äº†ç½‘ç»œä¸­çš„å‚æ•°ã€‚ä¸‹é¢å°±è®©æˆ‘ä»¬ä¸€èµ·ç…ç…CNNåŠ å…¥äº†å“ªäº›ç¥å¥‡çš„ä¸œè¥¿å§ :)</p><a id="more"></a><blockquote><p>A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.</p></blockquote><p>ä¸Šé¢è¿™å¥è¯é€éœ²äº†å¾ˆå¤šæœ‰æ„æ€çš„ä¸œè¥¿ï¼ŒåŒ…æ‹¬<strong>3D volume</strong>ã€<strong>Layers</strong>ã€<strong>Parameters</strong>ï¼Œè®©æˆ‘ä»¬ä¸€ä¸ªä¸ªæ¥è¯´è¯´ï½</p><h3 id="3D-volume"><a href="#3D-volume" class="headerlink" title="3D volume"></a>3D volume</h3><p>æ™®é€šçš„ç¥ç»ç½‘ç»œå°†è¾“å…¥å›¾åƒæ’åˆ—æˆä¸€ä¸ªå‘é‡ï¼Œé€šè¿‡å’Œå¯¹åº”æ•°é‡çš„å‚æ•°ç‚¹ä¹˜è·å¾—é¢„æµ‹ç»“æœï¼š</p><p><img src="/2018/01/23/cnn/fc_layer.png" alt=""></p><p>ä½†CNNä¿ç•™äº†è¾“å…¥å›¾åƒçš„ç©ºé—´ç»“æ„ï¼Œå°†å…¶çœ‹ä½œæ˜¯3ç»´ï¼ˆ<strong>width, height, depth</strong>ï¼‰ç»“æ„çš„ï¼Œå¹¶åˆ©ç”¨è¾ƒå°‘çš„å‚æ•°è¿‡æ»¤æ˜ å°„å‡ºä¸‹ä¸€å±‚ï¼š</p><p><img src="/2018/01/23/cnn/cn_layer.png" alt=""></p><h3 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h3><p>æˆ‘ä»¬ä¸»è¦ä½¿ç”¨ä¸‰ç§ç±»å‹çš„å±‚æ¥æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œï¼Œåˆ†åˆ«æ˜¯ï¼š<strong>å·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰</strong>ã€<strong>æ±‡èšå±‚ï¼ˆ Pooling Layerï¼‰</strong>ã€å’Œ<strong>å…¨è¿æ¥å±‚ï¼ˆFully-Connected Layerï¼‰</strong>ã€‚</p><h4 id="å·ç§¯å±‚ï¼ˆConvolutional-Layerï¼‰"><a href="#å·ç§¯å±‚ï¼ˆConvolutional-Layerï¼‰" class="headerlink" title="å·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰"></a>å·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰</h4><p>å·ç§¯å±‚æ˜¯æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒå±‚ã€‚å·ç§¯å±‚çš„å‚æ•°æ˜¯ç”±ä¸€äº›å¯å­¦ä¹ çš„æ»¤æ³¢å™¨é›†åˆï¼ˆå‚æ•°ï¼‰æ„æˆçš„ã€‚æ¯ä¸ªæ»¤æ³¢å™¨åœ¨ç©ºé—´ä¸Šï¼ˆå®½åº¦å’Œé«˜åº¦ï¼‰éƒ½æ¯”è¾ƒå°ï¼Œä½†æ˜¯æ·±åº¦å’Œè¾“å…¥æ•°æ®ä¸€è‡´ã€‚</p><p><strong>å±€éƒ¨è¿æ¥</strong>ï¼šæˆ‘ä»¬å·²ç»çŸ¥é“å…¨è¿æ¥éœ€è¦ä¸å¯¹åº”æ•°é‡çš„å‚æ•°ç‚¹ä¹˜ï¼Œä½†è¿™å¯¹äºå¤§å°ºå¯¸çš„å›¾åƒæ¥è¯´è¿ç®—é‡æ˜¯éå¸¸å¤§çš„ã€‚å› æ­¤æˆ‘ä»¬è®©æ¯ä¸ªç¥ç»å…ƒåªä¸è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸè¿æ¥ã€‚è¯¥è¿æ¥çš„ç©ºé—´å¤§å°å«åšç¥ç»å…ƒçš„<strong>æ„Ÿå—é‡ï¼ˆreceptive fieldï¼‰</strong>ã€‚å®ƒçš„å°ºå¯¸å…¶å®å°±æ˜¯æ»¤æ³¢å™¨çš„ç©ºé—´å°ºå¯¸ã€‚</p><p>â—ï¸æˆ‘ä»¬è®©åœ¨æ»¤æ³¢å™¨åœ¨å®½åº¦å’Œé«˜åº¦ä¸Šæ»‘åŠ¨ï¼Œä½†æ€»æ˜¯è®©æ»¤æ³¢å™¨çš„æ·±åº¦=è¾“å…¥æ•°æ®æ·±åº¦ã€‚</p><p><strong>ç©ºé—´æ’åˆ—</strong>ï¼šæœ‰äº†è¾“å…¥å’Œå‚æ•°ï¼Œæˆ‘ä»¬åº”è¯¥å°±å¯ä»¥å¾—åˆ°è¾“å‡ºäº†ã€‚ä½†è¿™é‡Œè¿˜è¦æä¸€ä¸‹3ä¸ªæ§åˆ¶è¾“å‡ºæ•°æ®å°ºå¯¸çš„è¶…å‚æ•°ï¼š<strong>æ·±åº¦ï¼ˆdepthï¼‰ï¼Œæ­¥é•¿ï¼ˆstrideï¼‰</strong>å’Œ<strong>é›¶å¡«å……ï¼ˆzero-paddingï¼‰</strong>ã€‚</p><ol><li><p>æ­¤æ·±åº¦éå½¼æ·±åº¦ã€‚ä¸Šé¢æˆ‘ä»¬æåˆ°äº†è¾“å…¥æ•°æ®çš„æ·±åº¦ï¼Œç°åœ¨è¿™ä¸ªè¾“å‡ºæ•°æ®çš„æ·±åº¦å…¶å®æ˜¯ä½¿ç”¨çš„<strong>æ»¤æ³¢å™¨æ•°é‡</strong>ã€‚å…¶ä¸­çš„æ¯ä¸€ä¸ªè¾“å‡ºæ•°æ®ç§°ä½œ<strong>æ·±åº¦åˆ‡ç‰‡ï¼ˆdepth sliceï¼‰</strong>ã€‚</p><p><img src="/2018/01/23/cnn/maps.png" alt=""></p></li><li><p>åœ¨æ»‘åŠ¨æ»¤æ³¢å™¨çš„æ—¶å€™æˆ‘ä»¬è¦æŒ‡å®šæ¯æ¬¡ç§»åŠ¨å¤šå°‘ä¸ªåƒç´ ï¼Œä¹Ÿå°±æ˜¯æ­¥é•¿ã€‚</p><p>å‡è®¾ä½¿ç”¨3x3æ»¤æ³¢å™¨åœ¨[7x7]çš„è¾“å…¥æ•°æ®ä¸Šæ»‘åŠ¨ =&gt; [5x5]çš„è¾“å‡ºæ•°æ®ï¼Œè€Œä½¿ç”¨2ä¸ªæ­¥é•¿æ»‘åŠ¨ï¼Œä¼šè®©è¾“å‡ºæ•°æ®åœ¨ç©ºé—´ä¸Šå˜å° =&gt; [3x3]çš„è¾“å‡ºæ•°æ®</p></li><li><p>æœ‰æ—¶å€™ä¼šç”¨0åœ¨è¾“å…¥æ•°æ®ä½“çš„è¾¹ç¼˜å¤„è¿›è¡Œå¡«å……ï¼Œå¯ä»¥è®©è¾“å‡ºæ•°æ®ä¸è¾“å…¥æ•°æ®ç©ºé—´ä¿æŒä¸€è‡´ã€‚</p><p><img src="/2018/01/23/cnn/zero_padding.png" alt=""></p></li></ol><p>æˆ‘ä»¬å°±å¯ä»¥é€šè¿‡è¾“å…¥æ•°æ®å°ºå¯¸ \( W_1 \times H_1 \times D_1 \)ã€æ»¤æ³¢å™¨å°ºå¯¸ğ‘­ã€æ­¥é•¿ğ‘º å’Œé›¶å¡«å……çš„æ•°é‡ğ‘·ï¼Œè®¡ç®—å‡ºè¾“å‡ºæ•°æ®çš„ç©ºé—´å°ºå¯¸ï¼š\( (W - F + 2P) / S + 1 \)</p><h4 id="æ±‡èšå±‚ï¼ˆ-Pooling-Layerï¼‰"><a href="#æ±‡èšå±‚ï¼ˆ-Pooling-Layerï¼‰" class="headerlink" title="æ±‡èšå±‚ï¼ˆ Pooling Layerï¼‰"></a>æ±‡èšå±‚ï¼ˆ Pooling Layerï¼‰</h4><p>æ±‡èšå±‚çš„ä½œç”¨æ˜¯é™ä½æ•°æ®çš„ç©ºé—´å°ºå¯¸ï¼Œå‡å°‘ç½‘ç»œä¸­å‚æ•°çš„æ•°é‡ã€‚æ±‡èšå±‚å…¶å®å°±æ˜¯å¯¹è¾“å…¥æ•°æ®çš„æ¯ä¸€ä¸ªæ·±åº¦åˆ‡ç‰‡è¿›è¡Œé™é‡‡æ ·ï¼Œæ”¹å˜å®ƒçš„ç©ºé—´å°ºå¯¸ã€‚æœ€å¸¸ç”¨çš„æ˜¯MAXæ“ä½œã€‚</p><p><img src="/2018/01/23/cnn/POOLING.png" alt=""></p><h4 id="å…¨è¿æ¥å±‚ï¼ˆFully-Connected-Layerï¼‰"><a href="#å…¨è¿æ¥å±‚ï¼ˆFully-Connected-Layerï¼‰" class="headerlink" title="å…¨è¿æ¥å±‚ï¼ˆFully Connected Layerï¼‰"></a>å…¨è¿æ¥å±‚ï¼ˆFully Connected Layerï¼‰</h4><p>è¿™ä¸ªå…¶å®å°±æ²¡ä»€ä¹ˆå¥½è¯´çš„å•¦ï¼Œå’Œæ™®é€šçš„ç¥ç»ç½‘ç»œæ˜¯ä¸€æ ·çš„</p><p><strong>å‚è€ƒé“¾æ¥</strong></p><ol><li><a href="https://www.quora.com/What-is-a-CNN%E2%80%99s-receptive-field" target="_blank" rel="external">https://www.quora.com/What-is-a-CNN%E2%80%99s-receptive-field</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;å·ç§¯ç¥ç»ç½‘ç»œå’Œæ™®é€šçš„ç¥ç»ç½‘ç»œå¾ˆç›¸ä¼¼ï¼Œä½†æ˜¯æ˜ç¡®è¡¨ç¤ºäº†è¾“å…¥æ˜¯å›¾åƒï¼Œå¹¶ä¸”å…è®¸æˆ‘ä»¬ç¼–ç ä¸€äº›ç‰¹å¾ï¼Œå› æ­¤å°±ä½¿å¾—æå‡äº†ç½‘ç»œå‰å‘ä¼ æ’­çš„æ•ˆç‡ï¼Œå¹¶ä¸”å¤§å¤§å‡å°‘äº†ç½‘ç»œä¸­çš„å‚æ•°ã€‚ä¸‹é¢å°±è®©æˆ‘ä»¬ä¸€èµ·ç…ç…CNNåŠ å…¥äº†å“ªäº›ç¥å¥‡çš„ä¸œè¥¿å§ :)&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ç¥ç»ç½‘ç»œæ–¹æ³•å°ç»“</title>
    <link href="http://yoursite.com/2018/01/21/neural-nets-note/"/>
    <id>http://yoursite.com/2018/01/21/neural-nets-note/</id>
    <published>2018-01-21T03:02:06.000Z</published>
    <updated>2018-01-23T09:12:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>åœ¨cs231nä¸Šå­¦ä¹ äº†å…³äºç¥ç»ç½‘ç»œä¸€ç³»åˆ—æ•°æ®å¤„ç†ã€å‚æ•°è®­ç»ƒã€ç»“æœåˆ†æçš„æ–¹æ³•ï¼Œä¸ºåŠ æ·±å°è±¡åšä¸€äº›æ•´ç†ã€‚</p><a id="more"></a><h3 id="æ•°æ®é¢„å¤„ç†"><a href="#æ•°æ®é¢„å¤„ç†" class="headerlink" title="æ•°æ®é¢„å¤„ç†"></a>æ•°æ®é¢„å¤„ç†</h3><p>æœºå™¨å­¦ä¹ æœ¬è´¨ä¸Šæ˜¯æ•°æ®å·¥ç¨‹ï¼Œæ•°æ®çš„åˆ†å¸ƒå¯¹äºç®—æ³•å­¦ä¹ è¿‡ç¨‹æ˜¯æœ‰å½±å“çš„ã€‚æ‰€ä»¥åœ¨æ•´ä¸ªå­¦ä¹ å¼€å§‹å‰ï¼Œéœ€è¦å¯¹<strong>åŸå§‹æ•°æ®</strong>è¿›è¡Œé¢„å¤„ç†ã€‚é€šå¸¸çš„æ–¹æ³•æœ‰ï¼š</p><ul><li><p><strong>å‡å€¼å‡æ³•ï¼ˆMean subtractionï¼‰</strong>ï¼šä½¿æ•°æ®é›¶å‡å€¼åŒ–<code> X -= np.mean(X)</code></p></li><li><p><strong>å½’ä¸€åŒ–ï¼ˆNormalizationï¼‰</strong>ï¼šä½¿æ•°æ®èŒƒå›´è¿‘ä¼¼ç›¸ç­‰<code>X /= np.std(X, axis=0)</code></p><p><img src="/2018/01/21/neural-nets-note/data_preprocessing1.jpeg" alt=""></p></li><li><p><strong>ä¸»æˆåˆ†åˆ†æï¼ˆPrincipal Component Analysisï¼ŒPCAï¼‰</strong>ï¼šé™ä½æ•°æ®ç»´åº¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># å¯¹æ•°æ®è¿›è¡Œé›¶ä¸­å¿ƒåŒ–(é‡è¦)</span></div><div class="line">cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>] <span class="comment"># å¾—åˆ°æ•°æ®çš„åæ–¹å·®çŸ©é˜µ</span></div><div class="line">U,S,V = np.linalg.svd(cov) <span class="comment"># å¥‡å¼‚å€¼åˆ†è§£</span></div><div class="line">Xrot = np.dot(X,U) <span class="comment"># å¯¹æ•°æ®å»ç›¸å…³æ€§</span></div><div class="line">Xrot_reduced = np.dot(X, U[:,:<span class="number">100</span>]) <span class="comment"># é™ç»´</span></div></pre></td></tr></table></figure></li><li><p><strong>ç™½åŒ–ï¼ˆWhiteningï¼‰</strong>ï¼šé™ä½æ•°æ®çš„å†—ä½™åº¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># é™¤ä»¥ç‰¹å¾å€¼ </span></div><div class="line">Xwhite = Xrot / np.sqrt(S + <span class="number">1e-5</span>)</div></pre></td></tr></table></figure><p><img src="/2018/01/21/neural-nets-note/data_preprocessing2.jpeg" alt=""></p></li></ul><p>â—ï¸åœ¨è¿›è¡Œé¢„å¤„ç†çš„è¿‡ç¨‹ä¸­ï¼Œå¯¹æ‰€æœ‰æ•°æ®ç»Ÿä¸€å¤„ç†åå†åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†çš„åšæ³•æ˜¯<strong>é”™è¯¯çš„</strong>ã€‚æ­£ç¡®åšæ³•æ˜¯ï¼šå…ˆå°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†ï¼Œå¯¹<strong>è®­ç»ƒé›†</strong>è¿›è¡Œæ“ä½œåï¼Œå°†å…¶è¿ç”¨äºéªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚</p><h3 id="å‚æ•°åˆå§‹åŒ–"><a href="#å‚æ•°åˆå§‹åŒ–" class="headerlink" title="å‚æ•°åˆå§‹åŒ–"></a>å‚æ•°åˆå§‹åŒ–</h3><p>é™¤äº†æ•°æ®Xï¼Œç¥ç»ç½‘ç»œè¿˜æœ‰ä¸€äº›å¾ˆé‡è¦çš„æ•°å€¼å°±æ˜¯<strong>æƒé‡W</strong>å’Œ<strong>åç½®b</strong>ã€‚</p><p><strong>åˆå§‹åŒ–æƒé‡</strong>æœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•ï¼š</p><ul><li><p><strong>å°éšæœºæ•°åˆå§‹åŒ–</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">W = <span class="number">0.01</span> * np.random.randn(D,H)</div></pre></td></tr></table></figure></li><li><p><strong>ä½¿ç”¨1/sqrt(n)æ ¡å‡†æ–¹å·®</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = np.random.randn(n) / sqrt(n)</div><div class="line">W = np.random.randn(n) * sqrt(<span class="number">2.0</span>/n) <span class="comment"># ReLUç¥ç»å…ƒçš„ç‰¹æ®Šåˆå§‹åŒ–</span></div></pre></td></tr></table></figure></li><li><p><strong>ç¨€ç–åˆå§‹åŒ–ï¼ˆSparse initializationï¼‰</strong></p></li></ul><p><strong>åˆå§‹åŒ–åç½®</strong>ï¼šé€šå¸¸åˆå§‹ä¸ºå…¨0ã€‚</p><h3 id="æŸå¤±å‡½æ•°ï¼ˆLoss-Functionsï¼‰"><a href="#æŸå¤±å‡½æ•°ï¼ˆLoss-Functionsï¼‰" class="headerlink" title="æŸå¤±å‡½æ•°ï¼ˆLoss Functionsï¼‰"></a>æŸå¤±å‡½æ•°ï¼ˆLoss Functionsï¼‰</h3><p><strong>æ•°æ®æŸå¤±</strong>æ˜¯ä¸€ä¸ªæœ‰ç›‘ç£å­¦ä¹ é—®é¢˜ï¼Œç”¨äºè¡¡é‡åˆ†ç±»ç®—æ³•çš„é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ç»“æœçš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¦è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„å¹³å‡æ•°æ®æŸå¤±ï¼Œå‘å‡å°è¿™ä¸ªæ•°å€¼çš„æ–¹å‘ä¸æ–­åŠªåŠ›ã€‚å¯ä»¥è¯´è¿™å°±æ˜¯æ·±åº¦å­¦ä¹ çš„æ ¹æœ¬ç›®çš„äº†ã€‚å› æ­¤ä¹Ÿå°±äº§ç”Ÿäº†ä¸€ç³»åˆ—è®¡ç®—æ•°æ®æŸå¤±çš„æŸå¤±å‡½æ•°ï¼š</p><ul><li><p><strong>Multiclass Support Vector Machine lossï¼ˆSVMï¼‰</strong>ï¼šSVMåˆ†ç±»å™¨çš„æŸå¤±å‡½æ•°æƒ³è¦SVMåœ¨æ­£ç¡®åˆ†ç±»çš„å¾—åˆ†æ¯”ä¸æ­£ç¡®åˆ†ç±»çš„å¾—åˆ†æ¥å¾—é«˜ï¼Œä¸”è‡³å°‘é«˜å‡ºä¸€ä¸ªè¾¹ç•Œå€¼ğš«ã€‚<br>$$<br>L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)<br>$$<br>è¿™é‡Œè¦æä¸€ä¸‹<strong>æŠ˜é¡µæŸå¤±ï¼ˆhinge lossï¼‰</strong>ï¼Œå³\(max(0, â€”)\)å‡½æ•°ï¼Œå®ƒå¸¸ç”¨äºâ€œmaximum-marginâ€çš„ç®—æ³•ã€‚å› ä¸ºSVMåˆ†ç±»å™¨å°±å±äºè¿™ç±»ç®—æ³•ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨åç§°SVMæ¥ä»£è¡¨è¿™ç±»æŸå¤±å‡½æ•°ã€‚</p></li><li><p><strong>Softmax</strong>ï¼šSoftmaxåˆ†ç±»å™¨å°†è¯„åˆ†å€¼è§†ä¸ºæ¯ä¸ªåˆ†ç±»çš„æœªå½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡ï¼ˆ\(e^{f_{y_{i}}}\)ï¼ŒæŠŠæŠ˜é¡µæŸå¤±æ›¿æ¢æˆäº†<strong>äº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰</strong>ï¼Œå®ƒæ‰€åšçš„å°±æ˜¯æœ€å°åŒ–åœ¨ä¼°è®¡åˆ†ç±»æ¦‚ç‡å’Œâ€œçœŸå®â€åˆ†å¸ƒä¹‹é—´çš„äº¤å‰ç†µï¼š<br>$$<br>L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)<br>$$</p></li></ul><p>â—ï¸åœ¨å®é™…ç¼–ç¨‹å®ç°Softmaxçš„è¿‡ç¨‹ä¸­ï¼Œä¸­é—´é¡¹ \(e^{f_{y_i}}\) å’Œ \(\sum_j e^{f_j}\) å› ä¸ºå­˜åœ¨æŒ‡æ•°å‡½æ•°ï¼Œæ•°å€¼å¯èƒ½éå¸¸å¤§ã€‚é™¤ä»¥å¤§æ•°å€¼å¯èƒ½å¯¼è‡´æ•°å€¼è®¡ç®—çš„ä¸ç¨³å®šï¼Œæ‰€ä»¥å­¦ä¼šä½¿ç”¨å½’ä¸€åŒ–çš„å°æŠ€å·§éå¸¸é‡è¦ã€‚é€šå¸¸å°†ğ¶è®¾ä¸º\(\log C = -\max_j f_j\)<br>$$<br>\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}<br>= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}<br>= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}<br>$$<br><img src="/2018/01/21/neural-nets-note/svmvssoftmax.png" alt="svmvssoftmax"></p><h3 id="æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰"><a href="#æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰" class="headerlink" title="æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰"></a>æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰</h3><p>é™¤äº†æ•°æ®æŸå¤±éƒ¨åˆ†ï¼Œæ­£åˆ™é¡¹ä¹Ÿæ˜¯åœ¨æŸå¤±å‡½æ•°å¾ˆé‡è¦çš„ä¸€éƒ¨åˆ†ã€‚å¦‚æœæ¨¡å‹å¤ªå¤æ‚å³å‡ºç°è¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ï¼Œæˆ‘ä»¬å°±éœ€è¦åŠ å…¥ä¸€äº›æ­£åˆ™é¡¹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p><ul><li><p><strong>L2æ­£åˆ™åŒ–</strong>ï¼š\(R(W) = \sum_k\sum_lW_{k,l}^2\) </p></li><li><p><strong>L1æ­£åˆ™åŒ–</strong>ï¼š\(R(W) = \sum_k\sum_l|W_{k,l}|\) </p></li><li><p><strong>æœ€å¤§èŒƒå¼çº¦æŸï¼ˆMax norm constraintsï¼‰</strong>ï¼šç»™æ¯ä¸ªç¥ç»å…ƒä¸­æƒé‡å‘é‡çš„é‡çº§è®¾å®šä¸Šé™ï¼Œå¹¶ä½¿ç”¨æŠ•å½±æ¢¯åº¦ä¸‹é™æ¥ç¡®ä¿è¿™ä¸€çº¦æŸã€‚</p></li><li><p><strong>éšæœºå¤±æ´»ï¼ˆDropoutï¼‰</strong>ï¼šè®©ç¥ç»å…ƒä»¥è¶…å‚æ•°ğ‘çš„æ¦‚ç‡è¢«æ¿€æ´»æˆ–è€…è¢«è®¾ç½®ä¸º0ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">p = <span class="number">0.5</span> <span class="comment"># æ¿€æ´»ç¥ç»å…ƒçš„æ¦‚ç‡. på€¼æ›´é«˜ = éšæœºå¤±æ´»æ›´å¼±</span></div><div class="line">U1 = (np.random.rand(*H1.shape) &lt; p) / p <span class="comment"># éšæœºå¤±æ´»é®ç½©</span></div><div class="line">H1 *= U1 <span class="comment"># drop!</span></div></pre></td></tr></table></figure></li><li><p><strong>æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰</strong>ï¼šä¸ºäº†ä½¿ç¥ç»ç½‘ç»œçš„æ¯ä¸€å±‚è¾“å…¥æ•°æ®éƒ½æ»¡è¶³æ­£æ€åˆ†å¸ƒï¼Œé™¤äº†ä¸€å¼€å§‹çš„æ•°æ®é¢„å¤„ç†ï¼Œç§‘å­¦å®¶ä»¬å¼•å…¥äº†æ‰¹é‡å½’ä¸€åŒ–ã€‚å°±æ˜¯åœ¨ä½¿ç”¨æ¯å±‚çš„æ¿€æ´»å‡½æ•°å‰ï¼Œå¯¹é‡‡æ ·çš„æ‰¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ã€‚</p></li></ul><p>â—ï¸åœ¨å¼€å§‹æœ€ä¼˜åŒ–å‰æˆ‘ä»¬æœ€å¥½åšä¸€äº›<strong>åˆç†æ€§æ£€æŸ¥</strong>ï¼š</p><ul><li>å¯»æ‰¾ç‰¹å®šæƒ…å†µçš„æ­£ç¡®æŸå¤±å€¼</li><li>æé«˜æ­£åˆ™åŒ–å¼ºåº¦æ—¶å¯¼è‡´æŸå¤±å€¼å˜å¤§</li><li>å¯¹å°æ•°æ®å­é›†è¿‡æ‹Ÿåˆ</li></ul><h3 id="æœ€ä¼˜åŒ–ï¼ˆOptimizationï¼‰"><a href="#æœ€ä¼˜åŒ–ï¼ˆOptimizationï¼‰" class="headerlink" title="æœ€ä¼˜åŒ–ï¼ˆOptimizationï¼‰"></a>æœ€ä¼˜åŒ–ï¼ˆOptimizationï¼‰</h3><p>æœºå™¨å­¦ä¹ çš„è¿‡ç¨‹ä¸æ–­ä¿®æ”¹æƒé‡Wï¼Œä½¿Lossèƒ½å¤Ÿå‡å°ã€‚æœ€å¸¸è§çš„æ–¹æ³•å°±æ˜¯è¿›è¡Œ<strong>åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰</strong>ã€‚é€šè¿‡å¾®åˆ†å…¬å¼å’Œé“¾å¼æ³•åˆ™è®¡ç®—å‡º<strong>è§£ææ¢¯åº¦</strong>ï¼Œæ²¿ç€æ¢¯åº¦çš„è´Ÿæ–¹å‘æ›´æ–°æƒé‡ã€‚ä½†è§£ææ¢¯åº¦éå¸¸å®¹æ˜“ç®—é”™ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¡ç®—<strong>æ•°å€¼æ¢¯åº¦</strong>æ¥è¿›è¡Œ<strong>æ¢¯åº¦æ£€æŸ¥</strong>ï¼Œæœ‰ä¸¤ç§æ¯”è¾ƒæ–¹å¼ï¼š</p><ul><li><strong>ä½¿ç”¨ä¸­å¿ƒåŒ–å…¬å¼</strong></li></ul><p>$$<br>\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in}<br>$$</p><ul><li><strong>ä½¿ç”¨ç›¸å¯¹è¯¯å·®</strong><br>$$<br>\frac{\mid fâ€™_a - fâ€™_n \mid}{\max(\mid fâ€™_a \mid, \mid fâ€™_n \mid)}<br>$$</li></ul><p>ä¸æ–­è¿­ä»£è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æƒé‡çš„æœ€ä¼˜åŒ–æ–¹æ³•å°±æ˜¯<strong>æ¢¯åº¦ä¸‹é™æ³•ï¼ˆGradient descentï¼‰</strong>ã€‚è¿­ä»£çš„æ€è·¯ä¸»è¦æœ‰ä¸¤ç§ï¼š</p><ul><li><strong>æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆBatch Gradient Descentï¼ŒBGDï¼‰</strong>ï¼šæ¯æ¬¡ä½¿ç”¨æ‰€æœ‰æ•°æ®è®¡ç®—æ¢¯åº¦</li><li><strong>éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descentï¼ŒSGDï¼‰</strong>ï¼šæ¯æ¬¡åªä½¿ç”¨ä¸€ä¸ªæ•°æ®è®¡ç®—æ¢¯åº¦</li><li><strong>å°æ‰¹é‡æ•°æ®æ¢¯åº¦ä¸‹é™ï¼ˆMini-batch gradient descentï¼‰</strong>ï¼šæ¯æ¬¡ä½¿ç”¨ä¸€ä¸ªå°æ‰¹é‡æ•°æ®è®¡ç®—</li></ul><p>â—ï¸å³ä½¿SGDåœ¨æŠ€æœ¯ä¸Šæ˜¯æŒ‡æ¯æ¬¡ä½¿ç”¨1ä¸ªæ•°æ®æ¥è®¡ç®—æ¢¯åº¦ï¼Œä½†äººä»¬ä¼šä½¿ç”¨SGDæ¥æŒ‡ä»£å°æ‰¹é‡æ•°æ®æ¢¯åº¦ä¸‹é™</p><p>å› ä¸ºæ·±åº¦å­¦ä¹ çš„å‚æ•°é€šå¸¸å¤„äºé«˜ç»´ç©ºé—´ï¼Œä¸åŒçš„æ›´æ–°æ–¹æ³•ä¼šå¯¼è‡´ä¸åŒçš„ä¼˜åŒ–é€Ÿåº¦ã€‚</p><ul><li><p><strong>æ™®é€šæ›´æ–°</strong>ï¼šæ²¿ç€è´Ÿæ¢¯åº¦æ–¹å‘æ”¹å˜å‚æ•°</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x += - learning_rate * dx</div></pre></td></tr></table></figure></li><li><p><strong>åŠ¨é‡æ›´æ–°</strong>ï¼šä»ç‰©ç†è§’åº¦å‡ºå‘ï¼Œè´Ÿæ¢¯åº¦ä¸è´¨ç‚¹çš„åŠ é€Ÿåº¦æ˜¯æˆæ¯”ä¾‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">v = mu * v - learning_rate * dx <span class="comment"># ä¸é€Ÿåº¦èåˆ</span></div><div class="line">x += v <span class="comment"># ä¸ä½ç½®èåˆ</span></div></pre></td></tr></table></figure></li><li><p><strong>NesterovåŠ¨é‡</strong>ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">v_prev = v <span class="comment"># å­˜å‚¨å¤‡ä»½</span></div><div class="line">v = mu * v - learning_rate * dx <span class="comment"># é€Ÿåº¦æ›´æ–°ä¿æŒä¸å˜</span></div><div class="line">x += -mu * v_prev + (<span class="number">1</span> + mu) * v <span class="comment"># ä½ç½®æ›´æ–°å˜äº†å½¢å¼</span></div></pre></td></tr></table></figure><p><img src="/2018/01/21/neural-nets-note/gradientdescent.png" alt="loss"></p><p>â€‹</p></li></ul><p>ç¬¬äºŒç±»å¸¸ç”¨çš„æœ€ä¼˜åŒ–æ–¹æ³•æ˜¯åŸºäºç‰›é¡¿æ³•çš„ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­æœ€æµè¡Œçš„æ˜¯<strong>L-BFGS</strong>ã€‚ä½†åœ¨æ·±åº¦å­¦ä¹ å’Œå·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼Œä½¿ç”¨L-BFGSä¹‹ç±»çš„äºŒé˜¶æ–¹æ³•å¹¶ä¸å¸¸è§ã€‚ç›¸åï¼ŒåŸºäºï¼ˆNesterovçš„ï¼‰åŠ¨é‡æ›´æ–°çš„å„ç§éšæœºæ¢¯åº¦ä¸‹é™æ–¹æ³•æ›´åŠ å¸¸ç”¨ï¼Œå› ä¸ºå®ƒä»¬æ›´åŠ ç®€å•ä¸”å®¹æ˜“æ‰©å±•ã€‚</p><p>ä¸Šé¢è¿™äº›æ›´æ–°æ–¹æ³•éƒ½æ˜¯å¯¹å­¦ä¹ ç‡è¿›è¡Œå…¨å±€åœ°æ“ä½œï¼Œå¹¶ä¸”å¯¹æ‰€æœ‰çš„å‚æ•°éƒ½æ˜¯ä¸€æ ·çš„ã€‚å› æ­¤å°±æœ‰äººæå‡ºäº†é€‚åº”æ€§å­¦ä¹ ç‡ç®—æ³•ï¼š</p><ul><li><p><strong>Adagrad</strong>ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cache += dx**<span class="number">2</span></div><div class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</div></pre></td></tr></table></figure></li><li><p><strong>RMSprop</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cache =  decay_rate * cache + (<span class="number">1</span> - decay_rate) * dx**<span class="number">2</span></div><div class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</div></pre></td></tr></table></figure></li><li><p><strong>Adam</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">m = beta1*m + (<span class="number">1</span>-beta1)*dx</div><div class="line">v = beta2*v + (<span class="number">1</span>-beta2)*(dx**<span class="number">2</span>)</div><div class="line">x += - learning_rate * m / (np.sqrt(v) + eps)</div></pre></td></tr></table></figure><p><img src="/2018/01/21/neural-nets-note/opt2.gif" alt="loss"></p></li></ul><h3 id="è¶…å‚æ•°è°ƒä¼˜"><a href="#è¶…å‚æ•°è°ƒä¼˜" class="headerlink" title="è¶…å‚æ•°è°ƒä¼˜"></a>è¶…å‚æ•°è°ƒä¼˜</h3><p>æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹æˆ‘ä»¬ä¼šé‡åˆ°å¾ˆå¤šè¶…å‚æ•°ï¼ŒæŒæ¡ä¸€äº›å°æŠ€å·§å¯¹äºè¶…å‚æ•°åˆçš„å§‹åŒ–å’Œè°ƒæ•´æ˜¯å¿…ä¸å¯å°‘çš„ã€‚</p><ul><li><strong>è¶…å‚æ•°èŒƒå›´</strong>ï¼šåœ¨å¯¹æ•°å°ºåº¦ä¸Šè¿›è¡Œè¶…å‚æ•°æœç´¢ã€‚ä¸€ä¸ªå…¸å‹çš„å­¦ä¹ ç‡åº”è¯¥çœ‹èµ·æ¥æ˜¯è¿™æ ·ï¼šlearning_rate = 10 ** uniform(-6, 1)ã€‚å¯¹äºæ­£åˆ™åŒ–å¼ºåº¦ï¼Œå¯ä»¥é‡‡ç”¨åŒæ ·çš„ç­–ç•¥ã€‚ä½†æ˜¯æœ‰ä¸€äº›å‚æ•°ï¼ˆæ¯”å¦‚éšæœºå¤±æ´»ï¼‰è¿˜æ˜¯åœ¨åŸå§‹å°ºåº¦ä¸Šè¿›è¡Œæœç´¢ï¼ˆä¾‹å¦‚ï¼šdropout=uniform(0,1)ï¼‰ã€‚</li><li><strong>éšæœºæœç´¢ä¼˜äºç½‘æ ¼æœç´¢</strong>ï¼šé€šå¸¸ï¼Œæœ‰äº›è¶…å‚æ•°æ¯”å…¶ä½™çš„æ›´é‡è¦ã€‚é€šè¿‡éšæœºæœç´¢ï¼Œå¯ä»¥æ›´ç²¾ç¡®åœ°å‘ç°é‚£äº›æ¯”è¾ƒé‡è¦çš„è¶…å‚æ•°çš„å¥½æ•°å€¼ã€‚</li><li><strong>å°å¿ƒè¾¹ç•Œä¸Šçš„æœ€ä¼˜å€¼</strong>ï¼šå‡è®¾æˆ‘ä»¬ä½¿ç”¨learning_rate = 10 ** uniform(-6,1)æ¥è¿›è¡Œæœç´¢ã€‚ä¸€æ—¦æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ¯”è¾ƒå¥½çš„å€¼ï¼Œä¸€å®šè¦ç¡®è®¤ä½ çš„å€¼ä¸æ˜¯å‡ºäºè¿™ä¸ªèŒƒå›´çš„è¾¹ç•Œä¸Šï¼Œä¸ç„¶ä½ å¯èƒ½é”™è¿‡æ›´å¥½çš„å…¶ä»–æœç´¢èŒƒå›´ã€‚</li><li><strong>ä»ç²—åˆ°ç»†åœ°åˆ†é˜¶æ®µæœç´¢</strong>ï¼šåœ¨å®è·µä¸­ï¼Œå…ˆè¿›è¡Œåˆç•¥èŒƒå›´æœç´¢ï¼Œè®©æ¨¡å‹è®­ç»ƒä¸€ä¸ªå‘¨æœŸå°±å¯ä»¥äº†ï¼›ç¬¬äºŒä¸ªé˜¶æ®µå°±æ˜¯æ ¹æ®å¥½ç»“æœå‡ºç°çš„åœ°æ–¹ï¼Œç¼©å°èŒƒå›´è¿›è¡Œæœç´¢ï¼Œè¿™æ—¶å¯ä»¥è®©æ¨¡å‹è¿è¡Œ5ä¸ªå‘¨æœŸï¼›æœ€åä¸€ä¸ªé˜¶æ®µå°±åœ¨æœ€ç»ˆçš„èŒƒå›´å†…è¿›è¡Œä»”ç»†æœç´¢ï¼Œè¿è¡Œå¾ˆå¤šæ¬¡å‘¨æœŸã€‚</li><li><strong>è´å¶æ–¯è¶…å‚æ•°æœ€ä¼˜åŒ–</strong>ï¼šä¸»è¦æ˜¯ç ”ç©¶åœ¨è¶…å‚æ•°ç©ºé—´ä¸­æ›´é«˜æ•ˆçš„å¯¼èˆªç®—æ³•ã€‚</li></ul><h3 id="æ£€æŸ¥å­¦ä¹ è¿‡ç¨‹"><a href="#æ£€æŸ¥å­¦ä¹ è¿‡ç¨‹" class="headerlink" title="æ£€æŸ¥å­¦ä¹ è¿‡ç¨‹"></a>æ£€æŸ¥å­¦ä¹ è¿‡ç¨‹</h3><p>å¯ä»¥é€šè¿‡å¯è§†åŒ–çš„æ–¹å¼æ¥æ£€æŸ¥æˆ‘ä»¬çš„æŸå¤±å€¼ã€ç²¾ç¡®å€¼ç­‰æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚</p><ul><li><p><strong>æŸå¤±å€¼</strong>ï¼šæŸå¤±å€¼çš„éœ‡è¡ç¨‹åº¦å’Œæ‰¹å°ºå¯¸ï¼ˆbatch sizeï¼‰æœ‰å…³ï¼Œå½“æ‰¹å°ºå¯¸ä¸º1ï¼Œéœ‡è¡ä¼šç›¸å¯¹è¾ƒå¤§ã€‚å½“æ‰¹å°ºå¯¸å°±æ˜¯æ•´ä¸ªæ•°æ®é›†æ—¶ï¼Œéœ‡è¡å°±ä¼šæœ€å°ã€‚</p><p><img src="/2018/01/21/neural-nets-note/loss.png" alt="loss"></p><p>â€‹</p></li><li><p><strong>è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‡†ç¡®ç‡</strong>ï¼šåœ¨è®­ç»ƒé›†å‡†ç¡®ç‡å’ŒéªŒè¯é›†å‡†ç¡®ç‡ä¸­é—´çš„ç©ºéš™æŒ‡æ˜äº†æ¨¡å‹è¿‡æ‹Ÿåˆçš„ç¨‹åº¦</p><p><img src="/2018/01/21/neural-nets-note/accuracies.jpeg" alt="accuracies"> </p></li><li><p><strong>æƒé‡æ›´æ–°æ¯”ä¾‹</strong>ï¼šæƒé‡ä¸­æ›´æ–°å€¼çš„æ•°é‡å’Œå…¨éƒ¨å€¼çš„æ•°é‡ä¹‹é—´çš„æ¯”ä¾‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># å‡è®¾å‚æ•°å‘é‡ä¸ºWï¼Œå…¶æ¢¯åº¦å‘é‡ä¸ºdW</span></div><div class="line">param_scale = np.linalg.norm(W.ravel())</div><div class="line">update = -learning_rate*dW <span class="comment"># ç®€å•SGDæ›´æ–°</span></div><div class="line">update_scale = np.linalg.norm(update.ravel())</div><div class="line">W += update <span class="comment"># å®é™…æ›´æ–°</span></div><div class="line"><span class="keyword">print</span> update_scale / param_scale <span class="comment"># è¦å¾—åˆ°1e-3å·¦å³</span></div></pre></td></tr></table></figure></li><li><p><strong>æ¯å±‚çš„æ¿€æ´»æ•°æ®åŠæ¢¯åº¦åˆ†å¸ƒ</strong>ï¼šå¯ä»¥è¾“å‡ºç½‘ç»œä¸­æ‰€æœ‰å±‚çš„æ¿€æ´»æ•°æ®å’Œæ¢¯åº¦åˆ†å¸ƒçš„æŸ±çŠ¶å›¾ã€‚å¦‚æœçœ‹åˆ°ä»»ä½•å¥‡æ€ªçš„åˆ†å¸ƒæƒ…å†µï¼Œé‚£éƒ½ä¸æ˜¯å¥½å…†å¤´ã€‚</p></li><li><p><strong>æƒé‡å¯è§†åŒ–</strong>ï¼šå¦‚æœæ•°æ®æ˜¯å›¾åƒåƒç´ æ•°æ®ï¼Œå¯ä»¥å¯¹ç¬¬ä¸€å±‚æƒé‡è¿›è¡Œå¯è§†åŒ–ï¼Œè§‚å¯Ÿç‰¹å¾åˆ†å¸ƒã€‚</p><p><img src="/2018/01/21/neural-nets-note/firstlayer.png" alt="accuracies"></p></li></ul><h3 id="æ¨¡å‹é›†æˆ"><a href="#æ¨¡å‹é›†æˆ" class="headerlink" title="æ¨¡å‹é›†æˆ"></a>æ¨¡å‹é›†æˆ</h3><p>æœ‰æ—¶å€™å•ä¸ªæ¨¡å‹å¹¶ä¸èƒ½æ»¡è¶³éœ€æ±‚ï¼Œå¯ä»¥è¿›è¡Œæ¨¡å‹é›†æˆæ¥è·å¾—é¢å¤–çš„æ€§èƒ½æé«˜ã€‚è¿›è¡Œé›†æˆæœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•ï¼š</p><ul><li><strong>åŒä¸€ä¸ªæ¨¡å‹ï¼Œä¸åŒçš„åˆå§‹åŒ–</strong>ï¼šä½¿ç”¨äº¤å‰éªŒè¯æ¥å¾—åˆ°æœ€å¥½çš„è¶…å‚æ•°ï¼Œç„¶åç”¨æœ€å¥½çš„å‚æ•°æ¥è®­ç»ƒä¸åŒåˆå§‹åŒ–æ¡ä»¶çš„æ¨¡å‹ã€‚</li><li><strong>åœ¨äº¤å‰éªŒè¯ä¸­å‘ç°æœ€å¥½çš„æ¨¡å‹</strong>ï¼šä½¿ç”¨äº¤å‰éªŒè¯æ¥å¾—åˆ°æœ€å¥½çš„è¶…å‚æ•°ï¼Œç„¶åå–å…¶ä¸­æœ€å¥½çš„å‡ ä¸ªï¼ˆæ¯”å¦‚10ä¸ªï¼‰æ¨¡å‹æ¥è¿›è¡Œé›†æˆã€‚</li><li><strong>ä¸€ä¸ªæ¨¡å‹è®¾ç½®å¤šä¸ªè®°å½•ç‚¹</strong>ï¼šå¦‚æœè®­ç»ƒéå¸¸è€—æ—¶ï¼Œé‚£å°±åœ¨ä¸åŒçš„è®­ç»ƒæ—¶é—´å¯¹ç½‘ç»œç•™ä¸‹è®°å½•ç‚¹ï¼ˆæ¯”å¦‚æ¯ä¸ªå‘¨æœŸç»“æŸï¼‰ï¼Œç„¶åç”¨å®ƒä»¬æ¥è¿›è¡Œæ¨¡å‹é›†æˆã€‚</li><li><strong>åœ¨è®­ç»ƒçš„æ—¶å€™è·‘å‚æ•°çš„å¹³å‡å€¼</strong>ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚æœæŸå¤±å€¼ç›¸è¾ƒäºå‰ä¸€æ¬¡æƒé‡å‡ºç°æŒ‡æ•°ä¸‹é™æ—¶ï¼Œå°±åœ¨å†…å­˜ä¸­å¯¹ç½‘ç»œçš„æƒé‡è¿›è¡Œä¸€ä¸ªå¤‡ä»½ã€‚</li></ul><h3 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h3><ol><li><p><a href="http://cs231n.github.io/neural-networks-2/" target="_blank" rel="external">http://cs231n.github.io/neural-networks-2/</a></p></li><li><p><a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="external">http://cs231n.github.io/neural-networks-3/</a></p></li><li><p><a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="external">Loss function</a></p><p>â€‹</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;åœ¨cs231nä¸Šå­¦ä¹ äº†å…³äºç¥ç»ç½‘ç»œä¸€ç³»åˆ—æ•°æ®å¤„ç†ã€å‚æ•°è®­ç»ƒã€ç»“æœåˆ†æçš„æ–¹æ³•ï¼Œä¸ºåŠ æ·±å°è±¡åšä¸€äº›æ•´ç†ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>è®­ç»ƒå…¨è¿æ¥ç½‘ç»œ</title>
    <link href="http://yoursite.com/2018/01/19/FullyConnectedNets-train/"/>
    <id>http://yoursite.com/2018/01/19/FullyConnectedNets-train/</id>
    <published>2018-01-19T03:08:25.000Z</published>
    <updated>2018-01-21T03:06:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>æœºå™¨å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ä¸æ˜¯ç›²ç›®çš„ï¼Œåº”è¯¥æŒæ¡ä¸€å®šçš„æŠ€å·§å’Œæ–¹æ³•ã€‚å‚è€ƒ<a href="https://www.reddit.com/r/cs231n/comments/443y2g/hints_for_a2/" target="_blank" rel="external">Hints for A2</a>å’Œ<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf" target="_blank" rel="external">Lecture</a>è®°å½•ä¸€ä¸‹FullyConnectedNetsçš„è®­ç»ƒè¿‡ç¨‹ã€‚åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰è¦å…ˆ<strong>é¢„å¤„ç†æ•°æ®</strong>å’Œ<strong>é€‰æ‹©ç½‘ç»œç»“æ„</strong>ï¼Œç„¶åæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹è®­(tiao)ç»ƒ(can)å•¦ï½</p><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>é¦–å…ˆæˆ‘ä»¬è¦å…ˆæ£€æµ‹ä¸€ä¸‹_loss_æ˜¯ä¸æ˜¯åˆç†çš„ï¼Œä¾‹å¦‚åä¸ªåˆ†ç±»ï¼Œlosså°±åº”è¯¥æ˜¯-np.log(0.1) = 2.3å·¦å³ã€‚</p><p>ç„¶åæˆ‘ä»¬éœ€è¦ç¡®ä¿åœ¨æœ€åˆçš„å‡ æ¬¡è¿­ä»£ä¸­_loss_æ˜¯ä¸‹é™çš„ï¼Œåœ¨è¿™é‡Œ_regularization_(L2/drop out)å¯ä»¥æ‰”æ‰ï¼Œ_learning rate decay_ä¹Ÿå¯ä»¥ä¸è®¾ç½®ã€‚æˆ‘ä»¬å°è¯•ä¸åŒçš„_weigtht scale_å’Œ_learning_rate_ï¼Œå°†ä¸¤è€…å®šä½åœ¨ä¸€ä¸ªå¤§è‡´èŒƒå›´ã€‚é‚£ä¹ˆå…ˆç”¨è¾ƒå°çš„æ•°æ®é›†å’Œ1ä¸ªepochæ¥è°ƒè°ƒ<strong>weight scale</strong>ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">weight_scale = [<span class="number">1e-5</span>, <span class="number">1e-3</span>, <span class="number">1e-1</span>, <span class="number">1e2</span>, <span class="number">1e6</span>]</div><div class="line"></div><div class="line"><span class="keyword">for</span> ws, lr, hl, ur <span class="keyword">in</span> product(weight_scale, learning_rate, hidden_layers, update_rule):</div><div class="line">    num_layer = len(hl)</div><div class="line">    model = FullyConnectedNet(hl, weight_scale=ws, use_batchnorm=<span class="keyword">False</span>)</div><div class="line">    solver = Solver(model, small_data,</div><div class="line">                    print_every=print_every, num_epochs=num_epochs, batch_size=batch_size,</div><div class="line">                    update_rule=ur,</div><div class="line">                    verbose=<span class="keyword">True</span>,</div><div class="line">                    optim_config=&#123;</div><div class="line">                      <span class="string">'learning_rate'</span>: lr</div><div class="line">                    &#125;</div><div class="line">                    </div><div class="line">             )</div><div class="line">    solver.train()</div></pre></td></tr></table></figure><p><img src="/2018/01/19/FullyConnectedNets-train/weight_scale1.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/weight_scale2.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/weight_scale3.png" alt=""></p><p>å¯ä»¥çœ‹å‡º <code>weight_scale=1e-1</code> çš„æ—¶å€™è¡¨ç°è¾ƒå¥½ï¼Œ1e+2å°±å¼€å§‹çˆ†ç‚¸äº†ã€‚Hintsé‡Œè¯´ReLU netsçš„lectureé‡Œç»™äº†â€correctâ€ valueï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯lectureé‡Œçš„1e-2ï¼Œä½†è®¾ç½®æˆè¿™ä¸ªå€¼è¡¨ç°ç¡®å®æ¯”è¾ƒå¥½ï¼Œæ‰€ä»¥å°±å®ƒäº†ï¼</p><p>æ¥ä¸‹æ¥è°ƒæ•´<strong>learning_rate</strong>æ¥æŸ¥çœ‹lossçš„å˜åŒ–ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">learning_rate = [<span class="number">1e-7</span>, <span class="number">1e-5</span>, <span class="number">1e-3</span>, <span class="number">1e-1</span>, <span class="number">1e2</span>]</div></pre></td></tr></table></figure><p><img src="/2018/01/19/FullyConnectedNets-train/lr1.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/lr2.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/lr3.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/lr4.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/lr5.png" alt=""></p><p>å¯ä»¥çœ‹åˆ°_learning_rate_å¤ªå°(1e-7)æ—¶ï¼Œlossçš„å˜åŒ–ä¸å¤§ï¼›å½“_learning_rate_å¤ªå¤§(1e+2)æ—¶ï¼Œlosså°±çˆ†ç‚¸äº†ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå°trickï¼šå½“çœ‹åˆ°loss &gt; 3å€çš„åˆå§‹å€¼æ—¶ï¼Œå°±å¯ä»¥åœæ­¢äº†ã€‚</p><h3 id="Learning-rate"><a href="#Learning-rate" class="headerlink" title="Learning rate"></a>Learning rate</h3><p>æˆ‘ä»¬å¤§è‡´çŸ¥é“äº†_learning_rate_åŒå­¦çš„è¡¨ç°æƒ…å†µï¼Œç°åœ¨å¼€å§‹ç¼©å°_learning_rate_çš„èŒƒå›´ï¼Œå¹¶ä½¿ç”¨åŸå§‹æ•°æ®é›†ï¼Œæ¥çœ‹çœ‹è®­ç»ƒç»“æœï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">learning_rate = [<span class="number">10</span> ** uniform(<span class="number">-5</span>, <span class="number">-1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>)]</div></pre></td></tr></table></figure><p>å…¶ä¸­æ¯”è¾ƒå¥½çš„å‡ ä¸ªç»“æœï¼š</p><p><img src="/2018/01/19/FullyConnectedNets-train/learning_rate1.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/learning_rate2.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/learning_rate3.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/learning_rate4.png" alt=""></p><p>å¯ä»¥çœ‹åˆ°1.74e-4åŒå­¦è¡¨ç°è¾ƒå¥½ï¼Œé‚£æˆ‘ä»¬å°±æŠŠlearning_rateè®¾ç½®ä¸ºè¿™ä¸ªï¼Œepochå¢åŠ ä¸º2ï¼Œå†æ¥çœ‹çœ‹lossçš„å˜åŒ–ï¼š</p><p><img src="/2018/01/19/FullyConnectedNets-train/lr_loss.png" alt=""></p><p>çœ‹åˆ°lossè¶‹äºå¹³å¦ï¼Œé‚£æˆ‘ä»¬æŠŠ<strong>learning rate decay</strong>è®¾ç½®ä¸º0.95çœ‹çœ‹æ•ˆæœï¼š</p><p><img src="/2018/01/19/FullyConnectedNets-train/lr_decay_95.png" alt=""></p><p>è¡¨ç°ä¼¼ä¹è¿˜ä¸å¦‚ä¸è®¾ç½®å‘¢ï¼Ÿé‚£æŠŠ<strong>learning rate decay</strong>è®¾ç½®ä¸º0.9ï¼š</p><p><img src="/2018/01/19/FullyConnectedNets-train/lr_decay_90.png" alt=""></p><p>å¥½åƒå·®åˆ«ä¹Ÿä¸å¤§ï¼Œé‚£è®¾ç½®å›1.0ã€‚ç„¶åå¼€å§‹è€ƒè™‘<strong>å¢å¼ºæ¨¡å‹è®­ç»ƒèƒ½åŠ›</strong></p><h3 id="Increasing-model-capacity"><a href="#Increasing-model-capacity" class="headerlink" title="Increasing model capacity"></a>Increasing model capacity</h3><p>ä¸€å¼€å§‹æˆ‘è®¾ç½®çš„ç½‘ç»œç»“æ„æ˜¯3å±‚ï¼Œæ¯å±‚100ä¸ªç¥ç»å…ƒï¼Œå¢å¼ºæ¨¡å‹çš„è®­ç»ƒèƒ½åŠ›å¯ä»¥é€šè¿‡<strong>å¢åŠ ç¥ç»å…ƒ</strong>æˆ–è€…<strong>å¢åŠ å±‚æ•°</strong>ã€‚ç„¶åå°±éœ€è¦é‡æ–°è®­ç»ƒå­¦ä¹ ç‡äº†ï¼ˆæœ›å¤©</p><p>æˆ‘å…ˆå°†å±‚æ•°å¢åŠ ä¸º5å±‚ï¼Œæ”¹ç”¨å°çš„æ•°æ®é›†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hidden_layers = [[<span class="number">100</span>]*i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>,<span class="number">6</span>)]</div></pre></td></tr></table></figure><p><img src="/2018/01/19/FullyConnectedNets-train/layer5_1.png" alt=""></p><p>å¯ä»¥çœ‹åˆ°è¿™ä¸ªç»“æœå¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œéœ€è¦é€šè¿‡ä¸Šé¢çš„æ–¹æ³•ï¼ŒæŸ¥æ‰¾åˆé€‚çš„å­¦ä¹ ç‡ã€‚</p><p><img src="/2018/01/19/FullyConnectedNets-train/layer5_2.png" alt=""></p><p><img src="/2018/01/19/FullyConnectedNets-train/layer5_3.png" alt=""></p><h3 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h3><p>å†³å®šä½¿ç”¨ä¸€ä¸‹<strong>batchnorm</strong>æ¥çœ‹çœ‹æ•ˆæœï½</p><p><img src="/2018/01/19/FullyConnectedNets-train/layer5_batch.png" alt=""></p><p>å¯ä»¥çœ‹åˆ°å‡†ç¡®ç‡ä¸€ä¸‹å­æé«˜äº†ï½ ä½†æ˜¯è¿˜æ²¡æœ‰è¾¾åˆ°æˆ‘ä»¬æƒ³è¦çš„50%ä»¥ä¸Šã€‚è¿™æ—¶å€™è®¾ç½®<strong>learning rate decay</strong>ä¸º0.95ï¼Œå¹¶è®­ç»ƒ2ä¸ªepochï¼Œå¯ä»¥çœ‹åˆ°å‡†ç¡®åº¦åˆæé«˜äº†ä¸€ç‚¹ã€‚ä½†æ˜¯è¿˜ä¸å¦‚ä¸Šé¢ä¸‰å±‚çš„ç»“æœï¼Ÿ</p><p><img src="/2018/01/19/FullyConnectedNets-train/layer5_decay.png" alt=""></p><p>ä¿ºç°åœ¨è¦æŠŠç¥ç»å…ƒåŠ åˆ°500ä¸ªï¼Œå›å»ç”¨ä¸‰å±‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hidden_layers = [[<span class="number">500</span>]*i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>,<span class="number">4</span>)]</div></pre></td></tr></table></figure><p><img src="/2018/01/19/FullyConnectedNets-train/layer3_500.png" alt=""></p><p>âœŒ åœ¨2ä¸ªepochå‡†ç¡®ç‡è¾¾åˆ°50%äº†ï¼Œå¼€å¿ƒï½</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;æœºå™¨å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ä¸æ˜¯ç›²ç›®çš„ï¼Œåº”è¯¥æŒæ¡ä¸€å®šçš„æŠ€å·§å’Œæ–¹æ³•ã€‚å‚è€ƒ&lt;a href=&quot;https://www.reddit.com/r/cs231n/comments/443y2g/hints_for_a2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hint
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>cs231n assignment1 å­¦ä¹ ç¬”è®°</title>
    <link href="http://yoursite.com/2017/11/10/cs231n-assignment1/"/>
    <id>http://yoursite.com/2017/11/10/cs231n-assignment1/</id>
    <published>2017-11-10T13:43:02.000Z</published>
    <updated>2017-12-10T09:53:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>ä½œä¸šçš„è¿è¡Œç¯å¢ƒæˆ‘é€‰æ‹©ã€ŒWorking locallyã€ã€‚åœ¨é…ç½®è™šæ‹Ÿç¯å¢ƒè¿‡ç¨‹ä¸­ï¼ŒæœçœŸé‡åˆ° matplotlib è¿è¡Œä¸äº†çš„é—®é¢˜ï¼Œå‚è€ƒ <a href="https://matplotlib.org/faq/osx_framework.html#osxframework-faq" target="_blank" rel="external">Working with Matplotlib on OSX</a>ï¼Œé™¤äº†æœ€åä¸€ä¸ªï¼Œå‡ ä¹æ¯ç§æ–¹æ³•è®¾ç½®ä¸€éï¼Œé‡å¯äº†å¥½å‡ æ¬¡è™šæ‹Ÿç¯å¢ƒï¼Œæœ€åå¯ä»¥ç”¨ jupyter notebook æ‰“å¼€ã€‚</p><h3 id="k-Nearest-Neighbor-kNN-exercise"><a href="#k-Nearest-Neighbor-kNN-exercise" class="headerlink" title="k-Nearest Neighbor (kNN) exercise"></a>k-Nearest Neighbor (kNN) exercise</h3><p>ç‚¹å‡»ã€Œrunã€æ‰§è¡Œæ¯ä¸ªæ¡†æ¡†ï¼Œ<code>dists = classifier.compute_distances_two_loops(X_test)</code> çœŸçš„è¦è¿è¡Œéå¸¸éå¸¸éå¸¸ä¹…ï¼ŒåŒæ—¶æ¡†æ¡†å·¦è¾¹ä¼šå·¦è¾¹å˜æˆ In [*]ï¼Œç„¶åæˆ‘å‚»å‚»çš„ä»¥ä¸ºå¡äº†ï¼Œé‡å¯äº†å¥½å¤šæ¬¡ï¼Œåæ¥æ‰é†’æ‚Ÿè¿™æ˜¯æ­£åœ¨è¿è¡Œçš„æ„æ€ã€‚</p><a id="more"></a><p>è¿›è¡Œé¢„æµ‹çš„æ—¶å€™å‘ç°å‡†ç¡®åº¦æ— è®ºå¦‚ä½•éƒ½æ˜¯0.14ï¼ŒæŸ¥äº†ä¸€ä¸‹å‘ç° <code>predict_labels</code> å‡½æ•°æ²¡æœ‰ä¿®æ”¹ğŸ˜‚ </p><p>äºŒæ¬¡å¾ªç¯çš„å‡½æ•°æ¯”è¾ƒç®€å•ï¼Œä¸€æ¬¡å¾ªç¯è¾¹æ´—æ¾¡è¾¹æ€è€ƒï¼Œç„¶åå¤´è„‘é£æš´çŸ©é˜µå˜æ¢ï¼Œå¼€å¿ƒåœ°æƒ³å‡ºæ¥äº†â˜ºï¸ æ ¸å¿ƒä»£ç <code>dists[i, :] = np.sqrt(np.sum((X[i, :] - self.X_train) ** 2, axis = 1)).T</code></p><p>æ— å¾ªç¯å‡½æ•°ä¼°æ‘¸ç€åº”è¯¥æ˜¯è¦è¿ç”¨æ•°å­¦å…¬å¼æ¥è§£å†³ã€‚å‡è®¾æµ‹è¯•é›†(2x3)ï¼š<br>$$<br>testX = \begin{pmatrix} x_{11}&amp;x_{12}&amp;x_{13} \\x_{21}&amp;x_{22}&amp;x_{23} \end{pmatrix}<br>$$<br>è®­ç»ƒé›†(4x3)ï¼š<br>$$<br>trainX = \begin{pmatrix}y_{11}&amp;y_{12}&amp;y_{13} \\y_{21}&amp;y_{22}&amp;y_{23}\\y_{31}&amp;y_{32}&amp;y_{33}\\y_{41}&amp;y_{42}&amp;y_{43}\ \end{pmatrix}<br>$$<br>æœ€åç”Ÿæˆ dist (2x4) çš„è·ç¦»çŸ©é˜µï¼Œè‡ªç„¶è”æƒ³åˆ°çŸ©é˜µä¹˜æ³• (2x4) := (2x3) x (3x4)ã€‚åˆšå¥½ä»£ç ä¸­ä¹Ÿæœ‰æç¤ºçŸ©é˜µä¹˜æ³•ï¼Œé‚£ä¹ˆ \(trainX\) å¿…ç„¶æ˜¯è½¬ç½®ä¸€ä¸‹çš„ã€‚<br>$$<br>trainX^T = \begin{pmatrix}y_{11}&amp;y_{21}&amp;y_{31}&amp;y_{41} \\y_{12}&amp;y_{22}&amp;y_{32}&amp;y_{42}\\y_{13}&amp;y_{23}&amp;y_{33}&amp;y_{43}\\ \end{pmatrix}<br>$$<br>æˆ‘ä»¬å–å‡ºä¸€ä¸ªæµ‹è¯•é›†å’Œä¸€ä¸ªè®­ç»ƒé›†ï¼Œè®¡ç®—ä¸€ä¸‹å®ƒä»¬çš„æ¬§æ°è·ç¦»ï¼š<br>$$<br>dist[1, 1] = \sqrt{(x_{11}-y_{11})^2 + (x_{12}-y_{12})^2 + (x_{13}-y_{13})^2 }<br>$$<br>æˆ‘ä»¬è¯•ä¸€ä¸‹æŠŠæ¯ä¸ªå¹³æ–¹æ‹†å¼€ï¼š<br>$$<br>dist[1, 1] = \sqrt{x_{11}^2 - 2x_{11}y_{11}+y_{11}^2 + x_{12}^2 - 2x_{12}y_{12}+y_{12}^2+x_{13}^2 - 2x_{13}y_{13}+y_{13}^2}<br>$$<br>æ•´ç†å‡ºæ ¹å·é‡Œå¤´çš„å®¶ä¼™ï¼š<br>$$<br>x_{11}^2+ x_{12}^2+x_{13}^2 +y_{11}^2+y_{12}^2 +y_{13}^2 - 2(x_{11}y_{11}   +x_{12}y_{12}+ x_{13}y_{13})<br>$$<br>å—¯ã€‚ã€‚ã€‚å†ä¸€æ¬¡æ„Ÿå¹æ•°å­¦ä¹‹ç¾ã€‚ã€‚ã€‚äºæ˜¯ã€Œæ ¹å·é‡Œå¤´çš„å®¶ä¼™ã€å°±è¢«åˆ†æˆäº†ä¸‰ä¸ªéƒ¨åˆ†</p><ul><li>\(x_{11}^2+ x_{12}^2 +x_{13}^2\) ç›¸å½“äº \(testX\) å…ƒç´ å¹³æ–¹ï¼Œå†æŒ‰åˆ—ç›¸åŠ ï¼Œå³æŠŠçŸ©é˜µå‹ç¼©æˆä¸€åˆ—ã€‚</li><li>\(y_{11}^2+y_{12}^2 +y_{13}^2\) ç›¸å½“äº \(trainX^T\) å…ƒç´ å¹³æ–¹ï¼Œå†æŒ‰è¡Œç›¸åŠ  ï¼Œå³æŠŠçŸ©é˜µå‹ç¼©æˆä¸€è¡Œã€‚</li><li>\(x_{11}y_{11}   +x_{12}y_{12}+ x_{13}y_{13}\) ç›¸å½“äº\(testX * trainX\)</li></ul><p>äºæ˜¯å°±å¯ä»¥<strong>broadcasting</strong>å•¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">transXtrain = self.X_train.T <span class="comment"># è½¬ç½®è®­ç»ƒé›†</span></div><div class="line">sumX = np.sum(X ** <span class="number">2</span>, axis = <span class="number">1</span>)[:, np.newaxis] <span class="comment">#ï¼ˆ500x1ï¼‰</span></div><div class="line">sumtransXtrain = np.sum(transXtrain ** <span class="number">2</span>, axis = <span class="number">0</span>)[np.newaxis] <span class="comment">#ï¼ˆ1x5000ï¼‰</span></div><div class="line">dists = np.sqrt( sumX + sumtransXtrain - <span class="number">2</span> * np.dot(X, transXtrain)) <span class="comment"># broadcasting &amp; matrix multiplication</span></div></pre></td></tr></table></figure><p>æœ€åä¸€ä¸ªéƒ¨åˆ†æ˜¯å…³äºk-æŠ˜äº¤å‰éªŒè¯ï¼Œæ ¹æ®ä½œä¸šæç¤ºï¼Œå¾ªç¯æ¯ä¸ªå¯èƒ½çš„kå€¼ï¼Œè¿è¡Œk-nnç®—æ³• num_folds æ¬¡ï¼Œæ¯æ¬¡é€‰æ‹©ä¸€ä¸ªå­é›†ä½œä¸ºè®­ç»ƒé›†ï¼Œæœ€åä¸€ä¸ªå­é›†ä¸ºéªŒè¯é›†ã€‚ä½†å‚è€ƒäº†ç½‘ä¸Šå…³äº10æŠ˜äº¤å‰éªŒè¯çš„è¯´æ³•ï¼Œæ˜¯è½®æµå°†å…¶ä¸­9ä»½ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œ1ä»½ä½œä¸ºæµ‹è¯•æ•°æ®çš„ã€‚æ‰€ä»¥æˆ‘å°±å¾ªç¯äº†num+folds-1æ¬¡ã€‚ï¼ˆååˆå‚è€ƒç½‘ä¸Šå…¶ä»–å®ç°ä»£ç ï¼Œå‘ç°åº”è¯¥é€‰æ‹©ä¸€ä¸ªè‡ªå·±ä½œä¸ºéªŒè¯é›†ï¼Œå…¶ä»–æ‰€æœ‰è‡ªå·±åˆå¹¶ä½œä¸ºè®­ç»ƒé›†ã€‚ï¼‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">size = X_train_folds[<span class="number">0</span>].shape[<span class="number">0</span>]</div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</div><div class="line">    k_to_accuracies[k] = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_folds<span class="number">-1</span>): <span class="comment"># each case </span></div><div class="line">        classifier.train(X_train_folds[i], y_train_folds[i]) <span class="comment"># use one as training data</span></div><div class="line">        predict_labels = classifier.predict(X_train_folds[<span class="number">-1</span>], k, num_loops = <span class="number">0</span>)</div><div class="line">        accuracy = sum(predict_labels == y_train_folds[<span class="number">-1</span>]) / size <span class="comment"># last fold as validation set</span></div><div class="line">        k_to_accuracies[k].append(accuracy)</div></pre></td></tr></table></figure><p><img src="/2017/11/10/cs231n-assignment1/knn.png" alt="cross-validation"></p><p>æœ€åæ ¹æ®äº¤å‰éªŒè¯çš„ç»“æœé€‰æ‹©k=8æœ€ä½³ã€‚</p><h3 id="Multiclass-Support-Vector-Machine-exercise"><a href="#Multiclass-Support-Vector-Machine-exercise" class="headerlink" title="Multiclass Support Vector Machine exercise"></a>Multiclass Support Vector Machine exercise</h3><p>åœ¨ç¬¬ä¸€éƒ¨åˆ†è¡¥å……dWå°±å¡äº†è¶…çº§ä¹…ã€‚ã€‚ã€‚é¦–å…ˆè¦å…ˆçœ‹å®˜æ–¹çš„è¯¾ç¨‹ç¬”è®° <a href="http://cs231n.github.io/optimization-1/#opt3" target="_blank" rel="external">optimization-1</a> ï¼Œæˆ‘ä»¬è¦ä½¿ç”¨å¾®ç§¯åˆ†æ¥è®¡ç®—dWã€‚å½“ $j = y_j $æ—¶å…¬å¼å¦‚ä¸‹ï¼š<br>$$<br>\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} ğŸ™(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) \right) x_i<br>$$<br>ä»£è¡¨æ¢¯åº¦å‡å°‘ margin &gt; 0 çš„ä¸ªæ•°ä¹˜ä»¥æ ·æœ¬ã€‚</p><p>å½“ $ j  \neq y_j $æ—¶ï¼Œå…¬å¼å¦‚ä¸‹ï¼š<br>$$<br>\nabla_{w_j} L_i = \ ğŸ™(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) x_i<br>$$<br>é¦–å…ˆæ˜¯å®ç”¨å¾ªç¯æ–¹å¼çš„å‡½æ•°ã€‚ä¸€å¼€å§‹æˆ‘æƒ³ç€é‚£å°±ç”¨å½“ margin &gt; 0 æ—¶è®¾ç½®ä¸€ä¸ªcntæ¥è¿›è¡Œè®¡æ•°ï¼Œç„¶åè¿˜å¼„äº†ä¸€ä¸ªéå¸¸éº»çƒ¦çš„ tile</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">correct_j = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_train):</div><div class="line">  cnt = <span class="number">0</span></div><div class="line">  scores = X[i].dot(W) <span class="comment"># (1, C)</span></div><div class="line">  correct_class_score = scores[y[i]]</div><div class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_classes):</div><div class="line">    <span class="keyword">if</span> j == y[i]:</div><div class="line">      correct_j = j</div><div class="line">      <span class="keyword">continue</span></div><div class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note delta = 1</span></div><div class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</div><div class="line">        loss += margin</div><div class="line">        cnt += <span class="number">1</span></div><div class="line">        </div><div class="line">  dW_test = np.tile(X[i].T[:,np.newaxis],(<span class="number">1</span>, num_classes)) <span class="comment"># é”™çš„é”™çš„</span></div><div class="line">  dW_test[:, correct_j] =  cnt * X[i].T</div></pre></td></tr></table></figure><p>åœ¨å®åœ¨æƒ³ä¸å‡ºæ¥çš„æƒ…å†µä¸‹ï¼Œå·å·æ‰¾äº†ä¸€ä¸‹å…¶ä»–åŒå­¦çš„ä»£ç ï¼Œå‘ç°å…¶å®åªè¦éå¸¸ç®€å•çš„</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> margin &gt; <span class="number">0</span>:</div><div class="line">loss += margin</div><div class="line">    dW[:, j] += X[i].T</div><div class="line">    dW[:, y[i]] -= X[i].T</div></pre></td></tr></table></figure><p>è¿™é‡Œæ„è¯†åˆ°äº†è‡ªå·±ä»£ç çš„ä¸¤ä¸ªé—®é¢˜ï¼š</p><ul><li><p>åå¯¼éƒ½æ˜¯ç´¯ç§¯çš„è¿‡ç¨‹ä¹Ÿå°±æ˜¯è¯´ä¸­é—´çš„ç¬¦å·æ˜¯ += æˆ–è€… -= </p></li><li><p>å½“ $ j \neq y_j $ æ—¶ï¼ŒdWåªæœ‰ç›¸åº”çš„ j åˆ—å‘ç”Ÿå˜åŒ–ã€‚</p></li><li><p>$$<br>\hat{y}(x) := \underbrace {w_0 + \sum_{i=1}^{n} w_i x_i }_{\text{çº¿æ€§å›å½’}} + \underbrace {\sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{ij} x_i x_j}_{\text{äº¤å‰é¡¹ï¼ˆç»„åˆç‰¹å¾ï¼‰}} \qquad \text{(n.ml.1.9.1)}<br>$$</p></li></ul><p>æ¥ä¸‹æ¥æ˜¯ä½¿ç”¨å‘é‡æ–¹å¼çš„å‡½æ•°ã€‚æ ¹æ® <a href="http://cs231n.github.io/linear-classify/#softmax" target="_blank" rel="external">linear classification note</a> å†™å‡ºä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">margins = np.maximum(<span class="number">0</span>, scores - scores[y] + <span class="number">1</span>)</div></pre></td></tr></table></figure><p>ä½†åœ¨è¿™é‡Œæˆ‘æµ‹è¯•äº†ä¸€ä¸‹ </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; print(scores[y].shape)</div><div class="line"></div><div class="line">(500,10)</div></pre></td></tr></table></figure><p>é¢„æ–™ä¸­ç»“æœåº”è¯¥æ˜¯ä¸€ä¸ªå‘é‡ï¼Œç”±labelç´¢å¼•æ‰€åœ¨å€¼ç»„æˆã€‚ä½†äº‹å®è¯æ˜<code>scores[y]</code>åªæ˜¯æŠŠscoersé‡æ–°æ’åˆ—äº†ä¸€æ¬¡ã€‚å‚è€ƒ<a href="https://stackoverflow.com/questions/37290879/how-to-extract-elements-from-a-matrix-using-a-vector-of-indices-using-numpy" target="_blank" rel="external">[1]</a>ï¼Œä¿®æ”¹ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">margins = np.maximum(<span class="number">0</span>, scores - scores[np.arange(scores.shape[<span class="number">0</span>]), y][:, np.newaxis] + <span class="number">1</span>)</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(scores[0]- scores[0][y[0]]) #1</div><div class="line">print((scores - scores[np.arange(scores.shape[0]), y][:, np.newaxis])[0]) #2</div><div class="line">print((scores - scores[y])[0]) #3</div><div class="line">print(scores[0]-scores[y[0]]) #4</div></pre></td></tr></table></figure><p>éªŒè¯ä¸€ä¸‹ï¼š12ç»“æœä¸€è‡´ï¼Œ34ç»“æœä¸€è‡´ï¼Œ12å’Œ34ä¸ä¸€è‡´ã€‚</p><p>åŒæ—¶ä¹Ÿè¦è®°å¾—åœ¨marginsä¸Šä½œlabelç´¢å¼•å¤„ç†ï¼Œå®Œæ•´æ ¸å¿ƒä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">num_train = X.shape[<span class="number">0</span>]</div><div class="line">scores = X.dot(W) <span class="comment"># scores.shape =  (N, C)</span></div><div class="line">margins = np.maximum(<span class="number">0</span>, scores - scores[np.arange(num_train), y][:, np.newaxis] + <span class="number">1</span>)</div><div class="line">margins[np.arange(num_train), y] = <span class="number">0</span> </div><div class="line">loss = np.sum(margins) / num_train + reg * np.sum(W * W)</div></pre></td></tr></table></figure><p>ä½¿ç”¨å‘é‡æ¥å®Œæˆæ¢¯åº¦ä¹Ÿå¡äº†æŒºä¹…ã€‚æç¤ºè¯´é‡ç”¨è®¡ç®—è¿‡çš„å€¼ï¼Œé‚£è‚¯å®šå°±æ˜¯marginså•¦ï¼Œé€šè¿‡å®ƒä»¬shapeæ¥åˆ¤æ–­äº†ä¸€ä¸‹ï¼Œä¼°æ‘¸ç€è¦ç”¨X.T(D, N) * margins(N, C)æ¥å®Œæˆï¼Œä½†æ˜¯ç©ºæƒ³ä¸å‡ºæ¥ï¼Œäºæ˜¯å†™ä¸€ä¸ªå…·ä½“çš„ä¾‹å­æ¥ç†è§£ä¸€ä¸‹ï¼š</p><p><img src="/2017/11/10/cs231n-assignment1/svm_dw.jpg" alt="IMG_3133(20171115-204831)"></p><p>å› ä¸ºæˆ‘ä»¬åªéœ€åˆ¤æ–­marginsæ˜¯å¦å¤§äº0ï¼Œé¦–å…ˆå°†å…¶è½¬åŒ–ä¸ºåªå«0ï¼Œ1çš„çŸ©é˜µã€‚æ¥ç€å¯ä»¥è®¡ç®—å‡ºæ¯ä¸€è¡Œ1çš„æ•°é‡ï¼ˆå³margin&gt;0çš„ä¸ªæ•°ï¼‰ï¼Œå°†åˆ†ç±»æ‰€åœ¨ä½ç½®æ”¹ä¸ºè¯¥æ•°é‡ï¼Œæœ€åä¸Xçš„è½¬ç½®ç›¸ä¹˜å³å¯ã€‚å®Œæ•´ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mat = np.zeros(margins.shape) <span class="comment"># mat.shape = N x C</span></div><div class="line">idx = np.where(margins &gt; <span class="number">0</span>) <span class="comment"># return index of margins &gt; 0</span></div><div class="line">mat[idx] = <span class="number">1</span> </div><div class="line">count = np.sum(mat, axis=<span class="number">1</span>) <span class="comment"># count the number of margins &gt; 0</span></div><div class="line">mat[np.arange(num_train), y] = -count </div><div class="line"></div><div class="line">dW = np.dot(X.T, mat) / num_train</div></pre></td></tr></table></figure><p>ä½†ç´ plot lossçš„ç»“æœé•¿è¿™æ ·ã€‚ã€‚ã€‚æ€»è§‰å¾—å“ªé‡Œæ€ªæ€ªçš„</p><p><img src="/2017/11/10/cs231n-assignment1/plot_loss.png" alt="IMG_3133(20171115-204831)"></p><p>ç„¶åplot weightsçš„ç»“æœé•¿è¿™æ ·ã€‚ã€‚ã€‚æ›´è§‰å¾—å“ªé‡Œæ€ªæ€ªçš„äº†</p><p><img src="/2017/11/10/cs231n-assignment1/plot_weights1.png" alt="IMG_3133(20171115-204831)"></p><p>æ„Ÿè°¢è¸©è¿‡å‘çš„åŒå­¦ <a href="https://bruceoutdoors.wordpress.com/2016/05/06/cs231n-assignment-1-tutorial-q2-training-a-support-vector-machine/" target="_blank" rel="external">https://bruceoutdoors.wordpress.com/2016/05/06/cs231n-assignment-1-tutorial-q2-training-a-support-vector-machine/</a> åŸæ¥æ˜¯dWå¿˜è®°åšæ­£åˆ™åŒ–äº†ã€‚åŠ ä¸Š<code>dW += reg * W </code>æˆ‘ä»¬å°±å¯ä»¥çœ‹è§å…‰æ»‘çš„æ›²çº¿å’Œå¤šæ ·çš„è‰²å½©äº†ï¼Œå™¢è€¶ï¼</p><p><img src="/2017/11/10/cs231n-assignment1/plot_loss2.png" alt="IMG_3133(20171115-204831)"></p><p><img src="/2017/11/10/cs231n-assignment1/plot_weights2.png" alt="IMG_3133(20171115-204831)"></p><h3 id="Softmax-exercise"><a href="#Softmax-exercise" class="headerlink" title="Softmax exercise"></a>Softmax exercise</h3><p>è¿™æ¬¡ä½œä¸šå’Œsvmçš„ç±»ä¼¼ï¼Œåˆ†åˆ«é€šè¿‡å¾ªç¯å’ŒçŸ©é˜µè¿ç®—å®ç°softmaxï¼Œè®¡ç®—losså’Œgradient</p><p>é¦–å…ˆæ˜¯é€šè¿‡å¾ªç¯å®ç°ï¼Œç†è§£ä¸€ä¸‹softmaxçš„å…¬å¼</p><p><img src="/2017/11/10/cs231n-assignment1/softmax_loss.png" alt=""></p><p>æ ¹æ® <a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf" target="_blank" rel="external">lecture3-slides</a>ï¼Œsoftmaxçš„scoresæ˜¯éæ ‡å‡†åŒ–çš„logæ¦‚ç‡ï¼ˆæ‹¬å·é‡Œçœ‹èµ·æ¥ç›¸å½“å¤æ‚ï¼Œå…¶å®å°±æ˜¯æ¦‚ç‡ï¼‰ã€‚è®¡ç®—è¿‡ç¨‹çœ‹ä¸‹å›¾æ¯”è¾ƒæ˜ç¡®ï¼š</p><p><img src="/2017/11/10/cs231n-assignment1/probability.png" alt=""></p><p>ä¸€å¼€å§‹è¿˜æŒ‰ç…§å…¬å¼å¾ªç¯è®¡ç®—ï¼Œç„¶åå‘ç°æ ‡å‡†åŒ–åï¼Œæ¦‚ç‡ç›¸åŠ ä¸º1ï¼Œå› æ­¤åªè¦å–å‡ºæ‰€å±ç±»åˆ«çš„æ¦‚ç‡logå°±å¯ä»¥äº†ï¼Œso easyï½</p><p>å…³äºæ¢¯åº¦çš„è®¡ç®—ç»“åˆäº†wikiä»¥åŠå‚è€ƒ <a href="https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function" target="_blank" rel="external">derivative-of-softmax-loss-function</a> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></div><div class="line">  â€œâ€â€œçœç•¥éƒ¨åˆ†ä»£ç â€â€œâ€</div><div class="line">  num_train = X.shape[<span class="number">0</span>]</div><div class="line">  num_classes = W.shape[<span class="number">1</span>]</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):</div><div class="line">    scores = X[i].dot(W)  <span class="comment"># (1,C)</span></div><div class="line">    probabilities = np.exp(scores) <span class="comment"># exp</span></div><div class="line">    probabilities /= np.sum(probabilities) <span class="comment">#normalize</span></div><div class="line">    loss -= np.log(probabilities[y[i]]) <span class="comment">#log</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes): <span class="comment"># pi-yi</span></div><div class="line">      <span class="keyword">if</span>(j == y[i]):</div><div class="line">        dW[:, j] += X[i] * (probabilities[y[i]] - <span class="number">1</span>)</div><div class="line">      <span class="keyword">else</span>:</div><div class="line">        dW[:, j] += X[i] * probabilities[j]</div></pre></td></tr></table></figure><p>ç„¶åè®©æˆ‘ä»¬è¿æ¥çŸ©é˜µçš„è®¡ç®—ï½</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></div><div class="line">  <span class="string">"""çœç•¥éƒ¨åˆ†ä»£ç """</span></div><div class="line">  num_train = X.shape[<span class="number">0</span>]</div><div class="line">  scores = X.dot(W)</div><div class="line">  probabilities = np.exp(scores) <span class="comment"># exp</span></div><div class="line">  probabilities /= np.sum(probabilities, axis=<span class="number">1</span>)[:, np.newaxis] <span class="comment"># normalize</span></div><div class="line"></div><div class="line">  mat = probabilities[np.arange(num_train), y] <span class="comment"># è·å–å¯¹åº”åˆ†ç±»çš„æ¦‚ç‡</span></div><div class="line">  loss = -np.sum(np.log(mat)) / num_train + reg * np.sum(W * W)</div><div class="line"></div><div class="line">  mat = np.zeros_like(probabilities) </div><div class="line">  mat[np.arange(num_train), y] = <span class="number">1</span> <span class="comment"># å¯¹åº”åˆ†ç±»ç½®ä¸º1</span></div><div class="line">  dW = X.T.dot(probabilities - mat) / num_train</div></pre></td></tr></table></figure><h3 id="Implementing-a-Neural-Network"><a href="#Implementing-a-Neural-Network" class="headerlink" title="Implementing a Neural Network"></a>Implementing a Neural Network</h3><p>lossçš„è®¡ç®—å‚è€ƒä¸Šé¢çš„softmaxï¼Œä½†æ˜¯è¦æ³¨æ„æ­£åˆ™åŒ–æ—¶W1å’ŒW2éƒ½éœ€è¦åŠ ä¸Š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># è®¡ç®—loss</span></div><div class="line">probabilities = np.exp(scores)  <span class="comment"># exp</span></div><div class="line">probabilities /= np.sum(probabilities, axis=<span class="number">1</span>)[:, np.newaxis]  <span class="comment"># normalize</span></div><div class="line">mat = probabilities[np.arange(N), y]  <span class="comment"># è·å–å¯¹åº”åˆ†ç±»çš„æ¦‚ç‡</span></div><div class="line">loss = -np.sum(np.log(mat)) / N + reg * (np.sum(W1*W1) + np.sum(W2*W2))</div></pre></td></tr></table></figure><p>åå‘ä¼ æ’­çš„æ—¶å€™æœ‰ä¸€é¡¹å¾ˆé‡è¦çš„<code>dh1[h1 &lt;=0] = 0</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># è®¡ç®—backward pass</span></div><div class="line"><span class="comment"># softmax gradient derivation</span></div><div class="line">dscores = probabilities</div><div class="line">dscores[range(N), y] -= <span class="number">1</span></div><div class="line">dscores /= N  <span class="comment"># (N, C)</span></div><div class="line"><span class="comment"># dW2 and db2</span></div><div class="line">grads[<span class="string">'W2'</span>] = h1.T.dot(dscores) + <span class="number">2</span> * reg * W2 <span class="comment"># (H, C)</span></div><div class="line">grads[<span class="string">'b2'</span>] = np.sum(dscores, axis=<span class="number">0</span>)</div><div class="line"><span class="comment"># next backprop into hidden layer</span></div><div class="line">dh1 = dscores.dot(W2.T) <span class="comment"># dh1.size = (N, H)</span></div><div class="line">dh1[h1 &lt;=<span class="number">0</span>] = <span class="number">0</span></div><div class="line"><span class="comment"># dW1 and db1</span></div><div class="line">grads[<span class="string">'W1'</span>] = X.T.dot(dh1) + <span class="number">2</span> * reg * W1 <span class="comment"># W1.size = (D, H)</span></div><div class="line">grads[<span class="string">'b1'</span>] = np.sum(dh1, axis = <span class="number">0</span>)</div></pre></td></tr></table></figure><p>ä½œä¸šè¦æ±‚è¯´æœ‰å‚æ•°çš„å¯¼æ•°å€¼ä¸æ•°å€¼è®¡ç®—å‡ºçš„å·®å€¼åº”è¯¥å°äº1e-8ï¼Œä¹‹å‰æ­£åˆ™åŒ–çš„æ—¶å€™éƒ½æ˜¯ä½¿ç”¨<code>reg * W2</code>ï¼Œä½†æ˜¯ç°åœ¨è¦ä¹˜ä»¥2ä»¥åè¯¯å·®æ‰ä¼šå°äº1e-11ï¼ˆåŒ…æ‹¬åé¢å‡†ç¡®ç‡ä¹Ÿä¼šé«˜ä¸€äº›ï¼‰</p><p>predictçš„æ—¶å€™æ³¨æ„ä½¿ç”¨ReLuï¼Œå¦åˆ™å°±å¡åœ¨0.38ä»¥ä¸‹ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œå‡†ç¡®ç‡ä¸Šä¸å»0.4ã€‚</p><p><img src="/2017/11/10/cs231n-assignment1/hs300.png" alt=""></p><p>ä¸‹é¢æˆ‘ä»¬è¦å¼€å§‹è°ƒå‚å•¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">best_net = <span class="keyword">None</span> <span class="comment"># store the best model into this </span></div><div class="line">best_val = <span class="number">-1</span></div><div class="line">results = &#123;&#125;</div><div class="line"></div><div class="line">hidden_size = [<span class="number">200</span>, <span class="number">300</span>, <span class="number">500</span>, <span class="number">800</span>, <span class="number">1000</span>]</div><div class="line">learning_rate = [<span class="number">9e-4</span>]</div><div class="line">iters = [<span class="number">100</span>]</div><div class="line">regularization_strength = [<span class="number">0.01</span>]</div><div class="line"></div><div class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> *</div><div class="line"></div><div class="line"><span class="keyword">for</span> item <span class="keyword">in</span> product(hidden_size, learning_rate, iters, regularization_strength):</div><div class="line">    </div><div class="line">    hs = item[<span class="number">0</span>]</div><div class="line">    lr = item[<span class="number">1</span>]</div><div class="line">    it = item[<span class="number">2</span>]</div><div class="line">    rg = item[<span class="number">3</span>]</div><div class="line">    net = TwoLayerNet(input_size, hs, num_classes)</div><div class="line"></div><div class="line">    <span class="comment"># Train the network</span></div><div class="line">    stats = net.train(X_train, y_train, X_val, y_val,</div><div class="line">                num_iters=it, batch_size=<span class="number">200</span>,</div><div class="line">                learning_rate=lr, learning_rate_decay=<span class="number">0.95</span>,</div><div class="line">                reg=rg, verbose=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Predict on the validation set</span></div><div class="line">    val_acc = (net.predict(X_val) == y_val).mean()</div><div class="line">    train_acc = (net.predict(X_train) == y_train).mean()</div><div class="line">    results[(hs, lr, it, rg)] = (train_acc, val_acc)</div><div class="line">    </div><div class="line">    <span class="comment"># Check best validation accuracy</span></div><div class="line">    <span class="keyword">if</span>(val_acc &gt; best_val):</div><div class="line">        best_val = val_acc</div><div class="line">        best_net = net</div><div class="line">        </div><div class="line"><span class="comment"># Print out results.\</span></div><div class="line"><span class="keyword">for</span> hs, lr, it, reg <span class="keyword">in</span> sorted(results):</div><div class="line">    </div><div class="line">    train_acc, val_acc = results[(hs, lr, it, reg)]</div><div class="line">    print(<span class="string">'hs:%d it:%d lr:%e rg:%e train_acc:%f val_accï¼š%f'</span> %(hs, it, lr, reg, train_acc, val_acc))</div><div class="line">print(<span class="string">'best validation accuracy achieved during cross-validation: %f'</span> % best_val)</div></pre></td></tr></table></figure><p>é¦–å…ˆæˆ‘ä»¬å›ºå®šå­¦ä¹ ç‡ã€è¿­ä»£æ¬¡æ•°ï¼ˆå°ä¸€ç‚¹ï¼‰ã€æ­£åˆ™åŒ–ç³»æ•°ï¼Œä¿®æ”¹éšè—å±‚å¤§å° = [200, 300, 500, 800, 1000]</p><p><img src="/2017/11/10/cs231n-assignment1/change_hs.png" alt=""></p><p>å¾ˆæ˜æ˜¾éšè—å±‚è¶Šå¤§ç²¾ç¡®åº¦æ›´é«˜ï¼Œæ¥ä¸‹æ¥å›ºå®šå…¶ä»–å‚æ•°ï¼Œæ¥è°ƒæ•´ä¸€ä¸‹å­¦ä¹ ç‡</p><p>å‘ç°å­¦ä¹ ç‡åœ¨ &gt; -e2 æ•°é‡çº§éƒ½ä¼šæŠ¥é”™ï¼Ÿï¼Ÿï¼Ÿåº”è¯¥æ˜¯å­¦ä¹ ç‡å¤ªå¤§ä¼šå¯¼è‡´Wè¶…å‡º-1åˆ°1çš„èŒƒå›´å§ã€‚</p><p><img src="/2017/11/10/cs231n-assignment1/learning_rate_error.png" alt=""></p><p>æµ‹è¯•å­¦ä¹ ç‡ = [3e-3, 4e-4, 5e-5, 6e-6]</p><p><img src="/2017/11/10/cs231n-assignment1/change_lr1.png" alt=""></p><p>ä¼¼ä¹å­¦ä¹ ç‡å¤§ä¸€äº›çš„ç»“æœæ¯”è¾ƒå¥½ï¼Œé‚£åœ¨è¿™ä¸ªæ•°é‡çº§å‘¨å›´å†æµ‹è¯•ä¸€ä¸‹</p><p><img src="/2017/11/10/cs231n-assignment1/change_lr2.png" alt=""></p><p>8e-2çš„å­¦ä¹ ç‡è¿˜æ˜¯å´©å•¦ï¼Œè¿™æ ·çœ‹èµ·æ¥å­¦ä¹ ç‡è®¾ç½®æˆ2e=eä¼šæ¯”è¾ƒå¥½ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è°ƒå¤§è¿­ä»£æ¬¡æ•°å’Œéšè—å±‚å¤§å°ï¼Œæ¥è°ƒæ•´æ­£åˆ™åŒ–å‚æ•°</p><p><img src="/2017/11/10/cs231n-assignment1/change_hs_rg.png" alt=""></p><p>å˜»å˜»æœ€é«˜åˆ°0.534äº†ï¼Œå¯ä»¥åŠ åˆ†äº†ï½</p><p><strong>å‚è€ƒé“¾æ¥</strong></p><ul><li><a href="https://stackoverflow.com/questions/37290879/how-to-extract-elements-from-a-matrix-using-a-vector-of-indices-using-numpy" target="_blank" rel="external">https://stackoverflow.com/questions/37290879/how-to-extract-elements-from-a-matrix-using-a-vector-of-indices-using-numpy</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ä½œä¸šçš„è¿è¡Œç¯å¢ƒæˆ‘é€‰æ‹©ã€ŒWorking locallyã€ã€‚åœ¨é…ç½®è™šæ‹Ÿç¯å¢ƒè¿‡ç¨‹ä¸­ï¼ŒæœçœŸé‡åˆ° matplotlib è¿è¡Œä¸äº†çš„é—®é¢˜ï¼Œå‚è€ƒ &lt;a href=&quot;https://matplotlib.org/faq/osx_framework.html#osxframework-faq&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Working with Matplotlib on OSX&lt;/a&gt;ï¼Œé™¤äº†æœ€åä¸€ä¸ªï¼Œå‡ ä¹æ¯ç§æ–¹æ³•è®¾ç½®ä¸€éï¼Œé‡å¯äº†å¥½å‡ æ¬¡è™šæ‹Ÿç¯å¢ƒï¼Œæœ€åå¯ä»¥ç”¨ jupyter notebook æ‰“å¼€ã€‚&lt;/p&gt;
&lt;h3 id=&quot;k-Nearest-Neighbor-kNN-exercise&quot;&gt;&lt;a href=&quot;#k-Nearest-Neighbor-kNN-exercise&quot; class=&quot;headerlink&quot; title=&quot;k-Nearest Neighbor (kNN) exercise&quot;&gt;&lt;/a&gt;k-Nearest Neighbor (kNN) exercise&lt;/h3&gt;&lt;p&gt;ç‚¹å‡»ã€Œrunã€æ‰§è¡Œæ¯ä¸ªæ¡†æ¡†ï¼Œ&lt;code&gt;dists = classifier.compute_distances_two_loops(X_test)&lt;/code&gt; çœŸçš„è¦è¿è¡Œéå¸¸éå¸¸éå¸¸ä¹…ï¼ŒåŒæ—¶æ¡†æ¡†å·¦è¾¹ä¼šå·¦è¾¹å˜æˆ In [*]ï¼Œç„¶åæˆ‘å‚»å‚»çš„ä»¥ä¸ºå¡äº†ï¼Œé‡å¯äº†å¥½å¤šæ¬¡ï¼Œåæ¥æ‰é†’æ‚Ÿè¿™æ˜¯æ­£åœ¨è¿è¡Œçš„æ„æ€ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ã€ŠMachine Learning in Actionã€‹å­¦ä¹ ç¬”è®°äº”ï¼šè‡ªé€‚åº”å¢å¼ºç®—æ³•</title>
    <link href="http://yoursite.com/2017/11/05/machine-learning-in-action-note5/"/>
    <id>http://yoursite.com/2017/11/05/machine-learning-in-action-note5/</id>
    <published>2017-11-05T01:14:40.000Z</published>
    <updated>2017-11-23T03:18:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>AdaBoostç®—æ³•æ˜¯ä¸€ç§å…ƒç®—æ³•ã€‚å…ƒç®—æ³•ï¼ˆmeta-algorithmï¼‰ä¹Ÿå«é›†æˆæ–¹æ³•ï¼ˆensemble methodï¼‰ï¼Œé€šè¿‡å°†å…¶ä»–ç®—æ³•è¿›è¡Œç»„åˆè€Œå½¢æˆæ›´ä¼˜çš„ç®—æ³•ï¼Œç»„åˆæ–¹å¼åŒ…æ‹¬ï¼šä¸åŒç®—æ³•çš„é›†æˆï¼Œæ•°æ®é›†ä¸åŒéƒ¨åˆ†é‡‡ç”¨ä¸åŒç®—æ³•åˆ†ç±»åçš„é›†æˆæˆ–è€…åŒä¸€ç®—æ³•åœ¨ä¸åŒè®¾ç½®ä¸‹çš„é›†æˆã€‚ä¸‹é¢æˆ‘ä»¬è®¨è®ºä¸¤ç§ä½¿ç”¨å¼±åˆ†ç±»å™¨å’Œå¤šä¸ªå®ä¾‹æ„å»ºä¸€ä¸ªå¼ºåˆ†ç±»å™¨çš„æŠ€æœ¯ï¼š</p><ul><li><p>Baggingï¼ˆbootstrap aggregatingï¼‰</p><p>Baggingå³å¥—è¢‹æ³•ï¼Œä»åŸå§‹æ•°æ®é›†ä¸­éšæœºæŠ½å–nä¸ªè®­ç»ƒæ ·æœ¬ï¼ŒæŠ½å–Sæ¬¡åï¼Œå¾—åˆ°Sä¸ªæ–°æ•°æ®é›†ï¼ˆå…¶ä¸­çš„éšæœºæ„å‘³ç€å¯èƒ½ä¼šæŠ½å–åˆ°é‡å¤æ ·æœ¬ï¼‰ã€‚å°†æŸä¸ªå­¦ä¹ ç®—æ³•åˆ†åˆ«ä½œç”¨äºæ¯ä¸ªæ•°æ®é›†å¾—åˆ°Sä¸ªåˆ†ç±»å™¨ã€‚å½“å¯¹æ–°æ•°æ®è¿›è¡Œåˆ†ç±»æ—¶ï¼Œè¿ç”¨Sä¸ªåˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»ï¼Œé€‰æ‹©æŠ•ç¥¨ç»“æœä¸­æœ€é«˜çš„ç±»åˆ«ä½œä¸ºåˆ†ç±»ç»“æœã€‚</p></li><li><p>Boosting</p><p>Boostingæœ€å¸¸è§çš„ç®—æ³•æ˜¯AdaBoostï¼ˆAdaptive Boostingï¼‰ã€‚ä¸åŒçš„åˆ†ç±»å™¨æ˜¯é€šè¿‡ä¸²è¡Œè®­ç»ƒè·å¾—ï¼Œæ¯ä¸ªæ–°åˆ†ç±»å™¨æ ¹æ®å·²è®­ç»ƒå‡ºçš„åˆ†ç±»å™¨çš„æ€§èƒ½æ¥è¿›è¡Œè®­ç»ƒã€‚Boostingæ˜¯é€šè¿‡å…³æ³¨è¢«å·²æœ‰åˆ†ç±»å™¨é”™åˆ†çš„é‚£äº›æ•°æ®æ¥è·å¾—æ–°çš„åˆ†ç±»å™¨ã€‚</p><p>æ ¹æ®<a href="https://www.kesci.com/apps/home/project/5a0aecde60680b295c25f5d8" target="_blank" rel="external">LightGBMä»‹ç»è§†é¢‘</a>å¯¹Bosstingåšä¸€äº›è¡¥å……ï¼šæœ¬è´¨ä¸Šæ¥è¯´ï¼ŒBoostingçš„æ–¹æ³•éƒ½æ˜¯åœ¨è®­ç»ƒå¥½ä¸€ä¸ªå­æ¨¡å‹åï¼Œç»Ÿè®¡ä¸€ä¸‹ç°æœ‰å¤åˆæ¨¡å‹çš„æ‹Ÿåˆæƒ…å†µï¼Œä»è€Œè°ƒèŠ‚æ¥ä¸‹æ¥å­¦ä¹ ä»»åŠ¡çš„settingï¼Œä½¿å¾—æ¥ä¸‹æ¥åŠ å…¥å¤åˆæ¨¡å‹çš„å­æ¨¡å‹ç¬¦åˆé™ä½æ•´ä½“lossçš„ç›®æ ‡ã€‚</p></li></ul><p>Baggingä¸­åˆ†ç±»å™¨æƒé‡æ˜¯ç›¸ç­‰çš„ã€‚è€ŒBoostingä¸­åˆ†ç±»å™¨çš„æƒé‡æ˜¯ä¸ç›¸ç­‰çš„ï¼Œåˆ†ç±»çš„ç»“æœæ˜¯åŸºäºæ‰€æœ‰åˆ†ç±»å™¨åŠ æƒæ±‚å’Œçš„ç»“æœï¼Œæ¯ä¸ªæƒé‡ä»£è¡¨çš„æ˜¯å…¶åˆ†ç±»å™¨åœ¨ä¸Šä¸€è½®è¿­ä»£çš„æˆåŠŸåº¦ã€‚</p><a id="more"></a><p>AdaBoostçš„æ¯ä¸ªæ ·æœ¬éƒ½æœ‰ä¸€ä¸ªæƒé‡ï¼Œæ„æˆå‘é‡Dã€‚é¦–å…ˆåˆå§‹åŒ–æ¯ä¸ªæ ·æœ¬çš„æƒé‡ç›¸ç­‰ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå‡ºä¸€ä¸ªå¼±åˆ†ç±»å™¨ï¼Œç„¶åè®¡ç®—å‡ºé”™è¯¯ç‡ ğï¼Œé€šè¿‡é”™è¯¯ç‡è®¡ç®—è¯¥åˆ†ç±»å™¨çš„ alpha å€¼ï¼Œé€šè¿‡è¿™ä¸ª alpha å€¼è®¡ç®—è¯¥åˆ†ç±»å™¨çš„æƒé‡ã€‚<br>$$<br>ğœ¶ = \frac{1}{2}\ln\frac{1-ğ}{ğ}<br>$$<br>æ¥ç€å¯¹æƒé‡åšå‡ºè°ƒæ•´ï¼Œé™ä½åˆ†å¯¹çš„æ ·æœ¬æƒé‡ï¼Œ<br>$$<br>D_{i+1} = \frac{D_i^{i}e^{-ğœ¶}}{Sum(D)}<br>$$</p><p>æé«˜åˆ†é”™çš„æ ·æœ¬æƒé‡ã€‚</p><p>$$<br>D_{i+1} = \frac{D_i^{i}e^{ğœ¶}}{Sum(D)}<br>$$<br>ä¸æ–­è¿­ä»£è¾¾åˆ°ä¸€å®šæ•°é‡æˆ–é”™è¯¯ç‡ä¸º0ï¼Œæœ€åè¾“å‡ºé›†æˆçš„å¼±åˆ†ç±»å™¨ï¼Œé€šè¿‡åŠ æƒæ¥è¿›è¡Œé¢„æµ‹ã€‚ç®—æ³•è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/2017/11/05/machine-learning-in-action-note5/adaboost.png" alt="adaboost"></p><p>###è®­ç»ƒï¼šå†³ç­–æ ‘æ¡©</p><p>ç®—æ³•çš„å…³é”®å°±åœ¨äºå¦‚ä½•è®­ç»ƒå¼±åˆ†ç±»å™¨ï¼Œå¹¶æŠŠå®ƒä»¬é›†æˆä¸€ä¸ªå¼ºåˆ†ç±»å™¨ã€‚æœ¬ç« æˆ‘ä»¬ä½¿ç”¨å†³ç­–æ ‘æ¡©ï¼ˆdecision stumpï¼‰æ¥å®ç°AdaBoostã€‚å†³ç­–æ ‘æ¡©çš„æ ‘æ¡©æ„å‘³ç€æˆ‘ä»¬åªç”¨å•ä¸ªç‰¹å¾æ¥è¿›è¡Œå†³ç­–ã€‚é¦–å…ˆæˆ‘ä»¬è®¾å®šä¸€ä¸ªé˜ˆå€¼ _threshVal_ ä¸æ¯”è¾ƒè§„åˆ™ _threshIneq_ ï¼Œåœ¨è§„åˆ™ä¸‹åˆ¤æ–­ç‰¹å¾å€¼ä¸é˜ˆå€¼çš„å¤§å°ã€‚å½“ _threshIneq == â€˜ltâ€™_ï¼Œå°†æ‰€æœ‰æ¯” _threshVal_ å°çš„å½’ä¸º -1ï¼›å½“ _threshIneq == â€˜gtâ€™_ æ—¶ï¼Œå°†æ‰€æœ‰æ¯” _threshVal_ å¤§çš„å½’ä¸º1ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span><span class="params">(data, dimen, threshVal, threshIneq)</span>:</span></div><div class="line">    <span class="string">"""æµ‹è¯•æ˜¯å¦æŸä¸ªå€¼å¤§äºæˆ–å°äºé˜ˆå€¼"""</span></div><div class="line">    retArr = ones((shape(data)[<span class="number">0</span>], <span class="number">1</span>))</div><div class="line">    <span class="keyword">if</span> threshIneq == <span class="string">'lt'</span>:</div><div class="line">        retArr[data[:, dimen] &lt;= threshVal] = <span class="number">-1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        retArr[data[:, dimen] &gt; threshVal] = <span class="number">-1</span></div><div class="line">    <span class="keyword">return</span> retArr</div></pre></td></tr></table></figure><p>è¿™é‡Œåˆ©ç”¨æ•°ç»„è¿‡æ»¤æ¥å¯¹æ¯”é˜ˆå€¼å¤§å° <code>retArr[data[:, dimen] &lt;= threshVal]</code> å¯ä»¥å¾ˆç®€å•æ»´è·å–åˆ°è¿”å›æ•°ç»„ï¼Œè¿™ä¸ªè¿”å›æ•°ç»„å°±æ˜¯ä¸€ä¸ªå¼±åˆ†ç±»å™¨é¢„æµ‹çš„ç»“æœã€‚å»ºç«‹å†³ç­–æ ‘æ¡©çš„è¿‡ç¨‹å°±æ˜¯æ‰¾å‡ºé”™è¯¯ç‡æœ€ä½çš„å¼±åˆ†ç±»å™¨ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span><span class="params">(data, labels, D)</span>:</span></div><div class="line">    <span class="string">"""éå†æ ·æœ¬çš„æ¯ä¸€åˆ—ï¼Œè¿”å›é”™è¯¯ç‡æœ€å°çš„å¼±åˆ†ç±»å™¨"""</span></div><div class="line">    dataMat = mat(data); labelMat = mat(labels).T</div><div class="line">    m, n = shape(dataMat)</div><div class="line">    numSteps = <span class="number">10</span>; bestStump = &#123;&#125;; bestClassEst = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    minError = inf</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n): <span class="comment"># æ¯ä¸ªç‰¹å¾</span></div><div class="line">        rangeMin = dataMat[:, i].min(); rangeMax = dataMat[:, i].max()</div><div class="line">        stepSize = (rangeMax - rangeMin) / numSteps</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">-1</span>, int(numSteps + <span class="number">1</span>)): <span class="comment"># æ¯ä¸ªæ­¥é•¿</span></div><div class="line">            <span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">'lt'</span>, <span class="string">'gt'</span>]: <span class="comment"># æ¯ä¸ªä¸ç­‰å·</span></div><div class="line">                threshVal = (rangeMin + float(j) * stepSize)</div><div class="line">                predictedVals = stumpClassify(dataMat, i, threshVal, inequal) <span class="comment"># å»ºç«‹ä¸€æ£µå†³ç­–æ ‘æ¡©</span></div><div class="line">                errArr = mat(ones((m, <span class="number">1</span>)))</div><div class="line">                errArr[predictedVals ==  labelMat] = <span class="number">0</span></div><div class="line"></div><div class="line">                <span class="comment"># è®¡ç®—é”™è¯¯ç‡</span></div><div class="line">                <span class="comment"># AdaBoostå’Œåˆ†ç±»å™¨äº¤äº’çš„åœ°æ–¹</span></div><div class="line">                weightedError = D.T * errArr</div><div class="line">                <span class="comment">#print("split: dim %d, thresh %.2f, thresh inequal: %s, the weighted error is %.3f" %(i, threshVal, inequal, weightedError))</span></div><div class="line">                <span class="keyword">if</span> weightedError &lt; minError: <span class="comment"># ä¿å­˜é”™è¯¯ç‡è¾ƒå°çš„å¼±åˆ†ç±»å™¨</span></div><div class="line">                    minError = weightedError</div><div class="line">                    bestClassEst = predictedVals.copy() <span class="comment"># é¢„æµ‹ç»“æœ</span></div><div class="line">                    bestStump[<span class="string">'dim'</span>] = i</div><div class="line">                    bestStump[<span class="string">'thresh'</span>] = threshVal</div><div class="line">                    bestStump[<span class="string">'ineq'</span>] = inequal</div><div class="line">    <span class="keyword">return</span> bestStump, minError, bestClassEst</div></pre></td></tr></table></figure><p>æˆ‘ä»¬çŸ¥é“äº†å¦‚ä½•å»ºç«‹ä¸€ä¸ªå¼±åˆ†ç±»å™¨ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥å°±åˆ°äº†é›†æˆå¼±åˆ†ç±»å™¨çš„éƒ¨åˆ†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span><span class="params">(data, labels, numIt = <span class="number">40</span>)</span>:</span></div><div class="line">    weakClassArr = []</div><div class="line">    m = shape(data)[<span class="number">0</span>]</div><div class="line">    <span class="comment"># Dä¿å­˜æ¯ä¸ªæ ·æœ¬çš„æƒé‡</span></div><div class="line">    <span class="comment"># AdaBoostç®—æ³•ä¼šé™ä½åˆ†å¯¹çš„æ ·æœ¬æƒé‡ï¼Œæé«˜åˆ†é”™çš„æ ·æœ¬æƒé‡</span></div><div class="line">    D = mat(ones((m, <span class="number">1</span>))/m)</div><div class="line">    aggClassEst = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</div><div class="line">        bestStump, error, classEst = buildStump(data, labels, D)</div><div class="line">        <span class="comment"># è®¡ç®—è¯¥åˆ†ç±»å™¨çš„æƒé‡</span></div><div class="line">        alpha = float(<span class="number">.5</span> * log((<span class="number">1</span> - error) / max(error, <span class="number">1e-16</span>))) <span class="comment"># ç¡®ä¿æ²¡æœ‰é”™è¯¯æ—¶ä¸å‘ç”Ÿé™¤é›¶æº¢å‡º</span></div><div class="line">        bestStump[<span class="string">'alpha'</span>] = alpha</div><div class="line">        weakClassArr.append(bestStump)</div><div class="line"></div><div class="line">        <span class="comment"># 1 / è®¡ç®—ä¸‹ä¸€æ¬¡è¿­ä»£çš„æƒé‡å‘é‡D</span></div><div class="line">        expon = multiply(<span class="number">-1</span> * alpha * mat(labels).T, classEst)</div><div class="line">        D = multiply(D, exp(expon))</div><div class="line">        D = D / D.sum() <span class="comment"># Dæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ, sum = 1</span></div><div class="line"></div><div class="line">        <span class="comment"># 2 / è®¡ç®—æ€»é”™è¯¯ç‡</span></div><div class="line">        aggClassEst += alpha * classEst</div><div class="line">        aggErrors = multiply(sign(aggClassEst) != mat(labels).T, ones((m, <span class="number">1</span>)))</div><div class="line">        errorRate = aggErrors.sum() / m</div><div class="line">        <span class="keyword">if</span> errorRate == <span class="number">0</span>: <span class="keyword">break</span></div><div class="line">    <span class="keyword">return</span> weakClassArr</div></pre></td></tr></table></figure><p>###åˆ†ç±»ï¼šåˆ†ç±»å™¨åŠ æƒ</p><p>å°†æ¯ä¸ªå¼±åˆ†ç±»å™¨çš„ç»“æœè¿›è¡ŒåŠ æƒï¼Œè¾“å‡ºæœ€ç»ˆé¢„æµ‹çš„åˆ†ç±»ç»“æœ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span><span class="params">(datToClass, classifierArr)</span>:</span></div><div class="line">    dataMatrix = mat(datToClass)</div><div class="line">    m = shape(dataMatrix)[<span class="number">0</span>]</div><div class="line">    aggClassEst = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(classifierArr)): <span class="comment"># æ¯ä¸ªå¼±åˆ†ç±»å™¨</span></div><div class="line">        classEst = stumpClassify(dataMatrix, classifierArray[i][<span class="string">'dim'</span>],classifierArray[i][<span class="string">'thresh'</span>], classifierArray[i][<span class="string">'ineq'</span>])</div><div class="line">        aggClassEst += classifierArr[i][<span class="string">'alpha'</span>] * classEst <span class="comment"># åŠ æƒ</span></div><div class="line">    <span class="comment"># è¿”å›é¢„æµ‹ç»“æœ</span></div><div class="line">    <span class="keyword">return</span> sign(aggClassEst)</div></pre></td></tr></table></figure><h3 id="éå‡è¡¡åˆ†ç±»é—®é¢˜ï¼šROCæ›²çº¿"><a href="#éå‡è¡¡åˆ†ç±»é—®é¢˜ï¼šROCæ›²çº¿" class="headerlink" title="éå‡è¡¡åˆ†ç±»é—®é¢˜ï¼šROCæ›²çº¿"></a>éå‡è¡¡åˆ†ç±»é—®é¢˜ï¼šROCæ›²çº¿</h3><p>ä¹‹å‰æˆ‘ä»¬éƒ½åªç”¨é”™è¯¯ç‡æ¥åˆ¤æ–­åˆ†ç±»å™¨çš„å¥½åï¼Œå‡è®¾åˆ†ç±»é—®é¢˜çš„ç»“æœæ˜¯ä¸å‡è¡¡çš„ï¼Œæ¯”å¦‚é¢„æµ‹ä¸€ä¸ªäººä¸€ä¸ªäººå¾—ç™Œç—‡ï¼æ²¡æœ‰å¾—ç™Œç—‡ï¼Œè¿™ä¸ªåˆ†ç±»çš„ä»£ä»·æ˜¯ä¸åŒçš„ï¼Œåªçœ‹é”™è¯¯ç‡æ˜¯æ²¡ä»€ä¹ˆæ„ä¹‰çš„ã€‚å› æ­¤æˆ‘ä»¬å¼•å…¥ä¸€äº›åˆ«çš„æ€§èƒ½æŒ‡æ ‡æ¥åˆ¤æ–­åˆ†ç±»å™¨</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">+1</th><th style="text-align:center">-1</th></tr></thead><tbody><tr><td style="text-align:center">+1</td><td style="text-align:center">çœŸæ­£ä¾‹ï¼ˆTPï¼‰</td><td style="text-align:center">ä¼ªåä¾‹ï¼ˆFNï¼‰</td></tr><tr><td style="text-align:center">-1</td><td style="text-align:center">ä¼ªæ­£ä¾‹ï¼ˆFPï¼‰</td><td style="text-align:center">çœŸåä¾‹ï¼ˆTNï¼‰</td></tr></tbody></table><ul><li>æ­£ç¡®ç‡ï¼ˆPrecisionï¼‰ = TP /ï¼ˆTP + FPï¼‰</li><li>å¬å›ç‡ï¼ˆRecallï¼‰ = TP /ï¼ˆTP + FNï¼‰</li></ul><p>ROCä»£è¡¨æ¥å—è€…ç‰¹å¾ï¼ˆreciver operating characteristicï¼‰æ›²çº¿ã€‚æ¨ªè½´æ˜¯ä¼ªæ­£ä¾‹çš„æ¯”ä¾‹ ï¼ˆå‡é˜³ç‡ = FP /ï¼ˆFP+TNï¼‰ï¼‰ï¼Œçºµè½´æ˜¯çœŸæ­£ä¾‹çš„æ¯”ä¾‹ï¼ˆçœŸé˜³ç‡ = TP / ï¼ˆTP + FNï¼‰ï¼‰ã€‚</p><blockquote><p>ä¸ºäº†åˆ›å»ºROCæ›²çº¿ï¼Œé¦–å…ˆå°†åˆ†ç±»æ ·ä¾‹æŒ‰ç…§å…¶æµ‹è¯•å¼ºåº¦æ’åºã€‚å…ˆä»æ’åæœ€ä½çš„æ ·ä¾‹å¼€å§‹ï¼Œæ‰€æœ‰æ’åæ›´ä½çš„æ ·ä¾‹éƒ½è¢«è§†ä¸ºåä¾‹ï¼Œè€Œæ‰€æœ‰æ’åæ›´é«˜çš„æ ·ä¾‹éƒ½è¢«åˆ¤ä¸ºæ­£ä¾‹ã€‚è¯¥æƒ…å†µå¯¹åº”ç‚¹ä¸º(1, 1)ã€‚ç„¶åå°†å…¶ç§»åˆ°æ’åæ¬¡ä½çš„æ ·ä¾‹ä¸­å»ï¼Œå¦‚æœè¯¥æ ·ä¾‹å±äºæ­£ä¾‹ï¼Œé‚£ä¹ˆå¯¹çœŸé˜³ç‡è¿›è¡Œä¿®æ”¹ï¼›å¦‚æœè¯¥æ ·ä¾‹å±äºåä¾‹ï¼Œé‚£ä¹ˆå¯¹å‡é˜´ç‡è¿›è¡Œä¿®æ”¹ã€‚</p></blockquote><p>è™½ç„¶æ²¡çœ‹æ‡‚ä¸Šé¢è¿™æ®µè¯ï¼Œä½†çœ‹æ‡‚äº†åŸä»£ç ï¼Œæ„Ÿè§‰å¾ªç¯ <code>for index in sortedIndicies.tolist()[0]</code> è¶…è¿·çš„ï¼Œtolist() æ˜¯ä»€ä¹ˆé¬¼ï¼Œ[0] åˆæ˜¯ä»€ä¹ˆé¬¼ã€‚å¯¹åŸå‡½æ•°è¿›è¡Œåˆ†æï¼Œé¦–å…ˆæ˜¯å¯¹ä¼ å…¥å‚æ•° _aggClassEst_ è¿›è¡Œ _argsort_ æ’åºã€‚_aggClassEst_ æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œ shape ==  (298,1)ï¼Œå¦‚æœç›´æ¥æ’åºç»“æœå¦‚ä¸‹ï¼š</p><p><img src="/2017/11/05/machine-learning-in-action-note5/argsort1.png" alt=""></p><p>å¦‚æœå°†å…¶è½¬ç½®å†è¿›è¡Œæ’åºç»“æœå¦‚ä¸‹ï¼š</p><p><img src="/2017/11/05/machine-learning-in-action-note5/argsort2.png" alt=""></p><p>æ ¹æ® <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.argsort.html" target="_blank" rel="external">numpy.argsort</a> å…³äºä¸€ç»´æ•°ç»„çš„æ’åºï¼Œæˆ‘ä»¬å…ˆå°†å…¶è½¬æ¢ä¸ºä¸€ç»´æ•°ç»„ï¼Œå¹¶å°†å…¶<strong>shape</strong>è½¬æ¢ (298 ,)ã€‚è½¬æ¢æœ‰ä¸¤ç§æ–¹æ³•ï¼š</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">aggClassEst.getA().reshape((-1, ))</div></pre></td></tr></table></figure></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">squeeze(aggClassEst.getA())</div></pre></td></tr></table></figure></li></ul><p>åœ¨è¿™é‡Œç®€å•è¯´æ˜ä¸€ä¸‹ (Rï¼Œ1)å’Œ (Rï¼Œ) çš„åŒºåˆ«ã€‚NumPyæ•°ç»„çš„<strong>shape</strong>ä¸º (Rï¼Œ ) æ„å‘³ç€è¿™ä¸ªæ•°ç»„åªæœ‰ä¸€ä¸ªç´¢å¼•ï¼Œä»¥ä¸€ä¸ªæœ‰12ä¸ªå…ƒç´ çš„æ•°ç»„ä¸ºä¾‹ï¼š</p><p><img src="/2017/11/05/machine-learning-in-action-note5/narray1.png" alt=""></p><p>å½“æˆ‘ä»¬å°†å…¶ <code>reshape((3, 4))</code> åï¼Œå®ƒæœ‰äº†ä¸¤ä¸ªç´¢å¼•ï¼š</p><p><img src="/2017/11/05/machine-learning-in-action-note5/reshape34.png" alt=""></p><p>å½“æˆ‘ä»¬ <code>reshape((12, 1))</code>ï¼Œå®ƒå…¶å®ä¹Ÿæ˜¯æœ‰ä¸¤ä¸ªç´¢å¼•ï¼Œåªæ˜¯å…¶ä¸­ä¸€ä¸ªæ’ä¸º0ï¼š</p><p><img src="/2017/11/05/machine-learning-in-action-note5/reshape1.png" alt=""></p><p>äºæ˜¯ä¿®æ”¹ä»£ç </p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotROC</span><span class="params">(predStrengths, classLabels)</span>:</span></div><div class="line">    cur = (<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># ä¿ç•™ç»˜åˆ¶å…‰æ ‡çš„ä½ç½®</span></div><div class="line">    ySum = <span class="number">0</span> <span class="comment"># è®¡ç®—AUC</span></div><div class="line">    numPosClas = sum(array(classLabels) == <span class="number">1</span>)</div><div class="line">    yStep = <span class="number">1</span> / float(numPosClas)</div><div class="line">    xStep = <span class="number">1</span> / float(len(classLabels) - numPosClas)</div><div class="line">    <span class="comment"># è·å–æ’åºåçš„ç´¢å¼•</span></div><div class="line">    <span class="comment"># ä» (1, 1) ç»˜åˆ¶åˆ° (0, 0)</span></div><div class="line">    sortedIndicies = predStrengths.argsort()</div><div class="line">    <span class="comment"># fig = plt.figure();  fig.clf();ax = plt.subplot(111)</span></div><div class="line">    fig, ax = plt.subplots()</div><div class="line">    <span class="comment"># for index in sortedIndicies.tolist()[0]:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> sortedIndicies:</div><div class="line">        print(predStrengths[i])</div><div class="line">        <span class="keyword">if</span> classLabels[i] == <span class="number">1</span>:</div><div class="line">            delX = <span class="number">0</span>; delY = yStep</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            delX = xStep; delY = <span class="number">0</span></div><div class="line">            ySum += cur[<span class="number">1</span>]</div><div class="line">        ax.plot([cur[<span class="number">0</span>], cur[<span class="number">0</span>]-delX], [cur[<span class="number">1</span>], cur[<span class="number">1</span>]-delY], c= <span class="string">'b'</span>)</div><div class="line">        cur = (cur[<span class="number">0</span>] - delX, cur[<span class="number">1</span>] - delY)</div><div class="line">    ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">'b--'</span>)</div><div class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>)</div><div class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>)</div><div class="line">    ax.axis([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</div><div class="line">    plt.show()</div><div class="line">    print(<span class="string">"the Area Under the Curve is: "</span>, ySum * xStep)</div><div class="line"></div><div class="line">predStrengths = aggClassEst.getA().reshape((<span class="number">-1</span>, ))</div><div class="line">plotROC(predStrengths, labels)</div></pre></td></tr></table></figure><p><img src="/2017/11/05/machine-learning-in-action-note5/roc.png" alt=""></p><p><strong>å‚è€ƒé“¾æ¥</strong></p><p>1) <a href="https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r" target="_blank" rel="external">Difference between numpy.array shape (R, 1) and (R,)</a></p><p>2ï¼‰<a href="https://www.kesci.com/apps/home/project/5a0aecde60680b295c25f5d8" target="_blank" rel="external">LIghtGBMå®˜æ–¹ä»‹ç»è§†é¢‘</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AdaBoostç®—æ³•æ˜¯ä¸€ç§å…ƒç®—æ³•ã€‚å…ƒç®—æ³•ï¼ˆmeta-algorithmï¼‰ä¹Ÿå«é›†æˆæ–¹æ³•ï¼ˆensemble methodï¼‰ï¼Œé€šè¿‡å°†å…¶ä»–ç®—æ³•è¿›è¡Œç»„åˆè€Œå½¢æˆæ›´ä¼˜çš„ç®—æ³•ï¼Œç»„åˆæ–¹å¼åŒ…æ‹¬ï¼šä¸åŒç®—æ³•çš„é›†æˆï¼Œæ•°æ®é›†ä¸åŒéƒ¨åˆ†é‡‡ç”¨ä¸åŒç®—æ³•åˆ†ç±»åçš„é›†æˆæˆ–è€…åŒä¸€ç®—æ³•åœ¨ä¸åŒè®¾ç½®ä¸‹çš„é›†æˆã€‚ä¸‹é¢æˆ‘ä»¬è®¨è®ºä¸¤ç§ä½¿ç”¨å¼±åˆ†ç±»å™¨å’Œå¤šä¸ªå®ä¾‹æ„å»ºä¸€ä¸ªå¼ºåˆ†ç±»å™¨çš„æŠ€æœ¯ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Baggingï¼ˆbootstrap aggregatingï¼‰&lt;/p&gt;
&lt;p&gt;Baggingå³å¥—è¢‹æ³•ï¼Œä»åŸå§‹æ•°æ®é›†ä¸­éšæœºæŠ½å–nä¸ªè®­ç»ƒæ ·æœ¬ï¼ŒæŠ½å–Sæ¬¡åï¼Œå¾—åˆ°Sä¸ªæ–°æ•°æ®é›†ï¼ˆå…¶ä¸­çš„éšæœºæ„å‘³ç€å¯èƒ½ä¼šæŠ½å–åˆ°é‡å¤æ ·æœ¬ï¼‰ã€‚å°†æŸä¸ªå­¦ä¹ ç®—æ³•åˆ†åˆ«ä½œç”¨äºæ¯ä¸ªæ•°æ®é›†å¾—åˆ°Sä¸ªåˆ†ç±»å™¨ã€‚å½“å¯¹æ–°æ•°æ®è¿›è¡Œåˆ†ç±»æ—¶ï¼Œè¿ç”¨Sä¸ªåˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»ï¼Œé€‰æ‹©æŠ•ç¥¨ç»“æœä¸­æœ€é«˜çš„ç±»åˆ«ä½œä¸ºåˆ†ç±»ç»“æœã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Boosting&lt;/p&gt;
&lt;p&gt;Boostingæœ€å¸¸è§çš„ç®—æ³•æ˜¯AdaBoostï¼ˆAdaptive Boostingï¼‰ã€‚ä¸åŒçš„åˆ†ç±»å™¨æ˜¯é€šè¿‡ä¸²è¡Œè®­ç»ƒè·å¾—ï¼Œæ¯ä¸ªæ–°åˆ†ç±»å™¨æ ¹æ®å·²è®­ç»ƒå‡ºçš„åˆ†ç±»å™¨çš„æ€§èƒ½æ¥è¿›è¡Œè®­ç»ƒã€‚Boostingæ˜¯é€šè¿‡å…³æ³¨è¢«å·²æœ‰åˆ†ç±»å™¨é”™åˆ†çš„é‚£äº›æ•°æ®æ¥è·å¾—æ–°çš„åˆ†ç±»å™¨ã€‚&lt;/p&gt;
&lt;p&gt;æ ¹æ®&lt;a href=&quot;https://www.kesci.com/apps/home/project/5a0aecde60680b295c25f5d8&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;LightGBMä»‹ç»è§†é¢‘&lt;/a&gt;å¯¹Bosstingåšä¸€äº›è¡¥å……ï¼šæœ¬è´¨ä¸Šæ¥è¯´ï¼ŒBoostingçš„æ–¹æ³•éƒ½æ˜¯åœ¨è®­ç»ƒå¥½ä¸€ä¸ªå­æ¨¡å‹åï¼Œç»Ÿè®¡ä¸€ä¸‹ç°æœ‰å¤åˆæ¨¡å‹çš„æ‹Ÿåˆæƒ…å†µï¼Œä»è€Œè°ƒèŠ‚æ¥ä¸‹æ¥å­¦ä¹ ä»»åŠ¡çš„settingï¼Œä½¿å¾—æ¥ä¸‹æ¥åŠ å…¥å¤åˆæ¨¡å‹çš„å­æ¨¡å‹ç¬¦åˆé™ä½æ•´ä½“lossçš„ç›®æ ‡ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Baggingä¸­åˆ†ç±»å™¨æƒé‡æ˜¯ç›¸ç­‰çš„ã€‚è€ŒBoostingä¸­åˆ†ç±»å™¨çš„æƒé‡æ˜¯ä¸ç›¸ç­‰çš„ï¼Œåˆ†ç±»çš„ç»“æœæ˜¯åŸºäºæ‰€æœ‰åˆ†ç±»å™¨åŠ æƒæ±‚å’Œçš„ç»“æœï¼Œæ¯ä¸ªæƒé‡ä»£è¡¨çš„æ˜¯å…¶åˆ†ç±»å™¨åœ¨ä¸Šä¸€è½®è¿­ä»£çš„æˆåŠŸåº¦ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ã€ŠMachine Learning in Actionã€‹å­¦ä¹ ç¬”è®°å››ï¼šæ”¯æŒå‘é‡æœº</title>
    <link href="http://yoursite.com/2017/10/22/machine-learning-in-action-note4/"/>
    <id>http://yoursite.com/2017/10/22/machine-learning-in-action-note4/</id>
    <published>2017-10-22T00:50:53.000Z</published>
    <updated>2017-11-07T11:54:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machineï¼‰çœŸçš„ä¸æ˜¯å¾ˆå¥½ç†è§£å•Šï¼Œè™½ç„¶ä½œè€…ç»™å‡ºäº†ä»£ç ï¼Œemmmmmâ€¦..è¿˜æ˜¯ç¨å¾®è®°å½•ä¸€ä¸‹å§ã€‚</p><p>ä¸Šä¸€ç« å­¦ä¹ çš„ã€Œå¯¹æ•°å‡ ç‡å‡½æ•°ã€ä¸­ï¼Œæˆ‘ä»¬æåˆ°äº†</p><blockquote><p>åˆ©ç”¨çº¿æ€§å›å½’æ¨¡å‹çš„é¢„æµ‹ç»“æœå»é€¼è¿‘çœŸå®æ ‡è®°çš„å¯¹æ•°å‡ ç‡</p></blockquote><p>æ ‡è®°ç»“æœä¸º1ï¼0ã€‚ä½†SVMä¸­ï¼Œæˆ‘ä»¬ç›®æ ‡æ˜¯æ‰¾å‡ºå…·æœ‰â€œæœ€å¤§é—´éš”â€ï¼ˆmaximum marginï¼‰çš„ã€Œåˆ’åˆ†è¶…å¹³é¢ã€ï¼Œæ ‡è®°ç»“æœä¸º-1ï¼1ã€‚</p><p>ä¸Šé¢ä¸€å¥è¯å‡ºç°äº†ä¸¤ä¸ªå¥½åƒä¼¼æ‡‚éæ‡‚çš„åè¯ï¼šæœ€å¤§é—´éš”å’Œåˆ’åˆ†è¶…å¹³é¢ã€‚</p><p><img src="/2017/10/22/machine-learning-in-action-note4/svmpic.jpg" alt="svmpic"></p><a id="more"></a><p>ğŸ‘†ğŸ»æœ‰ä¸€æ¡çº¿æŠŠè‹¹æœå’Œé¦™è•‰åˆ†å¼€äº†ï¼ˆåœ¨äºŒç»´ç©ºé—´ä¸­å°±æ˜¯ä¸€æ¡çº¿ï¼‰ï¼Œè¿™æ ·åˆ†å¼€ä¸åŒè®­ç»ƒæ ·æœ¬çš„çº¿å°±ç§°ä¸ºã€Œåˆ’åˆ†è¶…å¹³é¢ã€ã€‚è·ç¦»è¿™æ¡çº¿æœ€è¿‘çš„å‡ ä¸ªç‚¹å°±æ˜¯ã€Œæ”¯æŒå‘é‡ã€ï¼Œå®ƒä»¬åˆ°è¿™æ¡çº¿çš„è·ç¦»å°±ä¸ºã€Œé—´éš”ã€ã€‚é‚£ä¹ˆæˆ‘ä»¬å†æ¥å›é¡¾ä¸€ä¸‹åˆšè¯´çš„ä¸€å¥è¯ï¼š</p><blockquote><p>æ‰¾å‡ºå…·æœ‰â€œæœ€å¤§é—´éš”â€ï¼ˆmaximum marginï¼‰çš„ã€Œåˆ’åˆ†è¶…å¹³é¢ã€</p></blockquote><p>èƒ½å¤Ÿåˆ’åˆ†è®­ç»ƒæ ·æœ¬çš„è¶…å¹³é¢å¯èƒ½æœ‰å¾ˆå¤šï¼Œæˆ‘ä»¬åº”è¯¥è¦æ‰¾çš„ï¼Œæ˜¯ä½äºâ€œæ­£ä¸­é—´â€çš„é‚£ä¸ªåˆ’åˆ†è¶…å¹³é¢ï¼Œä¹Ÿå°±æ˜¯è·ç¦»ä¸åŒç±»åˆ«éƒ½å°½å¯èƒ½è¿œçš„é‚£ä¸ªè¶…å¹³é¢ã€‚è¿™æ ·è¿›è¡Œé¢„æµ‹æ—¶è¯¯å·®æ‰ä¼šå°½å¯èƒ½å°ã€‚</p><p>è¯´åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥æ˜ç¡®ä¸€ä¸‹SVMç®—æ³•çš„è®¾è®¡é—®é¢˜äº†ã€‚å› ä¸ºè¶Šæ¥è¿‘è¶…å¹³é¢çš„ç‚¹è¶Šâ€œéš¾â€åˆ†å‰²ï¼Œæ‰¾åˆ°è¿™äº›ç‚¹å°±ä¸‡äº‹å¤§å‰äº†ã€‚å› æ­¤SVMå­¦ä¹ åˆ†ç±»å™¨æœ€é‡è¦çš„æ˜¯æ‰¾åˆ°å“ªäº›æ ·æœ¬ä½œä¸ºã€Œæ”¯æŒå‘é‡ã€ã€‚å…¶æœ¬è´¨æ˜¯ä¸€ä¸ªæœ€ä¼˜åŒ–é—®é¢˜ã€‚</p><p>ä¸€ä¸ªæœ€ä¼˜åŒ–é—®é¢˜é€šå¸¸æœ‰ä¸¤ä¸ªæœ€åŸºæœ¬çš„å› ç´ ï¼š1ï¼‰ç›®æ ‡å‡½æ•°ï¼šå¸Œæœ›ä»€ä¹ˆä¸œè¥¿çš„æŒ‡æ ‡è¾¾åˆ°æœ€å¥½ï¼›2ï¼‰ä¼˜åŒ–å¯¹è±¡ï¼šä½ å¸Œæœ›é€šè¿‡æ”¹å˜å“ªäº›å› ç´ ä½¿ç›®æ ‡å‡½æ•°è¾¾åˆ°æœ€ä¼˜ã€‚åœ¨SVMä¸­ï¼Œç›®æ ‡å‡½æ•°æ˜¯ã€Œæœ€å¤§é—´éš”ã€ï¼Œä¼˜åŒ–å¯¹è±¡å°±æ˜¯ã€Œåˆ’åˆ†è¶…å¹³é¢ã€ã€‚ä¸‹é¢æˆ‘ä»¬å°±éœ€è¦å¯¹è¿™ä¸¤ä¸ªåŸºæœ¬å› ç´ è¿›è¡Œæ•°å­¦æè¿°ã€‚</p><p>###SVMçš„æ•°å­¦å»ºæ¨¡</p><p><img src="/2017/10/22/machine-learning-in-action-note4/svm_model.png" alt="svmpic"></p><p>åˆ’åˆ†è¶…å¹³é¢çš„çº¿æ€§æ–¹ç¨‹ï¼š<br>$$<br>w^Tx + b = 0<br>$$<br>å…¶ä¸­ï¼Œ<strong>w</strong> = ï¼ˆw~1~ï¼› w~2~ï¼›â€¦ ï¼› w~d~ï¼‰ä¸ºæ³•å‘é‡ã€‚æ ·æœ¬ç©ºé—´ä¸­ä»»æ„ç‚¹ <strong>x</strong> åˆ°è¶…å¹³é¢çš„è·ç¦»ï¼ˆå‡ ä½•é—´éš”ï¼‰å¯å†™ä¸ºï¼š<br>$$<br>d = \frac{|w^Tx + b|}{||w||}<br>$$<br>å…¶ä¸­ï¼Œ$||w||$ ä¸ºå‘é‡çš„æ¨¡ã€‚å‰é¢æˆ‘ä»¬è¯´åˆ°ï¼ŒSVMçš„åˆ†ç±»ç»“æœæ˜¯+1ï¼-1ï¼Œä»¤ï¼š<br>$$<br>\begin{cases}w^Tx + bâ‰¥+1, y_i = +1 \\ w^Tx + bâ‰¤-1, y_i = -1<br>\end{cases}<br>$$<br>æ”¯æŒå‘é‡ä½¿å¾—ç­‰å·æˆç«‹ã€‚ä¸¤ä¸ªå¼‚ç±»æ”¯æŒå‘é‡åˆ°è¶…å¹³é¢çš„è·ç¦»ä¹‹å’Œä¸º<br>$$<br>ğœ¸ = \frac{2}{||w||}<br>$$<br>æ˜¾ç„¶ï¼Œä¸ºäº†æœ€å¤§åŒ–é—´éš”ï¼Œä»…éœ€æœ€å¤§åŒ–$||w||^{-1}$ï¼Œç­‰ä»·äºæœ€å°åŒ–$||w||^2$ã€‚</p><p>åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ç»™å‡ºSVMçš„æ•°å­¦æè¿°ï¼š<br>$$<br>\min_{w,b}\frac{1}{2}||w||^2 \\  s.t. \quad y_i(w^Tx+b) â‰¥1,i = 1,2,â€¦,m<br>$$</p><p>ç¼©å†™s. t. è¡¨ç¤ºâ€œSubject toâ€ï¼Œæ˜¯â€œæœä»æŸæŸæ¡ä»¶â€çš„æ„æ€ã€‚æ ¹æ®å‚è€ƒé“¾æ¥[3]è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ¡ä»¶çš„å«ä¹‰ã€‚æˆ‘ä»¬å®šä¹‰ã€Œå‡½æ•°é—´éš”ã€ä¸º<br>$$<br>y(w^Tx+b)=yf(x)â‰¥ğœ¸<br>$$<br>å‰é¢ä¹˜ä¸Šç±»åˆ« y ä¹‹åä¿è¯é—´éš”çš„éè´Ÿæ€§ï¼ˆå› ä¸º f(x)&lt;0 å¯¹åº”äº y=âˆ’1 çš„é‚£äº›ç‚¹ï¼‰ã€‚</p><p>###å¯¹å¶é—®é¢˜</p><p>ä¸Šé¢SVMçš„æ•°å­¦æè¿°å…¶å®æ˜¯ä¸€ä¸ª<strong>äºŒæ¬¡ä¼˜åŒ–é—®é¢˜</strong>â€”â€”ç›®æ ‡å‡½æ•°æ˜¯äºŒæ¬¡çš„ï¼Œçº¦æŸæ¡ä»¶æ˜¯çº¿æ€§çš„ã€‚å¼•å…¥ã€Œæ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•ã€æ±‚è§£ï¼Œå¯¹æ¯æ¡çº¦æŸæ·»åŠ æ‹‰æ ¼æœ—æ—¥ä¹˜å­ğœ¶~i~ â‰¥ 0ï¼Œåˆ™è¯¥é—®é¢˜çš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°å¯å†™ä¸º<br>$$<br>Lï¼ˆw,b,ğœ¶) =\frac{1}{2}||w||^2 + ğœ¶_i\sum_{i=1}^m(1-y_i(w^Tx_i+b))<br>$$<br>å…¶ä¸­ï¼Œ\(ğœ¶ = ï¼ˆğ›¼_1;ğ›¼_2;â€¦;ğ›¼_m)\)ã€‚æˆ‘ä»¬ä»¤<br>$$<br>ğœƒ(w) =\max _{ğœ¶_iâ‰¥ 0}\quad Lï¼ˆw,b,ğœ¶)<br>$$</p><p>åˆ™ä¸Šå¼çš„æœ€ä¼˜å€¼ä¸º $ğœƒ(w) = \frac{1}{2}||w||^2$, å³æˆ‘ä»¬éœ€è¦ä¼˜åŒ–çš„SVMæ•°å­¦æ¨¡å‹ã€‚å…·ä½“å…¬å¼ä¸º</p><p>$$<br>\min_{w,b} ğœƒ(w)  =\min_{w,b}\max_{ğœ¶_iâ‰¥ 0}\quad Lï¼ˆw,b,ğœ¶)<br>$$<br>å°†minå’Œmaxäº¤æ¢ä½ç½®å¾—åˆ°åŸå§‹é—®é¢˜çš„å¯¹å¶é—®é¢˜</p><p>$$<br>\max_{ğœ¶_iâ‰¥ 0}\min_{w,b}\quad Lï¼ˆw,b,ğœ¶)<br>$$<br><strong>ä¸ºä»€ä¹ˆå¯ä»¥è½¬åŒ–å‘¢ï¼Ÿ</strong>å› ä¸ºç˜¦æ­»çš„éª†é©¼æ¯”é©¬å¤§ï¼Œã€Œæœ€å¤§å€¼ä¸­çš„æœ€å°å€¼ã€ä¹Ÿæ¯”ã€Œæœ€å°å€¼ä¸­çš„æœ€å¤§å€¼ã€æ¥å¾—å¤§ã€‚</p><p><strong>é‚£ä¹ˆå…ˆæ±‚æœ€å¤§å€¼å’Œå…ˆæ±‚æœ€å°å€¼æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ï¼Ÿ</strong>å› ä¸ºè¿™æ ·æ›´å®¹æ˜“æ±‚è§£ã€‚æˆ‘ä»¬é€šè¿‡åå¯¼å…ˆæ±‚ <strong>L</strong> å…³äº ğ’˜ å’Œ ğ‘ æå°ï¼Œå†æ±‚ <strong>L</strong> çš„æå¤§ã€‚åˆ†åˆ«ä»¤ âˆ‚îˆ¸/âˆ‚w å’Œ âˆ‚îˆ¸/âˆ‚b ä¸ºé›¶å¯å¾—<br>$$<br>\frac{âˆ‚L}{âˆ‚w} = 0 â‡’ w = \sum_{i=1}^mğœ¶_iy_ix_i<br>$$</p><p>$$<br>\frac{âˆ‚L}{âˆ‚b} = 0 â‡’ \sum_{i=1}^mğœ¶_iy_i = 0<br>$$</p><p>ä»£å› <strong>L</strong> å¾—åˆ°SVMæ•°å­¦æè¿°çš„å¯¹å¶é—®é¢˜<br>$$<br>max_ğœ¶\quad \sum_{i=1}^mğœ¶_i - \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^mğœ¶_iğœ¶_jy_iy_jx_i^Tx_j^T<br>$$</p><p>$$<br>s.t\quad\sum_{i=1}^mğœ¶_iy_i = 0,\quadğœ¶_iâ‰¥ 0,i =1,2,â€¦,m<br>$$</p><p>è§£å‡ºğœ¶åï¼Œæ±‚å‡ºwä¸bå³å¯å¾—åˆ°æ¨¡å‹<br>$$<br>\begin {align_} f(x) &amp; = w^T+b \\ &amp; = \sum_{i=1}^mğœ¶_iy_ix_i^Tx + b\end {align_}<br>$$<br>æ‰€ä»¥åªè¦æ±‚å‡ºäº†wå’Œbï¼Œå°†æµ‹è¯•æ•°æ®å¸¦å…¥ä¸Šé¢è¿™ä¸ªæ¨¡å‹ï¼Œå³å¯å¾—å‡ºé¢„æµ‹å€¼ã€‚</p><p>å®é™…ä¸Šï¼Œæ‰€æœ‰éæ”¯æŒå‘é‡çš„ğœ¶å€¼éƒ½ä¸ºé›¶ï¼Œ<strong>æœ€ç»ˆæ¨¡å‹åªä¸æ”¯æŒå‘é‡æœ‰å…³</strong>ã€‚å›å¿†ä¸€ä¸‹æˆ‘ä»¬çš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°<br>$$<br>\max _{ğœ¶_iâ‰¥ 0}\quad Lï¼ˆw,b,ğœ¶) =\max_{ğœ¶_iâ‰¥ 0}\quad \frac{1}{2}||w||^2 + \color{red}{ğœ¶_i\sum_{i=1}^m(1-y_i(w^Tx_i+b))}<br>$$<br>å¦‚æœ x~i~ æ˜¯æ”¯æŒå‘é‡ï¼Œé‚£ä¹ˆçº¢è‰²æ ‡å‡ºéƒ¨åˆ†ä¸º0ï¼ˆå› ä¸ºæ”¯æŒå‘é‡å‡½æ•°é—´éš”ä¸º1ï¼‰ã€‚å¯¹äºéæ”¯æŒå‘é‡ï¼Œå‡½æ•°é—´éš”å¤§äº1ï¼Œé‚£ä¹ˆçº¢è‰²æ ‡å‡ºéƒ¨åˆ†å°†å°äº0ï¼Œä¸ºæ»¡è¶³æ•´ä¸ªå¼å­æœ€å¤§ï¼Œåªèƒ½ğœ¶~i~ ä¸º0ã€‚å› æ­¤æˆ‘ä»¬é¢„æµ‹çš„è¿‡ç¨‹åªéœ€è¦è®¡ç®—å°‘é‡å‘é‡çš„å†…ç§¯ï¼Œé€Ÿåº¦æ˜¯å¾ˆå¿«çš„ã€‚</p><h3 id="SMOç®—æ³•"><a href="#SMOç®—æ³•" class="headerlink" title="SMOç®—æ³•"></a>SMOç®—æ³•</h3><p>å¥½çš„ï¼Œæ¥ä¸‹æ¥é—®é¢˜å°±è½¬æ¢ä¸º<strong>å¦‚ä½•æ±‚è§£å¯¹å¶é—®é¢˜</strong>ã€‚1996å¹´ï¼ˆç«Ÿç„¶åœ¨æˆ‘å‡ºç”Ÿè¿™å¹´æäº‹æƒ…ğŸ™‚ï¼‰John Plattå‘å¸ƒäº†SMOï¼ˆSequntial Minimal Optimizationï¼‰ç®—æ³•ï¼Œå°†å¤§ä¼˜åŒ–é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªå°ä¼˜åŒ–é—®é¢˜æ±‚è§£ã€‚SMOçš„åŸºæœ¬æ€è·¯æ˜¯å…ˆå›ºå®šğœ¶~i~ä¹‹å¤–çš„æ‰€æœ‰å‚æ•°ï¼Œç„¶åæ±‚ğœ¶~i~ä¸Šçš„æå€¼ã€‚ç”±äºå­˜åœ¨çº¦æŸ $sum_{i=1}^mğœ¶_iy_i = 0$ ï¼Œè‹¥å›ºå®š ğœ¶~i~ ä¹‹å¤–çš„å…¶ä»–å˜é‡ï¼Œåˆ™ ğœ¶~i~ å¯ç”±å…¶ä»–å˜é‡å¯¼å‡ºã€‚äºæ˜¯SMOæ¯æ¬¡é€‰æ‹©ä¸¤ä¸ªå˜é‡ğœ¶~i~ å’Œ ğœ¶~j~ ï¼Œå¹¶å›ºå®šå…¶ä»–å‚æ•°ã€‚è¿™æ ·åœ¨å‚æ•°åˆå§‹åŒ–åï¼ŒSMOä¸æ–­æ‰§è¡Œå¦‚ä¸‹ä¸¤ä¸ªæ­¥éª¤ç›´è‡³æ”¶æ•›ï¼š</p><ul><li>é€‰å–ä¸€å¯¹éœ€è¦æ›´æ–°çš„å˜é‡ ğœ¶~i~ å’Œ ğœ¶~j~ ï¼›</li><li>å›ºå®š ğœ¶~i~ å’Œ ğœ¶~j~ ä»¥å¤–å‚æ•°ï¼Œæ±‚è§£è·å¾—æ›´æ–°åçš„ ğœ¶~i~ å’Œ ğœ¶~j~ </li></ul><p>å¥½çš„ï¼Œç†è§£SMOå®åœ¨æ˜¯æ— èƒ½ä¸ºåŠ›äº†ï¼Œæˆ‘ä»¬è¿›å…¥ä¸‹ä¸€ä¸ªè¯é¢˜ã€Œæ ¸å‡½æ•°ã€ã€‚</p><h3 id="æ ¸å‡½æ•°"><a href="#æ ¸å‡½æ•°" class="headerlink" title="æ ¸å‡½æ•°"></a>æ ¸å‡½æ•°</h3><p>ä¸Šé¢æˆ‘ä»¬è§£å†³äº†çº¿æ€§åˆ†ç±»é—®é¢˜ï¼Œä½†SVMè¿˜å¯ä»¥è§£å†³éçº¿æ€§çš„åˆ†ç±»é—®é¢˜ï¼Œè¿™å°±éœ€è¦å¼•å…¥ã€Œæ ¸å‡½æ•°ã€ï¼Œæ¥å°†æ•°æ®ä»ä¸€ä¸ªç‰¹å¾ç©ºé—´è½¬æ¢åˆ°å¦ä¸€ä¸ªç‰¹å¾ç©ºé—´ï¼Œåœ¨æ–°ç©ºé—´ä¸‹å†åˆ©ç”¨æ¨¡å‹å¯¹æ•°æ®è¿›è¡Œå¤„ç†ã€‚</p><p><img src="/2017/10/22/machine-learning-in-action-note4/kernel.gif" alt="kernel"></p><p>å¾„å‘åŸºå‡½æ•°ï¼ˆradial bias functionï¼‰æ˜¯SVMå¸¸ç”¨çš„ä¸€ä¸ªæ ¸å‡½æ•°ï¼Œå…·ä½“å…¬å¼ä¸º<br>$$<br>k(x,y) = exp(\frac{-||x-y||^2}{2ğœ^2})<br>$$<br>å…¶ä¸­ ğœ æ˜¯ç”¨æˆ·å®šä¹‰çš„å‡½æ•°å€¼è·Œè½åˆ°0çš„é€Ÿåº¦å‚æ•°ã€‚</p><h3 id="SVMçš„ä¸€èˆ¬æµç¨‹"><a href="#SVMçš„ä¸€èˆ¬æµç¨‹" class="headerlink" title="SVMçš„ä¸€èˆ¬æµç¨‹"></a>SVMçš„ä¸€èˆ¬æµç¨‹</h3><ol><li>æ”¶é›†æ•°æ®ï¼šå¯ä»¥ä½¿ç”¨ä»»æ„æ–¹æ³•</li><li>å‡†å¤‡æ•°æ®ï¼šéœ€è¦æ•°å€¼å‹æ•°æ®</li><li>åˆ†ææ•°æ®ï¼šå¯è§†åŒ–åˆ†å‰²è¶…å¹³é¢æ˜¯å¾ˆæœ‰å¸®åŠ©çš„</li><li>è®­ç»ƒç®—æ³•ï¼šSVMç®—æ³•æœ€è€—æ—¶çš„åœ°æ–¹ã€‚è¯¥è¿‡ç¨‹ä¸»è¦å®ç°ä¸¤ä¸ªå‚æ•°è°ƒä¼˜</li><li>æµ‹è¯•ç®—æ³•ï¼šè®¡ç®—ååˆ†ç®€å•</li><li>ä½¿ç”¨ç®—æ³•ï¼šå‡ ä¹æ‰€æœ‰åˆ†ç±»é—®é¢˜éƒ½å¯ä»¥ç”¨SVMæ¥è§£å†³ï¼Œå€¼å¾—ä¸€æçš„æ˜¯ï¼ŒSVMæœ¬èº«æ˜¯ä¸€ä¸ªäºŒç±»åˆ†ç±»å™¨ï¼Œä½ éœ€è¦ä¿®æ”¹ä¸€äº›ä»£ç æ¥é€‚åº”å¤šåˆ†ç±»é—®é¢˜</li></ol><h3 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h3><p>åœ¨ä½œè€…ç»™çš„æºç ä¸­ï¼Œæœ‰å¯è§†åŒ–æ•°æ®çš„éƒ¨åˆ†ï¼Œä¿®æ”¹äº†ä¸€ä¸‹ç”¨äºæµ‹è¯•ä¸åŒkå€¼rbfé€‰æ‹©çš„æ”¯æŒå‘é‡ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">xcord0 = []; ycord0 = []; xcord1 = []; ycord1 = []</div><div class="line">fig = plt.figure()</div><div class="line">ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line">xcord0 = []; ycord0 = []; xcord1 = []; ycord1 = []</div><div class="line">fr = open(<span class="string">'testSetRBF.txt'</span>) <span class="comment"># generate data</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</div><div class="line">    lineSplit = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">    xPt = float(lineSplit[<span class="number">0</span>])</div><div class="line">    yPt = float(lineSplit[<span class="number">1</span>])</div><div class="line">    label = float(lineSplit[<span class="number">2</span>])</div><div class="line">    <span class="keyword">if</span> (label &lt; <span class="number">0</span>):</div><div class="line">        xcord0.append(xPt)</div><div class="line">        ycord0.append(yPt)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        xcord1.append(xPt)</div><div class="line">        ycord1.append(yPt)</div><div class="line">k1 = <span class="number">1.3</span> <span class="comment"># ä¿®æ”¹æµ‹è¯•</span></div><div class="line">sVs = svm.testRbf(k1)</div><div class="line">m = shape(sVs)[<span class="number">0</span>]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">    x = sVs.A[i][<span class="number">0</span>]</div><div class="line">    y = sVs.A[i][<span class="number">1</span>]</div><div class="line">    circle = Circle((x,y), <span class="number">0.05</span>, facecolor=<span class="string">'none'</span>, edgecolor=(<span class="number">0</span>, <span class="number">0.8</span>, <span class="number">0.8</span>), linewidth=<span class="number">3</span>, alpha=<span class="number">0.5</span>)</div><div class="line">    ax.add_patch(circle)</div><div class="line">ax.scatter(xcord0, ycord0, marker=<span class="string">'s'</span>, s=<span class="number">30</span>)</div><div class="line">ax.scatter(xcord1, ycord1, marker=<span class="string">'o'</span>, s=<span class="number">30</span>, c=<span class="string">'red'</span>)</div><div class="line">plt.title(<span class="string">'RBF k1 = %f, %d Support Vectors'</span> %(k1, m))</div><div class="line">plt.show()</div><div class="line">fr.close()</div></pre></td></tr></table></figure><p><img src="/2017/10/22/machine-learning-in-action-note4/k_1.3.png" alt="k_1.3"></p><p><img src="/2017/10/22/machine-learning-in-action-note4/k_0.1.png" alt="k_0.1"></p><p>å¯ä»¥çœ‹å‡ºå‚æ•°å€¼è¶Šå°æ”¯æŒå‘é‡çš„èŒƒå›´è¶Šæ¨¡ç³Šï¼Œé€‰æ‹©åˆé€‚çš„å‚æ•°è¿˜æ˜¯å¾ˆé‡è¦çš„ã€‚</p><p><strong>å‚è€ƒé“¾æ¥</strong></p><ul><li><a href="https://www.zhihu.com/question/21094489" target="_blank" rel="external">https://www.zhihu.com/question/21094489</a></li><li><a href="https://zhuanlan.zhihu.com/p/24638007" target="_blank" rel="external">é›¶åŸºç¡€å­¦SVMâ€”Support Vector Machine(ä¸€)</a> </li><li><a href="http://blog.pluskid.org/?p=632" target="_blank" rel="external">http://blog.pluskid.org/?p=632</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machineï¼‰çœŸçš„ä¸æ˜¯å¾ˆå¥½ç†è§£å•Šï¼Œè™½ç„¶ä½œè€…ç»™å‡ºäº†ä»£ç ï¼Œemmmmmâ€¦..è¿˜æ˜¯ç¨å¾®è®°å½•ä¸€ä¸‹å§ã€‚&lt;/p&gt;
&lt;p&gt;ä¸Šä¸€ç« å­¦ä¹ çš„ã€Œå¯¹æ•°å‡ ç‡å‡½æ•°ã€ä¸­ï¼Œæˆ‘ä»¬æåˆ°äº†&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;åˆ©ç”¨çº¿æ€§å›å½’æ¨¡å‹çš„é¢„æµ‹ç»“æœå»é€¼è¿‘çœŸå®æ ‡è®°çš„å¯¹æ•°å‡ ç‡&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;æ ‡è®°ç»“æœä¸º1ï¼0ã€‚ä½†SVMä¸­ï¼Œæˆ‘ä»¬ç›®æ ‡æ˜¯æ‰¾å‡ºå…·æœ‰â€œæœ€å¤§é—´éš”â€ï¼ˆmaximum marginï¼‰çš„ã€Œåˆ’åˆ†è¶…å¹³é¢ã€ï¼Œæ ‡è®°ç»“æœä¸º-1ï¼1ã€‚&lt;/p&gt;
&lt;p&gt;ä¸Šé¢ä¸€å¥è¯å‡ºç°äº†ä¸¤ä¸ªå¥½åƒä¼¼æ‡‚éæ‡‚çš„åè¯ï¼šæœ€å¤§é—´éš”å’Œåˆ’åˆ†è¶…å¹³é¢ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2017/10/22/machine-learning-in-action-note4/svmpic.jpg&quot; alt=&quot;svmpic&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ã€ŠMachine Learning in Actionã€‹å­¦ä¹ ç¬”è®°ä¸‰ï¼šå¯¹æ•°å‡ ç‡å›å½’</title>
    <link href="http://yoursite.com/2017/10/20/machine-learning-in-action-note3/"/>
    <id>http://yoursite.com/2017/10/20/machine-learning-in-action-note3/</id>
    <published>2017-10-20T08:24:26.000Z</published>
    <updated>2017-11-07T11:53:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>é¦–å…ˆæˆ‘ä»¬å…ˆæ¥è¯´è¯´ã€Œå›å½’ã€ã€‚wikiå‘Šè¯‰æˆ‘ä»¬ï¼Œå›å½’æŒ‡çš„æ˜¯ç ”ç©¶å˜é‡å…³ç³»çš„ä¸€ç§ç»Ÿè®¡åˆ†ææ–¹æ³•ã€‚å›å½’åˆ†ææ˜¯ä¸€ç§æ•°å­¦æ¨¡å‹ï¼Œè€Œæˆ‘ä»¬æœ€ç†Ÿæ‚‰çš„éã€Œçº¿æ€§æ¨¡å‹ã€è«å±äº†ã€‚ä»¥ä¸‹å¼•å…¥çš„ç†è®ºæ¥æºäºè¥¿ç“œä¹¦ã€‚</p><p>ã€Œçº¿æ€§å›å½’ã€è¯•å›¾é€šè¿‡ç»™å®šæ•°æ®é›†å­¦å¾—ä¸€ä¸ªã€Œçº¿æ€§æ¨¡å‹ã€ä»¥å°½å¯èƒ½å‡†ç¡®åœ°é¢„æµ‹è¾“å‡ºæ ‡è®°ã€‚ç”¨å…¬å¼æ¥è¡¨ç¤ºï¼š<br>$$<br>f(x_i) = wx_i+bï¼Œ\\ ä½¿å¾—f(x_i) \approx y_i<br>$$<br>æœ‰æ—¶æˆ‘ä»¬ç¤ºä¾‹å¯¹åº”çš„è¾“å‡ºæ ‡è®°æ˜¯åœ¨æŒ‡æ•°å°ºåº¦ä¸Šå˜åŒ–ï¼Œé‚£å°±å¯å°†è¾“å‡ºæ ‡è®°çš„å¯¹æ•°ä½œä¸ºçº¿æ€§æ¨¡å‹é€¼è¿‘çš„ç›®æ ‡ï¼Œå³<br>$$<br>\ln y = w^Tx + b<br>$$<br>è¿™å°±æ˜¯â€å¯¹æ•°çº¿æ€§å›å½’â€œï¼ˆlog-linear regressionï¼‰ã€‚ä»è€Œå¼•å‡ºäº†ä¸€ä¸ªâ€å¹¿ä¹‰çº¿æ€§æ¨¡å‹â€œï¼ˆgeneralized linear modelï¼‰<br>$$<br>y = g^{-1}(w^Tx + b)<br>$$<br>å…¶ä¸­å‡½æ•°g(ï½¥)ç§°ä¸ºâ€œè”ç³»å‡½æ•°â€ï¼ˆlink functionï¼‰ã€‚å¯¹æ•°å›å½’æ˜¯å¹¿ä¹‰çº¿æ€§æ¨¡å‹åœ¨g(ï½¥) = ln(ï½¥) æ—¶çš„ç‰¹ä¾‹ã€‚</p><a id="more"></a><p>å…¶æ¬¡ï¼Œæˆ‘ä»¬æƒ³ç”¨å›å½’åˆ†ææ¥åš<strong>åˆ†ç±»ä»»åŠ¡</strong>æ€ä¹ˆåŠï¼Ÿé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ‰¾ä¸€ä¸ªå•è°ƒå¯å¾®å‡½æ•°ï¼Œå°†åˆ†ç±»ä»»åŠ¡çš„çœŸå®æ ‡è®°yä¸çº¿æ€§å›å½’æ¨¡å‹çš„é¢„æµ‹å€¼ <strong>z=w^T^x+b</strong> è”ç³»èµ·æ¥ã€‚è€ƒè™‘æœ€ç®€å•çš„äºŒåˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬æƒ³åˆ°äº†â€œå•ä½é˜¶è·ƒå‡½æ•°â€ï¼ˆunit-step functionï¼‰<br>$$<br>y = \begin{cases}0, z<0\\0.5, z="0\\1,z">0<br>\end{cases}<br>$$<br>ä½†å•ä½é˜¶è·ƒå‡½æ•°ä¸è¿ç»­ï¼Œå› æ­¤ä¸èƒ½ä½œä¸ºg(ï½¥)ã€‚äºæ˜¯èªæ˜çš„äººä»¬å°±æ‰¾åˆ°äº†Sigmoidå‡½æ•°ï¼Œä¹Ÿç§°å¯¹æ•°å‡ ç‡å‡½æ•°ï¼ˆlogistic functionï¼‰ï¼š<br>$$<br>y = \frac{1}{1+e^{-z}}<br>$$<br>ç±»æ¯”ä¸Šé¢çš„çº¿æ€§å›å½’æˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š<br>$$<br>\ln\frac{y}{1-y} = w^Tx + b<br>$$<br>ç”±æ­¤å°±å¼•å‘äº†å…³äº Logistic Regression ä¸­æ–‡åçš„æ€è€ƒã€‚å¤§å¤šæ•°çœ‹åˆ°çš„ç¿»è¯‘éƒ½æ˜¯ã€Œé€»è¾‘å›å½’ã€ï¼Œå…¶ä¸­é€»è¾‘ä¸€è¯ä»£è¡¨ä»€ä¹ˆä¸€ç›´ä¸æ‡‚ã€‚ä½†åœ¨è¥¿ç“œä¹¦ä¸­ä½œè€…ç§°ä¹‹ä¸ºã€Œå¯¹æ•°å‡ ç‡å›å½’ã€ï¼Œå…¶è¨€è¯­æ˜¯è®©æˆ‘ä¿¡æœçš„ã€‚</0\\0.5,></p><p>å°† y è§†ä¸ºæ ·æœ¬xä½œä¸ºæ­£ä¾‹çš„å¯èƒ½æ€§ï¼Œåˆ™ 1-y æ—¶å…¶åä¾‹çš„å¯èƒ½æ€§ï¼Œä¸¤è€…æ¯”å€¼ç§°ä¸ºâ€œå¯¹ç‡â€ï¼ˆoddsï¼‰ï¼š<br>$$<br>\frac{y}{1-y}<br>$$<br>å¯¹ç‡åæ˜ äº†xä½œä¸ºæ­£ä¾‹çš„ç›¸å¯¹å¯èƒ½æ€§ã€‚å¯¹å‡ ç‡å–å¯¹æ•°åˆ™å¾—åˆ°â€œå¯¹æ•°å‡ ç‡â€ï¼ˆlog oddsï¼Œäº¦ç§°logitï¼‰ï¼š<br>$$<br>\ln\frac{y}{1-y}<br>$$<br>ç”±æ­¤å¯çœ‹å‡ºï¼Œå®é™…ä¸Šæ˜¯åœ¨ç”¨çº¿æ€§å›å½’æ¨¡å‹çš„é¢„æµ‹ç»“æœå»é€¼è¿‘çœŸå®æ ‡è®°çš„å¯¹æ•°å‡ ç‡ã€‚</p><p>ä¸ç®¡æ€ä¹ˆè¯´ï¼Œåœ¨ç†è§£ä¸€ä¸ªå›å½’æ¨¡å‹çš„æ—¶å€™è‡³å°‘å…ˆæŠŠå®ƒçš„åå­—å¿µå¯¹å§233</p><h3 id="åˆ†æï¼šå¯è§†åŒ–åˆ†ææ•°æ®"><a href="#åˆ†æï¼šå¯è§†åŒ–åˆ†ææ•°æ®" class="headerlink" title="åˆ†æï¼šå¯è§†åŒ–åˆ†ææ•°æ®"></a>åˆ†æï¼šå¯è§†åŒ–åˆ†ææ•°æ®</h3><p>åœ¨è°ƒç”¨plotBestFitæ—¶ï¼Œæœ‰ä¸€ä¸ª<code>weights.getA())</code>è¿™ä¸ªgetA()æ˜¯å•¥ç©æ„å„¿ï¼Ÿæ ¹æ®å‚è€ƒé“¾æ¥[1]-11æ¥¼çš„å°ä¼™ä¼´ç»™å‡ºäº†ç­”æ¡ˆï¼ŒçŸ©é˜µé€šè¿‡è¿™ä¸ªgetA()è¿™ä¸ªæ–¹æ³•å¯ä»¥å°†è‡ªèº«è¿”å›æˆä¸€ä¸ªnç»´æ•°ç»„å¯¹è±¡</p><p><img src="/2017/10/20/machine-learning-in-action-note3/geta_test.png" alt=""></p><p>ä»ä¸Šå›¾è¾“å‡ºç±»å‹å¯ä»¥çœ‹å‡ºï¼Œä½¿ç”¨getAå‡½æ•°å°†çŸ©é˜µè½¬åŒ–ä¸ºäº†æ•°ç»„</p><p><img src="/2017/10/20/machine-learning-in-action-note3/matnarr.png" alt=""></p><p>å½“çŸ©é˜µåªæœ‰ä¸€è¡Œçš„æ—¶å€™è¾“å‡º mat[1] æ˜¯ä¼šæŠ¥é”™çš„</p><p><img src="/2017/10/20/machine-learning-in-action-note3/mat_trans.png" alt=""></p><p>å°† mat è½¬åˆ¶å mat[1] è¾“å‡ºçš„æ˜¯ä¸€ä¸ª1x1çš„çŸ©é˜µè€Œä¸æ˜¯ä¸€ä¸ªæ•°å€¼</p><p>###è®­ç»ƒï¼šæ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰</p><p>åœ¨å¯¹æ•°å‡ ç‡å‡½æ•°çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ€é‡è¦çš„å°±æ˜¯å¦‚ä½•è®­ç»ƒæƒå€¼wã€‚ä¸ºäº†ä½¿å…¶å…¬å¼åŒ–ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªâ€œä»£ä»·å‡½æ•°â€ï¼ˆcost functionï¼‰ï¼Œæ¥è¡¡é‡é¢„æµ‹å€¼å’Œå®ä¾‹æ ‡è®°çš„å·®è·ï¼š<br>$$<br>J(w) = \frac{1}{2}\sum_{i=1}^m(h_w(x^{(i)})-y^{i})^2<br>$$<br>æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªå€¼å¾ˆå°ï¼Œäºæ˜¯å°±æœ‰äº†æ¢¯åº¦ä¸‹é™ç®—æ³•çš„è¿­ä»£å…¬å¼ï¼š<br>$$<br>w_j := w_j - ğ›¼\frac{\partial }{\partial w_j}J(w)<br>$$<br>è®©æˆ‘ä»¬é’ˆå¯¹ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ (x, y) ç®—ç®—è¿™ä¸ªåå¯¼æ˜¯å•¥ï¼š<br>$$<br>\begin{align}\frac{\partial }{\partial w_j}J(w)   &amp; =   \frac{\partial }{\partial w_j}\frac{1}{2}(h_w(x)-y)^2\\<br>&amp; =  2ï½¥\frac{1}{2}(h_w(x)-y)ï½¥\frac{ğœ•}{ğœ•w_j}(h_w(x)-y)\\<br>&amp; = (h_w(x)-y)ï½¥\frac{ğœ•}{ğœ•w_j}(\sum_{i=0}^nw_ix_i-y)\\<br>&amp; = (h_w(x)-y)x_j\end{align}<br>$$<br>å› æ­¤å¯¹äºä¸€ä¸ªè®­ç»ƒæ ·æœ¬æœ‰ï¼š<br>$$<br>w_j := w_j - ğ›¼(y^{i}-h_w(x^{i}))x_j^{(i)}<br>$$<br>è¿ç”¨åœ¨å¤šäºä¸€ä¸ªæ ·æœ¬çš„è®­ç»ƒé›†ä¸Šæ—¶ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§é€‰æ‹©ï¼š</p><ol><li><p><strong>æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆbatch gradient descentï¼‰</strong></p><p>å°†æ‰€æœ‰æƒå€¼åˆå§‹åŒ–ä¸º1</p><p>å¾ªç¯Ræ¬¡: </p><p>â€‹    è®¡ç®—æ•´ä¸ªè®­ç»ƒé›†çš„æ¢¯åº¦</p><p>â€‹    é€šè¿‡ alpha * gradient æ›´æ–°æƒå€¼å‘é‡</p><p>â€‹    è¿”å›æƒå€¼å‘é‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></div><div class="line">    dataMatrix = mat(dataMatIn) <span class="comment"># m x n</span></div><div class="line">    labelMat = mat(classLabels).transpose() <span class="comment">#  1x100 to 100x1</span></div><div class="line">    m, n = shape(dataMatrix)</div><div class="line">    alpha = <span class="number">0.001</span></div><div class="line">    maxCycles = <span class="number">500</span></div><div class="line">    weights = ones((n,<span class="number">1</span>)) <span class="comment"># n x 1</span></div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</div><div class="line">        h = sigmoid(dataMatrix * weights) <span class="comment"># m x 1, æ•´ä¸ªè®­ç»ƒé›†</span></div><div class="line">        error = labelMat - h</div><div class="line">        weights = weights + alpha * dataMatrix.transpose()*error</div><div class="line">    <span class="keyword">return</span> weights</div></pre></td></tr></table></figure></li><li><p><strong>éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆstochastic gradient descentï¼incremental gradient descentï¼‰</strong></p><p>å°†æ‰€æœ‰æƒå€¼åˆå§‹åŒ–ä¸º1</p><p>å¯¹æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼š</p><p>â€‹    è®¡ç®—è®­ç»ƒæ ·æœ¬çš„æ¢¯åº¦</p><p>â€‹    é€šè¿‡ alpha * gradient æ›´æ–°æƒå€¼å‘é‡</p><p>â€‹    è¿”å›æƒå€¼å‘é‡</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatIn, classLabels)</span>:</span></div><div class="line">    dataArr = array(dataMatIn)</div><div class="line">    m, n = shape(dataArr)</div><div class="line">    alpha = <span class="number">0.01</span></div><div class="line">    weights = ones(n)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        h = sigmoid(sum(dataArr[i] * weights)) <span class="comment"># single valueï¼Œä¸€ä¸ªè®­ç»ƒæ ·æœ¬</span></div><div class="line">        error = classLabels[i] - h <span class="comment"># single value</span></div><div class="line">        weights = weights + alpha * error * dataArr[i]</div><div class="line">    <span class="keyword">return</span> weights</div></pre></td></tr></table></figure><p>ä¸¤ç§æ–¹æ³•çš„åŒºåˆ«åœ¨äºè®¡ç®— <strong>weights</strong> æ—¶ï¼Œã€Œæ‰¹é‡æ¢¯åº¦ä¸‹é™ã€æ¯æ¬¡éƒ½ç”¨æ•´ä¸ªè®­ç»ƒé›†æ¥æ›´æ–°æƒå€¼ã€‚å‡è®¾æˆ‘ä»¬æœ‰mä¸ªå®ä¾‹å’Œnä¸ªç‰¹å¾ï¼Œæ¯æ¬¡å°±è¦åš <strong>m*n</strong> æ¬¡ä¹˜æ³•ï¼Œå½“ <strong>m</strong> éå¸¸å¤§æ—¶ï¼Œè®¡ç®—ä»£ä»·æ˜¯å¾ˆé«˜çš„ã€‚è€Œã€Œéšæœºæ¢¯åº¦ä¸‹é™ã€æ¯æ¬¡åªç”¨ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œå®ƒåŒæ—¶ä¹Ÿæ˜¯ä¸€ç§åœ¨çº¿å­¦ä¹ ç®—æ³•ã€‚è™½ç„¶å®ƒæœ‰æ—¶å€™å¾ˆéš¾å®‰å…¨ç­‰äºæœ€ä¼˜å€¼ï¼Œä½†ä¹Ÿå·®ä¸å¤šäº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ã€Œéšæœºæ¢¯åº¦ä¸‹é™ã€æ¥è®­ç»ƒæƒå€¼ã€‚</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬å¯¹éšæœºæ¢¯åº¦ä¸‹é™å‡½æ•°åšä¸€äº›ä¿®æ”¹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatIn, classLabels, numIter=<span class="number">150</span>)</span>:</span></div><div class="line">    dataArr = array(dataMatIn)</div><div class="line">    m, n = shape(dataArr)</div><div class="line">    alpha = <span class="number">0.01</span></div><div class="line">    weights = ones(n)</div><div class="line">    <span class="keyword">for</span> iter <span class="keyword">in</span> range(numIter): <span class="comment"># è¿­ä»£æ¬¡æ•°</span></div><div class="line">        dataIndex = list(range(m))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">            <span class="comment"># 1/ Alpha changes with each iteration</span></div><div class="line">            alpha = <span class="number">4</span>/(<span class="number">1</span>+iter+i) + <span class="number">0.01</span></div><div class="line">            <span class="comment"># 2/ Update vectors are randomly selected</span></div><div class="line">            randIndex = int(random.uniform(<span class="number">0</span>, len(dataIndex)))</div><div class="line">            h = sigmoid(sum(dataArr[randIndex] * weights)) <span class="comment"># single value</span></div><div class="line">            error = classLabels[randIndex] - h <span class="comment"># single value</span></div><div class="line">            weights = weights + alpha * error * dataArr[randIndex]</div><div class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</div><div class="line">    <span class="keyword">return</span> weights</div></pre></td></tr></table></figure><h3 id="é¢„æµ‹ï¼šä»ç–æ°”ç—…é¢„æµ‹ç—…é©¬çš„æ­»äº¡ç‡"><a href="#é¢„æµ‹ï¼šä»ç–æ°”ç—…é¢„æµ‹ç—…é©¬çš„æ­»äº¡ç‡" class="headerlink" title="é¢„æµ‹ï¼šä»ç–æ°”ç—…é¢„æµ‹ç—…é©¬çš„æ­»äº¡ç‡"></a>é¢„æµ‹ï¼šä»ç–æ°”ç—…é¢„æµ‹ç—…é©¬çš„æ­»äº¡ç‡</h3><p>è¿™é‡Œæ’æ’­ä¸€ä¸‹å¦‚ä½•å¤„ç†æ•°æ®çš„ç¼ºå¤±å€¼ã€‚é¢å¯¹ç¼ºå¤±çš„ä¸€äº›ç‰¹å¾æˆ‘ä»¬æœ‰å¦‚ä¸‹é€‰æ‹©ï¼š</p><ol><li>ä½¿ç”¨å¯ç”¨ç‰¹å¾çš„å‡å€¼æ¥å¡«è¡¥ç¼ºå¤±å€¼</li><li>ä½¿ç”¨ç‰¹æ®Šå€¼æ¥å¡«è¡¥ç¼ºå¤±å€¼ï¼Œå¦‚-1</li><li>å¿½ç•¥æœ‰ç¼ºå¤±å€¼çš„æ ·æœ¬</li><li>ä½¿ç”¨ç›¸ä¼¼æ ·æœ¬çš„å‡å€¼å¡«è¡¥ç¼ºå¤±å€¼</li><li>ä½¿ç”¨å¦å¤–çš„æœºå™¨å­¦ä¹ ç®—æ³•é¢„æµ‹ç¼ºå¤±å€¼</li></ol><p>åœ¨ã€Œå¯¹æ•°å‡ ç‡å›å½’ã€ä¸­ï¼Œç‰¹å¾çš„ç¼ºå¤±å€¼å¯ä»¥ç”¨0æ¥å¡«è¡¥ã€‚å› ä¸º <code>weights = weights + alpha _ error _ dataArr[randIndex]</code>ï¼Œå½“å¯¹åº”ç‰¹å¾å€¼ä¸º0æ—¶ï¼Œè¯¥ç‰¹å¾çš„ç³»æ•°å€¼å°†ä¸å˜ï¼Œåˆ™ <code>weights = weights</code>ã€‚ç”±äº <code>sigmoidï¼ˆ0ï¼‰=0.5</code>ï¼Œå¯¹äºç»“æœçš„é¢„æµ‹ä¸å…·æœ‰ä»»ä½•å€¾å‘æ€§ã€‚ä½†æ˜¯æ ‡è®°ç¼ºå¤±çš„æ ·æœ¬æˆ‘ä»¬å°±ä¸å¾—ä¸ä¸¢å¼ƒäº†å•Šï¼ˆéƒ½ä¸çŸ¥é“ä½ æœ‰ç—…æ²¡ç—…è¦ä½ ä½•ç”¨</p><p>å¥½çš„ï¼Œè¯´äº†è¿™ä¹ˆå¤šï¼Œä½œè€…å·²ç»å¸®æˆ‘ä»¬å¤„ç†å®Œæ•°æ®äº†ã€‚</p><p>ç»ˆäºæˆ‘ä»¬è¦å¼€å§‹é¢„æµ‹äº†ï¼</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX, weights)</span>:</span></div><div class="line">    prob = sigmoid(sum(inX*weights))</div><div class="line">    <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>: <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0</span></div></pre></td></tr></table></figure><p><img src="/2017/10/20/machine-learning-in-action-note3/test_result.png" alt=""></p><p>æˆ‘çš„å¦ˆå‘€è®­ç»ƒå¿«ä¸€å°æ—¶å‘¢ã€‚ã€‚ã€‚</p><p><strong>å‚è€ƒé“¾æ¥ï¼š</strong></p><p>[1] <a href="http://tieba.baidu.com/p/2905471495" target="_blank" rel="external">http://tieba.baidu.com/p/2905471495</a></p><p>[2] å‘¨å¿—åã€Šæœºå™¨å­¦ä¹ ã€‹</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;é¦–å…ˆæˆ‘ä»¬å…ˆæ¥è¯´è¯´ã€Œå›å½’ã€ã€‚wikiå‘Šè¯‰æˆ‘ä»¬ï¼Œå›å½’æŒ‡çš„æ˜¯ç ”ç©¶å˜é‡å…³ç³»çš„ä¸€ç§ç»Ÿè®¡åˆ†ææ–¹æ³•ã€‚å›å½’åˆ†ææ˜¯ä¸€ç§æ•°å­¦æ¨¡å‹ï¼Œè€Œæˆ‘ä»¬æœ€ç†Ÿæ‚‰çš„éã€Œçº¿æ€§æ¨¡å‹ã€è«å±äº†ã€‚ä»¥ä¸‹å¼•å…¥çš„ç†è®ºæ¥æºäºè¥¿ç“œä¹¦ã€‚&lt;/p&gt;
&lt;p&gt;ã€Œçº¿æ€§å›å½’ã€è¯•å›¾é€šè¿‡ç»™å®šæ•°æ®é›†å­¦å¾—ä¸€ä¸ªã€Œçº¿æ€§æ¨¡å‹ã€ä»¥å°½å¯èƒ½å‡†ç¡®åœ°é¢„æµ‹è¾“å‡ºæ ‡è®°ã€‚ç”¨å…¬å¼æ¥è¡¨ç¤ºï¼š&lt;br&gt;$$&lt;br&gt;f(x_i) = wx_i+bï¼Œ\\ ä½¿å¾—f(x_i) \approx y_i&lt;br&gt;$$&lt;br&gt;æœ‰æ—¶æˆ‘ä»¬ç¤ºä¾‹å¯¹åº”çš„è¾“å‡ºæ ‡è®°æ˜¯åœ¨æŒ‡æ•°å°ºåº¦ä¸Šå˜åŒ–ï¼Œé‚£å°±å¯å°†è¾“å‡ºæ ‡è®°çš„å¯¹æ•°ä½œä¸ºçº¿æ€§æ¨¡å‹é€¼è¿‘çš„ç›®æ ‡ï¼Œå³&lt;br&gt;$$&lt;br&gt;\ln y = w^Tx + b&lt;br&gt;$$&lt;br&gt;è¿™å°±æ˜¯â€å¯¹æ•°çº¿æ€§å›å½’â€œï¼ˆlog-linear regressionï¼‰ã€‚ä»è€Œå¼•å‡ºäº†ä¸€ä¸ªâ€å¹¿ä¹‰çº¿æ€§æ¨¡å‹â€œï¼ˆgeneralized linear modelï¼‰&lt;br&gt;$$&lt;br&gt;y = g^{-1}(w^Tx + b)&lt;br&gt;$$&lt;br&gt;å…¶ä¸­å‡½æ•°g(ï½¥)ç§°ä¸ºâ€œè”ç³»å‡½æ•°â€ï¼ˆlink functionï¼‰ã€‚å¯¹æ•°å›å½’æ˜¯å¹¿ä¹‰çº¿æ€§æ¨¡å‹åœ¨g(ï½¥) = ln(ï½¥) æ—¶çš„ç‰¹ä¾‹ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>image-classification-note</title>
    <link href="http://yoursite.com/2017/10/19/image-classification-note/"/>
    <id>http://yoursite.com/2017/10/19/image-classification-note/</id>
    <published>2017-10-19T07:41:20.000Z</published>
    <updated>2017-10-21T09:39:25.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems:"></a>Problems:</h3><ol><li>Semantic Gap: Thereâ€™s a huge gap between the semantic idea of a cat, and these pixel values that the computer is actually seeing.</li><li>Viewpoint variation: All pixels change when the camera moves</li><li>Illumination: There can be lighting conditions going on in the scene</li><li>Deformation: Cats can assume a lot of different, varied poses and positions.</li><li>Occlusion: You might only see a part of a cat.</li><li>Background Clutter: The foreground of the cat look similar in appearance</li><li>Intraclass variation: Cats can come in different shapes and sizes and colors and ages</li></ol><a id="more"></a><h3 id="An-image-classifier"><a href="#An-image-classifier" class="headerlink" title="An image classifier"></a>An image classifier</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify_image</span><span class="params">(image)</span>:</span></div><div class="line"><span class="comment"># Some magic here?</span></div><div class="line">    <span class="keyword">return</span> class_label</div></pre></td></tr></table></figure><p> <strong>no obvious way</strong> to hard-code the algorithm for recognizing a cat, or other classes.</p><h3 id="Data-Driven-Approach"><a href="#Data-Driven-Approach" class="headerlink" title="Data-Driven Approach"></a>Data-Driven Approach</h3><ol><li>Collect a dataset of images and labels</li><li>Use Machine Learning to train a classifier</li><li>Evaluate the classifier on new images</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(images, labels)</span>:</span></div><div class="line"><span class="comment"># Machine learning</span></div><div class="line"><span class="keyword">return</span> model</div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(model, test_images)</span>:</span></div><div class="line"><span class="comment"># Use model to predict labels</span></div><div class="line">    <span class="keyword">return</span> test_labels</div></pre></td></tr></table></figure><p>Rather than a single function that just inputs an image and recognizes a cat, we have these two functions. One called <strong>train</strong>, thatâ€™s going to input images and labels and then output a model, another function called <strong>predict</strong>, which will input the model and make predictions for images.</p><p>#Nearest Neighbor classifier</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NearestNeighbor</span>:</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line"><span class="keyword">pass</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></div><div class="line"><span class="string">""" X is N x D where each row is an example. Y is 1-dimension of size N """</span></div><div class="line">    <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></div><div class="line">    self.Xtr = X</div><div class="line">    self.ytr = y</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></div><div class="line">     <span class="string">""" X is N x D where each row is an example we wish to predict label for """</span></div><div class="line">    num_test = X.shape[<span class="number">0</span>]</div><div class="line">    <span class="comment"># lets make sure that the output type matches the input type</span></div><div class="line">    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)</div><div class="line">    </div><div class="line">    <span class="comment"># loop over all test rows</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line"><span class="comment"># find the nearest training image to the i'th test image</span></div><div class="line">     <span class="comment"># using the L1 distance (sum of absolute alue differences)</span></div><div class="line">        distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = <span class="number">1</span>)</div><div class="line">        min_index = np.argmin(distances) <span class="comment"># get the index with smallest distance</span></div><div class="line">Ypred[i] = self.ytr[min_index] <span class="comment">#predict the label of the nearest example</span></div><div class="line">     <span class="keyword">return</span> Ypred</div></pre></td></tr></table></figure><p>Q: With N examples. how fast are training and prediction?</p><p>A: Train O(1), predict O(N)</p><p>This is bad: we want classifiers that are <strong>fast</strong> at prediciton; <strong>slow</strong> for training is ok.</p><h3 id="k-Nearest-Neighbors"><a href="#k-Nearest-Neighbors" class="headerlink" title="k-Nearest Neighbors"></a>k-Nearest Neighbors</h3><p>Instead of copying label from nearest neighbor, thake <strong>majority vote</strong> form K closest points.</p><p>###Hyperparameters</p><ul><li>What is the best value of <strong>k</strong> to use?</li><li>What is the best <strong>distance</strong> to use?</li></ul><p>These are <strong>hyperparameters</strong>: choices about the algorithm that we set rather than learn</p><p>_Very problem-dependent._</p><p>_Must try them all out and see what works best._</p><h3 id="Setting-Hyperparameters"><a href="#Setting-Hyperparameters" class="headerlink" title="Setting Hyperparameters"></a>Setting Hyperparameters</h3><ul><li>Split data into <strong>train</strong>, <strong>val</strong>, and <strong>test</strong>; choose hyperparameters on val and evaluate on test</li><li><strong>Cross-Validation</strong>: Split data into **folds, try each fold as validation and average the results. Useful for small datasets but not used too frequently in deep learning.</li></ul><h3 id="k-Nearest-Neighbor-on-images-never-used"><a href="#k-Nearest-Neighbor-on-images-never-used" class="headerlink" title="k-Nearest Neighbor on images never used"></a>k-Nearest Neighbor on images never used</h3><ul><li>Very slow at test time</li><li>Distance metrics on pixels are not informative</li><li>Curse of dimensionality</li></ul><h3 id="k-Nearest-Neighbors-Summary"><a href="#k-Nearest-Neighbors-Summary" class="headerlink" title="k-Nearest Neighbors: Summary"></a>k-Nearest Neighbors: Summary</h3><ul><li>In <strong>Image classification</strong> we start with a <strong>training set</strong> of images and labels, and must predict labels on the <strong>test set</strong></li><li>The *K-Nearest Neighbors classifier predicts labels based on nearest training examples</li><li>Distance metric and K are <strong>hyperparameters</strong></li><li>Choose hyperparameters using the <strong>validation set</strong>; only run on the test set once at the very end!</li></ul><p>#Linear Classification</p><p>These deep neural networks are kind of like Legos and this linear classifier is kind of like the most basic building blocks of these giant networks.</p><p>f(x, W) = Wx + b</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Problems&quot;&gt;&lt;a href=&quot;#Problems&quot; class=&quot;headerlink&quot; title=&quot;Problems:&quot;&gt;&lt;/a&gt;Problems:&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Semantic Gap: Thereâ€™s a huge gap between the semantic idea of a cat, and these pixel values that the computer is actually seeing.&lt;/li&gt;
&lt;li&gt;Viewpoint variation: All pixels change when the camera moves&lt;/li&gt;
&lt;li&gt;Illumination: There can be lighting conditions going on in the scene&lt;/li&gt;
&lt;li&gt;Deformation: Cats can assume a lot of different, varied poses and positions.&lt;/li&gt;
&lt;li&gt;Occlusion: You might only see a part of a cat.&lt;/li&gt;
&lt;li&gt;Background Clutter: The foreground of the cat look similar in appearance&lt;/li&gt;
&lt;li&gt;Intraclass variation: Cats can come in different shapes and sizes and colors and ages&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ã€ŠMachine Learning in Actionã€‹å­¦ä¹ ç¬”è®°äºŒï¼šæœ´ç´ è´å¶æ–¯</title>
    <link href="http://yoursite.com/2017/10/18/machine-learning-in-action-note2/"/>
    <id>http://yoursite.com/2017/10/18/machine-learning-in-action-note2/</id>
    <published>2017-10-18T00:52:21.000Z</published>
    <updated>2018-01-21T08:35:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>æœ´ç´ è´å¶æ–¯æ˜¯è´å¶æ–¯å†³ç­–ç†è®ºçš„ä¸€éƒ¨åˆ†ï¼Œæ‰€ä»¥æˆ‘ä»¬æ¥å…ˆæ¥çœ‹çœ‹è´å¶æ–¯å†³ç­–ç†è®ºã€‚è´å¶æ–¯å†³ç­–ç†è®ºçš„æ ¸å¿ƒæ˜¯é€‰æ‹©å…·æœ‰æœ€é«˜æ¦‚ç‡çš„å†³ç­–ã€‚</p><p>å‡è®¾æœ‰iä¸ªåˆ†ç±»ï¼Œæˆ‘ä»¬éœ€è¦æ¯”è¾ƒçš„å…¶å®æ˜¯åéªŒæ¦‚ç‡ <strong>P(Y=c~k~|X=x)</strong> çš„å¤§å°ã€‚é‚£ä¹ˆåéªŒæ¦‚ç‡æ˜¯ä»€ä¹ˆé¬¼ï¼Ÿwikiè¯´ä¸€ä¸ªéšæœºäº‹ä»¶çš„åéªŒæ¦‚ç‡æ˜¯åœ¨è€ƒè™‘å’Œç»™å‡ºç›¸å…³è¯æ®æˆ–æ•°æ®åæ‰€å¾—åˆ°çš„æ¡ä»¶æ¦‚ç‡ã€‚ç®€è€Œè¨€ä¹‹ï¼ŒåéªŒæ¦‚ç‡å°±æ˜¯æ¡ä»¶æ¦‚ç‡ã€‚æ¢ç®—æˆæˆ‘ä»¬éœ€è¦è§£å†³çš„é—®é¢˜å°±æ˜¯ï¼Œåœ¨å·²çŸ¥ä¸€å †ç‰¹å¾çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—å‡ºå®ƒå±äºå„ä¸ªç±»çš„æ¦‚ç‡ï¼Œé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„é‚£ä¸€ç±»ä½œä¸ºé¢„æµ‹çš„ç±»åˆ«ã€‚</p><p>é‚£ä¹ˆé—®é¢˜çš„å…³é”®å°±è½¬å‘äº†å¦‚ä½•è®¡ç®—è¿™ä¸ªåéªŒæ¦‚ç‡ã€‚è´å¶æ–¯ç»™å‡ºäº†ä¸€ä¸ªå…¬å¼ï¼š<br>$$<br>P(A|B) = P(A)\frac{P(B|A)}{P(B)}<br>$$<br>è®©æˆ‘ä»¬æ¥ä»£å…¥ä¸€ä¸‹ï¼š</p><p>$$<br>P(Y=c_k|X=x) = P(Y=c_k)\frac{P(X=x|Y=c_k)}{P(X=x)}<br>$$<br>ç»™ä¸€ä¸ªè®­ç»ƒé›†ï¼Œ<strong>P(Y=c~i~)</strong>æ˜¯å¾ˆå¥½æ±‚çš„ï¼Œé‚£å®ƒé‚»å±…é‚£å¨ç©æ„å„¿æ€ä¹ˆåŠï¼Ÿè¿™é‡Œå°±å¼•å‡ºäº†ä¸€ä¸ªå¾ˆé‡è¦çš„ï¼ˆæ•²é»‘æ¿ï¼‰å…³äºã€Œæœ´ç´ ã€ä¸€è¯çš„å«ä¹‰ã€‚å®ƒç»™å‡ºäº†ä¸€ä¸ªå‡è®¾ï¼šå‡è®¾æ‰€æœ‰æ¡ä»¶éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚æ„æ€æ˜¯ä¸€ä¸ªç‰¹å¾å‡ºç°çš„æ¦‚ç‡å¹¶ä¸ä¾èµ–å…¶ä»–ç‰¹å¾ã€‚å› æ­¤æˆ‘ä»¬ä¸å¦¨å…ˆè€ƒè™‘ä¸€ä¸‹é‚»å±…çš„åˆ†å­ï¼š<br>$$<br>P(X=x|Y=c_k) = P(X_1=x_1,â€¦,X_n=x_n|Y=c_k) = \prod_{j=1}^{n}P(X_j=x_j|Y=c_k)<br>$$<br>ç”±äºåˆ†æ¯ <strong>P(X=x)</strong> å¯¹æ‰€æœ‰c~i~éƒ½æ²¡å·®ï¼Œé‚£æˆ‘ä»¬å¤§å¯ä¸å¿…è®¡ç®—å‡ºè¿™ä¸ªå€¼ã€‚</p><h3 id="æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š"><a href="#æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š" class="headerlink" title="æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š"></a>æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š</h3><p>è¾“å…¥ï¼šæ•°æ®é›† \(T = {(x_1,y_1), (x_~2,y_2), â€¦ ,(x_n, y_n)}\)ï¼Œå…¶ä¸­\(x_i = (x_i^1, x_i^2, â€¦ , x_i^n)^Tï¼Œx_i^j \)æ˜¯ç¬¬ i ä¸ªæ ·æœ¬çš„ç¬¬jä¸ªç‰¹å¾ï¼›å®ä¾‹x</p><p>è¾“å‡ºï¼šå®ä¾‹xçš„åˆ†ç±»</p><p>1) è®¡ç®—å…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡</p><p>$$P(Y=c_k) = \frac{\sum_{i=1}^{N}I(y_i=c_k)}{N}ï¼Œk=1,2,â€¦K$$</p><p>$$<br>P(X^j = a_{jl} | Y=c_k) = \frac{\sum_{i=1}^NI(x_i^j = a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i)=c_k}<br>$$</p><p>$$<br>j=1,2,â€¦,n; l=1,2,â€¦,S_j; k=1,2,â€¦,K<br>$$</p><p>2) å¯¹äºç»™å®šå®ä¾‹x=(x^1^, x^2^, â€¦ , x^n^)ï¼Œè®¡ç®—<br>$$<br>P(Y=c_k)\prod_{j=1}^{n}P(X^j = x^j|Y=c_k) ,  k=1,2,â€¦K<br>$$</p><p>3) ç¡®å®šå®ä¾‹xçš„ç±»<br>$$<br>y=\max P(Y=c_k)\prod_{j=1}^{n}P(X^j = x^j|Y=c_k) ,  k=1,2,â€¦K<br>$$</p><a id="more"></a><h3 id="ä¸€ä¸ªæ —å­ï¼šé‚®ä»¶åˆ†ç±»é—®é¢˜"><a href="#ä¸€ä¸ªæ —å­ï¼šé‚®ä»¶åˆ†ç±»é—®é¢˜" class="headerlink" title="ä¸€ä¸ªæ —å­ï¼šé‚®ä»¶åˆ†ç±»é—®é¢˜"></a>ä¸€ä¸ªæ —å­ï¼šé‚®ä»¶åˆ†ç±»é—®é¢˜</h3><p>å…¬å¼éƒ½æœ‰äº†ï¼Œåˆ°åº•è¦å¦‚ä½•å®ç°å‘¢ï¼Ÿæˆ‘ä»¬é€šè¿‡é‚®ä»¶åˆ†ç±»é—®é¢˜æ¥å¼•å…¥è§£å†³åŠæ³•ã€‚</p><p>é—®é¢˜ï¼šå‡è®¾æœ‰å¾ˆå¤šä¸ªé‚®ä»¶ï¼Œæ ‡è®°ä¸º<strong>1-åƒåœ¾é‚®ä»¶</strong>ï¼Œ<strong>0-æ­£å¸¸é‚®ä»¶</strong>ï¼Œç»™å®šä¸€ä¸ªå®ä¾‹åˆ¤æ–­å®ƒå±äºå“ªä¸€ç±»ã€‚</p><p>æ€è·¯ï¼šé¦–å…ˆåœ¨å•¥éƒ½æ²¡æœ‰çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è¦å¤„ç†é‚®ä»¶ï¼Œå°†å…¶è½¬åŒ–ä¸ºpythonå¯ä»¥ç†è§£çš„listï¼Œå¹¶ä¸ºå‡ºç°çš„æ‰€æœ‰å•è¯æ„å»ºä¸€ä¸ªè¯æ±‡è¡¨ï¼Œæ¯å°é‚®ä»¶å¯¹åº”ä¸ºè¯æ±‡è¡¨ä¸Šçš„ä¸€ä¸ªå‘é‡ï¼Œæ‰€æœ‰çš„é‚®ä»¶æ„æˆä¸€ä¸ªçŸ©é˜µï¼Œåˆ©ç”¨çŸ©é˜µè®¡ç®—å‡ºå…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡ï¼Œå°†ç»™å®šå®ä¾‹è½¬åŒ–ä¸ºå‘é‡ï¼Œé€šè¿‡æ¯”è¾ƒå¤§å°ç¡®å®šå®ä¾‹çš„ç±»ã€‚</p><ol><li><p>å¤„ç†é‚®ä»¶ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">26</span>):</div><div class="line">        wordList = textParse(open(<span class="string">'email/spam/%d.txt'</span> % i, <span class="string">"rb"</span>).read().decode(<span class="string">'GBK'</span>,<span class="string">'ignore'</span>))</div><div class="line">        docList.append(wordList) <span class="comment"># æ–‡æ¡£åˆé›†</span></div><div class="line">        fullText.extend(wordList) <span class="comment"># å•è¯åˆé›†</span></div><div class="line">        classList.append(<span class="number">1</span>)</div><div class="line">        wordList = textParse(open(<span class="string">'email/ham/%d.txt'</span> % i, <span class="string">"rb"</span>).read().decode(<span class="string">'GBK'</span>, <span class="string">'ignore'</span>))</div><div class="line">        docList.append(wordList)</div><div class="line">        fullText.extend(wordList)</div><div class="line">        classList.append(<span class="number">0</span>)</div></pre></td></tr></table></figure></li><li><p>æ„å»ºè¯æ±‡è¡¨ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></div><div class="line">    vocabSet = set([])</div><div class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</div><div class="line">        vocabSet = vocabSet | set(document) <span class="comment"># ä¸é‡å¤çš„å•è¯</span></div><div class="line">    <span class="keyword">return</span> list(vocabSet)</div><div class="line"> </div><div class="line">vocabList = vocabSet(docList)</div></pre></td></tr></table></figure></li><li><p>å°†æ‰€æœ‰é‚®ä»¶åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">trainIndex = list(range(<span class="number">50</span>)); testIndex = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">    randIndex = int(random.uniform(<span class="number">0</span>, len(trainIndex)))</div><div class="line">    testIndex.append(trainIndex[randIndex])</div><div class="line">    <span class="keyword">del</span>(trainIndex[randIndex])</div></pre></td></tr></table></figure></li><li><p>å°†æ‰€æœ‰é‚®ä»¶è½¬æ¢ä¸ºçŸ©é˜µï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWords2VecMN</span><span class="params">(vocabList, inputSet)</span>:</span></div><div class="line">    returnVec = [<span class="number">0</span>]*len(vocabList)</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> vocabList:</div><div class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</div><div class="line">            returnVec[vocabList.index(word)] += <span class="number">1</span> <span class="comment"># è½¬æ¢ä¸ºè¯æ±‡è¡¨å¯¹åº”å‘é‡</span></div><div class="line">    <span class="keyword">return</span>  returnVec</div><div class="line"></div><div class="line">trainMat = []; trainClasses = []</div><div class="line"><span class="keyword">for</span> docIndex <span class="keyword">in</span> trainIndex:</div><div class="line">trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex])) </div><div class="line">    trainClasses.append(classList[docIndex])</div></pre></td></tr></table></figure></li><li><p>è®¡ç®—å…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></div><div class="line">    numTrainDocs = len(trainMatrix)</div><div class="line">    numWords = len(trainMatrix[<span class="number">0</span>])</div><div class="line">    pAbusive = sum(trainCategory) / float(numTrainDocs) <span class="comment"># å…ˆéªŒæ¦‚ç‡ p(class=1)</span></div><div class="line"></div><div class="line">    <span class="comment"># 1/ Initialize probabilities</span></div><div class="line">    <span class="comment"># æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¤„ç†</span></div><div class="line">    p0Num = ones(numWords) <span class="comment"># p(xi|c0)</span></div><div class="line">    p1Num = ones(numWords) <span class="comment"># p(xi|c1)</span></div><div class="line">    p0Denom = <span class="number">2.0</span>; p1Denom = <span class="number">2.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</div><div class="line"></div><div class="line">        <span class="comment"># 2 / Vector addition</span></div><div class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</div><div class="line">            p1Num += trainMatrix[i]</div><div class="line">            p1Denom += sum(trainMatrix[i])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            p0Num += trainMatrix[i]</div><div class="line">            p0Denom += sum(trainMatrix[i])</div><div class="line"></div><div class="line">    <span class="comment"># 3/ Element-wise division</span></div><div class="line">    <span class="comment"># æ¡ä»¶æ¦‚ç‡</span></div><div class="line">    p1Vect = log(p1Num / p1Denom)</div><div class="line">    p0Vect = log(p0Num / p0Denom)</div><div class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</div><div class="line"></div><div class="line">p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))</div></pre></td></tr></table></figure><p>è®©æˆ‘ä»¬æŠŠæ¡ä»¶æ¦‚ç‡ç”¨æ™®é€šè¯ç¨å¾®ç¿»è¯‘ä¸€ä¸‹ï¼š<br>$$<br>P(X=x_i|c_k) = \frac{å•è¯x_iå‡ºç°æ¬¡æ•°}{c_kç±»æ–‡æ¡£æ€»å•è¯æ•°}<br>$$<br>æŠŠæ‰€æœ‰çš„ \(P(X=x_i|c_k)\) æ‹åˆ°ä¸€èµ·å°±æ˜¯ä¸€ä¸ªå‘é‡ piVcetã€‚</p><p>åœ¨ä¸Šé¢çš„ä»£ç ä¸­æˆ‘ä»¬å…¶å®å¤„ç†äº†ä¸¤ç§æç«¯æƒ…å†µï¼š</p><ol><li>æ—©äº›æ—¶å€™è¿™ä¸ªä»£ç æ˜¯<code>p0Num = zeros(numWords); p0Denom =0</code>ï¼ˆp1åŒç†ï¼‰ã€‚å¦‚æœæŸä¸ªå•è¯æ²¡æœ‰å‡ºç°ï¼Œå½“è®¡ç®—ä¹˜ç§¯ Î P(X=x~i~|c~k~)æ—¶ï¼Œç»“æœå°±ä¼šä¸º0ï¼Œè¿™æ˜¾ç„¶å°±æ²¡æœ‰åŠæ³•è¿›è¡Œé¢„æµ‹äº†å˜›ã€‚æ‹‰æ™®æ‹‰æ–¯å°±æå‡ºç”¨åŠ 1çš„æ–¹æ³•ä¼°è®¡æ²¡æœ‰å‡ºç°è¿‡çš„ç°è±¡çš„æ¦‚ç‡ã€‚</li><li>è¿˜æœ‰ä¸€ä¸ªæ˜¯ä¸‹æº¢å‡ºé—®é¢˜ã€‚åœ¨è®¡ç®—ä¹˜ç§¯  \(\prod P(X=x_i|c_k)\)æ—¶ï¼Œç”±äºæ¦‚ç‡éƒ½æ˜¯å¾ˆå°çš„æ•°å€¼ï¼Œç¨‹åºæœ‰å¯èƒ½ä¸‹æº¢å‡ºè€Œå¾—ä¸åˆ°æ­£ç¡®ç­”æ¡ˆã€‚è§£å†³åŠæ³•å°±æ˜¯å¯¹ä¹˜ç§¯å–è‡ªç„¶å¯¹æ•°ã€‚</li></ol></li><li><p>äº¤å‰éªŒè¯</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></div><div class="line">    p1 = sum(vec2Classify * p1Vec) + log(pClass1)</div><div class="line">    p0 = sum(vec2Classify * p0Vec) + log(<span class="number">1</span>-pClass1)</div><div class="line">    <span class="keyword">if</span> p1 &gt; p0:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    </div><div class="line">    errorCount = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testIndex:</div><div class="line">        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])</div><div class="line">classifyResult = classifyNB(array(wordVector), p0V, p1V, pSpam)</div><div class="line">    <span class="keyword">if</span>  classifyResult != classList[docIndex]:</div><div class="line">   errorCount += <span class="number">1</span></div><div class="line">print(<span class="string">"the error rate is: "</span>, float(errorCount)/len(testIndex))</div></pre></td></tr></table></figure></li></ol><p>è¿™é‡Œæˆ‘ä»¬ç»ˆäºè¦è®¡ç®—\(\prod P(X=x_i|c_k)\)äº†ã€‚<code>vec2Classify _ piVec</code> è¡¨ç¤ºå…ˆæ‰¾å‡ºå®ä¾‹æœ‰çš„å•è¯ï¼Œç”±äº\(\ln(a_b) = ln(a)+ln(b)\)ï¼Œæ¡ä»¶æ¦‚ç‡çš„ç›¸ä¹˜ä¾¿è½¬æ¢ä¸ºçŸ©é˜µå…ƒç´ ç›¸åŠ ã€‚</p><p>ğŸ™‚ é€‚ç”¨äºé‡å°‘çš„æ•°æ®é›†ï¼å¯ä»¥å¤„ç†å¤šç±»åˆ«é—®é¢˜</p><p>ğŸ™ å¯¹è¾“å…¥æ•°æ®çš„å‡†å¤‡æ–¹å¼è¾ƒæ•æ„Ÿ</p><p>ğŸ›  æ ‡ç§°å‹æ•°æ®</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æœ´ç´ è´å¶æ–¯æ˜¯è´å¶æ–¯å†³ç­–ç†è®ºçš„ä¸€éƒ¨åˆ†ï¼Œæ‰€ä»¥æˆ‘ä»¬æ¥å…ˆæ¥çœ‹çœ‹è´å¶æ–¯å†³ç­–ç†è®ºã€‚è´å¶æ–¯å†³ç­–ç†è®ºçš„æ ¸å¿ƒæ˜¯é€‰æ‹©å…·æœ‰æœ€é«˜æ¦‚ç‡çš„å†³ç­–ã€‚&lt;/p&gt;
&lt;p&gt;å‡è®¾æœ‰iä¸ªåˆ†ç±»ï¼Œæˆ‘ä»¬éœ€è¦æ¯”è¾ƒçš„å…¶å®æ˜¯åéªŒæ¦‚ç‡ &lt;strong&gt;P(Y=c~k~|X=x)&lt;/strong&gt; çš„å¤§å°ã€‚é‚£ä¹ˆåéªŒæ¦‚ç‡æ˜¯ä»€ä¹ˆé¬¼ï¼Ÿwikiè¯´ä¸€ä¸ªéšæœºäº‹ä»¶çš„åéªŒæ¦‚ç‡æ˜¯åœ¨è€ƒè™‘å’Œç»™å‡ºç›¸å…³è¯æ®æˆ–æ•°æ®åæ‰€å¾—åˆ°çš„æ¡ä»¶æ¦‚ç‡ã€‚ç®€è€Œè¨€ä¹‹ï¼ŒåéªŒæ¦‚ç‡å°±æ˜¯æ¡ä»¶æ¦‚ç‡ã€‚æ¢ç®—æˆæˆ‘ä»¬éœ€è¦è§£å†³çš„é—®é¢˜å°±æ˜¯ï¼Œåœ¨å·²çŸ¥ä¸€å †ç‰¹å¾çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—å‡ºå®ƒå±äºå„ä¸ªç±»çš„æ¦‚ç‡ï¼Œé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„é‚£ä¸€ç±»ä½œä¸ºé¢„æµ‹çš„ç±»åˆ«ã€‚&lt;/p&gt;
&lt;p&gt;é‚£ä¹ˆé—®é¢˜çš„å…³é”®å°±è½¬å‘äº†å¦‚ä½•è®¡ç®—è¿™ä¸ªåéªŒæ¦‚ç‡ã€‚è´å¶æ–¯ç»™å‡ºäº†ä¸€ä¸ªå…¬å¼ï¼š&lt;br&gt;$$&lt;br&gt;P(A|B) = P(A)\frac{P(B|A)}{P(B)}&lt;br&gt;$$&lt;br&gt;è®©æˆ‘ä»¬æ¥ä»£å…¥ä¸€ä¸‹ï¼š&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;P(Y=c_k|X=x) = P(Y=c_k)\frac{P(X=x|Y=c_k)}{P(X=x)}&lt;br&gt;$$&lt;br&gt;ç»™ä¸€ä¸ªè®­ç»ƒé›†ï¼Œ&lt;strong&gt;P(Y=c~i~)&lt;/strong&gt;æ˜¯å¾ˆå¥½æ±‚çš„ï¼Œé‚£å®ƒé‚»å±…é‚£å¨ç©æ„å„¿æ€ä¹ˆåŠï¼Ÿè¿™é‡Œå°±å¼•å‡ºäº†ä¸€ä¸ªå¾ˆé‡è¦çš„ï¼ˆæ•²é»‘æ¿ï¼‰å…³äºã€Œæœ´ç´ ã€ä¸€è¯çš„å«ä¹‰ã€‚å®ƒç»™å‡ºäº†ä¸€ä¸ªå‡è®¾ï¼šå‡è®¾æ‰€æœ‰æ¡ä»¶éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚æ„æ€æ˜¯ä¸€ä¸ªç‰¹å¾å‡ºç°çš„æ¦‚ç‡å¹¶ä¸ä¾èµ–å…¶ä»–ç‰¹å¾ã€‚å› æ­¤æˆ‘ä»¬ä¸å¦¨å…ˆè€ƒè™‘ä¸€ä¸‹é‚»å±…çš„åˆ†å­ï¼š&lt;br&gt;$$&lt;br&gt;P(X=x|Y=c_k) = P(X_1=x_1,â€¦,X_n=x_n|Y=c_k) = \prod_{j=1}^{n}P(X_j=x_j|Y=c_k)&lt;br&gt;$$&lt;br&gt;ç”±äºåˆ†æ¯ &lt;strong&gt;P(X=x)&lt;/strong&gt; å¯¹æ‰€æœ‰c~i~éƒ½æ²¡å·®ï¼Œé‚£æˆ‘ä»¬å¤§å¯ä¸å¿…è®¡ç®—å‡ºè¿™ä¸ªå€¼ã€‚&lt;/p&gt;
&lt;h3 id=&quot;æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š&quot;&gt;&lt;a href=&quot;#æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š&quot; class=&quot;headerlink&quot; title=&quot;æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š&quot;&gt;&lt;/a&gt;æœ´ç´ è´å¶æ–¯å­¦ä¹ ä¸åˆ†ç±»çš„ç®—æ³•è¿‡ç¨‹ï¼š&lt;/h3&gt;&lt;p&gt;è¾“å…¥ï¼šæ•°æ®é›† \(T = {(x_1,y_1), (x_~2,y_2), â€¦ ,(x_n, y_n)}\)ï¼Œå…¶ä¸­\(x_i = (x_i^1, x_i^2, â€¦ , x_i^n)^Tï¼Œx_i^j \)æ˜¯ç¬¬ i ä¸ªæ ·æœ¬çš„ç¬¬jä¸ªç‰¹å¾ï¼›å®ä¾‹x&lt;/p&gt;
&lt;p&gt;è¾“å‡ºï¼šå®ä¾‹xçš„åˆ†ç±»&lt;/p&gt;
&lt;p&gt;1) è®¡ç®—å…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡&lt;/p&gt;
&lt;p&gt;$$P(Y=c_k) = \frac{\sum_{i=1}^{N}I(y_i=c_k)}{N}ï¼Œk=1,2,â€¦K$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;P(X^j = a_{jl} | Y=c_k) = \frac{\sum_{i=1}^NI(x_i^j = a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i)=c_k}&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;j=1,2,â€¦,n; l=1,2,â€¦,S_j; k=1,2,â€¦,K&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;2) å¯¹äºç»™å®šå®ä¾‹x=(x^1^, x^2^, â€¦ , x^n^)ï¼Œè®¡ç®—&lt;br&gt;$$&lt;br&gt;P(Y=c_k)\prod_{j=1}^{n}P(X^j = x^j|Y=c_k) ,  k=1,2,â€¦K&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;3) ç¡®å®šå®ä¾‹xçš„ç±»&lt;br&gt;$$&lt;br&gt;y=\max P(Y=c_k)\prod_{j=1}^{n}P(X^j = x^j|Y=c_k) ,  k=1,2,â€¦K&lt;br&gt;$$&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ã€ŠMachine Learning in Actionã€‹å­¦ä¹ ç¬”è®°ä¸€ï¼škNNå’Œå†³ç­–æ ‘</title>
    <link href="http://yoursite.com/2017/10/15/machine-learning-in-action-note1/"/>
    <id>http://yoursite.com/2017/10/15/machine-learning-in-action-note1/</id>
    <published>2017-10-15T13:58:12.000Z</published>
    <updated>2017-11-06T14:02:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>æ­£åœ¨å­¦ä¹ ã€ŠMachine Learning in Actionã€‹ï¼Œéšç¬”è®°å½•ä¸€ä¸‹ï¼Œä»£ç åŸºæœ¬ä¸Šéƒ½æ˜¯è·Ÿç€ä¹¦æœ¬æ•²çš„ï¼Œå°±ä¸å¤§è´´å…¨éƒ¨çš„ä»£ç äº†ï¼Œä»…å†™ä¸€äº›è‡ªå·±çš„ç†è§£å¹¶å¯¹å‡ºç°çš„é—®é¢˜è¿›è¡Œæ•´ç†å’Œå½’çº³ã€‚</p><p>ç®—æ³•çš„ä¸€èˆ¬æµç¨‹ä¸ºï¼šæ”¶é›†æ•°æ® -&gt; å‡†å¤‡æ•°æ® -&gt; åˆ†ææ•°æ® -&gt; è®­ç»ƒç®—æ³• -&gt; æµ‹è¯•ç®—æ³• -&gt; ä½¿ç”¨ç®—æ³•</p><p>ç¬¬ä¸€ä¸ªç¬”è®°æœ¬åŒ…æ‹¬kNNåˆ†ç±»ç®—æ³•å’Œå†³ç­–æ ‘ç®—æ³•ã€‚</p><h1 id="kNNåˆ†ç±»ç®—æ³•"><a href="#kNNåˆ†ç±»ç®—æ³•" class="headerlink" title="kNNåˆ†ç±»ç®—æ³•"></a>kNNåˆ†ç±»ç®—æ³•</h1><p>kNNåˆ†ç±»ç®—æ³•ï¼ˆk-Nearest Neighbors classification algorithmï¼‰æ˜¯æ¯”è¾ƒç®€å•çš„ä¸€ç§åˆ†ç±»ç®—æ³•ã€‚åŸç†æ˜¯é€šè¿‡è®¡ç®—è·ç¦»æ‰¾å‡ºä¸å¾…é¢„æµ‹æ•°æ®æœ€æ¥è¿‘çš„kä¸ªç±»åˆ«ï¼Œè¿™kä¸ªç±»åˆ«ä¸­å‡ºç°æœ€å¤šçš„ç±»å³ä¸ºé¢„æµ‹ç»“æœã€‚</p><h3 id="kNNçš„ä¸€èˆ¬æµç¨‹"><a href="#kNNçš„ä¸€èˆ¬æµç¨‹" class="headerlink" title="kNNçš„ä¸€èˆ¬æµç¨‹"></a>kNNçš„ä¸€èˆ¬æµç¨‹</h3><ol><li>æ”¶é›†æ•°æ®</li><li>å‡†å¤‡æ•°æ®ï¼šæœ€å¥½ä½¿ç”¨ç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼Œå› ä¸ºè®¡ç®—è·ç¦»éœ€è¦æ•°å€¼ã€‚</li><li>åˆ†ææ•°æ®</li><li>è®­ç»ƒç®—æ³•ï¼šæ­¤æ­¥éª¤ä¸é€‚ç”¨äºkNNç®—æ³•</li><li>æµ‹è¯•ç®—æ³•ï¼šè®¡ç®—é”™è¯¯ç‡</li><li>ä½¿ç”¨ç®—æ³•ï¼šè¿™é¦–å…ˆéœ€è¦è·å–ä¸€äº›è¾“å…¥æ•°æ®å’Œç»“æ„åŒ–çš„è¾“å‡ºæ•°æ®ï¼Œç„¶ååœ¨è¾“å…¥æ•°æ®ä¸Šè¿è¡ŒkNNç®—æ³•å¹¶åˆ¤æ–­å®ƒå±äºå“ªä¸€ç±»ï¼Œæœ€åå¯¹è®¡ç®—å‡ºçš„åˆ†ç±»æ‰§è¡Œåç»­å¤„ç†ã€‚</li></ol><a id="more"></a><p>æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨æ¬§æ°è·ç¦»å…¬å¼æ¥è®¡ç®—è·ç¦»ï¼ˆä»¥ä¸¤ç‚¹ä¸ºä¾‹ï¼‰ï¼š</p><p>$$<br>d = \sqrt{(x_0-y_0)^2+(x_1-y_1)^2+â€¦+(x_n-y_n)^2)}<br>$$<br>ç”¨ä»£ç æ¥è¡¨ç¤ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">diffMat = tile(inX, (dataSetSize,<span class="number">1</span>)) - dataSet <span class="comment"># è®¡ç®—é¢„æµ‹å‘é‡inXä¸æ¯ä¸ªæ ·æœ¬çš„å·®å€¼çŸ©é˜µ(mxn)</span></div><div class="line">sqDiffMat = diffMat ** <span class="number">2</span> <span class="comment"># å°†çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ éƒ½å¹³æ–¹(mxn)</span></div><div class="line">sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>) <span class="comment"># çŸ©é˜µæ¯ä¸€è¡Œå‘é‡ç›¸åŠ ï¼ˆmx1ï¼‰</span></div><div class="line">distances  = sqDistances ** <span class="number">0.5</span> <span class="comment"># å°†çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ å¼€æ ¹å·(mx1)</span></div></pre></td></tr></table></figure><p>å¯¹è·ç¦»è¿›è¡Œæ’åºï¼Œå¹¶æ‰¾å‡ºæœ€å°çš„kä¸ªè·ç¦»ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sortedDistIndicies = distances.argsort() <span class="comment"># è¿”å›æ•°ç»„ä»å°åˆ°å¤§æ’åºåçš„ç´¢å¼•å€¼</span></div><div class="line">classCount = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k): </div><div class="line">        voteIlabel = labels[sortedDistIndicies[i]] <span class="comment"># è·å¾—è·ç¦»ç¬¬iå°çš„æ ·æœ¬ç±»åˆ«</span></div><div class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span> <span class="comment"># è®°å½•è¯¥ç±»åˆ«çš„å‡ºç°æ¬¡æ•°</span></div></pre></td></tr></table></figure><p>æœ€åå¯¹å‡ºç°æ¬¡æ•°è¿›è¡Œæ’åºï¼Œé¢„æµ‹ç»“æœå³ä¸ºå‡ºç°æ¬¡æ•°æœ€å¤šçš„ç±»åˆ«ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sortedClassCount = sorted(classCount.items(),key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="keyword">True</span>)</div><div class="line"><span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</div></pre></td></tr></table></figure><p>åŸä¹¦ä¸­sortedçš„ç¬¬ä¸€ä¸ªå‚æ•°ä¸º<code>classCount.iteritems</code>ï¼Œæ ¹æ®python3ä½œå‡ºä¿®æ”¹ã€‚</p><p>å®Œæ•´çš„åˆ†ç±»å‡½æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX, dataSet, labels, k)</span>:</span></div><div class="line">    <span class="string">"""k-Nearest Neighbors algorithm</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    :param inX: A row vector under test</span></div><div class="line"><span class="string">    :param dataSet: The training data</span></div><div class="line"><span class="string">    :param labels: Labels of training data</span></div><div class="line"><span class="string">    :return: Prediction for the class of inX</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 1 Distance calculation</span></div><div class="line">    diffMat = tile(inX, (dataSetSize,<span class="number">1</span>)) - dataSet <span class="comment"># è®¡ç®—é¢„æµ‹å‘é‡inXä¸æ¯ä¸ªæ ·æœ¬çš„å·®å€¼çŸ©é˜µ(mxn)</span></div><div class="line">sqDiffMat = diffMat ** <span class="number">2</span> <span class="comment"># å°†çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ éƒ½å¹³æ–¹(mxn)</span></div><div class="line">sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>) <span class="comment"># çŸ©é˜µæ¯ä¸€è¡Œå‘é‡ç›¸åŠ ï¼ˆmx1ï¼‰</span></div><div class="line">distances  = sqDistances ** <span class="number">0.5</span> <span class="comment"># å°†çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ å¼€æ ¹å·(mx1)</span></div><div class="line">    sortedDistIndicies = distances.argsort() <span class="comment"># è¿”å›æ•°ç»„ä»å°åˆ°å¤§æ’åºåçš„ç´¢å¼•å€¼</span></div><div class="line"></div><div class="line">    <span class="comment"># 2 Voting with lowest k distances</span></div><div class="line">    classCount = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</div><div class="line">        voteIlabel = labels[sortedDistIndicies[i]] <span class="comment"># è·å¾—è·ç¦»ç¬¬iå°çš„æ ·æœ¬ç±»åˆ«</span></div><div class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span> <span class="comment"># è®°å½•è¯¥ç±»åˆ«çš„å‡ºç°æ¬¡æ•°</span></div><div class="line"></div><div class="line">    <span class="comment"># 3 Sort dictionary</span></div><div class="line">    sortedClassCount = sorted(classCount.items(),</div><div class="line">                              key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</div></pre></td></tr></table></figure><p>ğŸ™‚ï¼šå‡†ç¡®åº¦é«˜ï¼å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼ä¸å‡è®¾æ•°æ®</p><p>ğŸ™ï¼šè®¡ç®—å¤æ‚åº¦é«˜ï¼å ç”¨å¤§é‡å†…å­˜</p><p>ğŸ› ï¼šæ•°å€¼å‹ï¼æ ‡ç§°å‹</p><h1 id="å†³ç­–æ ‘ç®—æ³•"><a href="#å†³ç­–æ ‘ç®—æ³•" class="headerlink" title="å†³ç­–æ ‘ç®—æ³•"></a>å†³ç­–æ ‘ç®—æ³•</h1><p>å†³ç­–æ ‘ç®—æ³•ï¼ˆDecision treesï¼‰ä¹Ÿæ˜¯ä¸€ç§å¸¸è§çš„åˆ†ç±»ç®—æ³•ã€‚æˆ‘ä»¬æ¯æ¬¡ç”¨ä¸€ä¸ªç‰¹å¾æ¥å¯¹æ•°æ®é›†è¿›è¡Œåˆ†ç±»ï¼Œè¿­ä»£ç›´åˆ°åˆ†å‡ºçš„æ•°æ®é›†éƒ½å±äºä¸€ä¸ªç±»åˆ«æ—¶ï¼Œè®­ç»ƒå®Œæˆï¼Œè®­ç»ƒæ¨¡å‹å³ä¸ºä¸€ä¸ªæ ‘ç»“æ„ã€‚</p><h3 id="å†³ç­–æ ‘çš„ä¸€èˆ¬æµç¨‹"><a href="#å†³ç­–æ ‘çš„ä¸€èˆ¬æµç¨‹" class="headerlink" title="å†³ç­–æ ‘çš„ä¸€èˆ¬æµç¨‹"></a>å†³ç­–æ ‘çš„ä¸€èˆ¬æµç¨‹</h3><ol><li>æ•°æ®æ”¶é›†</li><li>å‡†å¤‡æ•°æ®ï¼šè¿™ä¸ªæ„é€ æ ‘çš„è¿‡ç¨‹åªé€‚ç”¨äºæ ‡ç§°å‹æ•°æ®ï¼Œå› æ­¤éœ€è¦ç¦»æ•£åŒ–è¿ç»­çš„æ•°å€¼</li><li>åˆ†ææ•°æ®</li><li>è®­ç»ƒç®—æ³•ï¼šæ„é€ ä¸€ä¸ªæ ‘çš„æ•°æ®ç»“æ„</li><li>æµ‹è¯•ç®—æ³•ï¼šä½¿ç”¨ç»éªŒæ ‘è®¡ç®—é”™è¯¯ç‡</li><li>ä½¿ç”¨ç®—æ³•ï¼šè¿™å¯ä»¥åº”ç”¨äºä»»ä½•ç›‘ç£å­¦ä¹ ä»»åŠ¡ã€‚é€šå¸¸ï¼Œå†³ç­–æ ‘æ ‘å¯ä»¥æ›´å¥½çš„ç†è§£æ•°æ®çš„å†…åœ¨å«ä¹‰ã€‚</li></ol><p>åˆ¤æ–­ä½¿ç”¨å“ªä¸€ä¸ªç‰¹å¾æ¥è¿›è¡Œåˆ†ç±»å³ä¸ºè®­ç»ƒç®—æ³•çš„å…³é”®ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ç‰¹å¾çš„ã€Œä¿¡æ¯å¢ç›Šã€æ¥åˆ¤æ–­ã€‚å¥½äº†ï¼Œæˆ‘ä»¬å¾—æ¥å¤ä¹ ä¸€ä¸‹ã€Œä¿¡æ¯å¢ç›Šã€ã€‚</p><p>è¯´åˆ°ä¿¡æ¯å¢ç›Šå°±æœ‰ä¸€ä¸ªä¸å¾—ä¸æçš„å®¶ä¼™å«ã€Œç†µã€ï¼Œå®ƒæ˜¯éšæœºå˜é‡çš„å¹³å‡é‡ï¼Œä»£è¡¨äº†éšæœºå˜é‡çš„ä¸ç¡®å®šæ€§ã€‚å•¥ç©æ„å„¿ï¼Ÿï¼Ÿï¼Ÿä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡è¶Šå°ï¼Œæ‰€å«çš„ä¿¡æ¯é‡å°±è¶Šå¤§ï¼Œå¦‚æœæ‰€æœ‰äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡éƒ½å¾ˆå°ï¼Œå¹³å‡ä¿¡æ¯é‡å°±æ¯”è¾ƒå¤§ã€‚è®²äººè¯ã€‚ã€Œç†µã€è¶Šå¤§ï¼Œæ•°æ®é›†è¶Šæ··ä¹±ã€‚</p><p>ç”¨å…¬å¼æ¥è¡¨ç¤ºï¼š<br>$$<br>H = -\sum_{i=1}^np(x_i)log_2p(x_i)<br>$$<br>ç”¨ä»£ç æ¥è¡¨ç¤ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></div><div class="line">    numEntries = len(dataSet)</div><div class="line"></div><div class="line">    labelCounts = &#123;&#125; <span class="comment"># ç”¨ä¸€ä¸ªå­—å…¸è®°å½•ä¸€ä¸ªç±»åˆ«çš„å‡ºç°æ¬¡æ•°</span></div><div class="line">    <span class="keyword">for</span> featVect <span class="keyword">in</span> dataSet:</div><div class="line">        currentLabel = featVect[<span class="number">-1</span>]</div><div class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</div><div class="line">            labelCounts[currentLabel] = <span class="number">0</span></div><div class="line">        labelCounts[currentLabel] += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="comment"># è®¡ç®—ç†µ</span></div><div class="line">    shannonEnt = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</div><div class="line">        prob = float(labelCounts[key])/numEntries <span class="comment"># æ¦‚ç‡</span></div><div class="line">        shannonEnt -= prob * log(prob,<span class="number">2</span>)</div><div class="line">    <span class="keyword">return</span> shannonEnt</div></pre></td></tr></table></figure><p>è¿˜æœ‰ä¸€ä¸ªå®¶ä¼™å«ã€Œæ¡ä»¶ç†µã€ï¼Œæ˜¯å·²çŸ¥æ¡ä»¶ä¸‹ï¼Œéšæœºå˜é‡çš„ä¸ç¡®å®šæ€§ã€‚å³å½“æˆ‘ä»¬å›ºå®šäº†ä¸€ä¸ªç‰¹å¾æ—¶ï¼Œæ•´ä¸ªç³»ç»Ÿçš„ä¿¡æ¯é‡ã€‚ç„¶è€Œè¿™ä¸ªç‰¹å¾çš„å–å€¼ä¹Ÿä¸æ­¢ä¸€ä¸ªï¼Œå› æ­¤æˆ‘ä»¬å°±éœ€è¦æ±‚å‡ºå®ƒçš„å¹³å‡å€¼ã€‚</p><p>ç”¨å…¬å¼æ¥è¡¨ç¤ºï¼š<br>$$<br>H(C|X) = p_1H(C|x_1)+p_2(C|x_2)+â€¦p_n(C|x_n) = \sum_{i=1}^np_iH(C|x_i)<br>$$<br>ç”¨ä»£ç æ¥è¡¨ç¤ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</div><div class="line">featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">uniqueVals = set(featList) <span class="comment"># æ‰¾å‡ºç¬¬iä¸ªç‰¹å¾çš„æ‰€æœ‰å–å€¼</span></div><div class="line">newEntropy = <span class="number">0</span></div><div class="line">    </div><div class="line">    <span class="comment"># è®¡ç®—æ¡ä»¶ç†µ</span></div><div class="line"><span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">      subDataSet = splitDataSet(dataSet, i, value)</div><div class="line">   prob = len(subDataSet)/float(len(dataSet))</div><div class="line">   newEntropy += prob * calcShannonEnt(subDataSet)</div></pre></td></tr></table></figure><p>æ¥ç€åˆæ¥äº†ä¸€ä¸ªå®¶ä¼™ï¼Œå®ƒå°±æ˜¯ã€Œä¿¡æ¯å¢ç›Šã€ã€‚<strong>ä¿¡æ¯å¢ç›Š = ç†µ - æ¡ä»¶ç†µ</strong>ã€‚è¿™ä¸ªä¿¡æ¯å¢ç›Šä»£è¡¨ç€ï¼Œç³»ç»Ÿå›ºå®šä¸€ä¸ªç‰¹å¾åï¼Œ<strong>ä¸ç¡®å®šæ€§çš„å‡å°‘ç¨‹åº¦</strong>ã€‚æˆ‘ä»¬å½“ç„¶å¸Œæœ›è¿™ä¸ªå‡å°‘ç¨‹åº¦å°½å¯èƒ½å¤§ï¼Œä½¿å¾—ç³»ç»Ÿæ›´åŠ æœ‰ç»„ç»‡çºªå¾‹ï¼Œé‚£ä¹ˆä¿¡æ¯å¢ç›Šå¾ˆå¤§å°±è¡¨æ˜è¿™ä¸ªç‰¹å¾å¾ˆå…³é”®ï¼ï¼</p><p>æˆ‘ä»¬å°†ä¸Šé¢çš„å†…å®¹æ•´ç†è¿›ä¸€ä¸ªå‡½æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></div><div class="line">    </div><div class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span> <span class="comment"># è·å–ç‰¹å¾çš„æ•°é‡</span></div><div class="line">    baseEntropy = calcShannonEnt(dataSet)</div><div class="line">    bestInfoGain = <span class="number">0</span>; bestFeature = <span class="number">-1</span></div><div class="line">    </div><div class="line">    <span class="comment"># åˆ†åˆ«è®¡ç®—æ¯ä¸€ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Š</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</div><div class="line"></div><div class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">        uniqueVals = set(featList) <span class="comment"># æ‰¾å‡ºç¬¬iä¸ªç‰¹å¾çš„æ‰€æœ‰å–å€¼</span></div><div class="line">        newEntropy = <span class="number">0</span></div><div class="line"></div><div class="line">        <span class="comment"># è®¡ç®—æ¡ä»¶ç†µ</span></div><div class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">            subDataSet = splitDataSet(dataSet, i, value)</div><div class="line">            prob = len(subDataSet)/float(len(dataSet))</div><div class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</div><div class="line">        <span class="comment"># è®¡ç®—ä¿¡æ¯å¢ç›Š</span></div><div class="line">        infoGain = baseEntropy - newEntropy</div><div class="line">        </div><div class="line">        <span class="comment"># æ‰¾åˆ°æœ€å¤§çš„ä¿¡æ¯å¢ç›Š</span></div><div class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):</div><div class="line">            bestInfoGain = infoGain</div><div class="line">            bestFeature = i</div><div class="line">    <span class="keyword">return</span>  bestFeature <span class="comment"># è¿”å›æœ€ä½³åˆ†ç±»ç‰¹å¾</span></div></pre></td></tr></table></figure><p>æ•´ç†åˆ°è¿™é‡Œï¼Œå…¶å®æœ‰ä¸€ä¸ªç–‘æƒ‘ï¼Œæˆ‘è§‰å¾—ä¿¡æ¯å¢ç›Šå¹¶æ²¡æœ‰ä»€ä¹ˆåµç”¨ï¼Œæ¯æ¬¡æ‰¾å‡ºæ¡ä»¶ç†µæœ€å°çš„ä¸å°±è¡Œäº†ï¼Ÿï¼Ÿï¼Ÿç»å®éªŒæ˜¯å¯ä»¥çš„ã€‚</p><p>åœ¨treePlotter.pyä¸­å‘ç°ä¸€ä¸ªç¥å¥‡çš„åœ°æ–¹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotNode</span><span class="params">(nodeTxt, centerPt, parentPt, nodeType)</span>:</span></div><div class="line">    <span class="comment"># 2 Draws annotations with arrows</span></div><div class="line">    createPlot.ax.annotate(nodeTxt, xy=parentPt, xycoords=<span class="string">'axes fraction'</span>,</div><div class="line">                           xytext = centerPt, textcoords=<span class="string">'axes fraction'</span>,</div><div class="line">                           va=<span class="string">'center'</span>, ha=<span class="string">'center'</span>, bbox=nodeType, arrowprops=arrow_args)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createPlot</span><span class="params">()</span>:</span></div><div class="line">    fig = plt.figure(<span class="number">1</span>, facecolor=<span class="string">'white'</span>)</div><div class="line">    fig.clf()</div><div class="line">    createPlot.ax = plt.subplot(<span class="number">111</span>, frameon=<span class="keyword">False</span>)</div><div class="line">    plotNode(<span class="string">'a decision node'</span>, (<span class="number">.5</span>, <span class="number">.1</span>), (<span class="number">.1</span>, <span class="number">.5</span>), decisionNode)</div><div class="line">    plotNode(<span class="string">'a leaf node'</span>, (<span class="number">.8</span>, <span class="number">.1</span>), (<span class="number">.3</span>, <span class="number">.8</span>), leafNode)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p>Pythonä¸­ä¸€åˆ‡çš†ä¸ºå¯¹è±¡ï¼Œåœ¨createPlotå‡½æ•°ä¸­ï¼Œä¸ºè¿™ä¸ªå‡½æ•°å¯¹è±¡ç»‘å®šäº†ä¸€ä¸ªå±æ€§axï¼Œå˜æˆäº†ä¸€ä¸ªå…¨å±€çš„å˜é‡ï¼Œå¯ä»¥åœ¨plotNodeå‡½æ•°ä¸­è°ƒç”¨ã€‚</p><p>ä¹¦ä¸­ä½œè€…åˆ©ç”¨treePlotterä¸­å†™å¥½çš„æ ‘ç»“æ„æ¥è¿›è¡Œé¢„æµ‹ï¼Œä½†tree.pyé‡Œå¤´ä¸æœ‰ä¸€ä¸ªcreateDataSetå‡½æ•°å’ŒcreateTreeå‡½æ•°å—ï¼Ÿå°è¯•ä¸€ä¸‹åˆ©ç”¨è¿™ä¸¤ä¸ªå‡½æ•°æ¥ç”Ÿæˆå¹¶é¢„æµ‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">myDat, labels = createDataSet()</div><div class="line">myTree = createTree(myDat, labels)</div></pre></td></tr></table></figure><p>Buuuuuuuutâ€¦â€¦â€¦.</p><p><img src="/2017/10/15/machine-learning-in-action-note1/no_surfacing_error.png" alt=""></p><p>æ£€æŸ¥äº†ä¸€ä¸‹è°ƒç”¨createTreeå‡½æ•°å‰ålabelsçš„å€¼ï¼Œå‘ç°è°ƒç”¨å‰ålabelsçš„å€¼å‘ç”Ÿäº†å˜åŒ–ï¼Œå› æ­¤å¯¹åŸå‡½æ•°createTreeç¨ä½œä¿®æ”¹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></div><div class="line"></div><div class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line"></div><div class="line">    <span class="comment"># 1 Stop when all classes are equal</span></div><div class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</div><div class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 2 When just one feature, return majority</span></div><div class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> majorityCnt(classList)</div><div class="line"></div><div class="line">    subLabels = labels[:] <span class="comment"># å°†labelså…¨éƒ¨å¤åˆ¶åˆ°subLabelsï¼Œè¿›è¡Œæ¥ä¸‹æ¥çš„å¤„ç†</span></div><div class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</div><div class="line">    bestFeatLabel = subLabels[bestFeat] <span class="comment"># åˆ©ç”¨subLabelsæ¥è·å–æœ€ä½³åˆ†ç±»ç‰¹å¾</span></div><div class="line">    myTree = &#123;bestFeatLabel: &#123;&#125;&#125;</div><div class="line">    <span class="keyword">del</span>(subLabels[bestFeat])</div><div class="line"></div><div class="line">    <span class="comment"># 3 Get list of unique values</span></div><div class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">    uniqueVals = set(featValues)</div><div class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">        <span class="comment">#subLabels = labels[:] ä½œè€…åœ¨è¿™é‡Œæ‰è¿›è¡Œå‚æ•°å¤åˆ¶ï¼Œå¯¼è‡´labelsçš„å€¼å‘ç”Ÿæ”¹å˜</span></div><div class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)</div><div class="line">    <span class="keyword">return</span> myTree</div></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥å°±å¯ä»¥æ„‰å¿«åˆ©ç”¨è¯¥å‡½æ•°è¿›è¡Œåˆ†ç±»äº†ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> treePlotter</div><div class="line"></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="string">çœç•¥ä¸€å †ä½œè€…æºä»£ç </span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line">myDat, labels = createDataSet()</div><div class="line">myTree = createTree(myDat, labels) <span class="comment"># è®­ç»ƒæ•°æ®</span></div><div class="line">treePlotter.createPlot(myTree) <span class="comment"># æ˜¾ç¤ºæ¨¡å‹</span></div><div class="line">print(classify(myTree, labels, [<span class="number">1</span>, <span class="number">1</span>])) <span class="comment"># é¢„æµ‹æ•°æ®</span></div></pre></td></tr></table></figure><p>çœ‹ä¸€çœ‹ç”Ÿæˆçš„å†³ç­–æ ‘æ¨¡å‹ï¼š</p><p><img src="/2017/10/15/machine-learning-in-action-note1/tree1.png" alt=""></p><p>æˆ‘ä»¬å¯ä»¥å¼•å…¥pickleæ¨¡å—æ¥å°†è®­ç»ƒå‡ºçš„æ¨¡å‹åºåˆ—åŒ–ï¼Œä¿å­˜åœ¨ç£ç›˜ä¸­ï¼Œä»¥ä¾¿åç»­çš„è°ƒç”¨ã€‚å› ä¸ºä¹¦æœ¬ä½œè€…æ˜¯ä½¿ç”¨Python2çš„ï¼Œæˆ‘æ‰“ç®—ç”¨Python3æ¥å®Œæˆï¼Œåœ¨ä¸‹é¢çš„ä»£ç ä¸­å°±é‡åˆ°äº†é—®é¢˜ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    <span class="comment">#Python2ç”¨æ³•ï¼šfw = open(filename,'w')</span></div><div class="line">    <span class="comment">#æ”¹ä¸ºpython3:</span></div><div class="line">    <span class="keyword">with</span> open(filename,<span class="string">'wb'</span>) <span class="keyword">as</span> fw:</div><div class="line">        pickle.dump(inputTree, fw)</div><div class="line">    fw.close()</div></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥å°±è¦å¼•å…¥ç¨å¾®å¤§ä¸€ç‚¹çš„æ•°æ®é›†æ¥è¿›è¡Œè®­ç»ƒäº†ï¼Œç„¶é¹…â€¦.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">fr = open(<span class="string">'lenses.txt'</span>)</div><div class="line">lenses = [inst.strip().split(<span class="string">'\t'</span>) <span class="keyword">for</span> inst <span class="keyword">in</span> fr.readline()]</div><div class="line">lensesLables = [<span class="string">'age'</span>, <span class="string">'prescript'</span>, <span class="string">'astigmatic'</span>, <span class="string">'tearRate'</span>]</div><div class="line">print(lenses)</div></pre></td></tr></table></figure><p><img src="/2017/10/15/machine-learning-in-action-note1/readlines_error.png" alt=""></p><p>è¿™è¾“å‡ºçš„å•¥ç©æ„å„¿ï¼Ÿä»”ç»†ä¸€çœ‹ï¼Œ<strong>fr.readlines()</strong>å‡½æ•°å†™é”™äº†ï¼Œå°‘äº†ä¸€ä¸ª<strong>sssssssss</strong>ã€‚ä¿®æ”¹å¥½ä»¥åæˆ‘ä»¬å°±æ¥çœ‹çœ‹è®­ç»ƒå®Œçš„å†³ç­–æ ‘å§ï¼š</p><p><img src="/2017/10/15/machine-learning-in-action-note1/lenses_tree1.png" alt=""></p><p>ï¼Ÿï¼Ÿï¼Ÿè¿™åˆå•¥ç©æ„å„¿ï¼Ÿï¼Ÿè¿™çœ‹å¾—ä¸‹å»ï¼Ÿï¼Ÿï¼Ÿï¼Ÿé‚£å°±åªèƒ½ä¿®æ”¹ä¸€ä¸‹plotMidTextå‡½æ•°äº†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotMidText</span><span class="params">(cntrPt, parentPt, txtString)</span>:</span></div><div class="line">    xMid = (parentPt[<span class="number">0</span>] - cntrPt[<span class="number">0</span>])/<span class="number">2</span> + cntrPt[<span class="number">0</span>]</div><div class="line">    yMid = (parentPt[<span class="number">1</span>] - cntrPt[<span class="number">1</span>])/<span class="number">2</span> + cntrPt[<span class="number">1</span>]</div><div class="line">    createPlot.ax.text(xMid, yMid, txtString, fontsize=<span class="number">8</span>, horizontalalignment=<span class="string">'center'</span>,verticalalignment=<span class="string">'center'</span>, rotation=<span class="number">30</span>)</div></pre></td></tr></table></figure><p><img src="/2017/10/15/machine-learning-in-action-note1/lenses_tree2.png" alt=""></p><p>å®Œç¾ï¼</p><p>ğŸ™‚ï¼šè®¡ç®—å¤æ‚åº¦ä¸é«˜ï¼ä¾¿äºäººä»¬ç†è§£å­¦ä¹ ç»“æœï¼å¯¹ä¸­é—´çš„ç¼ºå¤±å€¼ä¸æ•æ„Ÿï¼å¯ä»¥å¤„ç†æ— å…³çš„ç‰¹å¾å€¼</p><p>ğŸ™ï¼šå¯èƒ½ä¼šè¿‡æ‹Ÿåˆ</p><p>ğŸ› ï¼šæ•°å€¼å‹ï¼æ ‡ç§°å‹</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æ­£åœ¨å­¦ä¹ ã€ŠMachine Learning in Actionã€‹ï¼Œéšç¬”è®°å½•ä¸€ä¸‹ï¼Œä»£ç åŸºæœ¬ä¸Šéƒ½æ˜¯è·Ÿç€ä¹¦æœ¬æ•²çš„ï¼Œå°±ä¸å¤§è´´å…¨éƒ¨çš„ä»£ç äº†ï¼Œä»…å†™ä¸€äº›è‡ªå·±çš„ç†è§£å¹¶å¯¹å‡ºç°çš„é—®é¢˜è¿›è¡Œæ•´ç†å’Œå½’çº³ã€‚&lt;/p&gt;
&lt;p&gt;ç®—æ³•çš„ä¸€èˆ¬æµç¨‹ä¸ºï¼šæ”¶é›†æ•°æ® -&amp;gt; å‡†å¤‡æ•°æ® -&amp;gt; åˆ†ææ•°æ® -&amp;gt; è®­ç»ƒç®—æ³• -&amp;gt; æµ‹è¯•ç®—æ³• -&amp;gt; ä½¿ç”¨ç®—æ³•&lt;/p&gt;
&lt;p&gt;ç¬¬ä¸€ä¸ªç¬”è®°æœ¬åŒ…æ‹¬kNNåˆ†ç±»ç®—æ³•å’Œå†³ç­–æ ‘ç®—æ³•ã€‚&lt;/p&gt;
&lt;h1 id=&quot;kNNåˆ†ç±»ç®—æ³•&quot;&gt;&lt;a href=&quot;#kNNåˆ†ç±»ç®—æ³•&quot; class=&quot;headerlink&quot; title=&quot;kNNåˆ†ç±»ç®—æ³•&quot;&gt;&lt;/a&gt;kNNåˆ†ç±»ç®—æ³•&lt;/h1&gt;&lt;p&gt;kNNåˆ†ç±»ç®—æ³•ï¼ˆk-Nearest Neighbors classification algorithmï¼‰æ˜¯æ¯”è¾ƒç®€å•çš„ä¸€ç§åˆ†ç±»ç®—æ³•ã€‚åŸç†æ˜¯é€šè¿‡è®¡ç®—è·ç¦»æ‰¾å‡ºä¸å¾…é¢„æµ‹æ•°æ®æœ€æ¥è¿‘çš„kä¸ªç±»åˆ«ï¼Œè¿™kä¸ªç±»åˆ«ä¸­å‡ºç°æœ€å¤šçš„ç±»å³ä¸ºé¢„æµ‹ç»“æœã€‚&lt;/p&gt;
&lt;h3 id=&quot;kNNçš„ä¸€èˆ¬æµç¨‹&quot;&gt;&lt;a href=&quot;#kNNçš„ä¸€èˆ¬æµç¨‹&quot; class=&quot;headerlink&quot; title=&quot;kNNçš„ä¸€èˆ¬æµç¨‹&quot;&gt;&lt;/a&gt;kNNçš„ä¸€èˆ¬æµç¨‹&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;æ”¶é›†æ•°æ®&lt;/li&gt;
&lt;li&gt;å‡†å¤‡æ•°æ®ï¼šæœ€å¥½ä½¿ç”¨ç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼Œå› ä¸ºè®¡ç®—è·ç¦»éœ€è¦æ•°å€¼ã€‚&lt;/li&gt;
&lt;li&gt;åˆ†ææ•°æ®&lt;/li&gt;
&lt;li&gt;è®­ç»ƒç®—æ³•ï¼šæ­¤æ­¥éª¤ä¸é€‚ç”¨äºkNNç®—æ³•&lt;/li&gt;
&lt;li&gt;æµ‹è¯•ç®—æ³•ï¼šè®¡ç®—é”™è¯¯ç‡&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨ç®—æ³•ï¼šè¿™é¦–å…ˆéœ€è¦è·å–ä¸€äº›è¾“å…¥æ•°æ®å’Œç»“æ„åŒ–çš„è¾“å‡ºæ•°æ®ï¼Œç„¶ååœ¨è¾“å…¥æ•°æ®ä¸Šè¿è¡ŒkNNç®—æ³•å¹¶åˆ¤æ–­å®ƒå±äºå“ªä¸€ç±»ï¼Œæœ€åå¯¹è®¡ç®—å‡ºçš„åˆ†ç±»æ‰§è¡Œåç»­å¤„ç†ã€‚&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex8</title>
    <link href="http://yoursite.com/2017/06/16/machine-learning-ex8/"/>
    <id>http://yoursite.com/2017/06/16/machine-learning-ex8/</id>
    <published>2017-06-16T11:46:41.000Z</published>
    <updated>2017-10-21T09:38:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>ä»¥å…‰é€Ÿåˆ·è¯¾ã€‚ã€‚æ˜¨å¤©ä¸€å¤©åˆ·å®Œweek9ï¼Œä»Šå¤©åˆåˆ·å®Œweek10ï¼Œæ­£åœ¨å‘week11è¿›å†›ã€‚ã€‚è¿˜æ˜¯è¦å®Œæˆä¸€ä¸‹wee9çš„ç¼–ç¨‹ä½œä¸šã€‚</p><p>è¿™ä¸€ç« ä¸»è¦æ˜¯è®²äº†å¼‚å¸¸æ£€æµ‹å’Œæ¨èç³»ç»Ÿã€‚å¼‚å¸¸æ£€æµ‹ç®—æ³•ä½¿ç”¨çš„æ˜¯ä»¥å‰æ¦‚ç‡è®ºå­¦è¿‡çš„æ­£æ€ï¼ˆé«˜æ–¯ï¼‰åˆ†å¸ƒã€‚åªä½¿ç”¨ç‰¹å¾å€¼Xæ¥è®¡ç®—å‡ºæ¦‚ç‡åˆ†å¸ƒï¼Œæ ¹æ®ä¸´ç•Œå€¼çš„å¤§å°å†åˆ¤æ–­yæ˜¯å¦å¼‚å¸¸ã€‚</p><a id="more"></a><h3 id="Anomaly-detection"><a href="#Anomaly-detection" class="headerlink" title="Anomaly detection"></a>Anomaly detection</h3><p>é¦–å…ˆè®¡ç®—å‡º <strong>Î¼</strong> å’Œ <strong>Ïƒ^2^ </strong>ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mu = mean(X)';</div><div class="line">sigma2 = var(X)'*(m<span class="number">-1</span>)/m;</div></pre></td></tr></table></figure><p>åœ¨è¿™é‡Œè¦æ³¨æ„å‡½æ•° var() é™¤ä»¥çš„æ˜¯m-1æ‰€ä»¥æˆ‘ä»¬è¦ä¿®æ”¹ä¸€ä¸‹å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬è¦åˆ©ç”¨äº¤å‰éªŒè¯æ ·æœ¬ï¼Œè®¡ç®— F~1~ Score å¹¶æŒ‘é€‰ä¸´ç•Œå€¼ <strong>Îµ</strong>ï¼š</p> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% è·å–éªŒè¯é›†å¼‚å¸¸å€¼åæ ‡</span></div><div class="line">cvPredictions = (pval &lt; epsilon);</div><div class="line">tp = sum( (cvPredictions == <span class="number">1</span>) &amp; (yval == <span class="number">1</span>) );</div><div class="line">fp = sum( (cvPredictions == <span class="number">1</span>) &amp; (yval == <span class="number">0</span>) );</div><div class="line">fn = sum( (cvPredictions == <span class="number">0</span>) &amp; (yval == <span class="number">1</span>) );</div><div class="line"><span class="comment">% è®¡ç®—ç²¾ç¡®ç‡</span></div><div class="line">prec = tp / (tp + fp);</div><div class="line"><span class="comment">% è®¡ç®—å¬å›ç‡</span></div><div class="line">rec = tp / (tp + fn);</div><div class="line">F1 = <span class="number">2</span> * prec * rec / (prec + rec);</div></pre></td></tr></table></figure><p>ç„¶åå¯ä»¥çœ‹åˆ°çº¢çº¢çš„åœˆå‡ºçš„å¼‚å¸¸å€¼ï¼š</p><img src="/2017/06/16/machine-learning-ex8/2017/06/16/machine-learning-ex8/detected.png" alt="detected.png" title=""><h3 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h3><p>è¯´åˆ°æ¨èç³»ç»Ÿï¼Œä»¥ç”µå½±ä¸ºä¾‹ï¼Œä¸€æ–¹é¢è¦é¢„æµ‹ç”¨æˆ·å¯¹äºæŸç”µå½±çš„è¯„åˆ†ï¼Œå¦ä¸€æ–¹é¢è¦å¯»æ‰¾ç›¸ä¼¼çš„ç”µå½±ï¼Œæˆ‘ä»¬ç»å¸¸ä½¿ç”¨çš„ç®—æ³•æ˜¯ååŒè¿‡æ»¤ç®—æ³•ã€‚è¿›ä¸€æ­¥äº†è§£è¿™ä¸ªç®—æ³•ï¼ŒæŸ¥äº†ä¸€äº›ä¸­æ–‡èµ„æ–™ã€‚åŸæœ¬çš„çº¿æ€§å›å½’ï¼Œæˆ‘ä»¬åªéœ€è¦æ ¹æ®ç‰¹å¾å€¼è®¡ç®—å‡ºå‚æ•° <strong>Î¸</strong>ï¼Œä½†æ˜¯ç°åœ¨å˜æ€äº†ï¼Œæˆ‘ä»¬ä¸å…‰è¦é¢„æµ‹ç”¨æˆ·çš„å–œå¥½ï¼Œè¿˜è¦æŸ¥æ‰¾ç›¸ä¼¼çš„ç‰¹å¾å‘é‡ï¼Œä¿©å‚æ•°ï¼ˆéƒ½ç”¨çŸ©é˜µè¡¨ç¤ºï¼‰ä¸€èµ·å­¦ä¹ ã€‚</p><p>é¦–å…ˆæˆ‘ä»¬å®Œæˆæœªæ­£è§„åŒ–çš„æ¢¯åº¦å’Œä»£ä»·å‡½æ•°çš„è®¡ç®—ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">X_grad = (X * Theta' - Y) .* R * Theta;</div><div class="line">Theta_grad = (X * Theta' - Y)' .* R' * X;</div><div class="line"></div><div class="line">J = sum(( (X * Theta' - Y).^<span class="number">2</span> .* R )(:)) / <span class="number">2</span>;</div></pre></td></tr></table></figure><p>æœŸé—´å®Œå…¨å¿˜è®°æ¢¯åº¦æ˜¯ä»€ä¹ˆé¬¼ã€‚ã€‚å›é¡¾ä¸€ä¸‹ï¼Œæ˜¯ä»£ä»·å‡½æ•°å¯¹å˜é‡æ±‚åå¯¼~ è®¡ç®—å…¬å¼å®Œå…¨æŒ‰ç…§çŸ©é˜µçš„å¤§å°æ¥åˆ¤æ–­ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ­£è§„åŒ–ä»£ä»·å‡½æ•°ï¼ŒæŒ‰ç…§å…¬å¼åŠ ä¸Š<code>J += lambda / 2 _ sum(Theta.^2(:)) + lambda / 2 _ sum(X.^2(:));</code>ï¼Œä½†å‘ç°Jå˜æˆäº†1x3çš„å‘é‡ï¼Œå‘ç°é—®é¢˜åœ¨äºsumä¸­åº”è¯¥åœ¨å¹³æ–¹çš„æ—¶å€™æ·»åŠ æ‹¬å·ï¼Œä¿®æ”¹ä»£ç å¦‚ä¸‹ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">J += lambda / <span class="number">2</span> * sum((Theta.^<span class="number">2</span>)(:)) + lambda / <span class="number">2</span> * sum((X.^<span class="number">2</span>)(:));</div></pre></td></tr></table></figure><p>ç„¶åç»§ç»­å®Œæˆæ¢¯åº¦çš„æ­£è§„åŒ–ã€‚</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ä»¥å…‰é€Ÿåˆ·è¯¾ã€‚ã€‚æ˜¨å¤©ä¸€å¤©åˆ·å®Œweek9ï¼Œä»Šå¤©åˆåˆ·å®Œweek10ï¼Œæ­£åœ¨å‘week11è¿›å†›ã€‚ã€‚è¿˜æ˜¯è¦å®Œæˆä¸€ä¸‹wee9çš„ç¼–ç¨‹ä½œä¸šã€‚&lt;/p&gt;
&lt;p&gt;è¿™ä¸€ç« ä¸»è¦æ˜¯è®²äº†å¼‚å¸¸æ£€æµ‹å’Œæ¨èç³»ç»Ÿã€‚å¼‚å¸¸æ£€æµ‹ç®—æ³•ä½¿ç”¨çš„æ˜¯ä»¥å‰æ¦‚ç‡è®ºå­¦è¿‡çš„æ­£æ€ï¼ˆé«˜æ–¯ï¼‰åˆ†å¸ƒã€‚åªä½¿ç”¨ç‰¹å¾å€¼Xæ¥è®¡ç®—å‡ºæ¦‚ç‡åˆ†å¸ƒï¼Œæ ¹æ®ä¸´ç•Œå€¼çš„å¤§å°å†åˆ¤æ–­yæ˜¯å¦å¼‚å¸¸ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Mmachine Learning ex7</title>
    <link href="http://yoursite.com/2017/06/13/machine-learning-ex7/"/>
    <id>http://yoursite.com/2017/06/13/machine-learning-ex7/</id>
    <published>2017-06-13T01:46:37.000Z</published>
    <updated>2017-06-15T04:38:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>è¿™ä¸€ç« ä¸»è¦å­¦ä¹ äº† <strong>K-å‡å€¼ç®—æ³•</strong> å’Œ <strong>PCA ç®—æ³•</strong>ï¼Œå‰è€…ç”¨äºæ— ç›‘ç£å­¦ä¹ ä¸­èšç±»çš„è®­ç»ƒï¼Œåè€…ç”¨äºå‹ç¼©è¾“å…¥ç‰¹å¾å€¼çš„ç»´åº¦ã€‚</p><a id="more"></a><h3 id="K-means-Clustering"><a href="#K-means-Clustering" class="headerlink" title="K-means Clustering"></a>K-means Clustering</h3><p>æˆ‘ä»¬å…ˆä½¿ç”¨2ç»´çš„æ•°æ®é›†æ¥æ„Ÿå—ä¸€ä¸‹Kå‡å€¼ç®—æ³•ã€‚æ¥ç€æˆ‘ä»¬è¦å°†å†™å¥½çš„å‡½æ•°è¿ç”¨åˆ°å›¾åƒå‹ç¼©ä¸Šã€‚K-å‡å€¼ç®—æ³•æœ€æ ¸å¿ƒçš„æ­¥éª¤å¦‚ä¸‹ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% Initialize centroids</span></div><div class="line">centroids = kMeansInitCentroids(X, K);</div><div class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:iterations</div><div class="line"><span class="comment">% Cluster assignment step: Assign each data point to the</span></div><div class="line"><span class="comment">% closest centroid. idx(i) corresponds to cË†(i), the index</span></div><div class="line"><span class="comment">% of the centroid assigned to example i</span></div><div class="line">idx = findClosestCentroids(X, centroids);</div><div class="line"><span class="comment">% Move centroid step: Compute means based on centroid</span></div><div class="line"><span class="comment">% assignments</span></div><div class="line">centroids = computeMeans(X, idx, K);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>ç¬¬ä¸€æ­¥å®Œæˆ <strong>findClosesCentroids</strong> å‡½æ•°ï¼Œè®¡ç®—æ¯ä¸ªæ ·æœ¬åˆ°ä¸­å¿ƒç‚¹çš„è·ç¦»ï¼Œç”¨æ•°å€¼è¡¨ç¤ºå…¶æ‰€å±ç±»ï¼Œè¿”å›èšç±»åçš„å‘é‡ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(X,<span class="number">1</span>)</div><div class="line">  min = norm(X(<span class="built_in">i</span>,:) - centroids(<span class="number">1</span>,:), <span class="number">2</span>).^<span class="number">2</span>;</div><div class="line">  min_idx = <span class="number">1</span>;</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">2</span> : K</div><div class="line">    cur = norm(X(<span class="built_in">i</span>,:) - centroids(<span class="built_in">j</span>,:), <span class="number">2</span>).^<span class="number">2</span>;</div><div class="line">    <span class="keyword">if</span>(cur &lt; min)</div><div class="line">      min = cur;</div><div class="line">      min_idx = <span class="built_in">j</span>;</div><div class="line">    <span class="keyword">end</span></div><div class="line">  <span class="keyword">end</span></div><div class="line">  idx(<span class="built_in">i</span>) = min_idx;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>é¢˜è§£é‡Œè¯´ç”¨ä¸€ä¸ªforå¾ªç¯å®Œæˆï¼Œä½†æˆ‘å…ˆä½¿ç”¨äº†ä¸¤ä¸ªï¼Œåé¢å†è¿›è¡Œä¼˜åŒ–å¥½äº†ã€‚è¿™å…¶ä¸­å‡ºç°äº†ä¸€ä¸ªå°é—®é¢˜ï¼Œè®¡ç®—normçš„æ—¶å€™ï¼Œ<code>norm(X(i,:) - centroids(j,:), 2).^2;</code> ä¸»è¦åŒ…å«æ‰€æœ‰åˆ—ï¼Œå¦åˆ™åªåŒ…å«äº†å•ä¸ªæ•°å­—ã€‚</p><p>æ¥ä¸‹æ¥å®Œæˆ <strong>computeMeans</strong> å‡½æ•°ï¼Œé€šè¿‡åŒä¸ªç±»é‡Œçš„æ ·æœ¬è®¡ç®—æ–°çš„ä¸­å¿ƒï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : K</div><div class="line">  <span class="comment">% æŸ¥æ‰¾èšç±»æ ·æœ¬</span></div><div class="line">  examples_idx = <span class="built_in">find</span>(idx == <span class="built_in">i</span>);</div><div class="line">  <span class="comment">% è®¡ç®—ä¸­å¿ƒå€¼</span></div><div class="line">  X(examples_idx, :);</div><div class="line">  centroids(<span class="built_in">i</span>,:) = sum( X(examples_idx, :) ) / <span class="built_in">size</span>(examples_idx, <span class="number">1</span>);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>è¿™é‡Œå‡ºç°çš„é—®é¢˜åœ¨<code>centroids(i,:) = sum( X(examples_idx, :) ) / size(examples_idx, 1);</code> ã€‚æ³¨æ„åŒ…å«centroidsçš„æ‰€æœ‰åˆ—ï¼Œå’Œåœ¨è®¡ç®—szie()çš„æ—¶å€™ï¼Œé€‰æ‹©æ‰€æœ‰è¡Œçš„å¤§å°ã€‚</p><p>ç„¶åæˆ‘ä»¬å°±å¯ä»¥è¿è¡Œæˆ‘ä»¬çš„K-å‡å€¼ç®—æ³•æ¥èšç±»äº†ã€‚å¯ä»¥çœ‹åˆ°åˆå§‹åŒ–çš„æ—¶å€™ä¸‰ä¸ªä¸­å¿ƒç‚¹åˆ†åˆ«ä¸ºï¼ˆ3,3ï¼‰ã€ï¼ˆ6,2ï¼‰ã€ï¼ˆ8,5ï¼‰ã€‚</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/iter1.png" alt="iter1.png" title=""><p>ç»è¿‡6æ¬¡è¿­ä»£å¯ä»¥çœ‹åˆ°ä¸­å¿ƒç‚¹é€æ¸å¾€å¥½çš„æ–¹å‘ç§»åŠ¨ï¼š</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/iter6.png" alt="iter6.png" title=""><p>ç»è¿‡10æ¬¡è¿­ä»£åŸºæœ¬åˆ°è¾¾æœ‰æ¨¡æœ‰æ ·çš„èšç±»ä¸­å¿ƒäº†ï¼š</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/iter10.png" alt="iter10.png" title=""><p>æ¥ä¸‹æ¥æˆ‘ä»¬è¦ä½¿ç”¨Kå‡å€¼ç®—æ³•æ¥å‹ç¼©å›¾åƒäº†ã€‚æ¯ä¸ªåƒç´ ç”¨ <strong>24-bit</strong> æ¥è¡¨ç¤ºé¢œè‰²ï¼Œå³3ä¸ª <strong>8-bit</strong> çš„æ— ç¬¦å·æ•´å½¢æ¥è¡¨ç¤ºRGBçš„å€¼ï¼Œç›®æ ‡å‹ç¼©æˆç”¨<strong>16-bit</strong> æ¥è¡¨ç¤ºã€‚</p><p>æˆ‘ä»¬ä½¿ç”¨ <strong>imread(A)</strong> æ¥è¯»å…¥å›¾åƒï¼Œå› ä¸ºæˆ‘ä»¬åŸå§‹å›¾åƒçš„å¤§å°ä¸º128x128ï¼Œå› æ­¤ A ä¸ºä¸€ä¸ªä¸‰ç»´çŸ©é˜µï¼Œ<strong>size(A) = 128x128x3</strong> ï¼Œç„¶åreshapeå›¾åƒå˜ä¸º <strong>mX3</strong>ï¼ˆm = 16384 = 128x128ï¼‰ çš„çŸ©é˜µï¼Œç”¨äºåé¢æ‰§è¡ŒK-å‡å€¼ç®—æ³•ã€‚</p><p>æˆ‘ä»¬å°†Kè®¾ç½®ä¸º16ï¼Œå¯¹æ¯ä¸ªåƒç´ ç‚¹è¿›è¡Œèšç±»ã€‚è·å¾—æœ€åçš„å›¾åƒã€‚åŸå§‹å›¾åƒéœ€è¦ <strong>128 x 128 x 24 = 393,216</strong> bitsã€‚è€Œå‹ç¼©åæˆ‘ä»¬ä½¿ç”¨ 24bitså­˜å‚¨16ç§é¢œè‰²ï¼Œä½†æ¯ä¸ªåƒç´ ç‚¹åªéœ€è¦4bits æ¥è¿›è¡Œå®šä½ã€‚å› æ­¤å‹ç¼©åçš„å›¾åƒä¸º <strong>16 x 24+128x128x4 = 65,920</strong> bitsã€‚ï¼ˆä»pdfé‡Œç†è§£æ˜¯è¿™æ ·ï¼Œç„¶è€ŒçœŸå®çš„æƒ…å†µä¼¼ä¹å¹¶æ²¡æœ‰è¿›è¡Œå‹ç¼©ï¼Œçœ‹äº†åŠ©æ•™åœ¨è®ºå›é‡Œçš„å›ç­”ï¼Œå®Œæ•´çš„å‹ç¼©è¿‡ç¨‹è¿˜è¦åˆ›å»ºä¸€ä¸ªæ–°çš„å›¾åƒï¼Œåªä½¿ç”¨4bitæ¥è¡¨ç¤ºï¼Œå› ä¸ºæœ¬è¯¾ç¨‹åªæ˜¯å…³äºèšç±»ï¼Œè€Œä¸æ˜¯å…³äºå‹ç¼©å›¾åƒçš„ç»†èŠ‚ã€‚ï¼‰å› æ­¤å‹ç¼©åçš„å›¾ç‰‡å¦‚ä¸‹ï¼š</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/compress.png" alt="compress.png" title=""><p>ç„¶åæˆ‘ä»¬æ¢ä¸€å¼ è‡ªå·±çš„å›¾ç‰‡æ¥çœ‹çœ‹æ•ˆæœï¼š</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/compress2.png" alt="compress2.png" title=""><p>ç„¶åä¿®æ”¹ <strong>K=5</strong> å†çœ‹çœ‹æ•ˆæœï¼š</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/compress3.png" alt="compress3.png" title=""><h3 id="Principal-Component-Analysis"><a href="#Principal-Component-Analysis" class="headerlink" title="Principal Component Analysis"></a>Principal Component Analysis</h3><p>æˆ‘ä»¬ä½¿ç”¨PCAæ¥å‡å°‘æ•°æ®é›†çš„ç»´åº¦ã€‚å…ˆå®éªŒ2Dçš„æ•°æ®é›†æ¥äº†è§£ä¸€ä¸‹PCAçš„è¿ä½œï¼Œå†å°†å…¶è¿ç”¨æ›´é«˜çš„ç»´åº¦ä¸Šã€‚</p><p>PCAçš„æ­¥éª¤ä¸ºï¼š1ã€æ­£è§„åŒ–æ•°æ®é›†ã€‚2ã€è®¡ç®—åæ–¹å·®çŸ©é˜µã€‚3ã€åˆ©ç”¨SVDå‡½æ•°è®¡ç®—ä¸»æˆåˆ†ï¼ˆUã€Sï¼‰ã€‚</p><p>2ã€3æ­¥éª¤å®ç°</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Sigma = X' * X / m;</div><div class="line">[U, S, V] = svd(Sigma);</div></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°ç‰¹å¾å‘é‡å¦‚ä¸‹å›¾ï¼š</p><p><strong>ç‰¹å¾å‘é‡1</strong></p><p><strong>ç‰¹å¾å‘é‡1 &amp; 2</strong></p><p>å› ä¸ºæˆ‘ä»¬è¦é™ä½åˆ°ä¸€ç»´ï¼Œå³ <strong>K=1</strong> å› æ­¤åœ¨è¿™æ¬¡åªä¼šä½¿ç”¨åˆ°U(:, 1)</p><p>é€šè¿‡SVDå‡½æ•°è®¡ç®—å‡ºäº†ä¸»æˆåˆ†åï¼Œæˆ‘ä»¬å¯ä»¥å°±åˆ©ç”¨ç‰¹å¾å‘é‡Uæ¥å°†æ¯ä¸ªæ ·æœ¬æ˜ å°„ä¸ºæ›´ä½çš„ç»´åº¦ï¼Œx^(i)^ -&gt; z^(i)^ ã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">U_reduce = U(:, <span class="number">1</span>:K);</div><div class="line">Z = X * U_reduce;</div></pre></td></tr></table></figure><p>é‡æ„å‡ºé€šè¿‡PCAæ˜ å°„åçš„ç‚¹ï¼ˆçº¢è‰²ï¼‰ï¼š</p><img src="/2017/06/13/machine-learning-ex7/2017/06/13/machine-learning-ex7/reconstruction.png" alt="reconstruction.png" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è¿™ä¸€ç« ä¸»è¦å­¦ä¹ äº† &lt;strong&gt;K-å‡å€¼ç®—æ³•&lt;/strong&gt; å’Œ &lt;strong&gt;PCA ç®—æ³•&lt;/strong&gt;ï¼Œå‰è€…ç”¨äºæ— ç›‘ç£å­¦ä¹ ä¸­èšç±»çš„è®­ç»ƒï¼Œåè€…ç”¨äºå‹ç¼©è¾“å…¥ç‰¹å¾å€¼çš„ç»´åº¦ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Machine Learning ex6</title>
    <link href="http://yoursite.com/2017/06/10/machine-learning-ex6/"/>
    <id>http://yoursite.com/2017/06/10/machine-learning-ex6/</id>
    <published>2017-06-10T01:58:07.000Z</published>
    <updated>2017-10-21T09:38:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>ç»ˆäºæ¥åˆ°æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰äº†ï¼è¿™ä¸€ç« æˆ‘ä»¬è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨é«˜æ–¯æ ¸SVMæ¥å»ºç«‹ä¸€ä¸ªåƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ã€‚</p><a id="more"></a><h3 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h3><p>é¦–å…ˆæ˜¾ç¤ºå‡ºæˆ‘ä»¬çš„æ•°æ®ï¼Œå¾ˆæ˜æ˜¾åœ°å¯ä»¥çœ‹å‡º <strong>C=1</strong> æ—¶ä¸¤ä¸ªåˆ†ç±»çš„å†³ç­–è¾¹ç•Œæ˜¯ä¸­é—´çš„ä¸€æ¡çº¿ï¼Œä½†æ˜¯è¦æ³¨æ„åˆ°å·¦è¾¹æœ‰ä¸€ä¸ª <strong>+</strong> åœ¨ï¼ˆ0.1,4.1ï¼‰ã€‚</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/dataset1_c1.png" alt="dataset1_c1.png" title=""><p>å¢å¤§Cï¼Œä¿®æ”¹ <strong>C=100</strong> å¯ä»¥çœ‹åˆ°å†³ç­–è¾¹ç•Œçš„åå·®å‡å°äº†ã€‚</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/dataset1_c100.png" alt="dataset1_c100.png" title=""><p>ç»§ç»­å¢å¤§Cï¼Œæ­¤æ—¶ <strong>C=1000</strong> ï¼Œ</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/dataset1_c1000.png" alt="dataset1_c1000.png" title=""><p>æ ¹æ®å…¬å¼å³å¯å®Œæˆé«˜æ–¯æ ¸çš„ä»£ç ï¼Œæ²¡æœ‰å‡ºç°ä»€ä¹ˆå¤§é—®é¢˜ã€‚æ¥ä¸‹æ¥å‡ºç°äº†ä¸€ä¸ªæ ·æœ¬è¾ƒå¤§ä¸”æ˜¯éçº¿æ€§çš„å†³ç­–è¾¹ç•Œçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬åˆ©ç”¨å·²å®Œæˆçš„é«˜æ–¯æ ¸SVMæ¥æ˜¾ç¤ºå†³ç­–è¾¹ç•Œã€‚</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/dataset2.png" alt="dataset2.png" title=""><p>é€šè¿‡è®­ç»ƒé›†3æˆ‘ä»¬è¦é€šè¿‡éªŒè¯é›†æ¥æ‰¾åˆ°æœ€ä½³çš„ C å’Œ Ïƒï¼Œæœ€åˆçš„å†³ç­–åˆ†ç•Œå¦‚ä¸‹å›¾ï¼š</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/dataset3_base.png" alt="dataset3_base.png" title=""><p>ç»è¿‡8864çš„å¾ªç¯ç»ˆäºå¾—åˆ°äº†æœ€ä¼˜å‚æ•° :-)</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">min = <span class="number">1</span>;</div><div class="line">step = [<span class="number">0.01</span>; <span class="number">0.03</span>; <span class="number">0.1</span>; <span class="number">0.3</span>; <span class="number">1</span>; <span class="number">3</span>; <span class="number">10</span>; <span class="number">30</span>];</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: <span class="built_in">size</span>(step)</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>: <span class="built_in">size</span>(step)</div><div class="line">    model= svmTrain(X, y, step(<span class="built_in">i</span>), @(x1, x2) gaussianKernel(x1, x2, step(<span class="built_in">j</span>)));</div><div class="line">    predictions = svmPredict(model, Xval);</div><div class="line">    cur = mean(double(predictions ~= yval));</div><div class="line">    <span class="keyword">if</span>(cur &lt; min) </div><div class="line">      min = cur;</div><div class="line">      C = step(<span class="built_in">i</span>);</div><div class="line">      sigma = step(<span class="built_in">j</span>);</div><div class="line">    <span class="keyword">end</span> </div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/dataset3_over.png" alt="dataset3_over.png" title=""><h3 id="Spam-Classification"><a href="#Spam-Classification" class="headerlink" title="Spam Classification"></a>Spam Classification</h3><p>åœ¨å¤„ç†åƒåœ¾é‚®ä»¶çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å¯¹é‚®ä»¶è¿›è¡Œæ ‡å‡†åŒ–ã€‚åŒ…æ‹¬å…¨éƒ¨è½¬æ¢ä¸ºå°å†™å­—æ¯ã€ç§»é™¤HTMLæ ‡ç­¾ã€ä»¥åŠä¸€äº›è¡¨ç¤ºå…·ä½“å«ä¹‰çš„å†…å®¹ï¼ˆå¦‚é“¾æ¥ã€é‚®ä»¶ã€ç¬¦å·ã€æ•°å­—ç­‰ï¼‰æ›¿æ¢ä¸ºå›ºå®šçš„å­—ç¬¦ä¸²ã€‚</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯å°†é‚®ä»¶ä¸­å‡ºç°çš„å•è¯æ˜ å°„ä¸ºè¯å…¸ä¸­çš„ç´¢å¼•ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">length</span>(vocabList)</div><div class="line">  <span class="keyword">if</span>(strcmp(str, vocabList&#123;i&#125;))</div><div class="line">      word_indices = [word_indices; i];</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>åæ¥åœ¨æŸ¥çœ‹ç»ƒä¹ èµ„æ–™çš„æ—¶å€™å‘ç°ï¼Œå¯ä»¥ä½¿ç”¨<code>ismember()</code>å‡½æ•°æ¥å®ç°åŒæ ·åŠŸèƒ½ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[tf, idx] = ismember(str, vocabList);</div><div class="line"><span class="keyword">if</span>(idx)</div><div class="line">  word_indices = [word_indices; idx];</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>ç„¶åå°†é‚®ä»¶è½¬åŒ–æˆä¸€ä¸ªå‘é‡xï¼Œå¦‚æœå•è¯å‡ºç°è¿‡åˆ™è®¾ç‰¹å¾å€¼ x~i~ ä¸º1ï¼Œå¦åˆ™ä¸º0ï¼Œi ä¸ºè¯å…¸ä¸­çš„ç´¢å¼•ã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(word_indices)</div><div class="line">  x(word_indices(<span class="built_in">i</span>)) = <span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°±æ˜¯åˆ©ç”¨ä¸Šé¢å®Œæˆçš„ä¸¤ä¸ªå‡½æ•°ï¼Œé€šè¿‡SVMæ¥è¿›è¡Œé‚®ä»¶åƒåœ¾åˆ†ç±»äº†ã€‚æµ‹è¯•ä¸€ä¸‹è‡ªå·±æ”¶åˆ°è¿‡çš„åƒåœ¾é‚®ä»¶ï¼š</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/evernote.png" alt="evernote.png" title=""><p>æœç„¶æ˜¯åƒåœ¾é‚®ä»¶å‘¢ï¼š</p><img src="/2017/06/10/machine-learning-ex6/2017/06/10/machine-learning-ex6/result.png" alt="result.png" title="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ç»ˆäºæ¥åˆ°æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰äº†ï¼è¿™ä¸€ç« æˆ‘ä»¬è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨é«˜æ–¯æ ¸SVMæ¥å»ºç«‹ä¸€ä¸ªåƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ã€‚&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
